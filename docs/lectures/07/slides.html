<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.24">

  <meta name="author" content="Marcel Turcotte">
  <title>CSI 4106 - Fall 2025 – Performance Evaluation</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-534cd8e3a96973385dffff3f4709048d.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<meta property="og:title" content="Performance Evaluation – CSI 4106 - Fall 2025">
<meta property="og:description" content="CSI 4106 - Fall 2025">
<meta property="og:site_name" content="CSI 4106 - Fall 2025">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Performance Evaluation</h1>
  <p class="subtitle">CSI 4106 - Fall 2025</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Marcel Turcotte 
</div>
</div>
</div>

  <p class="date">Version: Sep 21, 2025 12:33</p>
</section>
<section>
<section id="preamble" class="title-slide slide level1 center">
<h1>Preamble</h1>

</section>
<section id="message-of-the-day" class="slide level2">
<h2>Message of the Day</h2>
<div class="columns">
<div class="column" style="width:10%;">

</div><div class="column" style="width:80%;">
<iframe data-external="1" src="https://www.youtube.com/embed/sDZ1j0J-fe8" width="1050" height="450" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div><div class="column" style="width:10%;">

</div></div>

<aside class="notes">
<p>In a recent interview with Bloomberg Technology, Demis Hassabis discussed the innovative work of Isomorphic Labs in significantly expediting drug development processes. Below is a summary of Hassabis’ notable achievements:</p>
<ul>
<li>A chess prodigy from a young age, Hassabis began playing at four years old and achieved an Elo rating of approximately 2300 by the age of 13.</li>
<li>He co-founded <a href="https://deepmind.google">DeepMind</a> in 2010 alongside Shane Legg and Mustafa Suleyman, where he currently serves as CEO.</li>
<li>Under his leadership, DeepMind has pioneered several groundbreaking advancements in artificial intelligence, including the development of <a href="https://deepmind.google/research/projects/alphago/">AlphaGo</a> and, notably, <a href="https://deepmind.google/science/alphafold/">AlphaFold and AlphaFold2</a>, which are pivotal in protein structure prediction.</li>
<li>In recognition of his contributions to protein structure prediction, Hassabis was awarded the <a href="https://www.nobelprize.org/prizes/chemistry/2024/hassabis/facts/">Nobel Prize in Chemistry in 2024</a>.</li>
<li>In 2021, he founded <a href="https://www.isomorphiclabs.com">Isomorphic Labs</a>, which concentrates on the application of AI in drug discovery and translational science.</li>
<li><a href="https://thinkinggamefilm.com">“The Thinking Game”</a> is a documentary that explores the life of Demis Hassabis, the evolution of DeepMind, and the pursuit of artificial general intelligence (AGI).</li>
</ul>
<p>In a related vein, an article titled “<a href="https://www.nature.com/articles/d41586-025-02993-x">Which diseases will you have in 20 years? This AI accurately predicts your risks</a>” was published in Nature on September 17, 2025. This brief news piece discusses Delphi-2M, a large language model designed to analyze an individual’s medical records and lifestyle factors to provide risk assessments for over 1,000 diseases. Complementing the article, a <a href="https://www.nature.com/articles/d41586-025-03026-3">podcast</a> is also available for further insights.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><a href="https://youtu.be/sDZ1j0J-fe8">Demis Hassabis: The CEO Working to Solve Cancer With AI</a>, Bloomberg Technology, 2025-09-14.</p>
</div></aside></section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<p>This lecture covers classification model evaluation, focusing on confusion matrices and key metrics: accuracy, precision, recall, and F₁ score. It addresses accuracy’s limitations in imbalanced datasets, introducing micro and macro averaging. The precision-recall trade-off and ROC analysis, including AUC, are also explored. Practical insights are provided through Python implementations like logistic regression via gradient descent.</p>
</section>
<section id="learning-outcomes" class="slide level2 smaller">
<h2>Learning Outcomes</h2>
<ul>
<li><strong>Describe</strong> the structure and role of the confusion matrix in model evaluation.</li>
<li><strong>Compute</strong> and <strong>interpret</strong> accuracy, precision, recall, and <span class="math inline">\(F_1\)</span> score.</li>
<li><strong>Identify</strong> the pitfalls of using accuracy with imbalanced datasets.</li>
<li><strong>Differentiate</strong> between micro and macro averaging for performance metrics.</li>
<li><strong>Analyze</strong> precision-recall trade-offs and <strong>construct</strong> ROC curves, including the calculation of AUC.</li>
<li><strong>Implement</strong> the calculation or ROC curves and AUC in Python.</li>
</ul>
</section></section>
<section>
<section id="performance-metrics" class="title-slide slide level1 center">
<h1>Performance Metrics</h1>

</section>
<section id="confusion-matrix" class="slide level2">
<h2>Confusion Matrix</h2>
<table class="caption-top">
<colgroup>
<col style="width: 32%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Positive</strong> (<strong>Predicted</strong>)</th>
<th><strong>Negative</strong> (<strong>Predicted</strong>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Positive</strong> (<strong>Actual</strong>)</td>
<td>True positive (TP)</td>
<td>False negative (FN)</td>
</tr>
<tr class="even">
<td><strong>Negative</strong> (<strong>Actual</strong>)</td>
<td>False positive (FP)</td>
<td>True negative (TN)</td>
</tr>
</tbody>
</table>

<aside class="notes">
<ul>
<li>In statistical analysis, <strong>False Positives (FP)</strong> are commonly referred to as <strong>Type I errors</strong>, and <strong>False Negatives (FN)</strong> are known as <strong>Type II errors</strong>.</li>
<li>The diagonal elements represent the correctly predicted outcomes, namely true positives (TP) and true negatives (TN).</li>
<li>In contrast, the off-diagonal elements correspond to incorrect predictions, specifically false positives (FP) and false negatives (FN).</li>
<li>The <strong>confusion matrix</strong> encapsulates all essential information required to assess the performance of a classification model.</li>
<li>While the confusion matrix provides a comprehensive view, more <strong>concise metrics</strong> such as <strong>accuracy</strong>, <strong>precision</strong>, <strong>recall</strong>, and the <strong>F<span class="math inline">\(_1\)</span> score</strong> are often more intuitive and practical for summarizing model performance.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>A <strong>confusion matrix</strong> is a table summarizing the performance of a classification algorithm (here for a binary classification task).</p>
</div></aside></section>
<section id="confusionmatrixdisplay" class="slide level2">
<h2>ConfusionMatrixDisplay</h2>
<div id="91e44490" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb1-3"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb1-4"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-5"><a></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-6"><a></a></span>
<span id="cb1-7"><a></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-8"><a></a></span>
<span id="cb1-9"><a></a>X, y <span class="op">=</span> make_classification(n_samples <span class="op">=</span> <span class="dv">500</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb1-10"><a></a></span>
<span id="cb1-11"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-12"><a></a></span>
<span id="cb1-13"><a></a>clf <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span>seed)</span>
<span id="cb1-14"><a></a></span>
<span id="cb1-15"><a></a>clf.fit(X_train, y_train)</span>
<span id="cb1-16"><a></a></span>
<span id="cb1-17"><a></a>predictions <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb1-18"><a></a></span>
<span id="cb1-19"><a></a>cm <span class="op">=</span> confusion_matrix(y_test, predictions, labels<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">0</span>])</span>
<span id="cb1-20"><a></a></span>
<span id="cb1-21"><a></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>[<span class="st">"Positive"</span>, <span class="st">"Negative"</span>])</span>
<span id="cb1-22"><a></a></span>
<span id="cb1-23"><a></a>disp.plot()</span>
<span id="cb1-24"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img data-src="slides_files/figure-revealjs/cell-2-output-1.png" class="quarto-figure quarto-figure-center" width="558" height="434"></a></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>We employ the <code>make_classification</code> function to generate a synthetic dataset, which are subsequently analyzed using a <code>LogisticRegression</code> model. For both <code>confusion_matrix</code> and <code>ConfusionMatrixDisplay</code>, we configure the labels to ensure that the ‘Positive’ class precedes, aligning with the tabular data presented in the previous screen. The resulting confusion matrix yields the following values: True Positives (TP) = 37, False Negatives (FN) = 10, False Positives (FP) = 3, and True Negatives (TN) = 50.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="confusion-matrix-1" class="slide level2">
<h2>Confusion Matrix</h2>
<p>Given a test set with <span class="math inline">\(N\)</span> examples and a classifier <span class="math inline">\(h(x):\)</span></p>
<p><span class="math display">\[
C_{i,j} = \sum_{k = 1}^N [y_k = i \wedge h(x_k) = j]
\]</span></p>
<p>Where <span class="math inline">\(C\)</span> is <span class="math inline">\(l \times l\)</span> matrix, for a dataset with <span class="math inline">\(l\)</span> classes.</p>

<aside class="notes">
<p>Let us now examine the general case of a confusion matrix with <span class="math inline">\(l\)</span> classes, which may initially appear “confusing” to comprehend.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>A confusion matrix <span class="math inline">\(C\)</span> is defined such that each element <span class="math inline">\(C_{i,j}\)</span> represents the count of observations actually belonging to class <span class="math inline">\(i\)</span> but predicted to belong to class <span class="math inline">\(j\)</span>.</p>
</div></aside></section>
<section id="confusion-matrix-2" class="slide level2">
<h2>Confusion Matrix</h2>
<ul>
<li><p>The total number of examples of the (actual) class <span class="math inline">\(i\)</span> is <span class="math display">\[
C_{i \cdot} = \sum_{j=1}^l C_{i,j}
\]</span></p></li>
<li><p>The total number of examples assigned to the (predicted) class <span class="math inline">\(j\)</span> by classiﬁer <span class="math inline">\(h\)</span> is <span class="math display">\[
C_{\cdot j} = \sum_{i=1}^l C_{i,j}
\]</span></p></li>
</ul>
</section>
<section id="confusion-matrix-3" class="slide level2">
<h2>Confusion Matrix</h2>
<ul>
<li><p>Terms on the diagonal denote the total number of examples classified correctly by classifier <span class="math inline">\(h\)</span>. Hence, the number of correctly classified examples is <span class="math display">\[
\sum_{i=1}^l C_{i,i}
\]</span></p></li>
<li><p>Non-diagonal terms represent misclassifications.</p></li>
</ul>
</section>
<section id="confusion-matrix---multi-class" class="slide level2">
<h2>Confusion Matrix - Multi-Class</h2>
<p>To evaluate performance in a <strong>multi-class</strong> setting, one typically derives <strong>“one-vs-all”</strong> metrics for <strong>each class</strong> from the confusion matrix. These metrics are then <strong>averaged</strong> using specific weighting schemes.</p>
</section>
<section id="confusion-matrix---multi-class-1" class="slide level2">
<h2>Confusion Matrix - Multi-Class</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/cm_multiclass-00.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img data-src="../../assets/images/cm_multiclass-00.png" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>

<aside><div>
<p>Using data from the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups">20 newsgroups text dataset</a> from <a href="https://scikit-learn.org">scikit-learn.org</a>.</p>
</div></aside></section>
<section id="confusion-matrix---true-positive" class="slide level2">
<h2>Confusion Matrix - True Positive</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/cm_multiclass-01-tp.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img data-src="../../assets/images/cm_multiclass-01-tp.png" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>

<aside><div>
<p><code>comp.graphics</code> is the <strong>true</strong> class (<span class="math inline">\(i\)</span>).</p>
</div></aside></section>
<section id="confusion-matrix---false-positive" class="slide level2">
<h2>Confusion Matrix - False Positive</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/cm_multiclass-02-fp.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img data-src="../../assets/images/cm_multiclass-02-fp.png" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>

<aside><div>
<p><code>comp.graphics</code> is the <strong>true</strong> class (<span class="math inline">\(i\)</span>).</p>
</div></aside></section>
<section id="confusion-matrix---false-negative" class="slide level2">
<h2>Confusion Matrix - False Negative</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/cm_multiclass-03-fn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img data-src="../../assets/images/cm_multiclass-03-fn.png" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>

<aside><div>
<p><code>comp.graphics</code> is the <strong>true</strong> class (<span class="math inline">\(i\)</span>).</p>
</div></aside></section>
<section id="confusion-matrix---true-negative" class="slide level2">
<h2>Confusion Matrix - True Negative</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/cm_multiclass-04-tn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img data-src="../../assets/images/cm_multiclass-04-tn.png" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>

<aside><div>
<p><code>comp.graphics</code> is the <strong>true</strong> class (<span class="math inline">\(i\)</span>).</p>
</div></aside></section>
<section id="confusion-matrix---multi-class-2" class="slide level2">
<h2>Confusion Matrix - Multi-Class</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/cm_multiclass-05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img data-src="../../assets/images/cm_multiclass-05.png" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>

<aside><div>
<p><code>comp.graphics</code> is the <strong>true</strong> class (<span class="math inline">\(i\)</span>).</p>
</div></aside></section>
<section id="multi-class" class="slide level2">
<h2>Multi-Class</h2>
<p>To evaluate performance in a multi-class setting, one typically derives “one-vs-all” metrics for each class from the confusion matrix. These metrics are then averaged using specific weighting schemes.</p>
<ul>
<li><strong>True Positives</strong> (<span class="math inline">\(\mathrm{TP}_i\)</span>): Diagonal entry <span class="math inline">\(C_{i,i}\)</span></li>
<li><strong>False Positives</strong> (<span class="math inline">\(\mathrm{FP}_i\)</span>): Sum of column <span class="math inline">\(i\)</span> excluding <span class="math inline">\(C_{i,i}\)</span></li>
<li><strong>False Negatives</strong> (<span class="math inline">\(\mathrm{FN}_i\)</span>): Sum of row <span class="math inline">\(i\)</span> excluding <span class="math inline">\(C_{i,i}\)</span></li>
<li><strong>True Negatives</strong> (<span class="math inline">\(\mathrm{TN}_i\)</span>): <span class="math inline">\(N - (\mathrm{TP}_i + \mathrm{FP}_i + \mathrm{FN}_i)\)</span></li>
</ul>
</section>
<section id="multi-class-1" class="slide level2">
<h2>Multi-Class</h2>
<p>To evaluate performance in a multi-class setting, one typically derives “one-vs-all” metrics for each class from the confusion matrix. These metrics are then averaged using specific weighting schemes.</p>
<ul>
<li><span class="math inline">\(\mathrm{TP}_i = C_{i,i}\)</span></li>
<li><span class="math inline">\(\mathrm{FP}_i = \sum_{k \ne i} C_{k,i}\)</span></li>
<li><span class="math inline">\(\mathrm{FN}_i = \sum_{k \ne i} C_{i,k}\)</span></li>
<li><span class="math inline">\(\mathrm{TN}_i = \sum_{j \ne i} \sum_{k \ne i} C_{j,k}\)</span></li>
</ul>
</section>
<section id="sklearn.metrics.confusion_matrix" class="slide level2">
<h2>sklearn.metrics.confusion_matrix</h2>
<div id="9ae9a71a" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb2-2"><a></a></span>
<span id="cb2-3"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb2-4"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb2-5"><a></a></span>
<span id="cb2-6"><a></a>confusion_matrix(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>array([[1, 2],
       [3, 4]])</code></pre>
</div>
</div>
<div class="fragment">
<div id="c3c8af36" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_actual, y_pred).ravel().tolist()</span>
<span id="cb4-2"><a></a>(tn, fp, fn, tp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(1, 2, 3, 4)</code></pre>
</div>
</div>
<aside class="notes">
<p>By default, <code>sklearn.metrics.confusion_matrix</code> determines the set of labels from the data (<span class="math inline">\(\textrm{y_true} \cup \textrm{y_pred}\)</span>), and then:</p>
<ul>
<li>It sorts them in ascending order (which for strings or mixed types corresponds to Python’s lexicographic ordering).</li>
<li>It then builds the matrix so that row <code>i</code> corresponds to the true class with label <code>labels[i]</code>, and column <code>j</code> corresponds to the predicted class with label <code>labels[j]</code>.</li>
</ul>
<p>So if you don’t pass <code>labels=...</code>, you may get a confusion matrix with class order that is not what you expect — especially if your classes are strings, or if you assume the order follows the order of appearance in the dataset.</p>
<p><strong>Example</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb6-2"><a></a></span>
<span id="cb6-3"><a></a>y_true <span class="op">=</span> [<span class="st">"dog"</span>, <span class="st">"cat"</span>, <span class="st">"cat"</span>, <span class="st">"dog"</span>]</span>
<span id="cb6-4"><a></a>y_pred <span class="op">=</span> [<span class="st">"dog"</span>, <span class="st">"dog"</span>, <span class="st">"cat"</span>, <span class="st">"cat"</span>]</span>
<span id="cb6-5"><a></a></span>
<span id="cb6-6"><a></a><span class="bu">print</span>(confusion_matrix(y_true, y_pred))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Output:</p>
<pre><code>[[1 1]
 [1 1]]</code></pre>
<p>Here the rows/columns are in lexicographic order: <code>["cat", "dog"]</code>. So the matrix is:</p>
<ul>
<li>Row 0: true = “cat”</li>
<li>Row 1: true = “dog”</li>
</ul>
<p><strong>Controlling order</strong></p>
<p>To force a specific order, you should pass the labels argument:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>confusion_matrix(y_true, y_pred, labels<span class="op">=</span>[<span class="st">"dog"</span>, <span class="st">"cat"</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This will swap the row/column order accordingly.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="perfect-prediction" class="slide level2">
<h2>Perfect Prediction</h2>
<div id="59fd2796" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb9-2"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb9-3"><a></a></span>
<span id="cb9-4"><a></a>confusion_matrix(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>array([[4, 0],
       [0, 6]])</code></pre>
</div>
</div>
<div class="fragment">
<div id="ae4910a5" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a>tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_actual, y_pred).ravel().tolist()  </span>
<span id="cb11-2"><a></a>(tn, fp, fn, tp)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(4, 0, 0, 6)</code></pre>
</div>
</div>
<aside class="notes">
<p>When an algorithm achieves perfect classification accuracy, all non-zero values in the confusion matrix appear exclusively along its diagonal.</p>
<p>All off-diagonal entries, which represent misclassifications, will be zero.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="confusion-matrix---multiple-classes" class="slide level2">
<h2>Confusion Matrix - Multiple Classes</h2>
<div id="0cfc7f3e" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb13-2"><a></a></span>
<span id="cb13-3"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-4"><a></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb13-5"><a></a></span>
<span id="cb13-6"><a></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb13-7"><a></a></span>
<span id="cb13-8"><a></a>X <span class="op">=</span> digits.data</span>
<span id="cb13-9"><a></a>y <span class="op">=</span> digits.target</span>
<span id="cb13-10"><a></a></span>
<span id="cb13-11"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb13-12"><a></a></span>
<span id="cb13-13"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-14"><a></a></span>
<span id="cb13-15"><a></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb13-16"><a></a></span>
<span id="cb13-17"><a></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb13-18"><a></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb13-19"><a></a></span>
<span id="cb13-20"><a></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb13-21"><a></a><span class="im">from</span> sklearn.multiclass <span class="im">import</span> OneVsRestClassifier</span>
<span id="cb13-22"><a></a></span>
<span id="cb13-23"><a></a>clf <span class="op">=</span> OneVsRestClassifier(LogisticRegression())</span>
<span id="cb13-24"><a></a></span>
<span id="cb13-25"><a></a>clf <span class="op">=</span> clf.fit(X_train, y_train)</span>
<span id="cb13-26"><a></a></span>
<span id="cb13-27"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-28"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb13-29"><a></a></span>
<span id="cb13-30"><a></a>X_test <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb13-31"><a></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb13-32"><a></a></span>
<span id="cb13-33"><a></a>ConfusionMatrixDisplay.from_predictions(y_test, y_pred)</span>
<span id="cb13-34"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-7-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img data-src="slides_files/figure-revealjs/cell-7-output-1.png" class="quarto-figure quarto-figure-center" width="507" height="434"></a></p>
</figure>
</div>
</div>
</div>

<aside class="notes">
<p>The image displays a heatmap of the confusion matrix for the digit classification task. This task, a multiclass classification problem, was addressed using <code>OneVsRestClassifier</code> and <code>LogisticRegression</code>.</p>
<p>The confusion matrix summarizes the predictions made on the test set, which is a subset of the data that was neither used for training nor for preprocessing with <code>StandardScaler</code>.</p>
<p>The confusion matrix encapsulates all the results from applying the classifier to the test set. However, to summarize this information more succinctly, we often refer to performance metrics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Confusion matrix</strong> for the <strong>digits example</strong> presented in the previous lecture.</p>
</div></aside></section>
<section id="visualizing-errors" class="slide level2">
<h2>Visualizing errors</h2>
<div id="77bfdc79" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>mask <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">9</span>) <span class="op">&amp;</span> (y_pred <span class="op">==</span> <span class="dv">8</span>)</span>
<span id="cb14-2"><a></a></span>
<span id="cb14-3"><a></a>X_9_as_8 <span class="op">=</span> X_test[mask]</span>
<span id="cb14-4"><a></a></span>
<span id="cb14-5"><a></a>y_9_as_8 <span class="op">=</span> y_test[mask]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="2204092c" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb15-3"><a></a></span>
<span id="cb15-4"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_digits</span>
<span id="cb15-5"><a></a>digits <span class="op">=</span> load_digits()</span>
<span id="cb15-6"><a></a></span>
<span id="cb15-7"><a></a>X <span class="op">=</span> digits.data</span>
<span id="cb15-8"><a></a>y <span class="op">=</span> digits.target</span>
<span id="cb15-9"><a></a></span>
<span id="cb15-10"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb15-11"><a></a></span>
<span id="cb15-12"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb15-13"><a></a></span>
<span id="cb15-14"><a></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb15-15"><a></a></span>
<span id="cb15-16"><a></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb15-17"><a></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb15-18"><a></a></span>
<span id="cb15-19"><a></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb15-20"><a></a><span class="im">from</span> sklearn.multiclass <span class="im">import</span> OneVsRestClassifier</span>
<span id="cb15-21"><a></a></span>
<span id="cb15-22"><a></a>clf <span class="op">=</span> OneVsRestClassifier(LogisticRegression())</span>
<span id="cb15-23"><a></a></span>
<span id="cb15-24"><a></a>clf <span class="op">=</span> clf.fit(X_train, y_train)</span>
<span id="cb15-25"><a></a></span>
<span id="cb15-26"><a></a>X_test <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb15-27"><a></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb15-28"><a></a></span>
<span id="cb15-29"><a></a>mask <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">9</span>) <span class="op">&amp;</span> (y_pred <span class="op">==</span> <span class="dv">8</span>)</span>
<span id="cb15-30"><a></a></span>
<span id="cb15-31"><a></a>X_9_as_8 <span class="op">=</span> X_test[mask]</span>
<span id="cb15-32"><a></a></span>
<span id="cb15-33"><a></a>y_9_as_8 <span class="op">=</span> y_test[mask]</span>
<span id="cb15-34"><a></a></span>
<span id="cb15-35"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-36"><a></a></span>
<span id="cb15-37"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>,<span class="dv">2</span>))</span>
<span id="cb15-38"><a></a></span>
<span id="cb15-39"><a></a><span class="cf">for</span> index, (image, label) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(X_9_as_8, y_9_as_8)):</span>
<span id="cb15-40"><a></a>    plt.subplot(<span class="dv">1</span>, <span class="bu">len</span>(X_9_as_8), index <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb15-41"><a></a>    plt.imshow(np.reshape(image, (<span class="dv">8</span>,<span class="dv">8</span>)), cmap<span class="op">=</span>plt.cm.gray)</span>
<span id="cb15-42"><a></a>    plt.title(<span class="ss">f'y = </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img data-src="slides_files/figure-revealjs/cell-9-output-1.png" class="quarto-figure quarto-figure-center" width="335" height="197"></a></p>
</figure>
</div>
</div>
</div>

<aside><div>
<p>In the confusion matrix on the previous screen, we had seen that there were examples for which the true label was 9, but the prediction was was 8. We can visualize the examples to see if we understand the nature of those errors.</p>
</div></aside></section>
<section id="confusion-matrix---multiple-classes-1" class="slide level2">
<h2>Confusion Matrix - Multiple Classes</h2>
<div id="ef3e5d8a" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img data-src="slides_files/figure-revealjs/cell-10-output-1.png" width="507" height="434"></a></p>
</figure>
</div>
</div>
</div>

<aside><div>
<p>It is often preferable to summarize the classifier’s performance with a single metric.</p>
</div></aside></section>
<section id="accuracy" class="slide level2">
<h2>Accuracy</h2>
<p>How <strong>accurate</strong> is this result?</p>
<p><span class="math display">\[
  \mathrm{accuracy} = \frac{\mathrm{TP}+\mathrm{TN}}{\mathrm{TP}+\mathrm{TN}+\mathrm{FP}+\mathrm{FN}} = \frac{\mathrm{TP}+\mathrm{TN}}{\mathrm{N}}
\]</span></p>
<div id="f2bd6d50" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb16-2"><a></a></span>
<span id="cb16-3"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb16-4"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb16-5"><a></a></span>
<span id="cb16-6"><a></a>accuracy_score(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>0.5</code></pre>
</div>
</div>

<aside><div>
<p><strong>Accuracy</strong> is the ratio of correctly predicted instances to the total number of predictions.</p>
</div></aside></section>
<section id="accuracy-1" class="slide level2">
<h2>Accuracy</h2>
<div id="20553efb" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb18-2"><a></a>y_pred   <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb18-3"><a></a></span>
<span id="cb18-4"><a></a>accuracy_score(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>0.0</code></pre>
</div>
</div>
<div id="8eadff1b" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb20-2"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb20-3"><a></a></span>
<span id="cb20-4"><a></a>accuracy_score(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>1.0</code></pre>
</div>
</div>

<aside><div>
<p><strong>Accuracy</strong> is a number between 0 (all wrong) and 1 (perfect).</p>
</div></aside></section>
<section id="accuracy-can-be-misleading" class="slide level2">
<h2>Accuracy can be misleading</h2>
<div id="8d63181d" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb22-2"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb22-3"><a></a></span>
<span id="cb22-4"><a></a>accuracy_score(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>0.8</code></pre>
</div>
</div>

<aside class="notes">
<p>Accuracy can be misleading in the context of <strong>class imbalance</strong>, as it disproportionately reflects the performance on the majority class, thereby masking poor performance on the minority class.</p>
<p>As <strong>class imbalance increases</strong>, the accuracy metric becomes <strong>increasingly misleading</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Why</strong> is it problematic?</p>
</div></aside></section>
<section id="precision" class="slide level2">
<h2>Precision</h2>
<p>AKA, <strong>positive predictive value</strong> (PPV).</p>
<p><span class="math display">\[
  \mathrm{precision} = \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}
\]</span></p>
<div id="5266e09e" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score</span>
<span id="cb24-2"><a></a></span>
<span id="cb24-3"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb24-4"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb24-5"><a></a></span>
<span id="cb24-6"><a></a>precision_score(y_actual, y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>0.6666666666666666</code></pre>
</div>
</div>

<aside class="notes">
<p>Can you think of a problem or situation where precision is paramount?</p>
<p>A classic example: <strong>medical screening for a rare but serious disease</strong>.</p>
<ul>
<li>Suppose you have a test for a disease with very low prevalence (say 1 in 10,000).</li>
<li>If your model predicts “positive” too loosely, you will generate many false positives.</li>
<li>Here, precision (the proportion of predicted positives that are actually true positives) is crucial:</li>
</ul>
<p><span class="math display">\[
\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}
\]</span></p>
<ul>
<li>A high precision means that when the test says “positive,” it is very likely correct.</li>
<li>This reduces unnecessary anxiety, costs, and follow-up procedures for patients incorrectly flagged.</li>
</ul>
<p>Other real-world settings where precision is key:</p>
<ul>
<li>Spam detection: High precision ensures that emails classified as spam are really spam (minimizing false positives that would hide real emails).</li>
<li>Legal document search / e-discovery: High precision ensures that returned documents are relevant, reducing time wasted on irrelevant results.</li>
<li>Recommender systems: High precision means that recommended items are very likely to be of interest, improving user trust.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Precision</strong> is the proportion of <strong>true positive predictions</strong> among <strong>all positive predictions</strong>.</p>
</div></aside></section>
<section id="precision-alone-is-not-enough" class="slide level2">
<h2>Precision alone is not enough</h2>
<div id="aa464525" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb26-2"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb26-3"><a></a></span>
<span id="cb26-4"><a></a>precision_score(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>1.0</code></pre>
</div>
</div>

<aside><div>
<p>An algorithm that makes a small number of high-confidence predictions might achieve a high precision score, but this may not necessarily be useful.</p>
</div></aside></section>
<section id="recall" class="slide level2">
<h2>Recall</h2>
<p>AKA <strong>sensitivity</strong> or <strong>true positive rate</strong> (TPR) <span class="math display">\[
  \mathrm{recall} = \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}
\]</span></p>
<div id="4218d43e" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb28-2"><a></a></span>
<span id="cb28-3"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb28-4"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb28-5"><a></a></span>
<span id="cb28-6"><a></a>recall_score(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>0.5714285714285714</code></pre>
</div>
</div>

<aside class="notes">
<p>Can you think of a problem or situation where recall is paramount?</p>
<p>An example where recall is the critical measure: <strong>cancer diagnosis (screening for malignant tumors)</strong>.</p>
<ul>
<li>Here, false negatives (missing an actual cancer case) are far more dangerous than false positives.</li>
<li>Recall measures the proportion of actual positives correctly identified:</li>
</ul>
<p><span class="math display">\[
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\]</span></p>
<ul>
<li>A high recall means the test finds nearly all patients with cancer, even if it also produces some false alarms.</li>
<li>Missing a true case (low recall) could mean a patient doesn’t receive treatment in time — a much more serious error than investigating a few extra false positives.</li>
</ul>
<p>Other real-world settings where recall matters most:</p>
<ul>
<li>Security / Intrusion detection: Better to flag all suspicious activity (even with false positives) than miss a real attack.</li>
<li>Search engines: For certain queries (e.g., legal precedent search, medical literature search), recall ensures you retrieve all relevant documents.</li>
<li>Emergency response systems: For natural disaster warnings, high recall ensures no real threat goes unnoticed.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Recall</strong> is the proportion of true positive instances correctly identified among all actual positive instances.</p>
</div></aside></section>
<section id="f_1-score" class="slide level2">
<h2>F<span class="math inline">\(_1\)</span> score</h2>
<p><span class="math display">\[
\begin{align*}
  F_1~\mathrm{score} &amp;= \frac{2}{\frac{1}{\mathrm{precision}}+\frac{1}{\mathrm{recall}}} = 2 \times \frac{\mathrm{precision}\times\mathrm{recall}}{\mathrm{precision}+\mathrm{recall}} \\
                     &amp;= \frac{\mathrm{TP}}{\mathrm{FP}+\frac{\mathrm{FN}+\mathrm{FP}}{2}}
\end{align*}
\]</span></p>
<div id="2f95dfd0" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb30-2"><a></a></span>
<span id="cb30-3"><a></a>y_actual <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb30-4"><a></a>y_pred   <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb30-5"><a></a></span>
<span id="cb30-6"><a></a>f1_score(y_actual,y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>0.6153846153846154</code></pre>
</div>
</div>

<aside class="notes">
<ul>
<li>The harmonic mean places greater emphasis on lower values, while the arithmetic mean treats all values equally.</li>
<li>Using the harmonic mean ensures that a high score is only achieved when both precision and recall are high, thus providing a more holistic measure of a classifier’s performance in scenarios with imbalanced datasets.</li>
<li>The F<span class="math inline">\(_1\)</span> score favors classifiers that achieve a balance between precision and recall.</li>
<li>Increasing <strong>recall</strong> often results in a decrease in <strong>precision</strong>, and vice versa. This phenomenon is known as the <strong>precision/recall trade-off</strong>.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>F<span class="math inline">\(_1\)</span></strong> is the <strong>harmonic mean</strong> of precision and recall.</p>
</div></aside></section></section>
<section>
<section id="micro-and-macro-averaging" class="title-slide slide level1 center">
<h1>Micro and Macro Averaging</h1>

</section>
<section id="definition" class="slide level2">
<h2>Definition</h2>
<p>The <strong>class imbablance problem</strong> is a scenario where the number of instances in one class significantly outnumbers the instances in other classes.</p>
<div class="fragment">
<p>Models tend to be biased towards the <strong>majority class</strong>, leading to <strong>poor performance on the minority class</strong>.</p>

</div>
<aside><div>
<p>Standard evaluation metrics like accuracy may be misleading in the presence of class imbalance.</p>
</div></aside></section>
<section id="micro-performance-metrics" class="slide level2">
<h2>Micro Performance Metrics</h2>
<ul>
<li>Micro performance metrics <strong>aggregate the contributions of all instances to compute average performance metrics</strong> like precision, recall, or F1 score.</li>
<li>This approach <strong>treats each individual prediction equally</strong>, regardless of its class, as it considers the total number of true positives, false positives, and false negatives across all classes.</li>
<li>Consequently, micro metrics are particularly <strong>sensitive to the performance on frequent classes</strong> because they are more numerous and thus have a greater influence on the overall metric.</li>
</ul>
</section>
<section id="macro-performance-metrics" class="slide level2">
<h2>Macro Performance Metrics</h2>
<ul>
<li>Macro performance metrics <strong>compute the performance metric independently for each class and then average these metrics</strong>.</li>
<li>This approach <strong>treats each class equally</strong>, regardless of its frequency, providing an evaluation that equally considers performance across both frequent and infrequent classes.</li>
<li>Consequently, macro metrics are less <strong>sensitive to the performance on frequent classes</strong>.</li>
</ul>
</section>
<section id="multi-class-2" class="slide level2">
<h2>Multi-Class</h2>
<p>When calculating <strong>precision</strong>, <strong>recall</strong>, and <span class="math inline">\(F_1\)</span>, one usually compute “one-vs-all” metrics for each class. Then, average them using weighting schemes (macro, micro).</p>
<ul>
<li><strong>True Positives</strong> (<span class="math inline">\(\mathrm{TP}_i\)</span>): Diagonal entry <span class="math inline">\(C_{i,i}\)</span></li>
<li><strong>False Positives</strong> (<span class="math inline">\(\mathrm{FP}_i\)</span>): Sum of column <span class="math inline">\(i\)</span> excluding <span class="math inline">\(C_{i,i}\)</span></li>
<li><strong>False Negatives</strong> (<span class="math inline">\(\mathrm{FN}_i\)</span>): Sum of row <span class="math inline">\(i\)</span> excluding <span class="math inline">\(C_{i,i}\)</span></li>
<li><strong>True Negatives</strong> (<span class="math inline">\(\mathrm{TN}_i\)</span>): <span class="math inline">\(N - (\mathrm{TP}_i + \mathrm{FP}_i + \mathrm{FN}_i)\)</span></li>
</ul>
</section>
<section id="multi-class-3" class="slide level2">
<h2>Multi-Class</h2>
<p>When calculating <strong>precision</strong>, <strong>recall</strong>, and <span class="math inline">\(F_1\)</span>, one usually compute “one-vs-all” metrics for each class. Then, average them using weighting schemes (macro, micro).</p>
<ul>
<li><span class="math inline">\(\mathrm{TP}_i = C_{i,i}\)</span></li>
<li><span class="math inline">\(\mathrm{FP}_i = \sum_{k \ne i} C_{k,i}\)</span></li>
<li><span class="math inline">\(\mathrm{FN}_i = \sum_{k \ne i} C_{i,k}\)</span></li>
<li><span class="math inline">\(\mathrm{TN}_i = \sum_{j \ne i} \sum_{k \ne i} C_{j,k}\)</span></li>
</ul>
</section>
<section id="micromacro-metrics" class="slide level2 smaller">
<h2>Micro/Macro Metrics</h2>
<div id="a5aaee4f" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb32-2"><a></a></span>
<span id="cb32-3"><a></a><span class="co"># Sample data</span></span>
<span id="cb32-4"><a></a>y_true <span class="op">=</span> [<span class="st">'Cat'</span>] <span class="op">*</span> <span class="dv">42</span> <span class="op">+</span> [<span class="st">'Dog'</span>] <span class="op">*</span>  <span class="dv">7</span> <span class="op">+</span> [<span class="st">'Fox'</span>] <span class="op">*</span> <span class="dv">11</span></span>
<span id="cb32-5"><a></a>y_pred <span class="op">=</span> [<span class="st">'Cat'</span>] <span class="op">*</span> <span class="dv">39</span> <span class="op">+</span> [<span class="st">'Dog'</span>] <span class="op">*</span>  <span class="dv">1</span> <span class="op">+</span> [<span class="st">'Fox'</span>] <span class="op">*</span>  <span class="dv">2</span> <span class="op">+</span> <span class="op">\</span></span>
<span id="cb32-6"><a></a>         [<span class="st">'Cat'</span>] <span class="op">*</span>  <span class="dv">4</span> <span class="op">+</span> [<span class="st">'Dog'</span>] <span class="op">*</span>  <span class="dv">3</span> <span class="op">+</span> [<span class="st">'Fox'</span>] <span class="op">*</span>  <span class="dv">0</span> <span class="op">+</span> <span class="op">\</span></span>
<span id="cb32-7"><a></a>         [<span class="st">'Cat'</span>] <span class="op">*</span>  <span class="dv">5</span> <span class="op">+</span> [<span class="st">'Dog'</span>] <span class="op">*</span>  <span class="dv">1</span> <span class="op">+</span> [<span class="st">'Fox'</span>] <span class="op">*</span>  <span class="dv">5</span></span>
<span id="cb32-8"><a></a></span>
<span id="cb32-9"><a></a>ConfusionMatrixDisplay.from_predictions(y_true, y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-19-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img data-src="slides_files/figure-revealjs/cell-19-output-1.png" width="525" height="429"></a></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>The dataset can be conceptualized as resulting from an <strong>image classification task</strong>, involving images of <strong>cats</strong>, <strong>dogs</strong>, and <strong>foxes</strong>. Reflecting common trends observed on the internet, images of cats are disproportionately represented, leading to a <strong>class imbalance</strong> issue.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="micromacro-precision" class="slide level2 scrollable">
<h2>Micro/Macro Precision</h2>
<div id="9c2f0d90" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, precision_score</span>
<span id="cb33-2"><a></a></span>
<span id="cb33-3"><a></a><span class="bu">print</span>(classification_report(y_true, y_pred), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb33-4"><a></a></span>
<span id="cb33-5"><a></a><span class="bu">print</span>(<span class="st">"Micro precision: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(precision_score(y_true, y_pred, average<span class="op">=</span><span class="st">'micro'</span>)))</span>
<span id="cb33-6"><a></a><span class="bu">print</span>(<span class="st">"Macro precision: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(precision_score(y_true, y_pred, average<span class="op">=</span><span class="st">'macro'</span>)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

         Cat       0.81      0.93      0.87        42
         Dog       0.60      0.43      0.50         7
         Fox       0.71      0.45      0.56        11

    accuracy                           0.78        60
   macro avg       0.71      0.60      0.64        60
weighted avg       0.77      0.78      0.77        60
 

Micro precision: 0.78
Macro precision: 0.71</code></pre>
</div>
</div>
</section>
<section id="micromacro-precision-1" class="slide level2 scrollable">
<h2>Micro/Macro Precision</h2>
<ul>
<li><p><strong>Macro-average precision</strong> is calculated as the mean of the <strong>precision</strong> scores<sup>1</sup> for each class: <span class="math inline">\(\frac{0.81 + 0.60 + 0.71}{3} = 0.71\)</span>.</p></li>
<li><p>Whereas, the <strong>micro-average precision</strong> is calculated using the formala, <span class="math inline">\(\frac{TP}{TP+FP}\)</span> and the <strong>data from the entire confusion matrix</strong> <span class="math inline">\(\frac{39+3+5}{39+3+5+9+2+2} = \frac{47}{60} = 0.78\)</span></p></li>
</ul>
<aside class="notes">
<p>The high micro-average precision observed here is primarily due to the high precision and large number of examples in the majority class, Cat. This masks the classifier’s relatively poor performance on the minority classes, Dog and Fox.</p>
<p>In a balanced dataset, both micro-average and macro-average metrics yield similar scores.</p>
<p>However, in an imbalanced dataset, significant disparities in classifier performance between the majority and minority classes will result in divergent micro-average and macro-average scores. Specifically, the classifier tends to underperform on the minority class(es), leading to these discrepancies.</p>
<p>In <strong>macro-average metrics</strong>, each class contributes equally to the final metric calculation, <strong>irrespective of the number of examples it contains</strong>. This means that the performance metric for each class are computed independently and then averaged, without considering the proportion of instances that each class represents in the dataset. Consequently, macro-averaging ensures that <strong>each class has an equal impact on the overall metric</strong>, which can be particularly useful in cases where the class distribution is imbalanced.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn1"><p>Therefore, macro-average precision remains unaffected by the varying number of examples across different classes.</p></li></ol></aside></section>
<section id="micromacro-recall" class="slide level2 scrollable">
<h2>Micro/Macro Recall</h2>
<div id="911892be" class="cell" data-execution_count="20">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-21-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img data-src="slides_files/figure-revealjs/cell-21-output-1.png" width="525" height="429"></a></p>
</figure>
</div>
</div>
</div>
<div id="7a6c8335" class="cell" data-execution_count="21">
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

         Cat       0.81      0.93      0.87        42
         Dog       0.60      0.43      0.50         7
         Fox       0.71      0.45      0.56        11

    accuracy                           0.78        60
   macro avg       0.71      0.60      0.64        60
weighted avg       0.77      0.78      0.77        60
 

Micro recall: 0.78
Macro recall: 0.60</code></pre>
</div>
</div>
</section>
<section id="micromacro-recall-1" class="slide level2">
<h2>Micro/Macro Recall</h2>
<ul>
<li><p><strong>Macro-average</strong> recall is calculated as the <strong>mean of the recall scores for each class</strong>: <span class="math inline">\(\frac{0.93 + 0.43 + 0.45}{3} = 0.60\)</span>.</p></li>
<li><p>Whereas, the <strong>micro-average</strong> recall is calculated using the formala, <span class="math inline">\(\frac{TP}{TP+FN}\)</span> and the <strong>data from the entire confusion matrix</strong> <span class="math inline">\(\frac{39+3+5}{39+3+5+3+4+6} = \frac{39}{60} = 0.78\)</span></p></li>
</ul>
</section>
<section id="example" class="slide level2">
<h2>Example</h2>
<p>Using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups">20 newsgroups text dataset</a> from <a href="https://scikit-learn.org">scikit-learn.org</a>.</p>
<p>Comprises around 18,000 newsgroups posts on 20 topics.</p>
<div id="3a5978db" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a></a><span class="co">## https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html</span></span>
<span id="cb36-2"><a></a></span>
<span id="cb36-3"><a></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb36-4"><a></a></span>
<span id="cb36-5"><a></a><span class="co">## Load Dataset</span></span>
<span id="cb36-6"><a></a></span>
<span id="cb36-7"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_20newsgroups</span>
<span id="cb36-8"><a></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb36-9"><a></a></span>
<span id="cb36-10"><a></a>categories <span class="op">=</span> [</span>
<span id="cb36-11"><a></a>    <span class="st">"alt.atheism"</span>,</span>
<span id="cb36-12"><a></a>    <span class="st">"talk.religion.misc"</span>,</span>
<span id="cb36-13"><a></a>    <span class="st">"comp.graphics"</span>,</span>
<span id="cb36-14"><a></a>    <span class="st">"sci.space"</span>,</span>
<span id="cb36-15"><a></a>]</span>
<span id="cb36-16"><a></a></span>
<span id="cb36-17"><a></a><span class="kw">def</span> size_mb(docs):</span>
<span id="cb36-18"><a></a>    <span class="cf">return</span> <span class="bu">sum</span>(<span class="bu">len</span>(s.encode(<span class="st">"utf-8"</span>)) <span class="cf">for</span> s <span class="kw">in</span> docs) <span class="op">/</span> <span class="fl">1e6</span></span>
<span id="cb36-19"><a></a></span>
<span id="cb36-20"><a></a><span class="kw">def</span> load_dataset(verbose<span class="op">=</span><span class="va">False</span>, remove<span class="op">=</span>()):</span>
<span id="cb36-21"><a></a>    <span class="co">"""Load and vectorize the 20 newsgroups dataset."""</span></span>
<span id="cb36-22"><a></a></span>
<span id="cb36-23"><a></a>    data_train <span class="op">=</span> fetch_20newsgroups(</span>
<span id="cb36-24"><a></a>        subset<span class="op">=</span><span class="st">"train"</span>,</span>
<span id="cb36-25"><a></a>        categories<span class="op">=</span>categories,</span>
<span id="cb36-26"><a></a>        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-27"><a></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb36-28"><a></a>        remove<span class="op">=</span>remove,</span>
<span id="cb36-29"><a></a>    )</span>
<span id="cb36-30"><a></a></span>
<span id="cb36-31"><a></a>    data_test <span class="op">=</span> fetch_20newsgroups(</span>
<span id="cb36-32"><a></a>        subset<span class="op">=</span><span class="st">"test"</span>,</span>
<span id="cb36-33"><a></a>        categories<span class="op">=</span>categories,</span>
<span id="cb36-34"><a></a>        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-35"><a></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb36-36"><a></a>        remove<span class="op">=</span>remove,</span>
<span id="cb36-37"><a></a>    )</span>
<span id="cb36-38"><a></a></span>
<span id="cb36-39"><a></a>    <span class="co"># order of labels in `target_names` can be different from `categories`</span></span>
<span id="cb36-40"><a></a>    target_names <span class="op">=</span> data_train.target_names</span>
<span id="cb36-41"><a></a></span>
<span id="cb36-42"><a></a>    <span class="co"># split target in a training set and a test set</span></span>
<span id="cb36-43"><a></a>    y_train, y_test <span class="op">=</span> data_train.target, data_test.target</span>
<span id="cb36-44"><a></a></span>
<span id="cb36-45"><a></a>    <span class="co"># Extracting features from the training data using a sparse vectorizer</span></span>
<span id="cb36-46"><a></a>    t0 <span class="op">=</span> time()</span>
<span id="cb36-47"><a></a>    vectorizer <span class="op">=</span> TfidfVectorizer(</span>
<span id="cb36-48"><a></a>        sublinear_tf<span class="op">=</span><span class="va">True</span>, max_df<span class="op">=</span><span class="fl">0.5</span>, min_df<span class="op">=</span><span class="dv">5</span>, stop_words<span class="op">=</span><span class="st">"english"</span></span>
<span id="cb36-49"><a></a>    )</span>
<span id="cb36-50"><a></a>    X_train <span class="op">=</span> vectorizer.fit_transform(data_train.data)</span>
<span id="cb36-51"><a></a>    duration_train <span class="op">=</span> time() <span class="op">-</span> t0</span>
<span id="cb36-52"><a></a></span>
<span id="cb36-53"><a></a>    <span class="co"># Extracting features from the test data using the same vectorizer</span></span>
<span id="cb36-54"><a></a>    t0 <span class="op">=</span> time()</span>
<span id="cb36-55"><a></a>    X_test <span class="op">=</span> vectorizer.transform(data_test.data)</span>
<span id="cb36-56"><a></a>    duration_test <span class="op">=</span> time() <span class="op">-</span> t0</span>
<span id="cb36-57"><a></a></span>
<span id="cb36-58"><a></a>    feature_names <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb36-59"><a></a></span>
<span id="cb36-60"><a></a>    <span class="cf">if</span> verbose:</span>
<span id="cb36-61"><a></a>        <span class="co"># compute size of loaded data</span></span>
<span id="cb36-62"><a></a>        data_train_size_mb <span class="op">=</span> size_mb(data_train.data)</span>
<span id="cb36-63"><a></a>        data_test_size_mb <span class="op">=</span> size_mb(data_test.data)</span>
<span id="cb36-64"><a></a></span>
<span id="cb36-65"><a></a>        <span class="co"># print(</span></span>
<span id="cb36-66"><a></a>        <span class="co">#     f"{len(data_train.data)} documents - "</span></span>
<span id="cb36-67"><a></a>        <span class="co">#     f"{data_train_size_mb:.2f}MB (training set)"</span></span>
<span id="cb36-68"><a></a>        <span class="co"># )</span></span>
<span id="cb36-69"><a></a>        <span class="co"># print(f"{len(data_test.data)} documents - {data_test_size_mb:.2f}MB (test set)")</span></span>
<span id="cb36-70"><a></a>        <span class="co"># print(f"{len(target_names)} categories")</span></span>
<span id="cb36-71"><a></a>        <span class="co"># print(</span></span>
<span id="cb36-72"><a></a>        <span class="co">#     f"vectorize training done in {duration_train:.3f}s "</span></span>
<span id="cb36-73"><a></a>        <span class="co">#     f"at {data_train_size_mb / duration_train:.3f}MB/s"</span></span>
<span id="cb36-74"><a></a>        <span class="co"># )</span></span>
<span id="cb36-75"><a></a>        <span class="co"># print(f"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}")</span></span>
<span id="cb36-76"><a></a>        <span class="co"># print(</span></span>
<span id="cb36-77"><a></a>        <span class="co">#     f"vectorize testing done in {duration_test:.3f}s "</span></span>
<span id="cb36-78"><a></a>        <span class="co">#     f"at {data_test_size_mb / duration_test:.3f}MB/s"</span></span>
<span id="cb36-79"><a></a>        <span class="co"># )</span></span>
<span id="cb36-80"><a></a>        <span class="co"># print(f"n_samples: {X_test.shape[0]}, n_features: {X_test.shape[1]}")</span></span>
<span id="cb36-81"><a></a></span>
<span id="cb36-82"><a></a>    <span class="cf">return</span> X_train, X_test, y_train, y_test, feature_names, target_names</span>
<span id="cb36-83"><a></a></span>
<span id="cb36-84"><a></a>X_train, X_test, y_train, y_test, feature_names, target_names <span class="op">=</span> load_dataset(</span>
<span id="cb36-85"><a></a>    verbose<span class="op">=</span><span class="va">True</span></span>
<span id="cb36-86"><a></a>)</span>
<span id="cb36-87"><a></a></span>
<span id="cb36-88"><a></a><span class="co">## Training and Prediction</span></span>
<span id="cb36-89"><a></a></span>
<span id="cb36-90"><a></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> RidgeClassifier</span>
<span id="cb36-91"><a></a></span>
<span id="cb36-92"><a></a>clf <span class="op">=</span> RidgeClassifier(tol<span class="op">=</span><span class="fl">1e-2</span>, solver<span class="op">=</span><span class="st">"sparse_cg"</span>)</span>
<span id="cb36-93"><a></a>clf.fit(X_train, y_train)</span>
<span id="cb36-94"><a></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb36-95"><a></a></span>
<span id="cb36-96"><a></a><span class="co">## Display the Confusion Matrix</span></span>
<span id="cb36-97"><a></a></span>
<span id="cb36-98"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb36-99"><a></a></span>
<span id="cb36-100"><a></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb36-101"><a></a>ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax<span class="op">=</span>ax)</span>
<span id="cb36-102"><a></a>ax.xaxis.set_ticklabels(target_names)</span>
<span id="cb36-103"><a></a>ax.yaxis.set_ticklabels(target_names)</span>
<span id="cb36-104"><a></a>_ <span class="op">=</span> ax.set_title(</span>
<span id="cb36-105"><a></a>    <span class="ss">f"Confusion Matrix for </span><span class="sc">{</span>clf<span class="sc">.</span><span class="va">__class__</span><span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">"</span></span>
<span id="cb36-106"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>

</section>
<section id="example-output" class="slide level2 output-location-slide"><h2>Example</h2><div class="cell output-location-slide" data-execution_count="22">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-23-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img data-src="slides_files/figure-revealjs/cell-23-output-1.png" width="621" height="449"></a></p>
</figure>
</div>
</div>
</div></section><section id="example-1" class="slide level2">
<h2>Example</h2>
<div id="67d9ecaa" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a></a>cm <span class="op">=</span> confusion_matrix(y_test, y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="tp-fp-fn-tn" class="slide level2">
<h2>TP, FP, FN, TN</h2>
<div id="14c8a97a" class="cell" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a></a><span class="kw">def</span> true_positive(cm, i):</span>
<span id="cb38-2"><a></a>    <span class="cf">return</span> cm[i,i] <span class="co"># diagonal entry i,i</span></span>
<span id="cb38-3"><a></a></span>
<span id="cb38-4"><a></a><span class="kw">def</span> false_positive(cm, i):</span>
<span id="cb38-5"><a></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(cm[:, i]) <span class="op">-</span> cm[i,i] <span class="co"># col - TP_i</span></span>
<span id="cb38-6"><a></a></span>
<span id="cb38-7"><a></a><span class="kw">def</span> false_negative(cm, i):</span>
<span id="cb38-8"><a></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(cm[i, :]) <span class="op">-</span> cm[i,i] <span class="co"># row - TP_i</span></span>
<span id="cb38-9"><a></a></span>
<span id="cb38-10"><a></a><span class="kw">def</span> true_negative(cm, i):</span>
<span id="cb38-11"><a></a>  N <span class="op">=</span> cm.<span class="bu">sum</span>()</span>
<span id="cb38-12"><a></a>  TP <span class="op">=</span> true_positive(cm, i)</span>
<span id="cb38-13"><a></a>  FP <span class="op">=</span> false_positive(cm, i)</span>
<span id="cb38-14"><a></a>  FN <span class="op">=</span> false_negative(cm, i)</span>
<span id="cb38-15"><a></a>  <span class="cf">return</span> N <span class="op">-</span> (TP <span class="op">+</span> FP <span class="op">+</span> FN)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="precision-1" class="slide level2">
<h2>Precision</h2>
<div id="56005969" class="cell" data-execution_count="25">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a></a><span class="kw">def</span> precision_micro(cm):</span>
<span id="cb39-2"><a></a>    _, l <span class="op">=</span> cm.shape</span>
<span id="cb39-3"><a></a>    tp <span class="op">=</span> fp <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-4"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(l):</span>
<span id="cb39-5"><a></a>        tp <span class="op">+=</span> true_positive(cm, i)</span>
<span id="cb39-6"><a></a>        fp <span class="op">+=</span> false_positive(cm, i)</span>
<span id="cb39-7"><a></a>    <span class="cf">return</span> tp <span class="op">/</span> (tp<span class="op">+</span>fp)</span>
<span id="cb39-8"><a></a></span>
<span id="cb39-9"><a></a><span class="kw">def</span> precision_macro(cm):</span>
<span id="cb39-10"><a></a>    _, l <span class="op">=</span> cm.shape</span>
<span id="cb39-11"><a></a>    precision <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-12"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(l):</span>
<span id="cb39-13"><a></a>        tp <span class="op">=</span> true_positive(cm, i)</span>
<span id="cb39-14"><a></a>        fp <span class="op">=</span> false_positive(cm, i)</span>
<span id="cb39-15"><a></a>        precision <span class="op">+=</span> tp<span class="op">/</span>(tp<span class="op">+</span>fp)</span>
<span id="cb39-16"><a></a>    <span class="cf">return</span> precision<span class="op">/</span>l</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="precision-micro-average" class="slide level2">
<h2>Precision Micro Average</h2>
<p><span class="math display">\[
  \frac{(258+380+371+199)}{(258+380+371+199)+(40+38+22+45)}
\]</span> where</p>
<ul>
<li>40 = 2 + 1 + 37</li>
<li>38 = 7 + 22 + 9</li>
<li>22 = 12 + 4 + 6</li>
<li>45 = 42 + 3 + 0</li>
</ul>

<aside><div>
<p>89.28307465 %</p>
</div></aside></section>
<section id="precision-macro-average" class="slide level2">
<h2>Precision Macro Average</h2>
<ul>
<li><span class="math inline">\(\mathrm{Precision}_0 = \frac{258}{258+(2+1+37)} = 0.8657718121\)</span></li>
<li><span class="math inline">\(\mathrm{Precision}_1 = \frac{380}{380+(7+22+9)} = 0.9090909091\)</span></li>
<li><span class="math inline">\(\mathrm{Precision}_2 = \frac{371}{371+(12+4+6)} = 0.9440203562\)</span></li>
<li><span class="math inline">\(\mathrm{Precision}_3 = \frac{199}{199+(42+3+0)} = 0.8155737705\)</span></li>
</ul>
<p><span class="math inline">\(\mathrm{Precision}_3 = \frac{0.8657718121 + 0.9090909091 + 0.9440203562 + 0.8155737705}{4}\)</span></p>

<aside><div>
<p>88.3614212 %</p>
</div></aside></section>
<section id="recall-1" class="slide level2">
<h2>Recall</h2>
<div id="4eb517aa" class="cell" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a></a><span class="kw">def</span> recall_micro(cm):</span>
<span id="cb40-2"><a></a>    _, l <span class="op">=</span> cm.shape</span>
<span id="cb40-3"><a></a>    tp <span class="op">=</span> fn <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb40-4"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(l):</span>
<span id="cb40-5"><a></a>        tp <span class="op">+=</span> true_positive(cm, i)</span>
<span id="cb40-6"><a></a>        fn <span class="op">+=</span> false_negative(cm, i)</span>
<span id="cb40-7"><a></a>    <span class="cf">return</span> tp <span class="op">/</span> (tp<span class="op">+</span>fn)</span>
<span id="cb40-8"><a></a></span>
<span id="cb40-9"><a></a><span class="kw">def</span> recall_macro(cm):</span>
<span id="cb40-10"><a></a>    _, l <span class="op">=</span> cm.shape</span>
<span id="cb40-11"><a></a>    recall <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb40-12"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(l):</span>
<span id="cb40-13"><a></a>        tp <span class="op">=</span> true_positive(cm, i)</span>
<span id="cb40-14"><a></a>        fn <span class="op">=</span> false_negative(cm, i)</span>
<span id="cb40-15"><a></a>        recall <span class="op">+=</span> tp <span class="op">/</span> (tp<span class="op">+</span>fn)</span>
<span id="cb40-16"><a></a>    <span class="cf">return</span> recall<span class="op">/</span>l</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="micromacro-metrics-medical-data" class="slide level2 smaller">
<h2>Micro/Macro Metrics (Medical Data)</h2>
<div id="4e091849" class="cell" data-execution_count="27">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-28-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img data-src="slides_files/figure-revealjs/cell-28-output-1.png" width="557" height="429"></a></p>
</figure>
</div>
</div>
</div>
<div class="asside">
<p>Consider a medical dataset, such as those involving diagnostic tests or imaging, comprising 990 normal samples and 10 abnormal (tumor) samples. This represents the ground truth.</p>
</div>
</section>
<section id="micromacro-metrics-medical-data-1" class="slide level2">
<h2>Micro/macro metrics (medical data)</h2>
<div id="61910102" class="cell" data-execution_count="28">
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

      Normal       1.00      0.99      1.00       990
      Tumour       0.55      0.60      0.57        10

    accuracy                           0.99      1000
   macro avg       0.77      0.80      0.78      1000
weighted avg       0.99      0.99      0.99      1000
 

Micro precision: 0.99
Macro precision: 0.77


Micro recall: 0.99
Macro recall: 0.80</code></pre>
</div>
</div>

<aside><div>
<p>The precision for the <code>Tumour</code> class is low. However, due to the small sample size, this does not significantly impact the micro-averaged precision.</p>
</div></aside></section></section>
<section>
<section id="precision-recall-trade-off" class="title-slide slide level1 center">
<h1>Precision-Recall Trade-Off</h1>

</section>
<section id="hand-written-digits-revisited" class="slide level2 smaller">
<h2>Hand-Written Digits (Revisited)</h2>
<p>Loading the dataset</p>
<div id="6e9cb98f" class="cell" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb42-2"><a></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb42-3"><a></a></span>
<span id="cb42-4"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb42-5"><a></a></span>
<span id="cb42-6"><a></a>digits <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, as_frame<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb42-7"><a></a>X, y <span class="op">=</span> digits.data, digits.target</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Plotting the first five examples</p>
<div id="146de381" class="cell" data-execution_count="30">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-31-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img data-src="slides_files/figure-revealjs/cell-31-output-1.png" width="790" height="190"></a></p>
</figure>
</div>
</div>
</div>
<p>These images have dimensions of <span class="math inline">\(28 \times 28\)</span> pixels.</p>
</section>
<section id="creating-a-binary-classification-task" class="slide level2">
<h2>Creating a Binary Classification Task</h2>
<div id="12abcabe" class="cell" data-execution_count="31">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a></a><span class="co"># Creating a binary classification task (one vs the rest)</span></span>
<span id="cb43-2"><a></a></span>
<span id="cb43-3"><a></a>some_digit <span class="op">=</span> X[<span class="dv">0</span>]</span>
<span id="cb43-4"><a></a>some_digit_y <span class="op">=</span> y[<span class="dv">0</span>]</span>
<span id="cb43-5"><a></a></span>
<span id="cb43-6"><a></a>y <span class="op">=</span> (y <span class="op">==</span> some_digit_y)</span>
<span id="cb43-7"><a></a>y</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>array([ True, False, False, ..., False,  True, False], shape=(70000,))</code></pre>
</div>
</div>
<div class="fragment">
<div id="59628613" class="cell" data-execution_count="32">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a></a><span class="co"># Creating the training and test sets</span></span>
<span id="cb45-2"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb45-3"><a></a></span>
<span id="cb45-4"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="sgdclassifier" class="slide level2">
<h2><code>SGDClassifier</code></h2>
<div id="80ef872c" class="cell" data-execution_count="33">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier</span>
<span id="cb46-2"><a></a></span>
<span id="cb46-3"><a></a>clf <span class="op">=</span> SGDClassifier()</span>
<span id="cb46-4"><a></a>clf.fit(X_train, y_train)</span>
<span id="cb46-5"><a></a></span>
<span id="cb46-6"><a></a>clf.predict(X[<span class="dv">0</span>:<span class="dv">5</span>]) <span class="co"># small sanity check</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>array([ True, False, False, False, False])</code></pre>
</div>
</div>

<aside><div>
<p>The <code>SGDClassifier</code> is a linear classifier that utilizes stochastic gradient descent (SGD) for training. Compared to <code>LogisticRegression</code>, it can offer faster training times, particularly for large datasets. Additionally, <code>SGDClassifier</code> allows for the adjustment of the decision threshold in subsequent examples.</p>
</div></aside></section>
<section id="performance" class="slide level2">
<h2>Performance</h2>
<div id="11a7efea" class="cell" data-execution_count="34">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb48-2"><a></a></span>
<span id="cb48-3"><a></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb48-4"><a></a></span>
<span id="cb48-5"><a></a>accuracy_score(y_test, y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>0.9572857142857143</code></pre>
</div>
</div>
<p>Wow!</p>
</section>
<section id="not-so-fast" class="slide level2">
<h2>Not so Fast</h2>
<div id="ca02af05" class="cell" data-execution_count="35">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a></a><span class="im">from</span> sklearn.dummy <span class="im">import</span> DummyClassifier</span>
<span id="cb50-2"><a></a></span>
<span id="cb50-3"><a></a>dummy_clf <span class="op">=</span> DummyClassifier()</span>
<span id="cb50-4"><a></a></span>
<span id="cb50-5"><a></a>dummy_clf.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="fragment">
<div id="b43f99d7" class="cell" data-execution_count="36">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a></a>y_pred <span class="op">=</span> dummy_clf.predict(X_test)</span>
<span id="cb51-2"><a></a></span>
<span id="cb51-3"><a></a>accuracy_score(y_test, y_pred)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>0.906</code></pre>
</div>
</div>

<aside class="notes">
<p>Why is the accuracy so high despite this classifier ignoring the input data?</p>
<p>The high accuracy is attributed to the class distribution within the dataset. Approximately 10% of the samples correspond to the digit ‘5’, which is the positive class in our binary classification task. Consequently, about 90% of the samples are ‘not 5’ and belong to the negative class. Since the DummyClassifier always predicts the majority class, its accuracy is expected to be around 90%.</p>
<p>This underscores the point that accuracy is often not the best metric, particularly when dealing with imbalanced datasets.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<aside><div>
<p>The <a href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html">DummyClassifier</a> in scikit-learn generates predictions without considering the input features. By default, it consistently predicts the most frequent class label in the training data. It is a simple baseline classifier.</p>
</div></aside></section>
<section id="precision-recall-trade-off-1" class="slide level2">
<h2>Precision-Recall Trade-Off</h2>
<p><a href="../../assets/images/geron_2022-f3_4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img data-src="../../assets/images/geron_2022-f3_4.png"></a></p>

<aside><div>
<p><strong>Attribution</strong>: <span class="citation" data-cites="Geron:2022aa">Géron (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span> Figure 3.4</p>
</div></aside></section>
<section id="precision-recall-trade-off-2" class="slide level2">
<h2>Precision-Recall Trade-Off</h2>
<div id="662d554e" class="cell" data-execution_count="37">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_predict</span>
<span id="cb53-2"><a></a>y_scores <span class="op">=</span> cross_val_predict(clf, X_train, y_train, cv<span class="op">=</span><span class="dv">3</span>, method<span class="op">=</span><span class="st">"decision_function"</span>)</span>
<span id="cb53-3"><a></a></span>
<span id="cb53-4"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_curve</span>
<span id="cb53-5"><a></a></span>
<span id="cb53-6"><a></a>precisions, recalls, thresholds <span class="op">=</span> precision_recall_curve(y_train, y_scores)</span>
<span id="cb53-7"><a></a></span>
<span id="cb53-8"><a></a>threshold <span class="op">=</span> <span class="dv">3000</span></span>
<span id="cb53-9"><a></a></span>
<span id="cb53-10"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))  <span class="co"># extra code – it's not needed, just formatting</span></span>
<span id="cb53-11"><a></a>plt.plot(thresholds, precisions[:<span class="op">-</span><span class="dv">1</span>], <span class="st">"b--"</span>, label<span class="op">=</span><span class="st">"Precision"</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb53-12"><a></a>plt.plot(thresholds, recalls[:<span class="op">-</span><span class="dv">1</span>], <span class="st">"g-"</span>, label<span class="op">=</span><span class="st">"Recall"</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb53-13"><a></a>plt.vlines(threshold, <span class="dv">0</span>, <span class="fl">1.0</span>, <span class="st">"k"</span>, <span class="st">"dotted"</span>, label<span class="op">=</span><span class="st">"threshold"</span>)</span>
<span id="cb53-14"><a></a></span>
<span id="cb53-15"><a></a><span class="co"># extra code – this section just beautifies and saves Figure 3–5</span></span>
<span id="cb53-16"><a></a>idx <span class="op">=</span> (thresholds <span class="op">&gt;=</span> threshold).argmax()  <span class="co"># first index ≥ threshold</span></span>
<span id="cb53-17"><a></a>plt.plot(thresholds[idx], precisions[idx], <span class="st">"bo"</span>)</span>
<span id="cb53-18"><a></a>plt.plot(thresholds[idx], recalls[idx], <span class="st">"go"</span>)</span>
<span id="cb53-19"><a></a>plt.axis([<span class="op">-</span><span class="dv">50000</span>, <span class="dv">50000</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb53-20"><a></a>plt.grid()</span>
<span id="cb53-21"><a></a>plt.xlabel(<span class="st">"Threshold"</span>)</span>
<span id="cb53-22"><a></a>plt.legend(loc<span class="op">=</span><span class="st">"center right"</span>)</span>
<span id="cb53-23"><a></a></span>
<span id="cb53-24"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-38-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img data-src="slides_files/figure-revealjs/cell-38-output-1.png" class="quarto-figure quarto-figure-center" width="645" height="361"></a></p>
</figure>
</div>
</div>
</div>

<aside class="notes">
<p>As the decision threshold decreases, a higher number of examples are predicted as positive, potentially leading the classifier to eventually label all instances as positive.</p>
<p>Conversely, as the decision threshold increases, fewer examples are classified as positive, which may result in the classifier predicting no positive instances at all.</p>
<p>For certain applications, a classifier with high precision is essential. For example, consider a scenario where each prediction necessitates a costly laboratory experiment to verify its accuracy, such as in a pharmaceutical company aiming to discover new drugs. Here, the classifier predicts whether a compound is active. Given the high cost of experiments to validate candidates, the company would prioritize focusing on the most promising compounds first.</p>
<p>In contrast, consider a scenario involving cancer screening, such as using mammograms to detect breast cancer. In this case, it may be preferable to lower the decision threshold, thereby increasing the number of false-positive predictions. Although this approach results in more patients undergoing additional tests, such as biopsies, it can potentially save more lives by ensuring that fewer cases of cancer go undetected.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><code>SGDClassifier</code> is used because it allows to vary the decision treshold (boundary) to produce a plot illustrating the precision-recall tradeoff. <span class="citation" data-cites="Geron:2022aa">(<a href="#/references" role="doc-biblioref" onclick="">Géron 2022</a>)</span> <a href="https://github.com/ageron/handson-ml3/blob/main/03_classification.ipynb"><code>03_classification.ipynb</code></a>.</p>
</div></aside></section>
<section id="precisionrecall-curve" class="slide level2">
<h2>Precision/Recall Curve</h2>
<div id="922a5071" class="cell" data-execution_count="38">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> patches  <span class="co"># extra code – for the curved arrow</span></span>
<span id="cb54-2"><a></a></span>
<span id="cb54-3"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))  <span class="co"># extra code – not needed, just formatting</span></span>
<span id="cb54-4"><a></a></span>
<span id="cb54-5"><a></a>plt.plot(recalls, precisions, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"Precision/Recall Curve"</span>)</span>
<span id="cb54-6"><a></a></span>
<span id="cb54-7"><a></a><span class="co"># extra code – just beautifies and saves Figure 3–6</span></span>
<span id="cb54-8"><a></a>plt.plot([recalls[idx], recalls[idx]], [<span class="fl">0.</span>, precisions[idx]], <span class="st">"k:"</span>)</span>
<span id="cb54-9"><a></a>plt.plot([<span class="fl">0.0</span>, recalls[idx]], [precisions[idx], precisions[idx]], <span class="st">"k:"</span>)</span>
<span id="cb54-10"><a></a>plt.plot([recalls[idx]], [precisions[idx]], <span class="st">"ko"</span>,</span>
<span id="cb54-11"><a></a>         label<span class="op">=</span><span class="st">"Point at threshold 3,000"</span>)</span>
<span id="cb54-12"><a></a>plt.gca().add_patch(patches.FancyArrowPatch(</span>
<span id="cb54-13"><a></a>    (<span class="fl">0.79</span>, <span class="fl">0.60</span>), (<span class="fl">0.61</span>, <span class="fl">0.78</span>),</span>
<span id="cb54-14"><a></a>    connectionstyle<span class="op">=</span><span class="st">"arc3,rad=.2"</span>,</span>
<span id="cb54-15"><a></a>    arrowstyle<span class="op">=</span><span class="st">"Simple, tail_width=1.5, head_width=8, head_length=10"</span>,</span>
<span id="cb54-16"><a></a>    color<span class="op">=</span><span class="st">"#444444"</span>))</span>
<span id="cb54-17"><a></a>plt.text(<span class="fl">0.56</span>, <span class="fl">0.62</span>, <span class="st">"Higher</span><span class="ch">\n</span><span class="st">threshold"</span>, color<span class="op">=</span><span class="st">"#333333"</span>)</span>
<span id="cb54-18"><a></a>plt.xlabel(<span class="st">"Recall"</span>)</span>
<span id="cb54-19"><a></a>plt.ylabel(<span class="st">"Precision"</span>)</span>
<span id="cb54-20"><a></a>plt.axis([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb54-21"><a></a>plt.grid()</span>
<span id="cb54-22"><a></a>plt.legend(loc<span class="op">=</span><span class="st">"lower left"</span>)</span>
<span id="cb54-23"><a></a></span>
<span id="cb54-24"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-39-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img data-src="slides_files/figure-revealjs/cell-39-output-1.png" class="quarto-figure quarto-figure-center" width="451" height="434"></a></p>
</figure>
</div>
</div>
</div>

<aside><div>
<p><span class="citation" data-cites="Geron:2022aa">(<a href="#/references" role="doc-biblioref" onclick="">Géron 2022</a>)</span> <a href="https://github.com/ageron/handson-ml3/blob/main/03_classification.ipynb"><code>03_classification.ipynb</code></a>.</p>
</div></aside></section></section>
<section>
<section id="roc-curve" class="title-slide slide level1 center">
<h1>ROC Curve</h1>

</section>
<section id="roc-curve-1" class="slide level2">
<h2>ROC Curve</h2>
<p><strong>Receiver Operating Characteristics (ROC) curve</strong></p>
<ul>
<li class="fragment"><strong>True positive rate</strong> (TPR) against <strong>false positive rate</strong> (FPR)</li>
<li class="fragment">An ideal classifier has <strong>TPR</strong> close to <strong>1.0</strong> and <strong>FPR</strong> close to <strong>0.0</strong></li>
<li class="fragment"><span class="math inline">\(\mathrm{TPR} = \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}\)</span> (recall, sensitivity)</li>
<li class="fragment"><strong>TPR</strong> approaches <strong>one</strong> when the number of <strong>false negative</strong> predictions is low</li>
<li class="fragment"><span class="math inline">\(\mathrm{FPR} = \frac{\mathrm{FP}}{\mathrm{FP}+\mathrm{TN}}\)</span> (aka~[1-specificity])</li>
<li class="fragment"><strong>FPR</strong> approaches <strong>zero</strong> when the number of <strong>false positive</strong> is low</li>
</ul>
<aside class="notes">
<p>ROC (Receiver Operating Characteristic) curves are popular in machine learning and statistics for several reasons:</p>
<ol type="1">
<li><strong>Comprehensive Performance Evaluation</strong>: ROC curves provide a visual representation of a classifier’s performance across all possible thresholds. By plotting the True Positive Rate (TPR) against the False Positive Rate (FPR), it allows practitioners to evaluate the trade-off between sensitivity (recall) and specificity.</li>
<li><strong>Threshold Independence</strong>: Unlike metrics like accuracy, ROC curves evaluate classifier performance without relying on a specific decision threshold. This makes them particularly useful in comparing models across varying thresholds.</li>
<li><strong>Area Under the Curve (AUC)</strong>: The Area Under the ROC Curve (AUC) provides a single value summary of the model’s performance. AUC-ROC is often used as a benchmark metric to compare different models, with values ranging from 0.5 (random guessing) to 1.0 (perfect classification).</li>
<li><strong>Broad Applicability</strong>: ROC curves can be used for any binary classification task and are easily extended to multiclass problems using techniques like one-vs-rest classification, making them versatile in evaluating classifiers.</li>
</ol>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="roc-curve-2" class="slide level2">
<h2>ROC Curve</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/tpr_fpr.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img data-src="../../assets/images/tpr_fpr.png" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>
</section>
<section id="roc-curve-3" class="slide level2">
<h2>ROC Curve</h2>
<div id="0f0416a2" class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a></a>idx_for_90_precision <span class="op">=</span> (precisions <span class="op">&gt;=</span> <span class="fl">0.90</span>).argmax()</span>
<span id="cb55-2"><a></a>threshold_for_90_precision <span class="op">=</span> thresholds[idx_for_90_precision]</span>
<span id="cb55-3"><a></a>y_train_pred_90 <span class="op">=</span> (y_scores <span class="op">&gt;=</span> threshold_for_90_precision)</span>
<span id="cb55-4"><a></a></span>
<span id="cb55-5"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve</span>
<span id="cb55-6"><a></a></span>
<span id="cb55-7"><a></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_train, y_scores)</span>
<span id="cb55-8"><a></a></span>
<span id="cb55-9"><a></a>idx_for_threshold_at_90 <span class="op">=</span> (thresholds <span class="op">&lt;=</span> threshold_for_90_precision).argmax()</span>
<span id="cb55-10"><a></a>tpr_90, fpr_90 <span class="op">=</span> tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]</span>
<span id="cb55-11"><a></a></span>
<span id="cb55-12"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))  <span class="co"># extra code – not needed, just formatting</span></span>
<span id="cb55-13"><a></a>plt.plot(fpr, tpr, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">"ROC curve"</span>)</span>
<span id="cb55-14"><a></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k:'</span>, label<span class="op">=</span><span class="st">"Random classifier's ROC curve"</span>)</span>
<span id="cb55-15"><a></a>plt.plot([fpr_90], [tpr_90], <span class="st">"ko"</span>, label<span class="op">=</span><span class="st">"Threshold for 90% precision"</span>)</span>
<span id="cb55-16"><a></a></span>
<span id="cb55-17"><a></a><span class="co"># extra code – just beautifies and saves Figure 3–7</span></span>
<span id="cb55-18"><a></a>plt.gca().add_patch(patches.FancyArrowPatch(</span>
<span id="cb55-19"><a></a>    (<span class="fl">0.20</span>, <span class="fl">0.89</span>), (<span class="fl">0.07</span>, <span class="fl">0.70</span>),</span>
<span id="cb55-20"><a></a>    connectionstyle<span class="op">=</span><span class="st">"arc3,rad=.4"</span>,</span>
<span id="cb55-21"><a></a>    arrowstyle<span class="op">=</span><span class="st">"Simple, tail_width=1.5, head_width=8, head_length=10"</span>,</span>
<span id="cb55-22"><a></a>    color<span class="op">=</span><span class="st">"#444444"</span>))</span>
<span id="cb55-23"><a></a>plt.text(<span class="fl">0.12</span>, <span class="fl">0.71</span>, <span class="st">"Higher</span><span class="ch">\n</span><span class="st">threshold"</span>, color<span class="op">=</span><span class="st">"#333333"</span>)</span>
<span id="cb55-24"><a></a>plt.xlabel(<span class="st">'False Positive Rate (Fall-Out)'</span>)</span>
<span id="cb55-25"><a></a>plt.ylabel(<span class="st">'True Positive Rate (Recall)'</span>)</span>
<span id="cb55-26"><a></a>plt.grid()</span>
<span id="cb55-27"><a></a>plt.axis([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb55-28"><a></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>, fontsize<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb55-29"><a></a></span>
<span id="cb55-30"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-40-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img data-src="slides_files/figure-revealjs/cell-40-output-1.png" class="quarto-figure quarto-figure-center" width="451" height="434"></a></p>
</figure>
</div>
</div>
</div>

<aside class="notes">
<p>It is common to measure the area under the curve, represented as AUC. Specifically, the area under the ROC curve. This allows to compare</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Attribution:</strong> <a href="https://github.com/ageron/handson-ml3/blob/main/03_classification.ipynb">03_classification.ipynb</a></p>
</div></aside></section>
<section id="dataset---openml" class="slide level2 scrollable">
<h2>Dataset - openml</h2>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong><i class="fa-solid fa-quote-right" aria-label="quote-right"></i> <a href="https://www.openml.org">www.openml.org</a></strong></p>
</div>
<div class="callout-content">
<p>OpenML is an open platform for sharing datasets, algorithms, and experiments - to learn how to learn better, together.</p>
</div>
</div>
</div>
<div class="fragment">
<div id="7409b175" class="cell" data-execution_count="40">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb56-2"><a></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb56-3"><a></a></span>
<span id="cb56-4"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb56-5"><a></a></span>
<span id="cb56-6"><a></a>diabetes <span class="op">=</span> fetch_openml(name<span class="op">=</span><span class="st">'diabetes'</span>, version<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb56-7"><a></a><span class="bu">print</span>(diabetes.DESCR)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

<aside class="notes">
<p>Today’s dataset is the PIMA dataset, which contains 768 instances and 8 numerical attributes. The numerical nature of these attributes facilitates our analysis. Additionally, since the data originates from a published paper, it likely reflects careful data collection, potentially leading to robust results, as the authors would have needed high-quality data to support their publication.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="dataset---openml-output" class="slide level2 scrollable output-location-slide"><h2>Dataset - openml</h2><div class="cell output-location-slide" data-execution_count="40">
<p><strong>Author</strong>: <a href="vgs@aplcen.apl.jhu.edu">Vincent Sigillito</a></p>
<p><strong>Source</strong>: <a href="https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes">Obtained from UCI</a></p>
<p><strong>Please cite</strong>: <a href="https://archive.ics.uci.edu/ml/citation_policy.html">UCI citation policy</a></p>
<ol type="1">
<li><p>Title: Pima Indians Diabetes Database</p></li>
<li><p>Sources:</p>
<ol type="a">
<li>Original owners: National Institute of Diabetes and Digestive and Kidney Diseases</li>
<li>Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu) Research Center, RMI Group Leader Applied Physics Laboratory The Johns Hopkins University Johns Hopkins Road Laurel, MD 20707 (301) 953-6231</li>
<li>Date received: 9 May 1990</li>
</ol></li>
<li><p>Past Usage:</p>
<ol type="1">
<li><p>Smith,<sub>J.</sub>W., Everhart,<sub>J.</sub>E., Dickson,<sub>W.</sub>C., Knowler,<sub>W.</sub>C., &amp; Johannes,<sub>R.</sub>S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In {it Proceedings of the Symposium on Computer Applications and Medical Care} (pp.&nbsp;261–265). IEEE Computer Society Press.</p>
<p>The diagnostic, binary-valued variable investigated is whether the patient shows signs of diabetes according to World Health Organization criteria (i.e., if the 2 hour post-load plasma glucose was at least 200 mg/dl at any survey examination or if found during routine medical care). The population lives near Phoenix, Arizona, USA.</p>
<p>Results: Their ADAP algorithm makes a real-valued prediction between 0 and 1. This was transformed into a binary decision using a cutoff of 0.448. Using 576 training instances, the sensitivity and specificity of their algorithm was 76% on the remaining 192 instances.</p></li>
</ol></li>
<li><p>Relevant Information: Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage. ADAP is an adaptive learning routine that generates and executes digital analogs of perceptron-like devices. It is a unique algorithm; see the paper for details.</p></li>
<li><p>Number of Instances: 768</p></li>
<li><p>Number of Attributes: 8 plus class</p></li>
<li><p>For Each Attribute: (all numeric-valued)</p>
<ol type="1">
<li>Number of times pregnant</li>
<li>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</li>
<li>Diastolic blood pressure (mm Hg)</li>
<li>Triceps skin fold thickness (mm)</li>
<li>2-Hour serum insulin (mu U/ml)</li>
<li>Body mass index (weight in kg/(height in m)^2)</li>
<li>Diabetes pedigree function</li>
<li>Age (years)</li>
<li>Class variable (0 or 1)</li>
</ol></li>
<li><p>Missing Attribute Values: None</p></li>
<li><p>Class Distribution: (class value 1 is interpreted as “tested positive for diabetes”)</p>
<p>Class Value Number of instances 0 500 1 268</p></li>
<li><p>Brief statistical analysis:</p>
<p>Attribute number: Mean: Standard Deviation:</p>
<ol type="1">
<li><pre><code>                3.8     3.4</code></pre></li>
<li><pre><code>              120.9    32.0</code></pre></li>
<li><pre><code>               69.1    19.4</code></pre></li>
<li><pre><code>               20.5    16.0</code></pre></li>
<li><pre><code>               79.8   115.2</code></pre></li>
<li><pre><code>               32.0     7.9</code></pre></li>
<li><pre><code>                0.5     0.3</code></pre></li>
<li><pre><code>               33.2    11.8</code></pre></li>
</ol></li>
</ol>
<p>Relabeled values in attribute ‘class’ From: 0 To: tested_negative<br>
From: 1 To: tested_positive</p>
<p>Downloaded from openml.org.</p>
</div></section><section id="pima-indians-diabetes-dataset" class="slide level2">
<h2>Pima Indians Diabetes Dataset</h2>
<div id="036c59e7" class="cell" data-execution_count="41">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb65-2"><a></a></span>
<span id="cb65-3"><a></a><span class="co"># Load the Pima Indians Diabetes dataset</span></span>
<span id="cb65-4"><a></a>pima <span class="op">=</span> fetch_openml(name<span class="op">=</span><span class="st">'diabetes'</span>, version<span class="op">=</span><span class="dv">1</span>, as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb65-5"><a></a></span>
<span id="cb65-6"><a></a><span class="co"># Extract the features and target</span></span>
<span id="cb65-7"><a></a>X <span class="op">=</span> pima.data</span>
<span id="cb65-8"><a></a>y <span class="op">=</span> pima.target</span>
<span id="cb65-9"><a></a></span>
<span id="cb65-10"><a></a><span class="co"># Convert target labels 'tested_negative' and 'tested_positive' to 0 and 1</span></span>
<span id="cb65-11"><a></a>y <span class="op">=</span> y.<span class="bu">map</span>({<span class="st">'tested_negative'</span>: <span class="dv">0</span>, <span class="st">'tested_positive'</span>: <span class="dv">1</span>})</span>
<span id="cb65-12"><a></a></span>
<span id="cb65-13"><a></a><span class="co"># Split the dataset</span></span>
<span id="cb65-14"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

<aside><div>
<p><a href="https://www.openml.org/search?type=data&amp;sort=version&amp;status=any&amp;order=asc&amp;exact_name=diabetes&amp;id=37">Pima Indians Diabetes Dataset</a> as described in <span class="citation" data-cites="Knowler:1981aa">Knowler et al. (<a href="#/references" role="doc-biblioref" onclick="">1981</a>)</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/7468572/">PubMed</a>].</p>
</div></aside></section>
<section id="comparing-multiple-classifiers" class="slide level2">
<h2>Comparing Multiple Classifiers</h2>
<div id="795fc607" class="cell" data-execution_count="42">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb66-2"><a></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb66-3"><a></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb66-4"><a></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="comparing-multiple-classifiers-1" class="slide level2">
<h2>Comparing Multiple Classifiers</h2>
<div id="0df72b96" class="cell" data-execution_count="43">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a></a>lr <span class="op">=</span> LogisticRegression()</span>
<span id="cb67-2"><a></a>lr.fit(X_train, y_train)</span>
<span id="cb67-3"><a></a></span>
<span id="cb67-4"><a></a>knn <span class="op">=</span> KNeighborsClassifier()</span>
<span id="cb67-5"><a></a>knn.fit(X_train, y_train)</span>
<span id="cb67-6"><a></a></span>
<span id="cb67-7"><a></a>dt <span class="op">=</span> DecisionTreeClassifier()</span>
<span id="cb67-8"><a></a>dt.fit(X_train, y_train)</span>
<span id="cb67-9"><a></a></span>
<span id="cb67-10"><a></a>rf <span class="op">=</span> RandomForestClassifier()</span>
<span id="cb67-11"><a></a>rf.fit(X_train, y_train)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

<aside><div>
<p>Using the default parameters.</p>
</div></aside></section>
<section id="aucroc" class="slide level2">
<h2>AUC/ROC</h2>
<div id="62249fa9" class="cell" data-execution_count="44">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb68-2"><a></a></span>
<span id="cb68-3"><a></a>y_pred_prob_lr <span class="op">=</span> lr.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb68-4"><a></a>y_pred_prob_knn <span class="op">=</span> knn.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb68-5"><a></a>y_pred_prob_dt <span class="op">=</span> dt.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb68-6"><a></a>y_pred_prob_rf <span class="op">=</span> rf.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb68-7"><a></a></span>
<span id="cb68-8"><a></a><span class="co"># Compute ROC curves</span></span>
<span id="cb68-9"><a></a>fpr_lr, tpr_lr, _ <span class="op">=</span> roc_curve(y_test, y_pred_prob_lr)</span>
<span id="cb68-10"><a></a>fpr_knn, tpr_knn, _ <span class="op">=</span> roc_curve(y_test, y_pred_prob_knn)</span>
<span id="cb68-11"><a></a>fpr_dt, tpr_dt, _ <span class="op">=</span> roc_curve(y_test, y_pred_prob_dt)</span>
<span id="cb68-12"><a></a>fpr_rf, tpr_rf, _ <span class="op">=</span> roc_curve(y_test, y_pred_prob_rf)</span>
<span id="cb68-13"><a></a></span>
<span id="cb68-14"><a></a><span class="co"># Compute AUC scores</span></span>
<span id="cb68-15"><a></a>auc_lr <span class="op">=</span> roc_auc_score(y_test, y_pred_prob_lr)</span>
<span id="cb68-16"><a></a>auc_knn <span class="op">=</span> roc_auc_score(y_test, y_pred_prob_knn)</span>
<span id="cb68-17"><a></a>auc_dt <span class="op">=</span> roc_auc_score(y_test, y_pred_prob_dt)</span>
<span id="cb68-18"><a></a>auc_rf <span class="op">=</span> roc_auc_score(y_test, y_pred_prob_rf)</span>
<span id="cb68-19"><a></a></span>
<span id="cb68-20"><a></a><span class="co"># Plot ROC curves</span></span>
<span id="cb68-21"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>)) <span class="co"># plt.figure()</span></span>
<span id="cb68-22"><a></a>plt.plot(fpr_lr, tpr_lr, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="ss">f'Logistic Regression (AUC = </span><span class="sc">{</span>auc_lr<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb68-23"><a></a>plt.plot(fpr_knn, tpr_knn, color<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="ss">f'K-Nearest Neighbors (AUC = </span><span class="sc">{</span>auc_knn<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb68-24"><a></a>plt.plot(fpr_dt, tpr_dt, color<span class="op">=</span><span class="st">'orange'</span>, label<span class="op">=</span><span class="ss">f'Decision Tree (AUC = </span><span class="sc">{</span>auc_dt<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb68-25"><a></a>plt.plot(fpr_rf, tpr_rf, color<span class="op">=</span><span class="st">'purple'</span>, label<span class="op">=</span><span class="ss">f'Random Forest (AUC = </span><span class="sc">{</span>auc_rf<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb68-26"><a></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)  <span class="co"># Diagonal line for random chance</span></span>
<span id="cb68-27"><a></a>plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb68-28"><a></a>plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</span>
<span id="cb68-29"><a></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb68-30"><a></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb68-31"><a></a>plt.title(<span class="st">'ROC Curves for Logistic Regression, KNN, Decision Tree, and Random Forest'</span>)</span>
<span id="cb68-32"><a></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb68-33"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-45-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img data-src="slides_files/figure-revealjs/cell-45-output-1.png" class="quarto-figure quarto-figure-center" width="627" height="449"></a></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>ROC curves provide a visual representation of a classifier’s performance across <strong>all possible thresholds</strong>. By plotting the True Positive Rate (TPR) against the False Positive Rate (FPR), it allows practitioners to evaluate the trade-off between sensitivity (recall) and specificity.</p>
<p>Unlike metrics like accuracy, ROC curves evaluate classifier performance <strong>without relying on a specific decision threshold</strong>. This makes them particularly useful in <strong>comparing models across varying thresholds</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="implementation-logistic-regression" class="slide level2">
<h2>Implementation: Logistic Regression</h2>
<p>Below is our implementation of the logistic regression.</p>
<div id="6355d821" class="cell" data-execution_count="45">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb69-2"><a></a>    <span class="co">"""Compute the sigmoid function."""</span></span>
<span id="cb69-3"><a></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb69-4"><a></a></span>
<span id="cb69-5"><a></a><span class="kw">def</span> cost_function(theta, X, y):</span>
<span id="cb69-6"><a></a>    <span class="co">"""</span></span>
<span id="cb69-7"><a></a><span class="co">    Compute the binary cross-entropy cost.</span></span>
<span id="cb69-8"><a></a><span class="co">    theta: parameter vector</span></span>
<span id="cb69-9"><a></a><span class="co">    X: feature matrix (each row is an example)</span></span>
<span id="cb69-10"><a></a><span class="co">    y: true binary labels (0 or 1)</span></span>
<span id="cb69-11"><a></a><span class="co">    """</span></span>
<span id="cb69-12"><a></a>    m <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb69-13"><a></a>    h <span class="op">=</span> sigmoid(X.dot(theta))</span>
<span id="cb69-14"><a></a>    <span class="co"># Add a small epsilon to avoid log(0)</span></span>
<span id="cb69-15"><a></a>    epsilon <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb69-16"><a></a>    cost <span class="op">=</span> <span class="op">-</span>(<span class="dv">1</span><span class="op">/</span>m) <span class="op">*</span> np.<span class="bu">sum</span>(y <span class="op">*</span> np.log(h <span class="op">+</span> epsilon) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> y) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> h <span class="op">+</span> epsilon))</span>
<span id="cb69-17"><a></a>    <span class="cf">return</span> cost</span>
<span id="cb69-18"><a></a></span>
<span id="cb69-19"><a></a><span class="kw">def</span> gradient(theta, X, y):</span>
<span id="cb69-20"><a></a>    <span class="co">"""Compute the gradient of the cost with respect to theta."""</span></span>
<span id="cb69-21"><a></a>    m <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb69-22"><a></a>    h <span class="op">=</span> sigmoid(X.dot(theta))</span>
<span id="cb69-23"><a></a>    <span class="cf">return</span> (<span class="dv">1</span><span class="op">/</span>m) <span class="op">*</span> X.T.dot(h <span class="op">-</span> y)</span>
<span id="cb69-24"><a></a></span>
<span id="cb69-25"><a></a><span class="kw">def</span> logistic_regression(X, y, learning_rate<span class="op">=</span><span class="fl">0.1</span>, iterations<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb69-26"><a></a>    <span class="co">"""</span></span>
<span id="cb69-27"><a></a><span class="co">    Train logistic regression using gradient descent.</span></span>
<span id="cb69-28"><a></a><span class="co">    Returns the optimized parameter vector theta and the history of cost values.</span></span>
<span id="cb69-29"><a></a><span class="co">    """</span></span>
<span id="cb69-30"><a></a>    m, n <span class="op">=</span> X.shape</span>
<span id="cb69-31"><a></a>    theta <span class="op">=</span> np.zeros(n)</span>
<span id="cb69-32"><a></a>    cost_history <span class="op">=</span> []</span>
<span id="cb69-33"><a></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):</span>
<span id="cb69-34"><a></a>        theta <span class="op">-=</span> learning_rate <span class="op">*</span> gradient(theta, X, y)</span>
<span id="cb69-35"><a></a>        cost_history.append(cost_function(theta, X, y))</span>
<span id="cb69-36"><a></a>    <span class="cf">return</span> theta, cost_history</span>
<span id="cb69-37"><a></a></span>
<span id="cb69-38"><a></a><span class="kw">def</span> predict_probabilities(theta, X):</span>
<span id="cb69-39"><a></a>    <span class="co">"""Return predicted probabilities for the positive class."""</span></span>
<span id="cb69-40"><a></a>    <span class="cf">return</span> sigmoid(X.dot(theta))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="implementation-roc" class="slide level2">
<h2>Implementation: ROC</h2>
<div id="8e73ef29" class="cell" data-execution_count="46">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a></a><span class="kw">def</span> compute_roc_curve(y_true, y_scores, thresholds):</span>
<span id="cb70-2"><a></a>    tpr_list, fpr_list <span class="op">=</span> [], []</span>
<span id="cb70-3"><a></a>    <span class="cf">for</span> thresh <span class="kw">in</span> thresholds:</span>
<span id="cb70-4"><a></a>        <span class="co"># Classify as positive if predicted probability &gt;= threshold</span></span>
<span id="cb70-5"><a></a>        y_pred <span class="op">=</span> (y_scores <span class="op">&gt;=</span> thresh).astype(<span class="bu">int</span>)</span>
<span id="cb70-6"><a></a>        TP <span class="op">=</span> np.<span class="bu">sum</span>((y_true <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (y_pred <span class="op">==</span> <span class="dv">1</span>))</span>
<span id="cb70-7"><a></a>        FN <span class="op">=</span> np.<span class="bu">sum</span>((y_true <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (y_pred <span class="op">==</span> <span class="dv">0</span>))</span>
<span id="cb70-8"><a></a>        FP <span class="op">=</span> np.<span class="bu">sum</span>((y_true <span class="op">==</span> <span class="dv">0</span>) <span class="op">&amp;</span> (y_pred <span class="op">==</span> <span class="dv">1</span>))</span>
<span id="cb70-9"><a></a>        TN <span class="op">=</span> np.<span class="bu">sum</span>((y_true <span class="op">==</span> <span class="dv">0</span>) <span class="op">&amp;</span> (y_pred <span class="op">==</span> <span class="dv">0</span>))</span>
<span id="cb70-10"><a></a>        TPR <span class="op">=</span> TP <span class="op">/</span> (TP <span class="op">+</span> FN) <span class="cf">if</span> (TP <span class="op">+</span> FN) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb70-11"><a></a>        FPR <span class="op">=</span> FP <span class="op">/</span> (FP <span class="op">+</span> TN) <span class="cf">if</span> (FP <span class="op">+</span> TN) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb70-12"><a></a>        tpr_list.append(TPR)</span>
<span id="cb70-13"><a></a>        fpr_list.append(FPR)</span>
<span id="cb70-14"><a></a>        </span>
<span id="cb70-15"><a></a>    tpr_list.reverse()</span>
<span id="cb70-16"><a></a>    fpr_list.reverse()</span>
<span id="cb70-17"><a></a></span>
<span id="cb70-18"><a></a>    <span class="cf">return</span> np.array(fpr_list), np.array(tpr_list)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="implementation-auc-roc" class="slide level2">
<h2>Implementation: AUC ROC</h2>
<div id="267990f8" class="cell" data-execution_count="47">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a></a><span class="kw">def</span> compute_auc(fpr, tpr):</span>
<span id="cb71-2"><a></a>    <span class="co">"""</span></span>
<span id="cb71-3"><a></a><span class="co">    Compute the Area Under the Curve (AUC) using the trapezoidal rule.</span></span>
<span id="cb71-4"><a></a><span class="co">    </span></span>
<span id="cb71-5"><a></a><span class="co">    fpr: array of false positive rates</span></span>
<span id="cb71-6"><a></a><span class="co">    tpr: array of true positive rates</span></span>
<span id="cb71-7"><a></a><span class="co">    """</span></span>
<span id="cb71-8"><a></a>    <span class="cf">return</span> np.trapezoid(tpr, fpr)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>

<aside><div>
<p>The <strong>Trapezoidal Rule</strong> (<code>trapezoid</code>), akin to the <strong>Riemann Sum</strong>, is a numerical method for approximating the definite integral of a function. By partitioning the area under the curve into trapezoids rather than rectangles, it typically yields a more precise approximation.</p>
</div></aside></section>
<section id="example-generate-data-predictions" class="slide level2">
<h2>Example: Generate Data + Predictions</h2>
<div id="e6bc00b9" class="cell" data-execution_count="48">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a></a><span class="co"># Generate synthetic data for binary classification</span></span>
<span id="cb72-2"><a></a>np.random.seed(seed)</span>
<span id="cb72-3"><a></a>m <span class="op">=</span> <span class="dv">1000</span>  <span class="co"># number of samples</span></span>
<span id="cb72-4"><a></a>X <span class="op">=</span> np.random.randn(m, <span class="dv">2</span>)</span>
<span id="cb72-5"><a></a>noise <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> np.random.randn(m)</span>
<span id="cb72-6"><a></a></span>
<span id="cb72-7"><a></a><span class="co"># Define labels: a noisy linear combination thresholded at 0</span></span>
<span id="cb72-8"><a></a>y <span class="op">=</span> (X[:, <span class="dv">0</span>] <span class="op">+</span> X[:, <span class="dv">1</span>] <span class="op">+</span> noise <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb72-9"><a></a></span>
<span id="cb72-10"><a></a><span class="co"># Add an intercept term (a column of ones) to X</span></span>
<span id="cb72-11"><a></a>X_intercept <span class="op">=</span> np.hstack([np.ones((m, <span class="dv">1</span>)), X])</span>
<span id="cb72-12"><a></a></span>
<span id="cb72-13"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_intercept, y, random_state<span class="op">=</span>seed)</span>
<span id="cb72-14"><a></a></span>
<span id="cb72-15"><a></a><span class="co"># Train logistic regression model using gradient descent</span></span>
<span id="cb72-16"><a></a>theta, cost_history <span class="op">=</span> logistic_regression(X_train, y_train, learning_rate<span class="op">=</span><span class="fl">0.1</span>, iterations<span class="op">=</span><span class="dv">1000</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="example-plot" class="slide level2">
<h2>Example: Plot</h2>
<div id="ed3768a1" class="cell" data-execution_count="49">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a></a><span class="co"># Compute predicted probabilities for the positive class on the test set</span></span>
<span id="cb73-2"><a></a>y_probs <span class="op">=</span> predict_probabilities(theta, X_test)</span>
<span id="cb73-3"><a></a></span>
<span id="cb73-4"><a></a><span class="co"># Define a set of threshold values between 0 and 1 (e.g., 100 equally spaced thresholds)</span></span>
<span id="cb73-5"><a></a>thresholds <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb73-6"><a></a></span>
<span id="cb73-7"><a></a><span class="co"># Compute the ROC curve (FPR and TPR for each threshold)</span></span>
<span id="cb73-8"><a></a>fpr, tpr <span class="op">=</span> compute_roc_curve(y_test, y_probs, thresholds)</span>
<span id="cb73-9"><a></a>auc_value <span class="op">=</span> compute_auc(fpr, tpr)</span>
<span id="cb73-10"><a></a></span>
<span id="cb73-11"><a></a><span class="co"># Plot the ROC curve</span></span>
<span id="cb73-12"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb73-13"><a></a>plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'blue'</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'ROC curve (AUC = </span><span class="sc">%0.2f</span><span class="st">)'</span> <span class="op">%</span> auc_value)</span>
<span id="cb73-14"><a></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'gray'</span>, lw<span class="op">=</span><span class="dv">1</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Random classifier'</span>)</span>
<span id="cb73-15"><a></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb73-16"><a></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb73-17"><a></a>plt.title(<span class="st">'Receiver Operating Characteristic (ROC) Curve'</span>)</span>
<span id="cb73-18"><a></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb73-19"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-50-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img data-src="slides_files/figure-revealjs/cell-50-output-1.png" class="quarto-figure quarto-figure-center" width="663" height="523"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="see-also" class="slide level2">
<h2>See Also</h2>
<ul>
<li><a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html">Multiclass Receiver Operating Characteristic (ROC)</a> presents examples of micro- and macro- average curves.</li>
</ul>
</section></section>
<section>
<section id="cross-validation" class="title-slide slide level1 center">
<h1>Cross-Validation</h1>

</section>
<section id="training-and-test-set" class="slide level2">
<h2>Training and test set</h2>
<p>Sometimes called <strong>holdout method</strong>.</p>
<ul>
<li class="fragment"><p><strong>Guideline:</strong> Typically, allocate <strong>80%</strong> of your dataset for <strong>training</strong> and reserve the remaining <strong>20%</strong> for testing.</p></li>
<li class="fragment"><p><strong>Training Set:</strong> This subset of data is utilized to <strong>train</strong> your model.</p></li>
<li class="fragment"><p><strong>Test Set:</strong> This is an <strong>independent</strong> subset used exclusively at the final stage to assess the model’s performance.</p></li>
</ul>
<aside class="notes">
<h3 id="common-training-and-testing-ratios">Common Training and Testing Ratios</h3>
<ol type="1">
<li><strong>80:20 Split:</strong>
<ul>
<li><strong>Training Set:</strong> 80% of the data</li>
<li><strong>Testing Set:</strong> 20% of the data</li>
<li>This is a widely used default split that provides a balance between having enough data to train the model and enough data to evaluate its performance.</li>
</ul></li>
<li><strong>90:10 Split:</strong>
<ul>
<li><strong>Training Set:</strong> 90% of the data</li>
<li><strong>Testing Set:</strong> 10% of the data</li>
<li>This split might be used when the dataset is very large, ensuring a substantial amount of data for training while still having a decent-sized test set.</li>
</ul></li>
</ol>
<h3 id="considerations-for-choosing-the-split-ratio">Considerations for Choosing the Split Ratio</h3>
<ol type="1">
<li><strong>Dataset Size:</strong>
<ul>
<li>For large datasets, a smaller proportion can be reserved for testing (e.g., 90:10) since even 10% of a large dataset can provide a robust evaluation.</li>
</ul></li>
<li><strong>Model Complexity:</strong>
<ul>
<li>Complex models with many parameters may require more training data to avoid overfitting, suggesting a larger training set.</li>
</ul></li>
<li><strong>Validation Set:</strong>
<ul>
<li>See discussion below.</li>
</ul></li>
<li><strong>Imbalanced Datasets:</strong>
<ul>
<li>For imbalanced datasets, it’s essential to ensure that both the training and testing sets represent the class distribution adequately. <strong>Stratified sampling can be used to maintain the class proportions in both sets.</strong></li>
</ul></li>
</ol>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="training-and-test-set-1" class="slide level2">
<h2>Training and test set</h2>
<p><strong>Training Error:</strong></p>
<ul>
<li>Generally tends to be <strong>low</strong></li>
<li>Achieved by optimizing learning algorithms to minimize error through parameter adjustments (e.g., weights)</li>
</ul>
</section>
<section id="definition-1" class="slide level2">
<h2>Definition</h2>
<p><strong>Generalization Error:</strong> The error rate observed when the model is evaluated on new, unseen data.</p>
</section></section>
<section>
<section id="prologue" class="title-slide slide level1 center">
<h1>Prologue</h1>

</section>
<section id="summary-1" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Examined classification model evaluation techniques, focusing on confusion matrices and key metrics: accuracy, precision, recall, and <span class="math inline">\(F_1\)</span> score.</li>
<li>Addressed the limitations of accuracy in imbalanced datasets, introducing micro and macro averaging techniques.</li>
<li>Explored the precision-recall trade-off and ROC analysis, including the area under the curve (AUC).</li>
<li>Provided practical insights through Python implementations.</li>
</ul>
</section>
<section id="on-performance-measures" class="slide level2">
<h2>On Performance Measures</h2>
<ul>
<li>Sokolova, M. &amp; Lapalme, G. (2009). A systematic analysis of performance measures for classification tasks.&nbsp;<em>Information Processing and Management</em>,&nbsp;<em>45</em>(4), 427–437.
<ul>
<li>Scopus: <strong>4,222 citations</strong></li>
<li>Google Scholar: <strong>6,839 citations</strong></li>
</ul></li>
</ul>
</section>
<section id="evaluating-learning-algorithms" class="slide level2 smaller">
<h2>Evaluating Learning Algorithms</h2>
<div class="columns">
<div class="column" style="width:20%;">
<p><a href="../../assets/images/evaluating_learning_algorithms.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img data-src="../../assets/images/evaluating_learning_algorithms.jpg"></a></p>
</div><div class="column" style="width:80%;">
<ul>
<li><p>This <a href="https://www.cambridge.org/core/books/evaluating-learning-algorithms/3CB22D16AB609D1770C24CA2CB5A11BF">book</a>, 4.6 stars rating on Amazon, delves into the evaluation process, particularly focusing on classification algorithms <span class="citation" data-cites="japkowicz:2011mm">(<a href="#/references" role="doc-biblioref" onclick="">Japkowicz and Shah 2011</a>)</span>.</p></li>
<li><p><a href="https://www.american.edu/cas/faculty/japkowic.cfm">Nathalie Japkowicz</a> previously served as a professor at the University of Ottawa and is currently affiliated with American University in Washington.</p></li>
<li><p><a href="http://www.mohakshah.com">Mohak Shah</a>, who earned his PhD from the University of Ottawa, has held numerous industry roles, including Vice President of AI and Machine Learning at LG Electronics.</p></li>
</ul>
</div></div>
</section>
<section id="further-reading" class="slide level2">
<h2>Further reading</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/evaluating_learning_algorithms.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img data-src="../../assets/images/evaluating_learning_algorithms.jpg" class="quarto-figure quarto-figure-center" style="height:50.0%"></a></p>
</figure>
</div>

<aside class="notes">
<p>This book, which examines various aspects of the evaluation process with an emphasis on classification algorithms, has excellent ratings on Amazon!</p>
<p><a href="https://www.american.edu/cas/faculty/japkowic.cfm">Nathalie Japkowicz</a> was formely a professor that the University of Ottawa. She now works at the American University in Washington.</p>
<p><a href="http://www.mohakshah.com">Mohak Shah</a> completed his PhD at the University of Ottawa. He has held several positions in the industry, including AI and Machine Learning Vice President for LG Electronics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="japkowicz:2011mm">Japkowicz and Shah (<a href="#/references" role="doc-biblioref" onclick="">2011</a>)</span></p>
</div></aside></section>
<section id="next-lecture" class="slide level2">
<h2>Next lecture</h2>
<ul>
<li>We will examine cross-validation and hyperparameter tuning.</li>
</ul>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Geron:2022aa" class="csl-entry" role="listitem">
Géron, Aurélien. 2022. <em>Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. 3rd ed. O’Reilly Media, Inc.
</div>
<div id="ref-japkowicz:2011mm" class="csl-entry" role="listitem">
Japkowicz, Nathalie, and Mohak Shah. 2011. <em>Evaluating Learning Algorithms: A Classification Perspective</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Knowler:1981aa" class="csl-entry" role="listitem">
Knowler, William C., David J. Pettitt, Peter J. Savage, and Peter H. Bennett. 1981. <span>“Diabetes Incidence in Pima Indians: Contributions of Obesity and Parental Diabetes.”</span> <em>American Journal of Epidemiology</em> 113 2: 144–56. <a href="https://api.semanticscholar.org/CorpusID:25209675">https://api.semanticscholar.org/CorpusID:25209675</a>.
</div>
<div id="ref-Russell:2020aa" class="csl-entry" role="listitem">
Russell, Stuart, and Peter Norvig. 2020. <em>Artificial Intelligence: <span>A</span> Modern Approach</em>. 4th ed. Pearson. <a href="http://aima.cs.berkeley.edu/">http://aima.cs.berkeley.edu/</a>.
</div>
</div>
</section>
<section class="slide level2">

<p>Marcel <strong>Turcotte</strong></p>
<p><a href="mailto:Marcel.Turcotte@uOttawa.ca">Marcel.Turcotte@uOttawa.ca</a></p>
<p>School of Electrical Engineering and <strong>Computer Science</strong> (EE<strong>CS</strong>)</p>
<p>University of Ottawa</p>


</section></section>

    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../assets/images/uottawa_hor_black.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://turcotte.xyz/teaching/csi-4106">turcotte.xyz/teaching/csi-4106</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/turcotte\.xyz\/teaching\/csi-4106");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

</body></html>