<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Marcel Turcotte">
  <title>CSI 4106 - Fall 2025 – Training Artificial Neural Networks (Part 2)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-f563837468303362081e247dddd440d0.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Training Artificial Neural Networks (Part 2) – CSI 4106 - Fall 2025">
<meta property="og:description" content="CSI 4106 - Fall 2025">
<meta property="og:site_name" content="CSI 4106 - Fall 2025">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Training Artificial Neural Networks (Part 2)</h1>
  <p class="subtitle">CSI 4106 - Fall 2025</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Marcel Turcotte 
</div>
</div>
</div>

  <p class="date">Version: Jul 10, 2025 16:54</p>
</section>
<section>
<section id="preamble" class="title-slide slide level1 center">
<h1>Preamble</h1>

</section>
<section id="quote-of-the-day" class="slide level2 scrollable">
<h2>Quote of the Day</h2>
<p></p><div id="tweet-65359"></div><script>tweet={"url":"https:\/\/twitter.com\/demishassabis\/status\/1839354651206160563","author_name":"Demis Hassabis","author_url":"https:\/\/twitter.com\/demishassabis","html":"\u003Cblockquote class=\"twitter-tweet\" align=\"center\"\u003E\u003Cp lang=\"en\" dir=\"ltr\"\u003EFeedback loop: train SOTA chip design model (AlphaChip) -&gt; use it to design better AI chips -&gt; use them to train better models -&gt; to design better chips... part of the reason why our TPU stack is so good. Congrats \u003Ca href=\"https:\/\/twitter.com\/Azaliamirh?ref_src=twsrc%5Etfw\"\u003E@Azaliamirh\u003C\/a\u003E, \u003Ca href=\"https:\/\/twitter.com\/annadgoldie?ref_src=twsrc%5Etfw\"\u003E@annadgoldie\u003C\/a\u003E, \u003Ca href=\"https:\/\/twitter.com\/JeffDean?ref_src=twsrc%5Etfw\"\u003E@JeffDean\u003C\/a\u003E &amp; the AlphaChip team! \u003Ca href=\"https:\/\/t.co\/MLwaAP79Tg\"\u003Ehttps:\/\/t.co\/MLwaAP79Tg\u003C\/a\u003E\u003C\/p\u003E&mdash; Demis Hassabis (@demishassabis) \u003Ca href=\"https:\/\/twitter.com\/demishassabis\/status\/1839354651206160563?ref_src=twsrc%5Etfw\"\u003ESeptember 26, 2024\u003C\/a\u003E\u003C\/blockquote\u003E\n\u003Cscript async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"\u003E\u003C\/script\u003E\n\n","width":550,"height":null,"type":"rich","cache_age":"3153600000","provider_name":"Twitter","provider_url":"https:\/\/twitter.com","version":"1.0"};document.getElementById("tweet-65359").innerHTML = tweet["html"];</script><p></p>
<aside class="notes">
<p><a href="https://www.linkedin.com/in/demishassabis/?originalSubdomain=uk">Sir Demis Hassabis</a> is the Co-founder and CEO of <a href="https://deepmind.google">Google DeepMind</a>, a leading company dedicated to addressing some of the most complex scientific and engineering challenges of our era to propel scientific advancement. A chess prodigy from the age of four, Hassabis achieved master-level proficiency by 13 and served as the captain for several England junior chess teams. In 2024, he was awarded the Nobel Prize in <a href="https://www.nobelprize.org/prizes/chemistry/2024/summary/">Chemistry</a> for his contributions to the development of <a href="https://deepmind.google/technologies/alphafold/">AlphaFold</a>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="learning-objectives" class="slide level2">
<h2>Learning objectives</h2>
<ul>
<li><strong>Describe</strong> the functioning of a softmax layer.</li>
<li><strong>Explain</strong> the concept of cross-entropy loss.</li>
<li><strong>Apply</strong> regularization techniques to improve the generalization of neural networks.</li>
</ul>
<aside class="notes">
<p>As with Assignment 2, I have compiled the important concepts for the next assignment into the lecture notes.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<ul>
<li class="fragment"><strong>Deep learning</strong> is a branch of <strong>machine learning</strong>.</li>
<li class="fragment">It uses <strong>neural networks</strong> organized in <strong>layers</strong>.</li>
<li class="fragment">Each unit computes a <strong>weighted sum</strong> (dot product) of the inputs, adds a <strong>bias</strong>, and then applies an <strong>activation function</strong> to produce its output.</li>
<li class="fragment">A sufficiently large single-layer network can <strong>approximate any continuous function</strong>.</li>
</ul>
</section>
<section id="backpropagation-general-overview" class="slide level2">
<h2>Backpropagation: General Overview</h2>
<ol type="1">
<li><strong>Initialization</strong></li>
<li><strong>Forward Pass</strong></li>
<li><strong>Loss Calculation</strong></li>
<li><strong>Backward Pass (Backpropagation)</strong></li>
<li><strong>Repeat steps 2 to 5</strong>.</li>
</ol>

<aside><div>
<p>The algorithm <strong>stops</strong> either after a <strong>predefined number of epochs</strong> or when the <strong>convergence criteria are met</strong>.</p>
</div></aside></section></section>
<section>
<section id="output-layer" class="title-slide slide level1 center">
<h1>Output layer</h1>

</section>
<section id="output-layer-regression-task" class="slide level2">
<h2>Output Layer: Regression Task</h2>
<ul>
<li><strong># of output neurons</strong>:
<ul>
<li>1 per dimension</li>
</ul></li>
<li><strong>Output layer activation function</strong>:
<ul>
<li>None, <em>ReLU/softplus</em>, if positive, <em>sigmoid/tanh</em>, if bounded</li>
</ul></li>
<li><strong>Loss function</strong>:
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredError">MeanSquaredError</a></li>
</ul></li>
</ul>

<aside><div>
<p>In an <a href="https://keras.io/guides/keras_cv/object_detection_keras_cv/">object detection problem</a>, determining the <strong>bounding box</strong> exemplifies a regression task where the output is multidimensional.</p>
</div></aside></section>
<section id="output-layer-classification-task" class="slide level2">
<h2>Output Layer: Classification Task</h2>
<ul>
<li><strong># of output neurons</strong>:
<ul>
<li>1 if binary, 1 per class, if multi-label or multiclass.</li>
</ul></li>
<li><strong>Output layer activation function</strong>:
<ul>
<li><em>sigmoid</em>, if binary or multi-label, <em>softmax</em> if multi-class.</li>
</ul></li>
<li><strong>Loss function</strong>:
<ul>
<li>cross-entropy</li>
</ul></li>
</ul>
</section>
<section id="softmax" class="slide level2">
<h2>Softmax</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_mlp_softmax-09-00.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img data-src="../../assets/images/ann_mlp_softmax-09-00.png" class="quarto-figure quarto-figure-center" height="475"></a></p>
</figure>
</div>

<aside class="notes">
<p>Observe that I have revised the representation of the output nodes to indicate that the softmax function is applied to the entire layer, rather than to individual nodes. This function transforms the raw output values of the layer into probabilities that sum to 1, facilitating multi-class classification. This characteristic distinguishes it from activation functions like ReLU or sigmoid, which are typically applied independently to each node’s output.</p>
<p>The <span class="math inline">\(\argmax\)</span> function is not suitable for optimization via gradient-based methods because its derivative is zero in all cases, similar to step functions. In contrast, the softmax function offers both a probabilistic interpretation and a computable derivative, making it more effective for such applications.</p>
<p>The <span class="math inline">\(\argmax\)</span> function can be applied <em>a posteriori</em> to trained networks for class prediction.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Softmax</strong> ensures that all activation outputs fall between 0 and 1 and collectively sum to 1.</p>
</div></aside></section>
<section id="softmax-1" class="slide level2">
<h2>Softmax</h2>
<p>The <strong>softmax</strong> function is an <strong>activation function</strong> used in <strong>multi-class classification problems</strong> to convert a vector of raw scores into <strong>probabilities that sum to 1</strong>.</p>
<p>Given a vector <span class="math inline">\(\mathbf{z} = [z_1, z_2, \ldots, z_n]\)</span>:</p>
<p><span class="math display">\[
\sigma(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}}
\]</span></p>
<p>where <span class="math inline">\(\sigma(\mathbf{z})_i\)</span> is the probability of the <span class="math inline">\(i\)</span>-th class, and <span class="math inline">\(n\)</span> is the number of classes.</p>
<aside class="notes">
<p>Softmax emphasizes higher scores while suppressing lower ones, enabling a probabilistic interpretation of the outputs.</p>
<p>We clearly see that such an activation applies for an entire layer since the denomination depends on the values of all the <span class="math inline">\(z_j\)</span>, for <span class="math inline">\(j in 1 \ldots n\)</span>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="softmax-2" class="slide level2">
<h2>Softmax</h2>
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(z_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(z_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(z_3\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\sigma(z_1)\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\sigma(z_2)\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\sigma(z_3)\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\sum\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;"><strong>1.47</strong></td>
<td style="text-align: right;">-0.39</td>
<td style="text-align: right;">0.22</td>
<td style="text-align: right;"><strong>0.69</strong></td>
<td style="text-align: right;">0.11</td>
<td style="text-align: right;">0.20</td>
<td style="text-align: right;">1.00</td>
</tr>
<tr class="even">
<td style="text-align: right;">5.00</td>
<td style="text-align: right;"><strong>6.00</strong></td>
<td style="text-align: right;">4.00</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;"><strong>0.67</strong></td>
<td style="text-align: right;">0.09</td>
<td style="text-align: right;">1.00</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.90</td>
<td style="text-align: right;">0.80</td>
<td style="text-align: right;"><strong>1.10</strong></td>
<td style="text-align: right;">0.32</td>
<td style="text-align: right;">0.29</td>
<td style="text-align: right;"><strong>0.39</strong></td>
<td style="text-align: right;">1.00</td>
</tr>
<tr class="even">
<td style="text-align: right;">-2.00</td>
<td style="text-align: right;"><strong>2.00</strong></td>
<td style="text-align: right;">-3.00</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: right;"><strong>0.98</strong></td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">1.00</td>
</tr>
</tbody>
</table>

<aside class="notes">
<ol type="1">
<li><p><strong>Maintains Relative Order</strong>: The softmax function preserves the relative order of the input values. If one input is greater than another, its corresponding output will also be greater.</p></li>
<li><p><strong>Interpreted as probabilities</strong>: Each value is in the range 0 to 1. The output values from the softmax function are normalized to sum to one, which allows them to be interpreted as probabilities.</p></li>
<li><p><strong>Relative Differences</strong>: When the relative differences among the input values are small, the differences in the output probabilities remain small, reflecting the input distribution. When the input values are identical, the output values will be <span class="math inline">\(\frac{1}{n}\)</span>, where <span class="math inline">\(n\)</span> is the number of classes.</p></li>
<li><p><strong>Wide Range of Values</strong>: The softmax function can effectively handle a wide range of input values, thanks to the exponential function and normalization, which scale the inputs to a probabilistic range.</p></li>
</ol>
<p>These properties make the softmax function particularly useful for multi-class classification tasks in machine learning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Softmax values for a vector of length 3.</p>
</div></aside></section>
<section id="softmax-3" class="slide level2">
<h2>Softmax</h2>
<iframe data-external="1" src="https://www.youtube.com/embed/KpKog-L9veg" width="889" height="500" title="Neural Networks Part 5: ArgMax and SoftMax" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</section>
<section id="cross-entropy-loss-function" class="slide level2">
<h2>Cross-entropy loss function</h2>
<p>The <strong>cross-entropy</strong> in a <strong>multi-class classification task</strong> for one example:</p>
<p><span class="math display">\[
J(W) = -\sum_{k=1}^{K} y_k \log(\hat{y}_k)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(K\)</span> is the <strong>number of classes</strong>.</li>
<li><span class="math inline">\(y_k\)</span> is the <strong>true distribution</strong> for the class <span class="math inline">\(k\)</span>.</li>
<li><span class="math inline">\(\hat{y}_k\)</span> is the <strong>predicted probability</strong> of class <span class="math inline">\(k\)</span> from the model.</li>
</ul>
<aside class="notes">
<ul>
<li><p>The target vector <span class="math inline">\(y\)</span> is expressed as a one-hot encoded vector of length <span class="math inline">\(K\)</span>, where the element corresponding to the true class is set to 1, and all other elements are 0.</p></li>
<li><p>Consequently, in the summation over classes, only the term associated with the true class contributes a non-zero value.</p></li>
<li><p>Therefore, the cross-entropy loss for a single example is given by <span class="math inline">\(-\log(\hat{y}_k)\)</span>, where <span class="math inline">\(\hat{y}_k\)</span> is the predicted probability for the true class.</p></li>
<li><p>The predicted probability <span class="math inline">\(\hat{y}_k\)</span> is derived from the softmax function applied in the output layer of the neural network.</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cross-entropy-loss-function-1" class="slide level2">
<h2>Cross-entropy loss function</h2>
<ul>
<li class="fragment"><strong>Classification Problem</strong>: 3 classes
<ul>
<li class="fragment">Versicolour, Setosa, Virginica.</li>
</ul></li>
<li class="fragment"><strong>One-Hot Encoding</strong>:
<ul>
<li class="fragment">Setosa = <span class="math inline">\([0, 1, 0]\)</span>.</li>
</ul></li>
<li class="fragment"><strong>Softmax Outputs &amp; Loss</strong>:
<ul>
<li class="fragment"><span class="math inline">\([0.22,\mathbf{0.7}, 0.08]\)</span>: Loss = <span class="math inline">\(-\log(0.7) = 0.3567\)</span>.</li>
<li class="fragment"><span class="math inline">\([0.7, \mathbf{0.22}, 0.08]\)</span>: Loss = <span class="math inline">\(-\log(0.22) = 1.5141\)</span>.</li>
<li class="fragment"><span class="math inline">\([0.7, \mathbf{0.08}, 0.22]\)</span>: Loss = <span class="math inline">\(-\log(0.08) = 2.5257\)</span>.</li>
</ul></li>
</ul>
<aside class="notes">
<p>Among the softmax outputs, cross-entropy evaluates only the component corresponding to <span class="math inline">\(k=1\)</span> (Setosa), as the other entries in the one-hot encoded vector are zero. This relevant element is highlighted in bold. When the softmax prediction aligns closely with the expected value, the resulting loss is minimal (0.3567). Conversely, as the prediction deviates further from the expected value, the loss increases (1.5141 and 2.5257).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="case-one-example" class="slide level2">
<h2>Case: one example</h2>
<div id="e0be575a" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img data-src="slides_files/figure-revealjs/cell-2-output-1.png" class="quarto-figure quarto-figure-center" width="651" height="532"></a></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li><p>In the summation, only the term where <span class="math inline">\(y_k = 1\)</span> contributes a non-zero value.</p></li>
<li><p>Due to the negative sign preceding the summation, the value of the function is <span class="math inline">\(-\log(\hat{y}_k\)</span>.</p></li>
<li><p>If the predicted probability <span class="math inline">\(\hat{y}_k\)</span> is near 1, the loss approaches zero, indicating minimal penalty.</p></li>
<li><p>Conversely, as <span class="math inline">\(\hat{y}_k\)</span> nears 0, indicating an incorrect prediction, the loss approaches infinity. This substantial penalty allows cross-entropy loss to converge more quickly than mean squared error.</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="case-dataset" class="slide level2">
<h2>Case: dataset</h2>
<p>For a dataset with <span class="math inline">\(N\)</span> examples, the <strong>average cross-entropy loss</strong> over all examples is computed as:</p>
<p><span class="math display">\[
L = -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i,k} \log(\hat{y}_{i,k})
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(i\)</span> indexes over the different <strong>examples</strong> in the dataset.</li>
<li><span class="math inline">\(y_{i,k}\)</span> and <span class="math inline">\(\hat{y}_{i,k}\)</span> are the <strong>true</strong> and <strong>predicted probabilities</strong> for class <span class="math inline">\(k\)</span> of example <span class="math inline">\(i\)</span>, respectively.</li>
</ul>
</section></section>
<section>
<section id="regularization" class="title-slide slide level1 center">
<h1>Regularization</h1>

</section>
<section id="definition" class="slide level2">
<h2>Definition</h2>
<p><strong>Regularization</strong> comprises a set of techniques designed to enhance a model’s ability to generalize by <strong>mitigating overfitting</strong>. By <strong>discouraging excessive model complexity</strong>, these methods <strong>improve</strong> the model’s <strong>robustness</strong> and <strong>performance</strong> on unseen data.</p>
</section>
<section id="adding-penalty-terms-to-the-loss" class="slide level2">
<h2>Adding penalty terms to the loss</h2>
<ul>
<li><p>In numerical optimization, it is standard practice to <strong>incorporate additional terms</strong> into the <strong>objective function</strong> to <strong>deter undesirable model characteristics</strong>.</p></li>
<li><p>For a <strong>minimization problem</strong>, the optimization process aims to <strong>circumvent the substantial costs</strong> associated with these <strong>penalty terms</strong>.</p></li>
</ul>
</section>
<section id="loss-function" class="slide level2">
<h2>Loss function</h2>
<p>Consider the <strong>mean absolute error</strong> loss function:</p>
<p><span class="math display">\[
  \mathrm{MAE}(X,W) = \frac{1}{N} \sum_{i=1}^N | h_W(x_i) - y_i |
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(W\)</span> are the weights of our network.</li>
<li><span class="math inline">\(h_W(x_i)\)</span> is the output of the network for example <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(y_i\)</span> is the true label for example <span class="math inline">\(i\)</span>.</li>
</ul>
</section>
<section id="penalty-terms" class="slide level2">
<h2>Penalty term(s)</h2>
<p>One or more terms can be added to the loss:</p>
<p><span class="math display">\[
  \mathrm{MAE}(X,W) = \frac{1}{N} \sum_{i=1}^N | h_W(x_i) - y_i | + \mathrm{penalty}
\]</span></p>
</section>
<section id="norm" class="slide level2">
<h2>Norm</h2>
<p>A <strong>norm</strong> is assigns a non-negative length to a vector.</p>
<p>The <strong><span class="math inline">\(\ell_p\)</span> norm</strong> of a vector <span class="math inline">\(\mathbf{z} = [z_1, z_2, \ldots, z_n]\)</span> is defined as:</p>
<p><span class="math display">\[
  \|\mathbf{z}\|_p = \left( \sum_{i=1}^{n} |z_i|^p \right)^{1/p}
\]</span></p>

<aside class="notes">
<p>A <strong>norm</strong> is a function that assigns a non-negative length or size to each vector in a vector space, satisfying certain properties: positivity, scalar multiplication, the triangle inequality, and the property that the norm is zero if and only if the vector is zero.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>With larger <span class="math inline">\(p\)</span>, the <span class="math inline">\(\ell_p\)</span> norm increasingly highlights larger <span class="math inline">\(z_i\)</span> values due to exponentiation.</p>
</div></aside></section>
<section id="ell_1-and-ell_2-norms" class="slide level2">
<h2><span class="math inline">\(\ell_1\)</span> and <span class="math inline">\(\ell_2\)</span> norms</h2>
<p>The <strong><span class="math inline">\(\ell_1\)</span> norm</strong> (<strong>Manhattan norm</strong>) is:</p>
<p><span class="math display">\[
  \|\mathbf{z}\|_1 = \sum_{i=1}^{n} |z_i|
\]</span></p>
<p>The <strong><span class="math inline">\(\ell_2\)</span> norm</strong> (<strong>Euclidean norm</strong>) is:</p>
<p><span class="math display">\[
  \|\mathbf{z}\|_2 = \sqrt{\sum_{i=1}^{n} z_i^2}
\]</span></p>
</section>
<section id="ell_1-and-ell_2-regularization" class="slide level2">
<h2><span class="math inline">\(\ell_1\)</span> and <span class="math inline">\(\ell_2\)</span> regularization</h2>
<p>Below, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> determine the degree of regularization applied; setting these values to zero effectively disables the regularization term. <span class="math display">\[
  \mathrm{MAE}(X,W) = \frac{1}{N} \sum_{i=1}^N | h_W(x_i) - y_i | + \alpha \ell_1 + \beta \ell_2
\]</span></p>
</section>
<section id="guidelines" class="slide level2">
<h2>Guidelines</h2>
<ul>
<li class="fragment"><strong><span class="math inline">\(\ell_1\)</span> Regularization</strong>:
<ul>
<li class="fragment">Promotes <strong>sparsity</strong>, setting many weights to zero.</li>
<li class="fragment">Useful for <strong>feature selection</strong> by reducing feature reliance.</li>
</ul></li>
<li class="fragment"><strong><span class="math inline">\(\ell_2\)</span> Regularization</strong>:
<ul>
<li class="fragment">Promotes <strong>small, distributed weights</strong> for stability.</li>
<li class="fragment">Ideal when <strong>all features contribute</strong> and reducing complexity is key.</li>
</ul></li>
</ul>
</section>
<section id="keras-example" class="slide level2">
<h2>Keras example</h2>
<div id="67ba1c0b" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a></a><span class="im">from</span> tensorflow.python.keras.layers <span class="im">import</span> Dense</span>
<span id="cb1-3"><a></a></span>
<span id="cb1-4"><a></a>regularizer <span class="op">=</span> tf.keras.regularizers.l2(<span class="fl">0.001</span>)</span>
<span id="cb1-5"><a></a></span>
<span id="cb1-6"><a></a>dense <span class="op">=</span> Dense(<span class="dv">50</span>, kernel_regularizer<span class="op">=</span>regularizer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<aside><div>
<p>This layer specifically utilizes <span class="math inline">\(\ell_2\)</span> regularization, in contrast to the prior discussion where regularization was applied globally across the entire model.</p>
</div></aside></section>
<section id="dropout" class="slide level2">
<h2>Dropout</h2>
<p><strong>Dropout</strong> is a regularization technique in neural networks where <em>randomly selected neurons are ignored during training</em>, reducing overfitting by <strong>preventing co-adaptation of features</strong>.</p>

<aside><div>
<p><span class="citation" data-cites="Hinton:2012aa">Hinton et al. (<a href="#/references" role="doc-biblioref" onclick="">2012</a>)</span></p>
</div></aside></section>
<section id="dropout-1" class="slide level2">
<h2>Dropout</h2>
<ul>
<li class="fragment"><p>During each training step, each neuron in a dropout layer has a probability <span class="math inline">\(p\)</span> of being <strong>excluded from the computation</strong>, typical values for <span class="math inline">\(p\)</span> are between 10% and 50%.</p></li>
<li class="fragment"><p>While seemingly counterintuitive, this approach <strong>prevents the network from depending on specific neurons</strong>, promoting the <strong>distribution of learned representations across multiple neurons</strong>.</p></li>
</ul>
</section>
<section id="dropout-2" class="slide level2">
<h2>Dropout</h2>
<ul>
<li class="fragment"><p>Dropout is one of the <strong>most popular</strong> and <strong>effective</strong> methods for reducing overfitting.</p></li>
<li class="fragment"><p>The typical improvement in performance is <strong>modest</strong>, usually around 1 to 2%.</p></li>
</ul>
</section>
<section id="keras" class="slide level2">
<h2>Keras</h2>
<div id="0f5f9a9c" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="im">import</span> keras</span>
<span id="cb2-2"><a></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb2-3"><a></a><span class="im">from</span> keras.layers <span class="im">import</span> InputLayer, Dropout, Flatten, Dense</span>
<span id="cb2-4"><a></a></span>
<span id="cb2-5"><a></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb2-6"><a></a>    InputLayer(shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]),</span>
<span id="cb2-7"><a></a>    Flatten(),</span>
<span id="cb2-8"><a></a>    Dropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb2-9"><a></a>    Dense(<span class="dv">300</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb2-10"><a></a>    Dropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb2-11"><a></a>    Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb2-12"><a></a>    Dropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb2-13"><a></a>    Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb2-14"><a></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<aside class="notes">
<p>The dropout rate may differ between layers; larger rates can be applied to larger layers, while smaller rates are suitable for smaller layers. It is common practice in many networks to apply dropout only after the final hidden layer.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Adding <code>Dropout</code> layers to the Fashion-MNIST model from last lecture.</p>
</div></aside></section>
<section id="definition-1" class="slide level2">
<h2>Definition</h2>
<p><strong>Early stopping</strong> is a regularization technique that halts training once the model’s performance on a validation set begins to degrade, preventing overfitting by stopping before the model learns noise.</p>

<aside><div>
<p>Geoffrey Hinton calls this the <em>“beautiful free lunch.”</em></p>
</div></aside></section>
<section id="early-stopping" class="slide level2">
<h2>Early Stopping</h2>
<div id="b64b038f" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img data-src="slides_files/figure-revealjs/cell-5-output-1.png" class="quarto-figure quarto-figure-center" width="825" height="434"></a></p>
</figure>
</div>
</div>
</div>

<aside><div>
<p><strong>Attribution</strong>: <span class="citation" data-cites="Geron:2022aa">Géron (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span>, <a href="https://github.com/ageron/handson-ml3/blob/main/04_training_linear_models.ipynb">04_training_linear_models.ipynb</a>.</p>
</div></aside></section></section>
<section>
<section id="prologue" class="title-slide slide level1 center">
<h1>Prologue</h1>

</section>
<section id="summary-1" class="slide level2 scrollable">
<h2>Summary</h2>
<ul>
<li><strong>Loss Functions:</strong>
<ul>
<li><strong>Regression Tasks:</strong> Mean Squared Error (MSE).</li>
<li><strong>Classification Tasks:</strong> Cross-Entropy Loss with Softmax activation for multi-class outputs.</li>
</ul></li>
<li><strong>Regularization Techniques:</strong>
<ul>
<li><strong>L1 and L2 Regularization:</strong> Add penalty terms to the loss to discourage large weights.</li>
<li><strong>Dropout:</strong> Randomly deactivate neurons during training to prevent overfitting.</li>
<li><strong>Early Stopping:</strong> Halt training when validation performance deteriorates.</li>
</ul></li>
</ul>
</section>
<section id="next-lecture" class="slide level2">
<h2>Next lecture</h2>
<ul>
<li>We will introduce various architectures of artificial neural networks.</li>
</ul>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Geron:2022aa" class="csl-entry" role="listitem">
Géron, Aurélien. 2022. <em>Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. 3rd ed. O’Reilly Media, Inc.
</div>
<div id="ref-Hinton:2012aa" class="csl-entry" role="listitem">
Hinton, Geoffrey E., Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2012. <span>“Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors.”</span> <em>CoRR</em> abs/1207.0580. <a href="http://arxiv.org/abs/1207.0580">http://arxiv.org/abs/1207.0580</a>.
</div>
<div id="ref-Russell:2020aa" class="csl-entry" role="listitem">
Russell, Stuart, and Peter Norvig. 2020. <em>Artificial Intelligence: <span>A</span> Modern Approach</em>. 4th ed. Pearson. <a href="http://aima.cs.berkeley.edu/">http://aima.cs.berkeley.edu/</a>.
</div>
</div>
</section>
<section class="slide level2">

<p>Marcel <strong>Turcotte</strong></p>
<p><a href="mailto:Marcel.Turcotte@uOttawa.ca">Marcel.Turcotte@uOttawa.ca</a></p>
<p>School of Electrical Engineering and <strong>Computer Science</strong> (EE<strong>CS</strong>)</p>
<p>University of Ottawa</p>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../assets/images/uottawa_hor_black.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://turcotte.xyz/teaching/csi-4106">turcotte.xyz/teaching/csi-4106</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/turcotte\.xyz\/teaching\/csi-4106");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

<script src="https://platform.twitter.com/widgets.js"></script>
</body></html>