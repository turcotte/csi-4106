<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Marcel Turcotte">
  <title>CSI 4106 - Fall 2025 – Introduction to Artificial Neural Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-f563837468303362081e247dddd440d0.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<meta property="og:title" content="Introduction to Artificial Neural Networks – CSI 4106 - Fall 2025">
<meta property="og:description" content="CSI 4106 - Fall 2025">
<meta property="og:site_name" content="CSI 4106 - Fall 2025">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Introduction to Artificial Neural Networks</h1>
  <p class="subtitle">CSI 4106 - Fall 2025</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Marcel Turcotte 
</div>
</div>
</div>

  <p class="date">Version: Jul 10, 2025 16:47</p>
</section>
<section>
<section id="preamble" class="title-slide slide level1 center">
<h1>Preamble</h1>

</section>
<section id="quote-of-the-day" class="slide level2 scrollable">
<h2>Quote of the Day</h2>
<p></p><div id="tweet-65152"></div><script>tweet=<!DOCTYPE html>
<html lang="en" class="dog">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>X / ?</title>
    <meta name="version" content="1">
    <link href="https://abs.twimg.com/favicons/twitter.3.ico" rel="shortcut icon" type="image/x-icon">
    <link rel="stylesheet" href="https://abs.twimg.com/errors/fullscreen_errors-047ca1475a6efac7c9c89a9ff92b7a20.css">
  </head>
  <body dir="auto">
    <div class="top">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1519 200">
        <defs/>
        <path d="M708 103l9-5 13 1 2-2 5 1h8l1-1 42-5h7l7 3v1l12-2a9368 9368 0 0129-6l2-5 12 1 6-2 3 1 2 1v-2l13-2v1l4 2 7-1h1l17-3 1 2 4-1 18-7 3-1 4-1h9l13-1 1-4 3-2 13 1v2l22-2 10-3h6l10 5 16-5 15-3 2-1 8-4 6-2 12-1 7-2 8 5 7 1 22-9h7l5-1v-1l25-3 1 2 5 2v1h11l2 1 8-4h3l-1 1h11l10-6 6 3 9-1 4-1 1 1 1-2 6-1 1-1 10-2h2l7-5v1h4l3-1c11 0 23 2 34-3 2-2 7 0 10 0l12 1 4 1 9 2 12-1 11-3 11 1h4l10-6 17 1 2 1c9 2 19-3 22-11l1-1 9 1 15-5c3-1 9 4 9-5 5 0 5 3 5 7l2 3 4-1 4-2 9-4 3-3h3l8-4 6-3 26 2 7-4h18l7 1c10 3 13-6 17-12l8 4 3-1 14-3 15-2a38 38 0 01-5-1l-8-4 7-8 8-4-10-136-922 71 16 205z"/>
        <path d="M-36 193l9-5 13 1 2-2 5 1h8l1-1 42-5h7l7 3v1l12-2a9328 9328 0 0129-6l2-5 12 1 6-2 3 1 2 1v-2l13-2v1l4 2 7-1h1l17-3 1 2 4-1 18-7 3-1 4-1h9l13-1 1-4 3-2 13 1v2l22-2 10-3h6l10 5 16-5 15-3 2-1 8-4 6-2 12-1 7-2 8 5 7 1 22-9h7l5-1v-1l25-3 1 2 5 2v1h11l2 1 8-4h3l-1 1h9a6 6 0 002 0l10-6 6 3 9-1 4-1a6 6 0 001 1l1-2 6-1 1-1 10-2h2l7-5v1h4l3-1c11 0 23 2 34-3 2-2 7 0 10 0l12 1 4 1 9 2 12-1 11-3 11 1h4l10-6 17 1 2 1c9 2 19-3 22-11l1-1 9 1 15-5c3-1 9 4 9-5 5 0 5 3 5 7l2 3 4-1 4-2 9-4 3-3h3l8-4 6-3 26 2 7-4h18l7 1c10 3 13-6 17-12l8 4 3-1 14-3 15-2a37 37 0 01-5-1l-8-4 7-8 8-4-10-136-922 71 16 205z"/>
      </svg>
    </div>
    <div class="container">
      <div class="content">
        <a href="https://twitter.com" title="X logo">
          <svg viewBox="0 0 24 24" aria-hidden="true" class="x-logo"><g><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path></g></svg>
        </a>
        <h1 id="header">Nothing to see here</h1>
        <p id="description">Looks like this page doesn’t exist. Here’s a picture of a poodle sitting in a chair for your trouble.</p>

          <a id="button_search" href="/" class="button">Looking for this?</a>

      </div>
      <img id="image" src="https://abs.twimg.com/errors/ErrorState_NotFound.png" alt="A primped poodle with a bow in its hair sitting in a chair like a human.">
      <div class="footer">
        <ul>
          <li><a href="https://twitter.com/" id="footer_home">Home</a></li>
          <li><a href="https://status.twitterstat.us/" id="footer_status">Status</a></li>
          <li><a href="https://twitter.com/tos" id="footer_tos">Terms of Service</a></li>
          <li><a href="https://twitter.com/privacy" id="footer_privacy">Privacy Policy</a></li>
          <li><a href="https://support.twitter.com/articles/20170514" id="footer_cookie">Cookie Policy</a></li>
          <li><a href="https://legal.twitter.com/imprint" id="footer_imprint">Imprint</a></li>
          <li><a href="https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html" id="footer_ads">Ads info</a></li>
          <li dir="ltr">&copy; X Corp. <span id="copyright-year">&emsp;&emsp;&emsp;&emsp;</span></li>
        </ul>
      </div>
    </div>
  </body>
  <script src="https://abs.twimg.com/errors/404-8651f633fd193e0b546010676a4fac06.js"></script>

;document.getElementById("tweet-65152").innerHTML = tweet["html"];<p></p>
<p>The <a href="https://www.nobelprize.org/prizes/physics/2024/summary/">Nobel Prize in Physics 2024</a> was awarded to <a href="https://en.wikipedia.org/wiki/John_Hopfield">John J. Hopfield</a> and <a href="https://www.cs.toronto.edu/~hinton/">Geoffrey E. Hinton</a> “for foundational discoveries and inventions that enable machine learning with artificial neural networks”</p>
</section>
<section id="learning-objectives" class="slide level2">
<h2>Learning objectives</h2>
<ul>
<li><strong>Explain</strong> perceptrons and MLPs: structure, function, history, and limitations.</li>
<li><strong>Describe</strong> activation functions: their role in enabling complex pattern learning.</li>
<li><strong>Implement</strong> a feedforward neural network with Keras on Fashion-MNIST.</li>
<li><strong>Interpret</strong> neural network training and results: visualization and evaluation metrics.</li>
<li><strong>Familiarize</strong> with deep learning frameworks: PyTorch, TensorFlow, and Keras for model building and deployment.</li>
</ul>
<aside class="notes">
<p>As stated at the beginning of this course, there are two primary schools of thought in artificial intelligence: <strong>symbolic AI</strong> and <strong>connectionism</strong>. While the symbolic approach initially dominated the field, the connectionist approach is now more prevalent. We will now focus on <strong>connectionism</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>

</section>
<section id="neural-networks-nn" class="slide level2">
<h2>Neural Networks (NN)</h2>
<p>We now shift our focus to a family of <strong>machine learning models</strong> that draw inspiration from the structure and function of <strong>biological neural networks</strong> found in animals.</p>

<aside><div>
<p>AKA <strong>artificial neural networks</strong> or <strong>neural nets</strong>, abbreviated as ANN or NN.</p>
</div></aside></section>
<section id="machine-learning-problems" class="slide level2">
<h2>Machine Learning Problems</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><a href="../../assets/images/ai_ml_dl-en.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img data-src="../../assets/images/ai_ml_dl-en.png"></a></p>
</div><div class="column" style="width:50%;">
<ul>
<li><p><strong>Supervised Learning</strong>: Classification, Regression</p></li>
<li><p><strong>Unsupervised Learning</strong>: Autoencoders, Self-Supervised</p></li>
<li><p><strong>Reinforcement Learning</strong>: Now an Integral Component</p></li>
</ul>
</div></div>
<aside class="notes">
<p>We will begin our exploration within the framework of supervised learning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="a-neuron" class="slide level2">
<h2>A neuron</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://upload.wikimedia.org/wikipedia/commons/3/36/Components_of_neuron.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img data-src="https://upload.wikimedia.org/wikipedia/commons/3/36/Components_of_neuron.jpg" class="quarto-figure quarto-figure-center" height="500"></a></p>
</figure>
</div>

<aside class="notes">
<p>In the study of artificial intelligence, it is logical to derive inspiration from the most well-understood form of intelligence: the human brain. The brain is composed of a complex network of neurons, which together form biological neural networks. Although each neuron exhibits relatively simple behavior, it is connected to thousands of other neurons, contributing to the intricate functionality of these networks.</p>
<p>A neuron can be conceptualized as a basic computational unit, and the complexity of brain function arises from the interconnectedness of these units.</p>
<p>Yann LeCun and other researchers have frequently noted that artificial neural networks used in machine learning resemble biological neural networks in much the same way that an airplane’s wings resemble those of a bird.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Attribution:</strong> Jennifer Walinga, <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a></p>
</div></aside></section>
<section id="interconnected-neurons" class="slide level2 nostretch">
<h2>Interconnected neurons</h2>
<iframe data-external="1" src="https://www.youtube.com/embed/uDnHOUPRTYM" width="844" height="475" title="Molecular Mechanism of Synaptic Function | HHMI BioInteractive Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<aside class="notes">
<p>From biology, we essentially adopt the concept of simple computational units that are interconnected to form a network, which collectively performs complex computations.</p>
<p>While research into understanding biological neural networks is undeniably important, the field of artificial neural networks has incorporated only a limited number of key concepts from this research.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Attribution</strong>: <a href="https://www.biointeractive.org/classroom-resources/molecular-mechanism-synaptic-function">Molecular Mechanism of Synaptic Function</a> from the Howard Hughes Medical Institute (HHMI). Published on YouTube on 2018-11-15.</p>
</div></aside></section>
<section id="connectionist" class="slide level2 nostretch">
<h2>Connectionist</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="https://raw.githubusercontent.com/alexlenail/NN-SVG/master/example.svg" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img data-src="https://raw.githubusercontent.com/alexlenail/NN-SVG/master/example.svg" class="quarto-figure quarto-figure-center" style="width:70.0%"></a></p>
</figure>
</div>

<aside class="notes">
<p>Another characteristic of biological neural networks that we adopt is the organization of neurons into layers, particularly evident in the cerebral cortex.</p>
<p>The term “connectionists” comes from the idea that nodes in these models are interconnected. Instead of being explicitly programmed, these models learn their behavior through training. Deep learning is a connectionist approach.</p>
<p><strong>Neural networks</strong> (<strong>NNs</strong>) consist of layers of <strong>interconnected nodes (neurons)</strong>, each <strong>connection</strong> having an associated <strong>weight</strong>.</p>
<p>Neural networks process input data through these weighted connections, and <strong>learning</strong> occurs by <strong>adjusting the weights</strong> based on <strong>errors</strong> in the <strong>training data</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Attribution</strong>: LeNail, (2019). NN-SVG: Publication-Ready Neural Network Architecture Schematics. Journal of Open Source Software, 4(33), 747, https://doi.org/10.21105/joss.00747 (<a href="https://github.com/alexlenail/NN-SVG">GitHub</a>)</p>
</div></aside></section>
<section id="hierarchy-of-concepts" class="slide level2">
<h2>Hierarchy of concepts</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/cnn_lecun_et_al_nature.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img data-src="../../assets/images/cnn_lecun_et_al_nature.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></a></p>
</figure>
</div>

<aside class="notes">
<p>In the book “Deep Learning” <span class="citation" data-cites="goodfellow:2016">(<a href="#/references" role="doc-biblioref" onclick="">Goodfellow, Bengio, and Courville 2016</a>)</span>, authors Goodfellow, Bengio, and Courville define deep learning as a subset of machine learning that enables computers to “understand the world in terms of a hierarchy of concepts.”</p>
<p>This hierarchical approach is one of deep learning’s most significant contributions. It reduces the need for manual feature engineering and redirects the focus toward the engineering of neural network architectures.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><strong>Attribution</strong>: <span class="citation" data-cites="lecun:2015dt">LeCun, Bengio, and Hinton (<a href="#/references" role="doc-biblioref" onclick="">2015</a>)</span></p>
</div></aside></section></section>
<section>
<section id="basics" class="title-slide slide level1 center">
<h1>Basics</h1>

</section>
<section id="computations-with-neurodes" class="slide level2">
<h2>Computations with neurodes</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_threhold_unit.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img data-src="../../assets/images/ann_threhold_unit.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></a></p>
</figure>
</div>
<p>where <span class="math inline">\(x_1, x_2 \in \{0,1\}\)</span> and <span class="math inline">\(f(z)\)</span> is an <strong>indicator function</strong>: <span class="math display">\[
f(z)= \begin{cases}0, &amp; z&lt;\theta \\ 1, &amp; z \geq \theta\end{cases}
\]</span></p>

<aside class="notes">
<p>In mathematics, <span class="math inline">\(f(z)\)</span>, as defined above, is known as an <strong>indicator function</strong> or a <strong>characteristic function</strong>.</p>
<p>These neurodes have one or more binary inputs, taking a value of 0 or 1, and one binary output.</p>
<p>They showed that such units could implement Boolean functions such as <strong>AND</strong>, <strong>OR</strong>, and <strong>NOT</strong>.</p>
<p>But also that networks of such units can compute any logical proposition.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="mcculloch:1943dq">McCulloch and Pitts (<a href="#/references" role="doc-biblioref" onclick="">1943</a>)</span> termed artificial neurons, <strong>neurodes</strong>, for <strong>“neuron”</strong> + <strong>“node”</strong>.</p>
</div></aside></section>
<section id="computations-with-neurodes-1" class="slide level2">
<h2>Computations with neurodes</h2>
<p><span class="math display">\[
y = f(x_1 + x_2)= \begin{cases}0, &amp; x_1 + x_2 &lt;\theta \\ 1, &amp; x_1 + x_2 \geq \theta\end{cases}
\]</span></p>
<ul>
<li><p>With <span class="math inline">\(\theta = 2\)</span>, the neurode implements an <strong>AND</strong> logic gate.</p></li>
<li><p>With <span class="math inline">\(\theta = 1\)</span>, the neurode implements an <strong>OR</strong> logic gate.</p></li>
</ul>

<aside class="notes">
<p>With <span class="math inline">\(\theta = 1\)</span>, $x_1 {1} and <span class="math inline">\(x_2\)</span> multiplied by (-1), <span class="math inline">\(y = 0\)</span> when <span class="math inline">\(x_2 = 1\)</span>, <span class="math inline">\(y = 1\)</span>, if <span class="math inline">\(x_2 = 0\)</span>.</p>
<p><span class="math display">\[
y = f(x_1 + (-1) x_2)= \begin{cases}0, &amp; x_1 + x_2 &lt;\theta \\ 1, &amp; x_1 + (-1) x_2 \geq \theta\end{cases}
\]</span></p>
<p>Neurons can be broadly categorized into two primary types: <strong>excitatory</strong> and <strong>inhibitory</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>More <strong>complex logic</strong> can be constructed by multiplying the inputs by <strong>-1</strong>, which is interpreted as <strong>inhibitory</strong>. Namely, this allows building a logical NOT.</p>
</div></aside></section>
<section id="computations-with-neurodes-2" class="slide level2">
<h2>Computations with neurodes</h2>
<ul>
<li class="fragment"><p><strong>Digital computations</strong> can be broken down into a <strong>sequence of logical operations</strong>, enabling neurode networks to <strong>execute any computation</strong>.</p></li>
<li class="fragment"><p><span class="citation" data-cites="mcculloch:1943dq">McCulloch and Pitts (<a href="#/references" role="doc-biblioref" onclick="">1943</a>)</span> did <strong>not</strong> focus on <strong>learning</strong> parameter <span class="math inline">\(\theta\)</span>.</p></li>
<li class="fragment"><p>They introduced a machine that <strong>computes any function</strong> but <strong>cannot learn</strong>.</p></li>
</ul>
<aside class="notes">
<p>From this work, we take the idea that networks of such units perform computations. Signal propagates from one end of the network to compute a result.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="threshold-logic-unit" class="slide level2">
<h2>Threshold logic unit</h2>
<p><a href="../../assets/images/ann_threhold_unit-00-en.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img data-src="../../assets/images/ann_threhold_unit-00-en.png"></a></p>

<aside class="notes">
<p>In 1957, Frank Rosenblatt developed a conceptually distinct model of a neuron known as the <strong>threshold logic unit</strong>, which he published in 1958.</p>
<p>In this model, both the inputs and the output of the neuron are represented as <strong>real values</strong>. Notably, each input connection has an associated weight.</p>
<p>The left section of the neuron, denoted by the sigma symbol, represents the computation of a weighted sum of its inputs, expressed as <span class="math inline">\(\theta_1 x_1 + \theta_2 x_2 + \ldots + \theta_D x_D + b\)</span>.</p>
<p>This sum is then processed through a step function, right section of the neuron, to generate the output.</p>
<p>Here, <span class="math inline">\(x^T \theta\)</span> represents the dot product of two vectors: <span class="math inline">\(x\)</span> and <span class="math inline">\(\theta\)</span>. Here, <span class="math inline">\(x^T\)</span> denotes the transpose of the vector <span class="math inline">\(x\)</span>, converting it from a row vector to a column vector, allowing the dot product operation to be performed with the vector <span class="math inline">\(\theta\)</span>.</p>
<p>The dot product <span class="math inline">\(x^T \theta\)</span> is then a scalar given by:</p>
<p><span class="math display">\[
x^T \theta = x^{(1)} \theta_1 + x^{(2)} \theta_2 + \cdots + x_{(D)} \theta_D
\]</span></p>
<p>where <span class="math inline">\(x^{(j)}\)</span> and <span class="math inline">\(theta_j\)</span> are the components of the vectors <span class="math inline">\(x\)</span> and <span class="math inline">\(\theta\)</span>, respectively.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="Rosenblatt:1958aa">Rosenblatt (<a href="#/references" role="doc-biblioref" onclick="">1958</a>)</span></p>
</div></aside></section>
<section id="simple-step-functions" class="slide level2">
<h2>Simple Step Functions</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/heavyside.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img data-src="../../assets/images/heavyside.png" class="nostretch quarto-figure quarto-figure-center" style="width:50.0%"></a></p>
</figure>
</div>
<p><strong><span class="math inline">\(\text{heaviside}(t)\)</span> =</strong></p>
<ul>
<li><p>1, if <span class="math inline">\(t \geq 0\)</span></p></li>
<li><p>0, if <span class="math inline">\(t &lt; 0\)</span></p></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/sign.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img data-src="../../assets/images/sign.png" class="nostretch quarto-figure quarto-figure-center" style="width:50.0%"></a></p>
</figure>
</div>
<p><strong><span class="math inline">\(\text{sign}(t)\)</span> =</strong></p>
<ul>
<li><p>1, if <span class="math inline">\(t &gt; 0\)</span></p></li>
<li><p>0, if <span class="math inline">\(t = 0\)</span></p></li>
<li><p>-1, if <span class="math inline">\(t &lt; 0\)</span></p></li>
</ul>
</div></div>
<aside class="notes">
<p>Common <strong>step functions</strong> include the <strong>heavyside function</strong> (0 if the input is negative and 1 otherwise) or the <strong>sign</strong> function (-1 if the input is negative, 0 if the input is zero, 1 otherwise).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="notation" class="slide level2">
<h2>Notation</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_threhold_unit-01-en.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img data-src="../../assets/images/ann_threhold_unit-01-en.png" class="quarto-figure quarto-figure-center" height="450"></a></p>
</figure>
</div>

<aside><div>
<p>Add an extra feature with a fixed value of 1 to the input. Associate it with weight <span class="math inline">\(b = \theta_{0}\)</span>, where <span class="math inline">\(b\)</span> is the bias/intercept term.</p>
</div></aside></section>
<section id="notation-1" class="slide level2">
<h2>Notation</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_threhold_unit-02-en.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img data-src="../../assets/images/ann_threhold_unit-02-en.png" class="quarto-figure quarto-figure-center" height="450"></a></p>
</figure>
</div>

<aside class="notes">
<p>The threshold logic unit is analogous to logistic regression, with the primary distinction being the substitution of the logistic (sigmoid) function with a step function. Similar to logistic regression, the perceptron is employed for classification tasks.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="math inline">\(\theta_{0} = b\)</span> is the bias/intercept term.</p>
</div></aside></section>
<section id="perceptron" class="slide level2">
<h2>Perceptron</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_perceptron-00-en.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img data-src="../../assets/images/ann_perceptron-00-en.png" class="quarto-figure quarto-figure-center" height="450"></a></p>
</figure>
</div>

<aside class="notes">
<p>Since the threshold logic units in this single layer also generate the output, it is referred to as the <strong>output layer</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>A <strong>perceptron</strong> consists of one or more <strong>threshold logic units</strong> arranged in a <strong>single layer</strong>, with each unit connected to all inputs. This configuration is referred to as <strong>fully connected</strong> or <strong>dense</strong>.</p>
</div></aside></section>
<section id="perceptron-1" class="slide level2">
<h2>Perceptron</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_perceptron-00-en.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img data-src="../../assets/images/ann_perceptron-00-en.png" class="quarto-figure quarto-figure-center" height="450"></a></p>
</figure>
</div>

<aside class="notes">
<p>Classification tasks, can be further divided into <strong>multilabel</strong> and <strong>multiclass</strong> classification.</p>
<ol type="1">
<li><p><strong>Multiclass Classification:</strong></p>
<ul>
<li><p>In multiclass classification, each instance is assigned to one and only one class out of a set of three or more possible classes. The classes are mutually exclusive, meaning that an instance cannot belong to more than one class at the same time.</p></li>
<li><p><strong>Example:</strong> Classifying an image as either a cat, dog, or bird. Each image can only belong to one of these categories.</p></li>
</ul></li>
<li><p><strong>Multilabel Classification:</strong></p>
<ul>
<li><p>In multilabel classification, each instance can be associated with multiple classes simultaneously. The classes are not mutually exclusive, allowing for the possibility that an instance can belong to several classes at once.</p></li>
<li><p><strong>Example:</strong> Tagging an image with multiple attributes such as “outdoor,” “sunset,” and “beach.” The image can simultaneously belong to all these labels.</p></li>
</ul></li>
</ol>
<p>The key difference lies in the relationship between classes: <strong>multiclass classification deals with a single label per instance</strong>, while <strong>multilabel classification handles multiple labels for each instance</strong>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>As this perceptron generates multiple outputs simultaneously, it performs <strong>multiple binary predictions</strong>, making it as a <strong>multilabel classifier</strong> (can also be used as multiclass classifier).</p>
</div></aside></section>
<section id="notation-2" class="slide level2">
<h2>Notation</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_perceptron-01-en.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img data-src="../../assets/images/ann_perceptron-01-en.png" class="quarto-figure quarto-figure-center" height="450"></a></p>
</figure>
</div>

<aside><div>
<p>As before, introduce an additional feature with a value of 1 to the input. <strong>Assign a bias <span class="math inline">\(b\)</span> to each neuron.</strong> Each incoming connection <strong>implicitly</strong> has an associated weight.</p>
</div></aside></section>
<section id="notation-3" class="slide level2">
<h2>Notation</h2>
<ul>
<li class="fragment"><p><span class="math inline">\(X\)</span> is the input <strong>data matrix</strong> where <strong>each row corresponds to an example</strong> and <strong>each column represents one of the <span class="math inline">\(D\)</span> features</strong>.</p></li>
<li class="fragment"><p><span class="math inline">\(W\)</span> is the <strong>weight matrix</strong>, structured with one <strong>row per input (feature)</strong> and <strong>one column per neuron</strong>.</p></li>
<li class="fragment"><p><strong>Bias terms</strong> can be represented separately; both approaches appear in the literature. Here, <span class="math inline">\(b\)</span> is a vector with a <strong>length equal to the number of neurons</strong>.</p></li>
</ul>

<aside><div>
<p>With neural networks, the <strong>parameters</strong> of the model are often reffered to as <span class="math inline">\(w\)</span> (vector) or <span class="math inline">\(W\)</span> (matrix), rather than <span class="math inline">\(\theta\)</span>.</p>
</div></aside></section>
<section id="discussion" class="slide level2">
<h2>Discussion</h2>
<ul>
<li><p>The algorithm to <strong>train</strong> the perceptron closely resembles stochastic gradient descent.</p>
<ul>
<li>In the <strong>interest of time</strong> and to <strong>avoid confusion</strong>, we will skip this algorithm and focus on <strong>multilayer perception</strong> (MLP) and its training algorithm, <strong>backpropagation</strong>.</li>
</ul></li>
</ul>
</section>
<section id="historical-note-and-justification" class="slide level2">
<h2>Historical Note and Justification</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_perceptron_xor.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img data-src="../../assets/images/ann_perceptron_xor.png" class="quarto-figure quarto-figure-center" height="425"></a></p>
</figure>
</div>

<aside class="notes">
<p>This limitation also applies to other linear classifiers, such as logistic regression.</p>
<p>Consequently, due to these limitations and a lack of practical applications, some researchers abandoned the perceptron.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="Minsky:1969aa">Minsky and Papert (<a href="#/references" role="doc-biblioref" onclick="">1969</a>)</span> demonstrated the limitations of perceptrons, notably their inability to solve <strong>exclusive OR</strong> (XOR) classification problems: <span class="math inline">\({([0,1],\mathrm{true}), ([1,0],\mathrm{true}), ([0,0],\mathrm{false}), ([1,1],\mathrm{false})}\)</span>.</p>
</div></aside></section>
<section id="multilayer-perceptron" class="slide level2">
<h2>Multilayer Perceptron</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_mlp_xor.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img data-src="../../assets/images/ann_mlp_xor.png" class="quarto-figure quarto-figure-center" height="425"></a></p>
</figure>
</div>

<aside><div>
<p>A <strong>multilayer perceptron</strong> (MLP) includes an input layer and one or more layers of threshold logic units. Layers that are neither input nor output are termed <strong>hidden layers</strong>.</p>
</div></aside></section>
<section id="xor-classification-problem" class="slide level2">
<h2>XOR Classification problem</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th><span class="math inline">\(x^{(1)}\)</span></th>
<th><span class="math inline">\(x^{(2)}\)</span></th>
<th><span class="math inline">\(y\)</span></th>
<th><span class="math inline">\(o_1\)</span></th>
<th><span class="math inline">\(o_2\)</span></th>
<th><span class="math inline">\(o_3\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

<aside class="notes">
<p>I developed an Excel spreadsheet to verify that the proposed multilayer perceptron effectively solves the XOR classification problem.</p>
<p>The step function used in the above model is the heavyside function.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="math inline">\(x^{(1)}\)</span> and <span class="math inline">\(x^{(2)}\)</span> are two attributes, <span class="math inline">\(y\)</span> is the target, <span class="math inline">\(o_1\)</span>, <span class="math inline">\(o_2\)</span>, and <span class="math inline">\(o_3 = h_\theta(x)\)</span>, are the output of the top left, bottom left, and right threshold units. Clearly <span class="math inline">\(h_\theta(x) = y, \forall x \in X\)</span>. The challenge during Rosenblatt’s time was the lack of algorithms to train multi-layer networks.</p>
</div></aside></section>
<section id="feedforward-neural-network-fnn" class="slide level2">
<h2>Feedforward Neural Network (FNN)</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/ann_mlp-07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img data-src="../../assets/images/ann_mlp-07.png" class="quarto-figure quarto-figure-center" height="425"></a></p>
</figure>
</div>

<aside class="notes">
<p>The network consists of <strong>three layers</strong>: input, hidden, and output. The <strong>input layer</strong> contains two nodes, the <strong>hidden layer</strong> comprises three nodes, and the <strong>output layer</strong> has two nodes. Additional hidden layers and nodes per layer can be added, which will be discussed later.</p>
<p>It is often useful to include explicit input nodes that do not perform calculations, known as <strong>input units</strong> or <strong>input neurons</strong>. These nodes act as placeholders to introduce input features into the network, passing data directly to the next layer without transformation. In the network diagram, these are the light blue nodes on the left, labeled 1 and 2. Typically, <strong>the number of input units corresponds to the number of features</strong>.</p>
<p>For clarity, nodes are labeled to facilitate discussion of the weights between them, such as <span class="math inline">\(w_{1,5}\)</span> between nodes 1 and 5. Similarly, the output of a node is denoted by <span class="math inline">\(o_k\)</span>, where <span class="math inline">\(k\)</span> represents the node’s label. For example, for <span class="math inline">\(k=3\)</span>, the output would be <span class="math inline">\(o_3\)</span>.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>Information in this architecture flows unidirectionally—from left to right, moving from input to output. Consequently, it is termed a <strong>feedforward neural network</strong>.</p>
</div></aside></section>
<section id="forward-pass-computatation" class="slide level2">
<h2>Forward Pass (Computatation)</h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><a href="../../assets/images/ann_mlp-07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img data-src="../../assets/images/ann_mlp-07.png"></a></p>
</div><div class="column" style="width:65%;">
<p><span class="math inline">\(o3 = \sigma(w_{13} x^{(1)}+ w_{23} x^{(2)} + b_3)\)</span></p>
<p><span class="math inline">\(o4 = \sigma(w_{14} x^{(1)}+ w_{24} x^{(2)} + b_4)\)</span></p>
<p><span class="math inline">\(o5 = \sigma(w_{15} x^{(1)}+ w_{25} x^{(2)} + b_5)\)</span></p>
<p><span class="math inline">\(o6 = \sigma(w_{36} o_3 + w_{46} o_4 + w_{56} o_5 + b_6)\)</span></p>
<p><span class="math inline">\(o7 = \sigma(w_{37} o_3 + w_{47} o_4 + w_{57} o_5 + b_7)\)</span></p>
</div></div>

<aside class="notes">
<p>To simplify the figure, I have opted not to display the bias terms, though they remain crucial components. Specifically, <span class="math inline">\(b_3\)</span> represents the bias term associated with node 3.</p>
<p>If bias terms were not significant, the training process would naturally reduce them to zero. Bias terms are essential as they enable the adjustment of the decision boundary, allowing the model to learn more complex patterns that weights alone cannot capture. By offering additional degrees of freedom, they also contribute to faster convergence during training.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>First, it’s important to <strong>understand the information flow</strong>: this network <strong>computes</strong> two outputs from its inputs.</p>
</div></aside></section>
<section id="forward-pass-computatation-1" class="slide level2">
<h2>Forward Pass (Computatation)</h2>
<div id="c656575e" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a></a></span>
<span id="cb1-3"><a></a><span class="co"># Sigmoid function</span></span>
<span id="cb1-4"><a></a></span>
<span id="cb1-5"><a></a><span class="kw">def</span> sigma(x):</span>
<span id="cb1-6"><a></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>x))</span>
<span id="cb1-7"><a></a></span>
<span id="cb1-8"><a></a><span class="co"># Input (two attributes) vector, one example of our trainig set</span></span>
<span id="cb1-9"><a></a></span>
<span id="cb1-10"><a></a>x1, x2 <span class="op">=</span> (<span class="fl">0.5</span>, <span class="fl">0.9</span>)</span>
<span id="cb1-11"><a></a></span>
<span id="cb1-12"><a></a><span class="co"># Initializing the weights of layers 2 and 3 to random values</span></span>
<span id="cb1-13"><a></a></span>
<span id="cb1-14"><a></a>w13, w14, w15, w23, w24, w25 <span class="op">=</span> np.random.uniform(low<span class="op">=-</span><span class="dv">1</span>, high<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb1-15"><a></a>w36, w46, w56, w37, w47, w57 <span class="op">=</span> np.random.uniform(low<span class="op">=-</span><span class="dv">1</span>, high<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb1-16"><a></a></span>
<span id="cb1-17"><a></a><span class="co"># Initializing all 5 bias terms to random values</span></span>
<span id="cb1-18"><a></a></span>
<span id="cb1-19"><a></a>b3, b4, b5, b6, b7 <span class="op">=</span> np.random.uniform(low<span class="op">=-</span><span class="dv">1</span>, high<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb1-20"><a></a></span>
<span id="cb1-21"><a></a>o3 <span class="op">=</span> sigma(w13 <span class="op">*</span> x1 <span class="op">+</span> w23 <span class="op">*</span> x2 <span class="op">+</span> b3)</span>
<span id="cb1-22"><a></a>o4 <span class="op">=</span> sigma(w14 <span class="op">*</span> x1 <span class="op">+</span> w24 <span class="op">*</span> x2 <span class="op">+</span> b4)</span>
<span id="cb1-23"><a></a>o5 <span class="op">=</span> sigma(w15 <span class="op">*</span> x1 <span class="op">+</span> w25 <span class="op">*</span> x2 <span class="op">+</span> b5)</span>
<span id="cb1-24"><a></a>o6 <span class="op">=</span> sigma(w36 <span class="op">*</span> o3 <span class="op">+</span> w46 <span class="op">*</span> o4 <span class="op">+</span> w56 <span class="op">*</span> o5 <span class="op">+</span> b6)</span>
<span id="cb1-25"><a></a>o7 <span class="op">=</span> sigma(w37 <span class="op">*</span> o3 <span class="op">+</span> w47 <span class="op">*</span> o4 <span class="op">+</span> w57 <span class="op">*</span> o5 <span class="op">+</span> b7)</span>
<span id="cb1-26"><a></a></span>
<span id="cb1-27"><a></a>(o6, o7)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>(np.float64(0.46460973054399307), np.float64(0.24291381296138898))</code></pre>
</div>
</div>
<aside class="notes">
<p>The example above illustrates the computation process with specific values. Before training a neural network, it is standard practice to initialize the weights and biases with random values. Gradient descent is then employed to iteratively adjust these parameters, aiming to minimize the loss function.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="forward-pass-computatation-2" class="slide level2 nostretch">
<h2>Forward Pass (Computatation)</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/nn-7layers-bezier-nobias.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img data-src="../../assets/images/nn-7layers-bezier-nobias.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></a></p>
</figure>
</div>

<aside><div>
<p>The information flow remains consistent even in more <strong>complex networks</strong>. Networks with many layers are called <strong>deep neural networks</strong> (DNN).</p>
<p>Produced using <strong>NN-SVG</strong>, <span class="citation" data-cites="LeNail:2019aa">LeNail (<a href="#/references" role="doc-biblioref" onclick="">2019</a>)</span>.</p>
</div></aside></section>
<section id="forward-pass-computatation-3" class="slide level2 nostretch">
<h2>Forward Pass (Computatation)</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="../../assets/images/nn-7layers-bezier-bias.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img data-src="../../assets/images/nn-7layers-bezier-bias.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></a></p>
</figure>
</div>

<aside><div>
<p>Same network with <strong>bias terms shown</strong>.</p>
<p>Produced using <strong>NN-SVG</strong>, <span class="citation" data-cites="LeNail:2019aa">LeNail (<a href="#/references" role="doc-biblioref" onclick="">2019</a>)</span>.</p>
</div></aside></section>
<section id="activation-function" class="slide level2">
<h2>Activation Function</h2>
<ul>
<li class="fragment"><p>As will be discussed later, the training algorithm, known as <strong>backpropagation</strong>, employs <strong>gradient descent</strong>, necessitating the calculation of the <strong>partial derivatives of the loss function</strong>.</p></li>
<li class="fragment"><p>The <strong>step function</strong> in the multilayer perceptron had to be replaced, as it consists only of flat surfaces. <strong>Gradient descent cannot progress on flat surfaces due to their zero derivative</strong>.</p></li>
</ul>
</section>
<section id="activation-function-1" class="slide level2">
<h2>Activation Function</h2>
<ul>
<li class="fragment"><p><strong>Nonlinear activation functions are paramount</strong> because, without them, multiple layers in the network would only compute a linear function of the inputs.</p></li>
<li class="fragment"><p>According to the <strong>Universal Approximation Theorem</strong>, sufficiently large deep networks with nonlinear activation functions can <strong>approximate any continuous function</strong>. See <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">Universal Approximation Theorem</a>.</p></li>
</ul>
</section>
<section id="sigmoid" class="slide level2">
<h2>Sigmoid</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div id="87e60329" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-3-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-20"><img data-src="slides_files/figure-revealjs/cell-3-output-1.png" width="794" height="411"></a></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<p><span class="math display">\[
\sigma(t) = \frac{1}{1 + e^{-t}}
\]</span></p>
</div></div>
</section>
<section id="hyperbolic-tangent-function" class="slide level2">
<h2>Hyperbolic Tangent Function</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div id="e025f7dc" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-21"><img data-src="slides_files/figure-revealjs/cell-4-output-1.png" width="813" height="411"></a></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<p><span class="math display">\[
\tanh(t) = 2 \sigma(2t) - 1
\]</span></p>
</div></div>

<aside><div>
<p>This S-shaped curve, similar to the sigmoid function, produces output values ranging from -1 to 1. According to <span class="citation" data-cites="Geron:2022aa">Géron (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span>, this range helps each layer’s output to be approximately centered around 0 at the start of training, thereby <strong>accelerating convergence</strong>.</p>
</div></aside></section>
<section id="rectified-linear-unit-function-relu" class="slide level2">
<h2>Rectified linear unit function (ReLU)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div id="80d6ef23" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-22"><img data-src="slides_files/figure-revealjs/cell-5-output-1.png" width="790" height="411"></a></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<p><span class="math display">\[
\mathrm{ReLU}(t) = \max(0, t)
\]</span></p>
</div></div>

<aside><div>
<p>Although the <strong>ReLU function</strong> is not differentiable at <span class="math inline">\(t=0\)</span> and has a derivative of 0 for <span class="math inline">\(t&lt;0\)</span>, it performs quite well in practice and is computationally efficient. Consequently, it has become the <strong>default activation function</strong>.</p>
</div></aside></section>
<section id="common-activation-functions" class="slide level2">
<h2>Common Activation Functions</h2>
<div id="6bce5c76" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-23"><img data-src="slides_files/figure-revealjs/cell-6-output-1.png" width="867" height="291"></a></p>
</figure>
</div>
</div>
</div>

<aside><div>
<p><span class="citation" data-cites="Geron:2022aa">Géron (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span> – <a href="https://github.com/ageron/handson-ml3/blob/main/10_neural_nets_with_keras.ipynb">10_neural_nets_with_keras.ipynb</a></p>
</div></aside></section></section>
<section>
<section id="universal-approximation" class="title-slide slide level1 center">
<h1>Universal Approximation</h1>

</section>
<section id="definition" class="slide level2">
<h2>Definition</h2>
<p>The <strong>universal approximation theorem (UAT)</strong> states that a feedforward neural network with a single hidden layer containing a finite number of neurons can <strong>approximate any continuous function</strong> on a compact subset of <span class="math inline">\(\mathbb{R}^n\)</span>, given appropriate weights and activation functions.</p>

<aside class="notes">
<p>In mathematical terms, a subset of <span class="math inline">\(\mathbb{R}^n\)</span> is considered <strong>compact</strong> if it is both <strong>closed</strong> and <strong>bounded</strong>.</p>
<ul>
<li><p><strong>Closed</strong>: A set is closed if it contains all its boundary points. In other words, it includes its limit points or accumulation points.</p></li>
<li><p><strong>Bounded</strong>: A set is bounded if there exists a real number (M) such that the distance between any two points in the set is less than <span class="math inline">\(M\)</span>.</p></li>
</ul>
<p>In the context of the universal approximation theorem, compactness ensures that the function being approximated is defined on a finite and well-behaved region, which is crucial for the theoretical guarantees provided by the theorem.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><span class="citation" data-cites="Cybenko:1989aa">Cybenko (<a href="#/references" role="doc-biblioref" onclick="">1989</a>)</span>; <span class="citation" data-cites="Hornik:1989aa">Hornik, Stinchcombe, and White (<a href="#/references" role="doc-biblioref" onclick="">1989</a>)</span></p>
</div></aside></section>
<section id="demonstration-with-code" class="slide level2">
<h2>Demonstration with code</h2>
<div id="0646aeb8" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a></a></span>
<span id="cb3-3"><a></a><span class="co"># Defining the function to be approximated</span></span>
<span id="cb3-4"><a></a></span>
<span id="cb3-5"><a></a><span class="kw">def</span> f(x):</span>
<span id="cb3-6"><a></a>  <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> x<span class="op">**</span><span class="dv">3</span> <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">5</span> <span class="op">*</span> x <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb3-7"><a></a></span>
<span id="cb3-8"><a></a><span class="co"># Generating a dataset, x in [-4,2), f(x) as above</span></span>
<span id="cb3-9"><a></a></span>
<span id="cb3-10"><a></a>X <span class="op">=</span> <span class="dv">6</span> <span class="op">*</span> np.random.rand(<span class="dv">1000</span>, <span class="dv">1</span>) <span class="op">-</span> <span class="dv">4</span></span>
<span id="cb3-11"><a></a></span>
<span id="cb3-12"><a></a>y <span class="op">=</span> f(X.flatten())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="increasing-the-number-of-neurons" class="slide level2">
<h2>Increasing the number of neurons</h2>
<div id="7b107e2a" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPRegressor</span>
<span id="cb4-2"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb4-3"><a></a></span>
<span id="cb4-4"><a></a>X_train, X_valid, y_train, y_valid <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-5"><a></a></span>
<span id="cb4-6"><a></a>models <span class="op">=</span> []</span>
<span id="cb4-7"><a></a></span>
<span id="cb4-8"><a></a>sizes <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">100</span>]</span>
<span id="cb4-9"><a></a></span>
<span id="cb4-10"><a></a><span class="cf">for</span> i, n <span class="kw">in</span> <span class="bu">enumerate</span>(sizes):</span>
<span id="cb4-11"><a></a></span>
<span id="cb4-12"><a></a>  models.append(MLPRegressor(hidden_layer_sizes<span class="op">=</span>[n], max_iter<span class="op">=</span><span class="dv">5000</span>, random_state<span class="op">=</span><span class="dv">42</span>))</span>
<span id="cb4-13"><a></a></span>
<span id="cb4-14"><a></a>  models[i].fit(X_train, y_train) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<aside><div>
<p><a href="https://scikit-learn.org/dev/modules/generated/sklearn.neural_network.MLPRegressor.html">MLPRegressor</a> is a multi-layer perceptron regressor from sklearn. Its default activation function is <code>relu</code>.</p>
</div></aside></section>
<section id="increasing-the-number-of-neurons-1" class="slide level2">
<h2>Increasing the number of neurons</h2>
<div id="753a23a2" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-24"><img data-src="slides_files/figure-revealjs/cell-9-output-1.png" class="quarto-figure quarto-figure-center" width="801" height="411"></a></p>
</figure>
</div>
</div>
</div>
<aside class="notes">
<p>In the example above, I retained only 10% of the data as the test set because the function being approximated is straightforward and noise-free. This decision was made to ensure that the true curve does not overshadow the other results.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="increasing-the-number-of-neurons-2" class="slide level2">
<h2>Increasing the number of neurons</h2>
<div id="b47de643" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="slides_files/figure-revealjs/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-25"><img data-src="slides_files/figure-revealjs/cell-10-output-1.png" class="quarto-figure quarto-figure-center" width="819" height="449"></a></p>
</figure>
</div>
</div>
</div>

<aside><div>
<p>As expected, increasing neuron count reduces loss.</p>
</div></aside></section>
<section id="universal-approximation-1" class="slide level2">
<h2>Universal Approximation</h2>
<iframe data-external="1" src="https://www.youtube.com/embed/CqOfi41LfDw" width="844" height="475" title="The Essential Main Ideas of Neural Networks" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<aside class="notes">
<p>The video effectively elucidates key concepts (terminology) in neural networks, including nodes, layers, weights, and activation functions. It demonstrates the process of summing activation outputs from a preceding layer, akin to the aggregation of curves. Additionally, the video illustrates how scaling an output by a weight not only alters the amplitude of a curve but also inverts its orientation when the weight is negative. Moreover, it clearly depicts the function of bias terms in vertically shifting the curve, contingent on the sign of the bias.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p>This video effectively conveys the underlying intuition of the universal approximation theorem. (18m&nbsp;53s)</p>
</div></aside></section></section>
<section>
<section id="lets-code" class="title-slide slide level1 center">
<h1>Let’s code</h1>

</section>
<section id="frameworks" class="slide level2">
<h2>Frameworks</h2>
<p><a href="https://pytorch.org/">PyTorch</a> and <a href="https://www.tensorflow.org/">TensorFlow</a> are the leading platforms for deep learning.</p>
<ul>
<li class="fragment"><p>PyTorch has gained considerable traction in the <strong>research community</strong>. Initially developed by <strong>Meta AI</strong>, it is now part of the Linux Foundation.</p></li>
<li class="fragment"><p>TensorFlow, created by <strong>Google</strong>, is widely adopted in <strong>industry</strong> for deploying models in production environments.</p></li>
</ul>
</section>
<section id="keras" class="slide level2">
<h2>Keras</h2>
<p><a href="https://keras.io/">Keras</a> is a high-level API designed to build, train, evaluate, and execute models across various backends, including PyTorch, TensorFlow, and <a href="https://jax.readthedocs.io/en/latest/quickstart.html">JAX</a>, Google’s high-performance platform.</p>

<aside class="notes">
<p>As highlighted in previous Quotes of the Day, François Chollet, a Google engineer, is the originator and one of the primary developers of the Keras project.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><div>
<p><a href="https://keras.io/">Keras</a> is powerful enough for most projects.</p>
</div></aside></section>
<section id="fashion-mnist-dataset" class="slide level2">
<h2>Fashion-MNIST dataset</h2>
<p>“<a href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a> is a dataset of <a href="https://en.zalando.de/?_rfl=de">Zalando</a>’s article images—consisting of a training set of <strong>60,000 examples</strong> and a test set of <strong>10,000 examples</strong>. Each example is a <strong>28x28 grayscale image</strong>, associated with a label from <strong>10 classes</strong>.”</p>

<aside><div>
<p><strong>Attribution</strong>: <span class="citation" data-cites="Geron:2022aa">Géron (<a href="#/references" role="doc-biblioref" onclick="">2022</a>)</span> – <a href="https://github.com/ageron/handson-ml3/blob/main/10_neural_nets_with_keras.ipynb">10_neural_nets_with_keras.ipynb</a></p>
</div></aside></section>
<section id="loading" class="slide level2">
<h2>Loading</h2>
<div id="b1b7e83b" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb5-2"><a></a></span>
<span id="cb5-3"><a></a>fashion_mnist <span class="op">=</span> tf.keras.datasets.fashion_mnist.load_data()</span>
<span id="cb5-4"><a></a></span>
<span id="cb5-5"><a></a>(X_train_full, y_train_full), (X_test, y_test) <span class="op">=</span> fashion_mnist</span>
<span id="cb5-6"><a></a></span>
<span id="cb5-7"><a></a>X_train, y_train <span class="op">=</span> X_train_full[:<span class="op">-</span><span class="dv">5000</span>], y_train_full[:<span class="op">-</span><span class="dv">5000</span>]</span>
<span id="cb5-8"><a></a>X_valid, y_valid <span class="op">=</span> X_train_full[<span class="op">-</span><span class="dv">5000</span>:], y_train_full[<span class="op">-</span><span class="dv">5000</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<aside><div>
<p>Setting aside 5000 examples as a validation set.</p>
</div></aside></section>
<section id="exploration" class="slide level2">
<h2>Exploration</h2>
<div id="09dc596e" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a>X_train.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(55000, 28, 28)</code></pre>
</div>
</div>
<div class="fragment">
<div id="9152105f" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>X_train.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>dtype('uint8')</code></pre>
</div>
</div>
</div>
<div class="fragment">
<p>Transforming the pixel intensities from integers in the range 0 to 255 to floats in the range 0 to 1.</p>
<div id="f050be2f" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>X_train, X_valid, X_test <span class="op">=</span> X_train <span class="op">/</span> <span class="fl">255.</span>, X_valid <span class="op">/</span> <span class="fl">255.</span>, X_test <span class="op">/</span> <span class="fl">255.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="what-are-these-images-anyway" class="slide level2">
<h2>What are these images anyway!</h2>
<div id="5e75443b" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb11-2"><a></a>plt.imshow(X_train[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"binary"</span>)</span>
<span id="cb11-3"><a></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb11-4"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-15-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-26"><img data-src="slides_files/figure-revealjs/cell-15-output-1.png" width="167" height="167"></a></p>
</figure>
</div>
</div>
</div>
<div class="fragment">
<div id="cebc884b" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a>y_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>array([9, 0, 0, ..., 9, 0, 2], shape=(55000,), dtype=uint8)</code></pre>
</div>
</div>
</div>
<div class="fragment">
<p>Since the labels are integers, 0 to 9. Class names will become handy.</p>
<div id="2adea358" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>class_names <span class="op">=</span> [<span class="st">"T-shirt/top"</span>, <span class="st">"Trouser"</span>, <span class="st">"Pullover"</span>, <span class="st">"Dress"</span>, <span class="st">"Coat"</span>,</span>
<span id="cb14-2"><a></a>               <span class="st">"Sandal"</span>, <span class="st">"Shirt"</span>, <span class="st">"Sneaker"</span>, <span class="st">"Bag"</span>, <span class="st">"Ankle boot"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="first-40-images" class="slide level2">
<h2>First 40 images</h2>
<div id="0d00b4a7" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a>n_rows <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb15-2"><a></a>n_cols <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb15-3"><a></a>plt.figure(figsize<span class="op">=</span>(n_cols <span class="op">*</span> <span class="fl">1.2</span>, n_rows <span class="op">*</span> <span class="fl">1.2</span>))</span>
<span id="cb15-4"><a></a><span class="cf">for</span> row <span class="kw">in</span> <span class="bu">range</span>(n_rows):</span>
<span id="cb15-5"><a></a>    <span class="cf">for</span> col <span class="kw">in</span> <span class="bu">range</span>(n_cols):</span>
<span id="cb15-6"><a></a>        index <span class="op">=</span> n_cols <span class="op">*</span> row <span class="op">+</span> col</span>
<span id="cb15-7"><a></a>        plt.subplot(n_rows, n_cols, index <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb15-8"><a></a>        plt.imshow(X_train[index], cmap<span class="op">=</span><span class="st">"binary"</span>, interpolation<span class="op">=</span><span class="st">"nearest"</span>)</span>
<span id="cb15-9"><a></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb15-10"><a></a>        plt.title(class_names[y_train[index]])</span>
<span id="cb15-11"><a></a>plt.subplots_adjust(wspace<span class="op">=</span><span class="fl">0.2</span>, hspace<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb15-12"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

</section>
<section id="first-40-images-output" class="slide level2 output-location-slide"><h2>First 40 images</h2><div class="cell output-location-slide" data-execution_count="17">
<div class="cell-output cell-output-display">
<div>
<figure>
<p><a href="slides_files/figure-revealjs/cell-18-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-27"><img data-src="slides_files/figure-revealjs/cell-18-output-1.png" width="911" height="394"></a></p>
</figure>
</div>
</div>
</div></section><section id="creating-a-model" class="slide level2">
<h2>Creating a model</h2>
<div id="90427902" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a>tf.random.set_seed(<span class="dv">42</span>)</span>
<span id="cb16-2"><a></a></span>
<span id="cb16-3"><a></a>model <span class="op">=</span> tf.keras.Sequential()</span>
<span id="cb16-4"><a></a></span>
<span id="cb16-5"><a></a>model.add(tf.keras.layers.InputLayer(shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]))</span>
<span id="cb16-6"><a></a>model.add(tf.keras.layers.Flatten())</span>
<span id="cb16-7"><a></a>model.add(tf.keras.layers.Dense(<span class="dv">300</span>, activation<span class="op">=</span><span class="st">"relu"</span>))</span>
<span id="cb16-8"><a></a>model.add(tf.keras.layers.Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>))</span>
<span id="cb16-9"><a></a>model.add(tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model.summary" class="slide level2">
<h2><code>model.summary()</code></h2>
<div id="86150184" class="cell" data-execution_count="19">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential"</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ flatten (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)               │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">784</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                   │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">300</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">235,500</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">100</span>)            │        <span style="color: #00af00; text-decoration-color: #00af00">30,100</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">10</span>)             │         <span style="color: #00af00; text-decoration-color: #00af00">1,010</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">266,610</span> (1.02 MB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">266,610</span> (1.02 MB)
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>
</div>
</div>
<aside class="notes">
<p>As observed, <code>dense_3</code> has <span class="math inline">\(235,500\)</span> parameters, while <span class="math inline">\(784 \times 300 = 235,200\)</span>.</p>
<p>Could you explain the origin of the additional parameters?</p>
<p>Similarly, <code>dense_3</code> has <span class="math inline">\(30,100\)</span> parameters, while <span class="math inline">\(300 \times 100 = 30,000\)</span>.</p>
<p>Can you explain why?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="creating-a-model-alternative" class="slide level2">
<h2>Creating a model (alternative)</h2>
<div id="3d698f8d" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb17-2"><a></a>    tf.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>)),</span>
<span id="cb17-3"><a></a>    tf.keras.layers.Flatten(),</span>
<span id="cb17-4"><a></a>    tf.keras.layers.Dense(<span class="dv">300</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb17-5"><a></a>    tf.keras.layers.Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb17-6"><a></a>    tf.keras.layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb17-7"><a></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model.summary-1" class="slide level2">
<h2><code>model.summary()</code></h2>
</section>
<section id="compiling-the-model" class="slide level2">
<h2>Compiling the model</h2>
<div id="25545eba" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb18-2"><a></a>              optimizer<span class="op">=</span><span class="st">"sgd"</span>,</span>
<span id="cb18-3"><a></a>              metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<aside><div>
<p><code>sparse_categorical_crossentropy</code> is the appropriate function for a multiclass classification problem (more later).</p>
<p>The method <code>compile</code> allows to set the loss function, as well as other parameters. Keras then prepares the model for training.</p>
</div></aside></section>
<section id="training-the-model" class="slide level2 scrollable">
<h2>Training the model</h2>
<div id="e2fea4f2" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb19-2"><a></a>                    validation_data<span class="op">=</span>(X_valid, y_valid))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<aside class="notes">
<p>The model is provided with both a taining set and a validation set. At each step, the model will report its performance on both sets. This will also allow to visualize the accuracy and loss curves on both sets (more later).</p>
<p>When calling the <code>fit</code> method in Keras (or similar frameworks), each step corresponds to the evaluation of a mini-batch. A mini-batch is a subset of the training data, and during each step, the model updates its weights based on the error calculated from this mini-batch.</p>
<p>An epoch is defined as one complete pass through the entire training dataset. During an epoch, the model processes multiple mini-batches until it has seen all the training data once. This process is repeated for a specified number of epochs to optimize the model’s performance.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualization" class="slide level2">
<h2>Visualization</h2>
<div id="3eaaaaa6" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb20-2"><a></a></span>
<span id="cb20-3"><a></a>pd.DataFrame(history.history).plot(</span>
<span id="cb20-4"><a></a>    figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>), xlim<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">29</span>], ylim<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], grid<span class="op">=</span><span class="va">True</span>, xlabel<span class="op">=</span><span class="st">"Epoch"</span>,</span>
<span id="cb20-5"><a></a>    style<span class="op">=</span>[<span class="st">"r--"</span>, <span class="st">"r--."</span>, <span class="st">"b-"</span>, <span class="st">"b-*"</span>])</span>
<span id="cb20-6"><a></a>plt.legend(loc<span class="op">=</span><span class="st">"lower left"</span>)  <span class="co"># extra code</span></span>
<span id="cb20-7"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

</section>
<section id="visualization-output" class="slide level2 output-location-slide"><h2>Visualization</h2><div class="cell output-location-slide" data-execution_count="25">

</div></section><section id="evaluating-the-model-on-our-test" class="slide level2">
<h2>Evaluating the model on our test</h2>
<div id="1de3d5b1" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a>model.evaluate(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="making-predictions" class="slide level2">
<h2>Making predictions</h2>
<div id="ff82f34f" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>X_new <span class="op">=</span> X_test[:<span class="dv">3</span>]</span>
<span id="cb22-2"><a></a>y_proba <span class="op">=</span> model.predict(X_new)</span>
<span id="cb22-3"><a></a>y_proba.<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="fragment">
<div id="0f040ab4" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a></a>y_pred <span class="op">=</span> y_proba.argmax(axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb23-2"><a></a>y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="fragment">
<div id="54638b55" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a>y_new <span class="op">=</span> y_test[:<span class="dv">3</span>]</span>
<span id="cb24-2"><a></a>y_new</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

</div>
<aside><div>
<p>As can be seen, the predictions are unambiguous, with only one class per prediction exhibiting a high value.</p>
</div></aside></section>
<section id="predicted-vs-observed" class="slide level2">
<h2>Predicted vs Observed</h2>
<div id="1263886c" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a></a>np.array(class_names)[y_pred]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="test-set-performance" class="slide level2">
<h2>Test Set Performance</h2>
<div id="d6eb88b5" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb26-2"><a></a></span>
<span id="cb26-3"><a></a>y_proba <span class="op">=</span> model.predict(X_test)</span>
<span id="cb26-4"><a></a>y_pred <span class="op">=</span> y_proba.argmax(axis<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="test-set-performance-1" class="slide level2">
<h2>Test Set Performance</h2>
<div id="42dee15e" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a></a><span class="bu">print</span>(classification_report(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section></section>
<section>
<section id="prologue" class="title-slide slide level1 center">
<h1>Prologue</h1>

</section>
<section id="summary" class="slide level2 scrollable">
<h2>Summary</h2>
<ul>
<li><strong>Introduction to Neural Networks and Connectionism</strong>
<ul>
<li>Shift from symbolic AI to connectionist approaches in artificial intelligence.</li>
<li>Inspiration from biological neural networks and the human brain’s structure.</li>
</ul></li>
<li><strong>Computations with Neurodes and Threshold Logic Units</strong>
<ul>
<li>Early models of neurons (neurodes) capable of performing logical operations (AND, OR, NOT).</li>
<li>Limitations of simple perceptrons in solving non-linearly separable problems like XOR.</li>
</ul></li>
<li><strong>Multilayer Perceptrons (MLPs) and Feedforward Neural Networks (FNNs)</strong>
<ul>
<li>Overcoming perceptron limitations by introducing hidden layers.</li>
<li>Structure and information flow in feedforward neural networks.</li>
<li>Explanation of forward pass computations in neural networks.</li>
</ul></li>
<li><strong>Activation Functions in Neural Networks</strong>
<ul>
<li>Importance of nonlinear activation functions (sigmoid, tanh, ReLU) for enabling learning of complex patterns.</li>
<li>Role of activation functions in backpropagation and gradient descent optimization.</li>
<li>Universal Approximation Theorem and its implications for neural networks.</li>
</ul></li>
<li><strong>Deep Learning Frameworks</strong>
<ul>
<li>Overview of PyTorch and TensorFlow as leading platforms for deep learning.</li>
<li>Introduction to Keras as a high-level API for building and training neural networks.</li>
<li>Discussion on the suitability of different frameworks for research and industry applications.</li>
</ul></li>
<li><strong>Hands-On Implementation with Keras</strong>
<ul>
<li>Loading and exploring the Fashion-MNIST dataset.</li>
<li>Building a neural network model using Keras’ Sequential API.</li>
<li>Compiling the model with appropriate loss functions and optimizers for multiclass classification.</li>
<li>Training the model and visualizing training and validation metrics over epochs.</li>
<li>Evaluating model performance on test data and interpreting results.</li>
</ul></li>
<li><strong>Making Predictions and Interpreting Results</strong>
<ul>
<li>Using the trained model to make predictions on new data.</li>
<li>Visualizing predictions alongside actual images and labels.</li>
<li>Understanding the output probabilities and class assignments in the context of the dataset.</li>
</ul></li>
</ul>
</section>
<section id="next-lecture" class="slide level2">
<h2>Next lecture</h2>
<ul>
<li>We will discuss the training algorithm for artificial neural networks.</li>
</ul>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Cybenko:1989aa" class="csl-entry" role="listitem">
Cybenko, George V. 1989. <span>“Approximation by Superpositions of a Sigmoidal Function.”</span> <em>Mathematics of Control, Signals and Systems</em> 2: 303–14. <a href="https://api.semanticscholar.org/CorpusID:3958369">https://api.semanticscholar.org/CorpusID:3958369</a>.
</div>
<div id="ref-Geron:2022aa" class="csl-entry" role="listitem">
Géron, Aurélien. 2022. <em>Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. 3rd ed. O’Reilly Media, Inc.
</div>
<div id="ref-goodfellow:2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. Adaptive Computation and Machine Learning. MIT Press. <a href="https://dblp.org/rec/books/daglib/0040158">https://dblp.org/rec/books/daglib/0040158</a>.
</div>
<div id="ref-Hornik:1989aa" class="csl-entry" role="listitem">
Hornik, Kurt, Maxwell Stinchcombe, and Halbert White. 1989. <span>“Multilayer Feedforward Networks Are Universal Approximators.”</span> <em>Neural Networks</em> 2 (5): 359–66. https://doi.org/<a href="https://doi.org/10.1016/0893-6080(89)90020-8">https://doi.org/10.1016/0893-6080(89)90020-8</a>.
</div>
<div id="ref-lecun:2015dt" class="csl-entry" role="listitem">
LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. <span>“Deep Learning.”</span> <em>Nature</em> 521 (7553): 436–44. <a href="https://doi.org/10.1038/nature14539">https://doi.org/10.1038/nature14539</a>.
</div>
<div id="ref-LeNail:2019aa" class="csl-entry" role="listitem">
LeNail, Alexander. 2019. <span>“<span>NN-SVG: Publication-Ready Neural Network Architecture Schematics</span>.”</span> <em>Journal of Open Source Software</em> 4 (33): 747. <a href="https://doi.org/10.21105/joss.00747">https://doi.org/10.21105/joss.00747</a>.
</div>
<div id="ref-mcculloch:1943dq" class="csl-entry" role="listitem">
McCulloch, Warren S, and Walter Pitts. 1943. <span>“<span class="nocase">A logical calculus of the ideas immanent in nervous activity</span>.”</span> <em>The Bulletin of Mathematical Biophysics</em> 5 (4): 115–33. <a href="https://doi.org/10.1007/bf02478259">https://doi.org/10.1007/bf02478259</a>.
</div>
<div id="ref-Minsky:1969aa" class="csl-entry" role="listitem">
Minsky, Marvin, and Seymour Papert. 1969. <em>Perceptrons: An Introduction to Computational Geometry</em>. Cambridge, MA, USA: MIT Press.
</div>
<div id="ref-Rosenblatt:1958aa" class="csl-entry" role="listitem">
Rosenblatt, F. 1958. <span>“<span class="nocase">The perceptron: A probabilistic model for information storage and organization in the brain.</span>”</span> <em>Psychological Review</em> 65 (6): 386–408. <a href="https://doi.org/10.1037/h0042519">https://doi.org/10.1037/h0042519</a>.
</div>
<div id="ref-Russell:2020aa" class="csl-entry" role="listitem">
Russell, Stuart, and Peter Norvig. 2020. <em>Artificial Intelligence: <span>A</span> Modern Approach</em>. 4th ed. Pearson. <a href="http://aima.cs.berkeley.edu/">http://aima.cs.berkeley.edu/</a>.
</div>
</div>
</section>
<section class="slide level2">

<p>Marcel <strong>Turcotte</strong></p>
<p><a href="mailto:Marcel.Turcotte@uOttawa.ca">Marcel.Turcotte@uOttawa.ca</a></p>
<p>School of Electrical Engineering and <strong>Computer Science</strong> (EE<strong>CS</strong>)</p>
<p>University of Ottawa</p>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../../assets/images/uottawa_hor_black.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://turcotte.xyz/teaching/csi-4106">turcotte.xyz/teaching/csi-4106</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/turcotte\.xyz\/teaching\/csi-4106");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

<script src="https://platform.twitter.com/widgets.js"></script>
</body></html>