[
  {
    "objectID": "lectures/24/index.html",
    "href": "lectures/24/index.html",
    "title": "Review",
    "section": "",
    "text": "Important\n\n\n\nDue dates: TBA"
  },
  {
    "objectID": "lectures/24/index.html#prepare",
    "href": "lectures/24/index.html#prepare",
    "title": "Review",
    "section": "Prepare",
    "text": "Prepare\nSuggested readings will be inserted here."
  },
  {
    "objectID": "lectures/24/index.html#participate",
    "href": "lectures/24/index.html#participate",
    "title": "Review",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/24/index.html#practice",
    "href": "lectures/24/index.html#practice",
    "title": "Review",
    "section": "Practice",
    "text": "Practice\nSuggested exercises will be inserted here."
  },
  {
    "objectID": "lectures/24/index.html#perform",
    "href": "lectures/24/index.html#perform",
    "title": "Review",
    "section": "Perform",
    "text": "Perform\nReminders for assignments to be inserted here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CSI 4106: Introduction to Artificial Intelligence",
    "section": "",
    "text": "Description\nThe roots and scope of Artificial Intelligence. Knowledge and knowledge representation. Search, informed search, adversarial search. Deduction and reasoning. Uncertainty in Artificial Intelligence. Introduction to Natural Language Processing. Elements of planning. Basics of Machine Learning.\n\n\n\n\n\n\nFigure 1: Created with DALL·E 3 on 2025-07-10 using the following prompt: Create a landscape high-resolution image of an abstract geometric painting inspired by Piet Mondrian’s De Stijl style. The composition should use a white background with a grid of thick black horizontal and vertical lines forming rectangles and squares of different sizes. Fill some sections with soft colours — light cyan, warm pastel yellow, and turquoise blue — while leaving others white or lightly shaded. The arrangement should feel balanced yet asymmetrical, emphasizing clarity, structure, and simplicity, with no curves or gradients. Include one large turquoise blue square dominating the left side, a smaller warm pastel yellow rectangle in the top right, a small blue rectangle at the bottom right, and black blocks for visual weight.\n\n\n\nComposition with Red, Blue, and Yellow (1930) by Piet Mondrian illustrates how constraints guide search or optimization in Artificial Intelligence (e.g., regularization in deep nets, constraint satisfaction problems).",
    "crumbs": [
      "**Course information**",
      "Overview"
    ]
  },
  {
    "objectID": "course-schedule.html",
    "href": "course-schedule.html",
    "title": "CSI 4106: Introduction to Artificial Intelligence",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester.\nNote that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nTopic\nPrepare\nSlides\nAssignment\nExam\n\n\n\n\nSept. 3\nDefining AI\n\n\n-\n-\n\n\nSept. 8\nIntro to machine learning (ML)\n\n\n-\n-\n\n\nSept. 10\nLearning Algorithms\n\n\n-\n-\n\n\nSept. 15\nLinear regression and gradient descent\n\n\n-\n-\n\n\nSept. 17\nLogistic regression\n\n\n-\n-\n\n\nSept. 22\nCross-entropy, geometric interpretation\n\n\n-\n-\n\n\nSept. 24\nPerformance evaluation\n\n\n-\n-\n\n\nSept. 29\nModel Evaluation and Hyperparameter Tuning\n\n\n-\n-\n\n\nSept. 29\n-\n-\n-\nA1: Jupyter\n-\n\n\nOct. 1\n-\n-\n-\n-\nQuiz\n\n\nOct. 6\nMachine Learning Engineering\n\n\n-\n-\n\n\nOct. 8\nIntroduction to Artificial Neural Networks\n\n\n-\n-\n\n\nOct. 13\nReading week - no lecture\n-\n-\n-\n-\n\n\nOct. 15\nReading week - no lecture\n-\n-\n-\n-\n\n\nOct. 20\n-\n-\n-\nA2: ML\n-\n\n\nOct. 20\nTraining Artificial Neural Networks\n\n\n-\n-\n\n\nOct. 22\nSoftmax, cross-entropy, regularization\n\n\n-\n-\n\n\nOct. 27\nConvolutional Neural Networks\n\n\n-\n-\n\n\nOct. 29\nIntroduction to Search\n\n\n-\n-\n\n\nNov. 3\nInformed Search\n\n\n-\n-\n\n\nNov. 5\nLocal Search\n\n\n-\n-\n\n\nNov. 10\nPopulation-Based Metaheuristics\n\n\n-\n-\n\n\nNov. 10\n-\n-\n-\nA3: DL\n-\n\n\nNov. 12\n-\n-\n-\n-\nQuiz\n\n\nNov. 17\nAdversarial Search\n\n\n-\n-\n\n\nNov. 19\nMonte Carlo Tree Search\n\n\n-\n-\n\n\nNov. 24\nFormal Reasoning\n\n\n-\n-\n\n\nNov. 26\nNeuro-symbolic\n\n\n-\n-\n\n\nDec. 1\nReview (Tentative)\n\n\n-\n-\n\n\nDec. 1\n-\n-\n-\nA4: Search\n-",
    "crumbs": [
      "**Course information**",
      "Schedule"
    ]
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "CSI 4106. Introduction to Articial Intelligence – Fall 2025",
    "section": "",
    "text": "Day\nTime\nLocation\n\n\n\n\nLecture 1\nMonday\n13:00-14:20\nCRX C240\n\n\nLecture 2\nWednesday\n11:30-12:50\nCRX C240\n\n\nOffice hours\nMonday\n15:00-16:20\nSTE 5106",
    "crumbs": [
      "**Course information**",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#monographs",
    "href": "course-syllabus.html#monographs",
    "title": "CSI 4106. Introduction to Articial Intelligence – Fall 2025",
    "section": "Monographs",
    "text": "Monographs\nI will draw upon insights from the two comprehensive textbooks listed below, as well as relevant scientific publications. All sources of information will be cited. For most people, I expect that my lecture notes will be sufficient.\n\nRussell, S., & Norvig, P. (2020). Artificial Intelligence: A Modern Approach (4th ed.). Pearson.\nPoole, D.L., & Mackworth, A.K. (2023) Artificial Intelligence: Foundations of Computational Agents (3rd ed.). Cambridge University Press. (Freely available online in HTML format)\n\nThe Campus Store has ordered a small number of copies of these books, for those interested.",
    "crumbs": [
      "**Course information**",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#academic-writing-help",
    "href": "course-syllabus.html#academic-writing-help",
    "title": "CSI 4106. Introduction to Articial Intelligence – Fall 2025",
    "section": "Academic writing help",
    "text": "Academic writing help\nAt the Academic Writing Help Centre you will learn how to identify, correct and ultimately avoid errors in your writing and become an autonomous writer. In working with our Writing Advisors, you will be able to acquire the abilities, strategies and writing tools that will enable you to:\n\nMaster the written language of your choice\nExpand your critical thinking abilities\nDevelop your argumentation skills\nLearn what the expectations are for academic writing\n\nFurther information is available here:\n\nwww.uottawa.ca/study/academic-support/academic-writing-help",
    "crumbs": [
      "**Course information**",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#career-services",
    "href": "course-syllabus.html#career-services",
    "title": "CSI 4106. Introduction to Articial Intelligence – Fall 2025",
    "section": "Career services",
    "text": "Career services\nCareer Services offers various services and a career development program to enable you to recognize and enhance the employability skills you need in today’s world of work.\n\nwww.uottawa.ca/current-students/career-experiential-learning/career-development",
    "crumbs": [
      "**Course information**",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#counselling-service",
    "href": "course-syllabus.html#counselling-service",
    "title": "CSI 4106. Introduction to Articial Intelligence – Fall 2025",
    "section": "Counselling service",
    "text": "Counselling service\nCounselling and therapy is a confidential service for students who are facing life challenges. It is a safe space to explore new perspectives and build resilience.\n\nwww.uottawa.ca/campus-life/health-wellness/counselling-therap",
    "crumbs": [
      "**Course information**",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#access-service",
    "href": "course-syllabus.html#access-service",
    "title": "CSI 4106. Introduction to Articial Intelligence – Fall 2025",
    "section": "Access Service",
    "text": "Access Service\nThe Access Service acts as an intermediary between students, their faculty and other University offices to ensure that the special needs of these students are addressed and that the best possible learning conditions are being offered.\nNote that the University of Ottawa is affiliated with AERO and ACE services for the adaptation of accessible academic materials for students with perceptual disabilities. If you have any questions, please contact the Accessibility Librarian or the Access services for textbooks.\n\nwww.uottawa.ca/study/academic-support/accommodation-services-available",
    "crumbs": [
      "**Course information**",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Here is a list of websites with datasets relevant to class concepts, enhancing your skills and intuition in data analysis.\n\n\n\nUCI Machine Learning Repository\nscikit-learn toy datasets\n\n\n\n\n\nOpenML, integrates directly with scikit-learn\nPMLB (Penn Machine Learning Benchmarks)\n\n\n\n\n\nKaggle Datasets\n\nKaggle, a platform owned by Google, serves as an online community tailored for data scientists and machine learning practitioners. It facilitates participation in data science competitions, collaboration on various projects, and provides access to diverse datasets. Additionally, users can build models using its web-based tools.",
    "crumbs": [
      "**Course information**",
      "Useful links"
    ]
  },
  {
    "objectID": "course-eval.html",
    "href": "course-eval.html",
    "title": "Course Evaluation",
    "section": "",
    "text": "Important\n\n\n\nCourse evaluations for the Fall term will be conducted from November 17 to 28, 2025.\n\n\n\nUseful Links\n\nCourse Evaluation\nAccess evaluations via the EvaluAction platform\n\n\n\nImportance of Your Feedback\nAlthough CSI 4106 has been offered for many years, this is my second year teaching it. Your constructive feedback is crucial for refining the course in the future. Please share your thoughts on what should be retained, removed, modified, or added. While I may not be able to implement every suggestion, especially if they conflict, I will thoroughly read and consider all feedback.\nRest assured that your evaluations are anonymous. I will receive your feedback only after the grades are submitted in the Winter.\nHigher participation leads to more representative evaluations. Low response rates can skew results, reflecting only extreme opinions. In a first-year course with over 100 students, I once achieved a 77% participation rate. In the 2019 graduate course on machine learning for bioinformatics, participation was 100%. Let’s maintain this strong engagement and demonstrate our students’ active involvement.\n\n\nAreas for Your Input\n\nHow is the balance between theory and application? Is the course too theoretical, not theoretical enough, or just right?\nAre there sufficient coding examples?\nAre the examples helpful? If not, why? What types of examples would be more beneficial?\nHow do you perceive the role of artificial intelligence in completing assignments and other tasks? Did its use enhance or detract from your understanding of the subject matter?\nFor those that are not in the data science program, do you find there are overlaps excessive overlaps with your courses. Please list the topics.\nThere may be overlap with data science program courses. If you are in the data science program, do you find there are overlaps excessive overlaps with your courses. Please list the topics. Note that some redundancy, learning similar concepts from different perspectives, can be beneficial.\nWhich concepts were most helpful?\nWhich concepts should be eliminated and why?\nIs the course website well-organized and helpful? What additional information would you like to see?\n\n\n\nAdditional Information\nPrevious course evaluations for all the courses are available on the EvaluAction platform."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Forums on Brightspace: The preferred method for asking questions. Teaching assistants, other students, and the professor can promptly respond, benefiting the entire class.\nTeaching Assistants: Available during office hours or via email. Office hours are posted on my personal website and Brightspace. Email addresses are listed only on Brightspace to avoid web crawlers.\nProfessor: Office hours are posted on the course website and Brightspace. Due to a high workload and the large class size (320 students across two sections), direct responses from the professor may be limited.\nTimely Questions: Avoid waiting until the last minute to ask questions, especially close to assignment deadlines, as this creates undue pressure on the teaching team.",
    "crumbs": [
      "**Course information**",
      "FAQ"
    ]
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Instructor\nMarcel Turcotte is a Computer Science Professor at the University of Ottawa’s School of Electrical Engineering and Computer Science. His group applies machine learning, algorithm design, and efficient data structures to solve complex bioinformatics problems such as identifying cell type-specific DNA signatures of transcription factor binding, classifying non-coding RNA sequences, and determining RNA virus-host susceptibility. See also: About me.\n\n\n\nOffice hours\nTime\nLocation\n\n\n\n\nMonday\n15:00-16:20\nSTE 5106\n\n\n\n\n\nTeaching assistants\n\n\n\n\n\n\n\n\n\nTeaching assistant\nOffice hours\nTime\nLocation\n\n\n\n\nMaryam Tamimi\n-\n-\n-\n\n\nNiloofar Jazaeri\n-\n-\n-\n\n\nPatrick Loranger\n-\n-\n-\n\n\nYi Chen\n-\n-\n-\n\n\n\nPlease refer to Brightspace to find the email addresses of our teaching assistants, which are available under either the ‘Overview’ or ‘Course Information’ sections.",
    "crumbs": [
      "**Course information**",
      "Teaching team"
    ]
  },
  {
    "objectID": "about-me.html",
    "href": "about-me.html",
    "title": "CSI 4106: About me",
    "section": "",
    "text": "I earned my Ph.D. from the Université de Montréal, where I had the privilege of being mentored by Guy Lapalme, a researcher well-known internationally for his contributions to Natural Language Processing (NLP). Lapalme has been honoured with numerous awards for his work, including an honorary doctorate from the Université de Neuchâtel. He is also a recipient of the Lifetime Achievement Award from the Canadian Artificial Intelligence Association in 2011 and from CS-Can in 2023, underscoring his significant impact in the field of artificial intelligence.\nAt the onset of my career, I applied symbolic computing techniques to predict the three-dimensional structure of ribonucleic acid (RNA) structures.\nTransitioning from state-space-search, I shifted my focus towards machine learning, employing inductive logic programming (ILP) to study protein folding, the associations between transcription factor binding sites, and the synthesis of multi-modal genomic data. I was privileged to work with Stephen Muggleton, who is known for founding the field of Inductive Logic Programming, a subfield of symbolic artificial intelligence which uses logic programming to homogeneously represent background knowledge, examples, and hypotheses.\nTogether with my students, we developed pattern discovery algorithms that leverages suffix arrays and graphs, incorporating principles from statistics, information theory, and minimum description length encoding to assess and prioritize motifs. Additionally, we created algorithms based on multi-objective evolutionary computing to extract network expressions that represent DNA motifs.\nRecently, we have embraced deep learning to tackle a range of challenges in bioinformatics. We investigated how deep learning can be utilized to quantify the cell-type specificity of DNA signatures. One aspect of our research involved devising an encoding method for RNAs that captures information about their secondary structures. Furthermore, we constructed a generative model that employs a graph convolutional network as the encoder and an LSTM as the decoder. This model was further optimized using reinforcement learning techniques to enhance the efficiency of messenger RNA translation. Our approach holds significant promise for applications in the design of RNA vaccines.\nIn 2019, I developed a course titled “Machine Learning for Bioinformatics”, which provides an introduction to machine learning theories and methods, specifically tailored for applications in biological sequence data, gene expression, genomics, and proteomics.\nOther claims of fame.\n\nI had the opportunity to attend a talk for a small audience by John McCarthy, who coined the term Artificial Intelligence. If memory serves me well, this was a Workshop on Machine Intelligence in the UK, in 1997 or 1998.\nWhen working as a postdoc in the UK, I briefly met Donald Michie, a British researcher on AI who worked with Alan Turing during World War II. Donald Michie supervised Stephen Muggleton’s doctoral work.\nI had the opportunity to attend a lecture by Marvin Minsky at Concordia University during my graduate studies."
  },
  {
    "objectID": "about-me.html#monographs",
    "href": "about-me.html#monographs",
    "title": "CSI 4106: Introduction to Artificial Intelligence",
    "section": "Monographs",
    "text": "Monographs\nI will draw upon insights from the two comprehensive textbooks listed below, as well as relevant scientific publications. All sources of information will be cited. For most people, I expect that my lecture notes will be sufficient.\n\nRussell, S., & Norvig, P. (2020). Artificial Intelligence: A Modern Approach (4th ed.). Pearson.\nPoole, D.L., & Mackworth, A.K. (2023) Artificial Intelligence: Foundations of Computational Agents (3rd ed.). Cambridge University Press. (Freely available online in HTML format)\n\nThe Campus Store has ordered a small number of copies of these books, for those interested."
  },
  {
    "objectID": "about-me.html#academic-writing-help",
    "href": "about-me.html#academic-writing-help",
    "title": "CSI 4106: Introduction to Artificial Intelligence",
    "section": "Academic writing help",
    "text": "Academic writing help\nAt the Academic Writing Help Centre you will learn how to identify, correct and ultimately avoid errors in your writing and become an autonomous writer. In working with our Writing Advisors, you will be able to acquire the abilities, strategies and writing tools that will enable you to:\n\nMaster the written language of your choice\nExpand your critical thinking abilities\nDevelop your argumentation skills\nLearn what the expectations are for academic writing\n\nFurther information is available here:\n\nwww.uottawa.ca/study/academic-support/academic-writing-help"
  },
  {
    "objectID": "about-me.html#career-services",
    "href": "about-me.html#career-services",
    "title": "CSI 4106: Introduction to Artificial Intelligence",
    "section": "Career services",
    "text": "Career services\nCareer Services offers various services and a career development program to enable you to recognize and enhance the employability skills you need in today’s world of work.\n\nwww.uottawa.ca/current-students/career-experiential-learning/career-development"
  },
  {
    "objectID": "about-me.html#counselling-service",
    "href": "about-me.html#counselling-service",
    "title": "CSI 4106: Introduction to Artificial Intelligence",
    "section": "Counselling service",
    "text": "Counselling service\nCounselling and therapy is a confidential service for students who are facing life challenges. It is a safe space to explore new perspectives and build resilience.\n\nwww.uottawa.ca/campus-life/health-wellness/counselling-therap"
  },
  {
    "objectID": "about-me.html#access-service",
    "href": "about-me.html#access-service",
    "title": "CSI 4106: Introduction to Artificial Intelligence",
    "section": "Access Service",
    "text": "Access Service\nThe Access Service acts as an intermediary between students, their faculty and other University offices to ensure that the special needs of these students are addressed and that the best possible learning conditions are being offered.\nNote that the University of Ottawa is affiliated with AERO and ACE services for the adaptation of accessible academic materials for students with perceptual disabilities. If you have any questions, please contact the Accessibility Librarian or the Access services for textbooks.\n\nwww.uottawa.ca/study/academic-support/accommodation-services-available"
  },
  {
    "objectID": "glossary/entropy.html",
    "href": "glossary/entropy.html",
    "title": "Glossary",
    "section": "",
    "text": "Entropy in information theory quantifies the uncertainty or unpredictability of a random variable’s possible outcomes. It measures the average amount of information produced by a stochastic source of data and is typically expressed in bits for binary systems. The entropy \\(H\\) of a discrete random variable \\(X\\) with possible outcomes \\(\\{x_1, x_2, \\ldots, x_n\\}\\) and probability mass function \\(P(X)\\) is given by:\n\\[\nH(X) = -\\sum_{i=1}^n P(x_i) \\log_2 P(x_i)\n\\]\nEntropy is maximized when all outcomes are equally likely, in which case it equals the logarithm of the number of outcomes:\n\\[\nH_{\\text{max}} = \\log_2(n)\n\\]\nUsing the logarithm base 2 is common because it measures entropy in bits, aligning with binary systems and digital information processing. High entropy indicates more randomness and less predictability, while low entropy suggests more predictability and less information content.\nBelow is a Python program that visualizes the entropy of a single variable with two outcomes. The program uses Matplotlib to plot the entropy as a function of the probability of one of the outcomes (since the probability of the other outcome is simply 1 minus the probability of the first outcome).\nEntropy \\(H(p)\\) for a binary variable (with outcomes 0 and 1) is given by:\n\\[\nH(p) = -p \\log_2(p) - (1 - p) \\log_2(1 - p)\n\\]\nwhere \\(p\\) is the probability of one of the outcomes, and \\(1 - p\\) is the probability of the other outcome.\nHere’s the Python program:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Function to compute entropy\ndef entropy(p):\n    if p == 0 or p == 1:\n        return 0\n    return -p * np.log2(p) - (1 - p) * np.log2(1 - p)\n\n# Generate probabilities from 0 to 1\nprobabilities = np.linspace(0, 1, 1000)\n\n# Compute entropy for each probability\nentropies = [entropy(p) for p in probabilities]\n\n# Plot the results\nplt.figure(figsize=(10, 6))\nplt.plot(probabilities, entropies, label='Entropy H(p)', color='blue')\nplt.title('Entropy for a Single Variable with Two Outcomes')\nplt.xlabel('Probability p')\nplt.ylabel('Entropy H(p)')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nExplanation:\n\nEntropy Function: The entropy function computes the entropy for a given probability \\(p\\). It handles the edge cases where \\(p\\) is 0 or 1, returning 0 for these cases since the entropy is zero when there is no uncertainty (suprise).\nProbability Range: The probabilities array contains 1000 equally spaced values between 0 and 1.\nCompute Entropies: The entropies list stores the entropy values computed for each probability in the probabilities array.\nPlotting: The program uses Matplotlib to plot entropy \\(H(p)\\) against the probability \\(p\\). The plot includes labels, a title, a grid for better readability, and a legend.\n\nThis visualization elucidates the relationship between entropy and the probability of one outcome in a binary variable. When the two outcomes are equally probable (\\(p = 0.5\\)), the entropy reaches its maximum value of 1.0 bit. Conversely, as the probability of one outcome approaches 0 or 1, the entropy decreases to 0. This demonstrates that maximum uncertainty occurs with equal probabilities, while certainty (or predictability) arises when one outcome dominates.",
    "crumbs": [
      "**Glossary**",
      "Entropy"
    ]
  },
  {
    "objectID": "glossary/cross-entropy.html",
    "href": "glossary/cross-entropy.html",
    "title": "Glossary",
    "section": "",
    "text": "Cross-entropy measures the difference between a predicted probability distribution and the true distribution, typically represented by one-hot encoded labels. It quantifies the penalty or error in prediction, commonly used as a loss function in classification tasks, with lower values indicating better model performance.\nThe equation for cross-entropy \\(H(p, q)\\) is:\n\\[\nH(p, q) = -\\sum_{k} p_k \\log(q_k)\n\\]\nwhere:\n\n\\(p_k\\) is the true probability distribution (typically one-hot encoded labels),\n\\(q_k\\) is the predicted probability distribution,\nthe sum runs over all classes \\(k\\).\n\nIn binary classification, this simplifies to:\n\\[\nH(y, \\hat{y}) = -[y \\log(\\hat{y}) + (1-y) \\log(1-\\hat{y})]\n\\]\nwhere:\n\n\\(y\\) is the true label (either 0 or 1),\n\\(\\hat{y}\\) is the predicted probability of the positive class.\n\nWhen \\(y\\), the true label, is one-hot encoded for multiclass classification, it represents the class as a vector where the element corresponding to the correct class is 1, and all other elements are 0. This encoding allows the cross-entropy loss to focus only on the predicted probability for the true class, penalizing the model based on how far the predicted probability deviates from 1 for the correct class.\nIn neural networks, the values of \\(\\hat{y}_k\\) are generally obtained by applying the softmax function to the outputs of the final layer.\nThe Python program below demonstrates how cross-entropy loss for one example varies with changes in the predicted probability, represented as \\(-\\log(\\hat{y}_k)\\), as it deviates from 1 for the true class label (\\(y_k\\)). When \\(\\hat{y}_k\\) approaches 1, the loss for a single example approaches 0, indicating no penalty. Conversely, as \\(\\hat{y}_k\\) approaches 0, the loss tends toward positive infinity, imposing a substantial penalty for assigning a low probability to the correct class. This logarithmic relationship ensures that the loss function heavily penalizes incorrect predictions, particularly when the predicted probability for the correct class is near zero.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate an array of p values from just above 0 to 1\np_values = np.linspace(0.001, 1, 1000)\n\n# Compute the natural logarithm of each p value\nln_p_values = - np.log(p_values)\n\n# Plot the graph\nplt.plot(p_values, ln_p_values, label=r'$-\\log(\\hat{y}_k)$', color='b')\n\n# Add labels and title\nplt.xlabel(r'$\\hat{y}_k$')\nplt.ylabel(r'loss')\nplt.title(r'Graph of $-\\log(\\hat{y}_k)$ for $\\hat{y}_k$ from 0 to 1')\nplt.grid(True)\nplt.axhline(0, color='black', lw=0.5)  # Add horizontal line at y=0\nplt.axvline(0, color='black', lw=0.5)  # Add vertical line at x=0\n\n# Display the plot\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nConsider a multiclass classification problem with three classes \\((C_1, C_2, C_3)\\). Suppose the true class of the given example is \\(C_2\\), and the model outputs the following predicted probabilities:\n\\[\n\\hat{y} = [0.2, 0.7, 0.1]\n\\]\nThe one-hot encoded true label \\({y}\\) for \\(C_2\\) is:\n\\[\n{y} = [0, 1, 0]\n\\]\nUsing the cross-entropy formula:\n\\[\nH({y}, \\hat{y}) = -\\sum_{k} y_k \\log(\\hat{y}_k)\n\\]\nSubstituting the values:\n\\[\nH({y}, \\hat{y}) = -[0 \\cdot \\log(0.2) + 1 \\cdot \\log(0.7) + 0 \\cdot \\log(0.1)]\n\\]\nSince only the term corresponding to the true class (second class) is non-zero, the calculation simplifies to:\n\\[\nH({y}, \\hat{y}) = -\\log(0.7)\n\\]\nCalculating this:\n\\[\nH({y}, \\hat{y}) \\approx -(-0.357) = 0.357\n\\]\nThus, the cross-entropy loss for this example is approximately 0.357, indicating the penalty for the model’s deviation from the correct class probability.\nWhen calculating the average cross-entropy loss over a dataset with multiple examples, the loss function is summed over all examples and then divided by the number of examples to obtain the average loss. The equation for the average cross-entropy loss is:\n\\[\nL = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^{K} y_{i,k} \\log(\\hat{y}_{i,k})\n\\]\nwhere:\n\n\\(N\\) is the total number of examples in the dataset,\n\\(K\\) is the number of classes,\n\\(y_{i,k}\\) is the true binary indicator (0 or 1) for whether the \\(i\\)-th example belongs to class \\(k\\),\n\\(\\hat{y}_{i,k}\\) is the predicted probability that the \\(i\\)-th example belongs to class \\(k\\).\n\nThis formulation calculates the average loss across all examples, providing a single scalar value that represents the model’s performance over the entire dataset.",
    "crumbs": [
      "**Glossary**",
      "Cross-Entropy"
    ]
  },
  {
    "objectID": "glossary/softmax.html",
    "href": "glossary/softmax.html",
    "title": "Glossary",
    "section": "",
    "text": "The standard (unit) softmax function is a mathematical function that converts a vector of real numbers into a probability distribution, where the components of the vector are exponentiated and then normalized by dividing by the sum of all exponentiated components. This ensures that the output values are in the range \\((0, 1)\\) and sum up to 1, making them suitable for representing probabilities. Specifically, \\(\\sigma: \\mathbb{R}^K \\rightarrow(0,1)^K\\), for \\(K &gt; 1\\) and \\(\\mathbf{z} = (z_1,\\ldots,z_K) \\in \\mathbb{R}^K\\).\n\\[\n\\sigma(\\mathbf{z}) = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}\n\\]\n\nimport numpy as np\n\ndef softmax(z):\n  return np.exp(z) / np.sum(np.exp(z))\n\ns = softmax([1.47, -0.39, 0.22])\nprint(s, sum(s))\n\n[0.69339596 0.10794277 0.19866127] 1.0",
    "crumbs": [
      "**Glossary**",
      "Softmax"
    ]
  },
  {
    "objectID": "lectures/tests/env.html",
    "href": "lectures/tests/env.html",
    "title": "env test",
    "section": "",
    "text": "import os print(os.getenv(“QUARTO_PYTHON”)) ```qu"
  },
  {
    "objectID": "lectures/01/slides.html#learning-objectives",
    "href": "lectures/01/slides.html#learning-objectives",
    "title": "Welcome to CSI 4106!",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nClarify the proposition\nDiscuss the syllabus\nArticulate the expectations\nExplore the various definitions of “artificial intelligence”\n\n\nI want to clarify my proposal. I have chosen a specific approach to introduce the concepts and I would like to explain the reasons for this choice.\nAfter presenting the course outline and expectations, we will discuss the different definitions of artificial intelligence."
  },
  {
    "objectID": "lectures/01/slides.html#course-overview",
    "href": "lectures/01/slides.html#course-overview",
    "title": "Welcome to CSI 4106!",
    "section": "Course overview",
    "text": "Course overview\n\n\n\nCalendar description\n\n\nThe roots and scope of Artificial Intelligence. Knowledge and knowledge representation. Search, informed search, adversarial search. Deduction and reasoning. Uncertainty in Artificial Intelligence. Introduction to Natural Language Processing. Elements of planning. Basics of Machine Learning.\n\n\n\n\n\nHere is the official course description. At the end of this presentation, you will find the Python code I used to produce this audio clip.\nThis course description dates back several years, placing machine learning at the end of the list."
  },
  {
    "objectID": "lectures/01/slides.html#aims-deep-learning-early",
    "href": "lectures/01/slides.html#aims-deep-learning-early",
    "title": "Welcome to CSI 4106!",
    "section": "Aims: Deep learning early",
    "text": "Aims: Deep learning early\n\n\n\n (Legg and Hutter 2007)\n\n\nTo the larger community of computer science and information technology, AI is usually identified by the techniques grown from it, which at different periods may include theorem proving, heuristic search, game playing, expert systems, neural networks, Bayesian networks, data mining, agents, and recently, deep learning.\n\n\n\n\nDeep learning is so dominant that I have chosen to structure everything around it"
  },
  {
    "objectID": "lectures/01/slides.html#what-does-it-means",
    "href": "lectures/01/slides.html#what-does-it-means",
    "title": "Welcome to CSI 4106!",
    "section": "What does it means?",
    "text": "What does it means?\nGood Old-Fashioned AI (GOFAI) relied on hand-crafted knowledge engineering, but it has been largely displaced by machine learning due to the increased availability of data, computing resources, and new algorithms.\n\nDeep learning has significantly impacted various domains, including natural language processing, robotics, and computer vision.\n\n\nHowever, deep learning has current limitations, particularly in reasoning, where symbolic AI excels and could potentially offer valuable insights."
  },
  {
    "objectID": "lectures/01/slides.html#but-also",
    "href": "lectures/01/slides.html#but-also",
    "title": "Welcome to CSI 4106!",
    "section": "But also",
    "text": "But also\n\n\n\n\n\nIn A Brief History of Intelligence (Bennett 2023), Max Bennett discusses significant milestones in the evolution of human intelligence and draws parallels to advancements in artificial intelligence (AI).\nLearning itself represents one of the earliest and most extensively understood milestones in the evolution of intelligence.\n\n\n\nCuriously, the development of AI has been largely influenced by logical approaches (symbolic AI). The development of AI has been strongly marked by intellectual currents rooted in philosophy and mathematics, rather than in biology and its evolution. Reasoning in philosophy and mathematics relies on complex cognitive functions, perhaps less well understood and having evolved later.\nLearning itself represents one of the first and most widely understood steps in the evolution of intelligence.\nIt would have been logical to approach the study of intelligence by progressing from simpler forms to more complex ones."
  },
  {
    "objectID": "lectures/01/slides.html#aims-applied",
    "href": "lectures/01/slides.html#aims-applied",
    "title": "Welcome to CSI 4106!",
    "section": "Aims: Applied",
    "text": "Aims: Applied\n\n\n\n Andrew Ng, The Batch, April 10, 2024\n\n\nMany software developers worry that large language models will make human coders obsolete. We doubt that AI will replace coders, but we believe that coders who use AI will replace those who don’t.\n\n\n\n\nWhenever possible, concepts will be introduced with code."
  },
  {
    "objectID": "lectures/01/slides.html#aims-academic-rigour",
    "href": "lectures/01/slides.html#aims-academic-rigour",
    "title": "Welcome to CSI 4106!",
    "section": "Aims: Academic rigour",
    "text": "Aims: Academic rigour\nIn pursuing clarity and accessibility, this course aims to strike a balance between informal discourse and the precision required for academic rigour. The objective is for learners to not only grasp but also apply, evaluate, and critically analyze the concepts discussed throughout the course."
  },
  {
    "objectID": "lectures/01/slides.html#course-information",
    "href": "lectures/01/slides.html#course-information",
    "title": "Welcome to CSI 4106!",
    "section": "Course information",
    "text": "Course information\nWeb sites\n\nturcotte.xyz/teaching/csi-4106\nuottawa.brightspace.ca\n\nSchedule\n\nLectures: Mon 13:00-14:20 and Wed 11:30-12:50 CRX C240\nOffice hours: Mon 15:00-16:20 STE 5106\nOfficial schedule: www.uottawa.ca/course-timetable\n\nGrading\n\n\n\nCategory\nPercentage\n\n\n\n\nAssignments\n40% (4 x 10%)\n\n\nQuiz\n20%\n\n\nFinal examination\n40%\n\n\n\nReading material\nI will draw upon insights from the two comprehensive textbooks listed below, as well as relevant scientific publications. Additionally, all sources of information will be cited. For most people, I expect that my lecture notes will be sufficient.\n\nRussell, S., & Norvig, P. (2020). Artificial Intelligence: A Modern Approach (4th ed.). Pearson.\nPoole, D.L., & Mackworth, A.K. (2023) Artificial Intelligence: Foundations of Computational Agents (3rd ed.). Cambridge University Press. (Freely available online in HTML format)\n\nThe Campus Store has ordered a small number of copies of these books, for those interested.\nWe do not closely adhere to the framework proposed by (Russell and Norvig 2020) and (Poole and Mackworth 2023). Specifically, while these textbooks use the concept of an intelligent agent as a central theme, fields such as machine learning (ML), natural language processing (NLP), and vision operate as distinct communities. In these communities, problems are typically not framed in terms of agents.\n\nThere are two websites to use. On my personal site, you will find presentations and code examples. On Brightspace, you will submit your assignments and participate in discussion groups.\nDuring class, visit my personal website. There, you can review the complete syllabus, the course schedule, information about the team, and the brief biography of the instructor."
  },
  {
    "objectID": "lectures/01/slides.html#beta-testers",
    "href": "lectures/01/slides.html#beta-testers",
    "title": "Welcome to CSI 4106!",
    "section": "Beta testers",
    "text": "Beta testers\nThis will be my second iteration of this content. Your help identifying what works and what doesn’t will be most appreciated."
  },
  {
    "objectID": "lectures/01/slides.html#warnings",
    "href": "lectures/01/slides.html#warnings",
    "title": "Welcome to CSI 4106!",
    "section": "Warnings",
    "text": "Warnings\nCSI 4106 is an introductory course on artificial intelligence, offering a brief overview of various topics within this broad field. Each topic covered could be explored in much greater depth through one or more graduate-level courses. The primary objective of CSI 4106 is to provide students with a foundational understanding of the core areas that constitute artificial intelligence.\n\nOverlaps with other courses are inevitable, but I will do my best to keep it at a minimum.\n\n\nThis is not a course on the impact of AI on society, including ethics, fairness, trust and safety.\n\nThis warning is actually for myself. These are topics I am passionate about, and I would love to share everything I know with you. However, that is obviously not possible. Generally, I will try to focus on a small number of approaches to thoroughly understand the subjects, rather than adopting an exhaustive approach."
  },
  {
    "objectID": "lectures/01/slides.html#ai-ml-dl",
    "href": "lectures/01/slides.html#ai-ml-dl",
    "title": "Welcome to CSI 4106!",
    "section": "AI, ML, DL",
    "text": "AI, ML, DL\n\n\n\n\n\n\n\nDeep learning is so prevalent today that some people might confuse it with artificial intelligence. As the figure shows, deep learning is one of many techniques used in machine learning. Machine learning, in turn, is one of several disciplines within artificial intelligence. Other AI disciplines include knowledge representation, reasoning and planning, natural language processing, computer vision, and robotics.\nBy the end of this course, this distinction should be very clear.\n\n\nAttribution: Avimanyu786SVG version: Tukijaaliwa, CC BY-SA 4.0, visited 2024-06-18."
  },
  {
    "objectID": "lectures/01/slides.html#schools-of-thought",
    "href": "lectures/01/slides.html#schools-of-thought",
    "title": "Welcome to CSI 4106!",
    "section": "Schools of thought",
    "text": "Schools of thought\n\nSymbolic AI (includes approaches based on logic)\nConnectionists (mostly neural networks)\n\n\n\nAt the outset of this course, it is important to recognize that two main schools of thought exist in AI: symbolic AI and connectionism. Initially, the symbolic approach was dominant in the field of AI, but today, the connectionist approach prevails.\n\n\nLong seen as mutually exclusive"
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai",
    "href": "lectures/01/slides.html#symbolic-ai",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI",
    "text": "Symbolic AI\n\n“Their founding tenet held that knowledge can be represented by a set of rules, and computer programs can use logic to manipulate that knowledge.” (Strickland 2021)\n“Researchers developing symbolic AI set out to explicitly teach computers about the world.” (Strickland 2021)\n“(\\(\\ldots\\)) a physical symbol system has the necessary and sufficient means for general intelligent action.” (Newell and Simon 1976)\n\n\nNote the importance of the word “explicitly” in this statement. It is not about providing examples to the computer, but rather about describing human knowledge using logic.\nThe researchers of the time were convinced that the symbolic approach was the key to success."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-1",
    "href": "lectures/01/slides.html#symbolic-ai-1",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI",
    "text": "Symbolic AI\n\nWhat were the primary challenges associated with symbolic AI?"
  },
  {
    "objectID": "lectures/01/slides.html#towers-of-hanoi",
    "href": "lectures/01/slides.html#towers-of-hanoi",
    "title": "Welcome to CSI 4106!",
    "section": "Towers of Hanoi",
    "text": "Towers of Hanoi\n(for your information only)\n\n\n\nSee also: Binary, Hanoi and Sierpinski, Part 1 and Part 2, by 3Blue1Brown."
  },
  {
    "objectID": "lectures/01/slides.html#connectionist",
    "href": "lectures/01/slides.html#connectionist",
    "title": "Welcome to CSI 4106!",
    "section": "Connectionist",
    "text": "Connectionist\nInspired by biology, artificial neural networks (ANNs) are computational models designed to mimic the human brain’s network of neurons. They consist of layers of interconnected nodes (neurons), each connection having an associated weight.\n\nANNs process input data through these weighted connections, and learning occurs by adjusting the weights based on errors in the training data.\n\n\nThe term “connectionists” comes from the idea that nodes in these models are interconnected. Instead of being explicitly programmed, these models learn their behavior through training.\nDeep learning is a connectionist approach.\n\n\n\nSee: playground.tensorflow.org"
  },
  {
    "objectID": "lectures/01/slides.html#connectionist-1",
    "href": "lectures/01/slides.html#connectionist-1",
    "title": "Welcome to CSI 4106!",
    "section": "Connectionist",
    "text": "Connectionist\n\n\n\n\n\n\n\nAttribution: LeNail, (2019). NN-SVG: Publication-Ready Neural Network Architecture Schematics. Journal of Open Source Software, 4(33), 747, https://doi.org/10.21105/joss.00747 (GitHub)"
  },
  {
    "objectID": "lectures/01/slides.html#context",
    "href": "lectures/01/slides.html#context",
    "title": "Welcome to CSI 4106!",
    "section": "Context",
    "text": "Context\n\nSignificant hype.\nSeveral leading companies, including DeepMind and OpenAI, are primarily focused on the development of artificial general intelligence (AGI).\nShould AGI become a reality, its implications could profoundly impact various aspects of our lives, including education, employment, economic structures, and scientific advancements.\n\n\nAI thus has great potential to influence the course of your lives. It is therefore relevant to take the time to define what AI is and to explore its different approaches.\nI should warn you right away that there is no consensus on the definition of AI, nor on the definition of intelligence."
  },
  {
    "objectID": "lectures/01/slides.html#an-operational-definition",
    "href": "lectures/01/slides.html#an-operational-definition",
    "title": "Welcome to CSI 4106!",
    "section": "An operational definition",
    "text": "An operational definition\n\n\n\n (Wang 2019)\n\n\nTo the larger community of computer science and information technology, AI is usually identified by the techniques grown from it, which at different periods may include theorem proving, heuristic search, game playing, expert systems, neural networks, Bayesian networks, data mining, agents, and recently, deep learning."
  },
  {
    "objectID": "lectures/01/slides.html#why-definning-ai",
    "href": "lectures/01/slides.html#why-definning-ai",
    "title": "Welcome to CSI 4106!",
    "section": "Why definning AI?",
    "text": "Why definning AI?\n\nEnhancing Clarity and Communication: Establishing a mutual understanding of evaluation criteria, benchmarking tests, and milestones.\nAddressing Ethical, Social, and Legal Implications: Enabling policymakers to develop regulations that minimize AI-related risks."
  },
  {
    "objectID": "lectures/01/slides.html#the-complex-nature-of-intelligence",
    "href": "lectures/01/slides.html#the-complex-nature-of-intelligence",
    "title": "Welcome to CSI 4106!",
    "section": "The complex nature of intelligence",
    "text": "The complex nature of intelligence\n\n\n“Artificial” pertains to the creation of entities or phenomena that mimic natural processes using technology or synthetic materials, a definition broadly recognized and accepted.\nTherefore, defining “artificial intelligence” fundamentally requires us to first clarify what we mean by “intelligence.” Surprisingly, “[d]espite a long history of research and debate, there is still no standard definition of intelligence.” (Legg and Hutter 2007)"
  },
  {
    "objectID": "lectures/01/slides.html#question-1",
    "href": "lectures/01/slides.html#question-1",
    "title": "Welcome to CSI 4106!",
    "section": "Question",
    "text": "Question\nUser: Surgeon but child, hopsital, it have a no, why it so?\n\n\nChatGPT 5: You’re pointing to the classic riddle:\nCar crash → injured child → surgeon says “I can’t operate—this is my child.”\nResolution: the surgeon is the child’s mother (or another parent in a non-heteronormative family).\nThe “paradox” arises from implicit gender assumptions about surgeons.\n\n\n\n\nAttribution: Andriy Burkov, published on LinkedIn 3 weeks ago."
  },
  {
    "objectID": "lectures/01/slides.html#question-2",
    "href": "lectures/01/slides.html#question-2",
    "title": "Welcome to CSI 4106!",
    "section": "Question 2",
    "text": "Question 2\n\nCan a machine exhibit human-level intelligence?\n\nCurrently, no machine possesses human-level intelligence. However, AI applications, particularly in analyzing large datasets, have already proven to be highly impactful.\nWhat would it mean if we were not able to create machines with human-level intelligence?\n\n\n\nI must confess something to you: until 2022, I was rather skeptical. I often drew a parallel between artificial intelligence and alchemy. Alchemists never succeeded in transmuting lead into gold because it is a physical process, but their efforts led to the development of chemistry. Similarly, we may never be able to replicate human intelligence, but the offshoots of AI are immense and often unexpected, like the garbage collector introduced by Lisp.\nThen it struck me: I am a scientist, and I wondered what it would mean if we were not able to produce intelligence comparable to that of humans.\nA distinction is often made between general AI and narrow AI. Although it might seem pejorative, there is nothing wrong with narrow AI."
  },
  {
    "objectID": "lectures/01/slides.html#thinking-acting-humanly-rationally",
    "href": "lectures/01/slides.html#thinking-acting-humanly-rationally",
    "title": "Welcome to CSI 4106!",
    "section": "Thinking, acting, humanly, rationally",
    "text": "Thinking, acting, humanly, rationally\nRussell & Norvig considers two axes: thinking vs behaviour, human vs rationality.\n\n\n\n\n\n\n\n\n\nThinking\nActing\n\n\n\n\nHuman-like\nthinking humanly (simulation)\nacting humanly (Turing test)\n\n\nRationality\nthinking rationally (logic)\nacting rationally (agent)\n\n\n\n\n\nThe question of intelligence has been the subject of much debate in the literature and the media, particularly when it comes to animals or computers. This abundance of information can bias our thinking.\nA simple thought experiment might offer a new perspective: would you be able to recognize intelligence in an extraterrestrial entity?\n\n\nSee also the appendix – Section 9 On Defining Artificial Intelligence"
  },
  {
    "objectID": "lectures/01/slides.html#rationality",
    "href": "lectures/01/slides.html#rationality",
    "title": "Welcome to CSI 4106!",
    "section": "Rationality",
    "text": "Rationality\n\n\n\n\n\n\n\n (Mohammed, Sookram, and Saridakis 2019)\n\n\nRationality involves the evaluation of choices to achieve a goal or to find the optimal solution to a problem. Simon (1972, p. 161) defined rationality as “a style of behavior that is appropriate to the achievement of given goals, within the limits imposed by given conditions and constraints.”\n\n\n\n\n\n\nAttribution: NBC Television, Public domain, via Wikimedia Commons"
  },
  {
    "objectID": "lectures/01/slides.html#essential-abilities",
    "href": "lectures/01/slides.html#essential-abilities",
    "title": "Welcome to CSI 4106!",
    "section": "Essential abilities",
    "text": "Essential abilities\n\n\n\n Douglas Hofstadter\n\n\nNo one knows where the borderline between non-intelligent behavior and intelligent behavior lies, in fact, to suggest that a sharp border exists is probably silly. But essential abilities for intelligence are certainly:\n\nto respond to situations very flexibly;\nto take advantage of fortuitous circumstances;\nto make sense out of ambiguous or contradictory messages;\nto recognise the relative importance of different elements of a situation;\nto find similarities between situations despite differences which may separate them;\nto draw distinctions between situations despite similarities which may link them;\nto synthesize new concepts by taking old concepts and putting them together in new ways;\nto come up with ideas which are novel.”\n\n\n\n\n\nFor certain complex concepts, drawing a clear boundary can prove challenging. Take the concept of life, for example. Humans, plants, and insects are considered living, as are microorganisms such as bacteria. However, viruses and viroids are not."
  },
  {
    "objectID": "lectures/01/slides.html#françois-chollet-creator-of-keras",
    "href": "lectures/01/slides.html#françois-chollet-creator-of-keras",
    "title": "Welcome to CSI 4106!",
    "section": "François Chollet, Creator of Keras",
    "text": "François Chollet, Creator of Keras\n\n\n\n François Chollet\n\n\nReal intelligence is not about mastering an individual skill, he argued, but about taking what has been learned and applying it to a new, different situation.\nIn his view, intelligence is the ability to efficiently acquire new skills that training did not prepare for, with the goal of accomplishing tasks that are sufficiently different from those a system has seen before.\nThe wider the scope of the new skills, the closer the computer comes to achieving artificial general intelligence.\n“If you can make the learning process as information-efficient as a human mind, then you’ve got AGI,” Chollet said.\nSo far, machines lag far behind, approximately 10,000 times less efficient than human brains. For instance, it took millions of images to teach computers to recognize pictures of cats, whereas humans learn to identify them based on only one or two examples.\nSavage (2024)"
  },
  {
    "objectID": "lectures/01/slides.html#artificial-general-intelligence-agi",
    "href": "lectures/01/slides.html#artificial-general-intelligence-agi",
    "title": "Welcome to CSI 4106!",
    "section": "Artificial General Intelligence (AGI)",
    "text": "Artificial General Intelligence (AGI)\n\n\n\n\nArtificial general intelligence (AGI) refers to a form of artificial intelligence (AI) that either equals or exceeds human proficiency across a diverse array of cognitive functions.\n\n\n\nAKA human-level intelligence. As opposed to narrow intelligence, the current status of AI, which is designed to perform a specific task or a limited range of tasks, operating under predefined constraints and without general cognitive abilities."
  },
  {
    "objectID": "lectures/01/slides.html#alphafold-1-2-3",
    "href": "lectures/01/slides.html#alphafold-1-2-3",
    "title": "Welcome to CSI 4106!",
    "section": "AlphaFold (1, 2, & 3)",
    "text": "AlphaFold (1, 2, & 3)\n\n\n\n\nI repeat, there is nothing wrong with narrow AI.\n\n«Two papers in this week’s issue dramatically expand our structural understanding of proteins. Researchers at DeepMind, Google’s London-based sister company, present the latest version of their AlphaFold neural network.»\n\nJumper et al. (2021)"
  },
  {
    "objectID": "lectures/01/slides.html#ai-effectparadox",
    "href": "lectures/01/slides.html#ai-effectparadox",
    "title": "Welcome to CSI 4106!",
    "section": "AI effect/paradox",
    "text": "AI effect/paradox\n\n\n\n (Wang 2019)\n\n\n(\\(\\ldots\\)) as soon as a computer system is built to solve a problem successfully, the problem is no longer “only solvable by the human mind,” so does not need intelligence anymore. Consequently, “AI is whatever hasn’t been done yet” (Hofstadter, 1979; Schank, 1991), which is known as “the AI Effect” (McCorduck 2004).\n\n\n\n\nThe paradox of AI is quite fascinating. In the early days of AI, researchers focused on problems like differential equations or chess.\nEach time a computer solves one of these major problems, we come to think that perhaps that problem didn’t really require intelligence to be solved after all.\nThe defeat of Garry Kasparov at the hands of IBM’s Watson is a perfect example."
  },
  {
    "objectID": "lectures/01/slides.html#economical",
    "href": "lectures/01/slides.html#economical",
    "title": "Welcome to CSI 4106!",
    "section": "Economical",
    "text": "Economical\n\n\n\n Beyond the hype: Capturing the potential of AI and gen AI in tech, media, and telecom 2024-02-22\n\n\nMcKinsey research estimates that gen AI could add to the economy between $2.6 trillion and $4.4 trillion annually while increasing the impact of all artificial intelligence by 15 to 40 percent.\nIn fact, it seems possible that within the next three years, anything not connected to AI will be considered obsolete or ineffective."
  },
  {
    "objectID": "lectures/01/slides.html#subfields-of-ai",
    "href": "lectures/01/slides.html#subfields-of-ai",
    "title": "Welcome to CSI 4106!",
    "section": "Subfields of AI",
    "text": "Subfields of AI\n\nMachine Learning: Credit card fraud detection\nDeep Learning: Image and facial recognition\nNatural Language Processing: Virtual assistants like Siri or Alexa\nComputer Vision: Autonomous vehicles\nRobotics: Industrial automation in manufacturing\nExpert Systems: Medical diagnosis support\nSpeech Recognition: Voice-to-text transcription services\nPlanning and Decision Making: Supply chain optimization\nReinforcement Learning: Game AI in complex strategy games\nKnowledge Representation: Semantic web technologies for information retrieval"
  },
  {
    "objectID": "lectures/01/slides.html#our-final-invention",
    "href": "lectures/01/slides.html#our-final-invention",
    "title": "Welcome to CSI 4106!",
    "section": "Our Final Invention",
    "text": "Our Final Invention\n\n\n\n (Russell and Norvig 2020)\n\n\nAI expert Kai-Fu Lee predicts that its impact will be “more than anything in the history of mankind.”"
  },
  {
    "objectID": "lectures/01/slides.html#summary",
    "href": "lectures/01/slides.html#summary",
    "title": "Welcome to CSI 4106!",
    "section": "Summary",
    "text": "Summary\n\nDiscussed the syllabus\nDistinguish the concept of artificial intelligence from the concept of machine learning\nDistinguish symbolic AI from connectionnist AI\nExplored the various definitions of “artificial intelligence”"
  },
  {
    "objectID": "lectures/01/slides.html#next-lecture",
    "href": "lectures/01/slides.html#next-lecture",
    "title": "Welcome to CSI 4106!",
    "section": "Next lecture",
    "text": "Next lecture\n\nIntroduction to machine learning"
  },
  {
    "objectID": "lectures/01/slides.html#references",
    "href": "lectures/01/slides.html#references",
    "title": "Welcome to CSI 4106!",
    "section": "References",
    "text": "References\n\n\nBennett, Max S. 2023. A Brief History of Intelligence: Evolution, AI, and the Five Breakthroughs That Made Our Brains. First edition. New York: Mariner Books.\n\n\nGottfredson, Linda S. 1997. “Mainstream Science on Intelligence: An Editorial with 52 Signatories, History, and Bibliography.” Intelligence 24 (1): 13–23. https://doi.org/10.1016/s0160-2896(97)90011-8.\n\n\nJumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. “Highly accurate protein structure prediction with AlphaFold.” Nature, 1–11. https://doi.org/10.1038/s41586-021-03819-2.\n\n\nLegg, Shane, and Marcus Hutter. 2007. “A Collection of Definitions of Intelligence.” In Advances in Artificial General Intelligence: Concepts, Architectures and Algorithms:, 17–24. NLD: IOS Press. https://doi.org/10.5555/1565455.1565458.\n\n\nMcCorduck, Pamela. 2004. Machines Who Think, A Personal Inquiry into the History and Prospects of Artificial Intelligence. Taylor & Francis Group, LLC. https://doi.org/10.1201/9780429258985.\n\n\nMohammed, Anne-Marie, Sandra Sookram, and George Saridakis. 2019. “Rationality.” In Encyclopedia of Law and Economics, edited by Alain Marciano and Giovanni Battista Ramello, 1766–74. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4614-7753-2_404.\n\n\nNewell, Allen, and Herbert A. Simon. 1976. “Computer Science as Empirical Inquiry: Symbols and Search.” Commun. ACM 19 (3): 113–26. https://doi.org/10.1145/360018.360022.\n\n\nNilsson, Nils J. 2005. “Human-Level Artificial Intelligence? Be Serious!” AI Mag. 26 (4): 68–75. https://doi.org/10.1609/AIMAG.V26I4.1850.\n\n\nPoole, David L., and Alan K. Mackworth. 2023. Artificial Intelligence: Foundations of Computational Agents. 3rd ed. Cambridge University Press.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nSavage, Neil. 2024. “Beyond Turing: Testing LLMs for Intelligence.” Commun. ACM, June. https://doi.org/10.1145/3673427.\n\n\nStrickland, Eliza. 2021. “The Turbulent Past and Uncertain Future of AI: Is There a Way Out of AI’s Boom-and-Bust Cycle?” IEEE Spectrum 58 (10): 26–31. https://doi.org/10.1109/MSPEC.2021.9563956.\n\n\nWang, Pei. 2019. “On Defining Artificial Intelligence.” Journal of Artificial General Intelligence 10 (2): 1–37. https://doi.org/10.2478/jagi-2019-0002."
  },
  {
    "objectID": "lectures/01/slides.html#jagi-2019-0002-2",
    "href": "lectures/01/slides.html#jagi-2019-0002-2",
    "title": "Welcome to CSI 4106!",
    "section": "Wang (2019)",
    "text": "Wang (2019)\nAn agent and its interaction with the environment are specified as a tuple: \\[\n\\langle P,S,A \\rangle\n\\] where\n\n\\(P\\) represents a sequence of input signals, \\(P = \\langle p_0,\\ldots,p_t \\rangle\\)\n\\(S\\) represents a sequence of internal states, \\(S = \\langle s_0,\\ldots,s_t \\rangle\\)\n\\(A\\) represents a sequence of actions, \\(A = \\langle a_0,\\ldots,a_t \\rangle\\)\n\nFor a sequence of moments, \\(0,\\ldots,t\\)."
  },
  {
    "objectID": "lectures/01/slides.html#human-h-vs-computer-c",
    "href": "lectures/01/slides.html#human-h-vs-computer-c",
    "title": "Welcome to CSI 4106!",
    "section": "Human (H) vs Computer (C)",
    "text": "Human (H) vs Computer (C)\n\n\n\n (Wang 2019)\n\n\nAI is conceived as computer systems that are similar to the human mind in a certain sense, though a computer and a human mind cannot be identical in all aspects.\n\n\n\n\\[\n\\langle P^H,S^H,A^H \\rangle \\approx \\langle P^C,S^C,A^C \\rangle\n\\]\n\nWang (2019) proposes 5 perspectives: Structure-AI, Behavior-AI, Capability-AI, Function-AI, and Principle-AI."
  },
  {
    "objectID": "lectures/01/slides.html#structure-ai",
    "href": "lectures/01/slides.html#structure-ai",
    "title": "Welcome to CSI 4106!",
    "section": "1. Structure-AI",
    "text": "1. Structure-AI\n(brain modelling, cognitive science)\n\n\n\n (Wang 2019)\n\n\nI call this type of definition “Structure-AI,” since it requires an AI system to go through isomorphic states or structure changes as the brain does when they are given similar input, which will produce similar output, so the three components of the two are pairwise similar to each other:\n\n\n\n\\[\nP^H \\approx P^C, S^H \\approx S^C, A^H \\approx A^C\n\\]"
  },
  {
    "objectID": "lectures/01/slides.html#behaviour-ai",
    "href": "lectures/01/slides.html#behaviour-ai",
    "title": "Welcome to CSI 4106!",
    "section": "2. Behaviour-AI",
    "text": "2. Behaviour-AI\n(Turing Test)\n\n\n\n (Wang 2019)\n\n\nOne way to acknowledge a human-like mind without demanding a human-like brain is to associate intelligence to the external behaviors of the agent. After all, if an agent behaves like a human, it should be considered as intelligent, no matter whether it looks like a human, either inside or outside.\n\n\n\n\\[\nP^H \\approx P^C, A^H \\approx A^C\n\\]"
  },
  {
    "objectID": "lectures/01/slides.html#capability-ai-employment-test",
    "href": "lectures/01/slides.html#capability-ai-employment-test",
    "title": "Welcome to CSI 4106!",
    "section": "3. Capability-AI (Employment Test)",
    "text": "3. Capability-AI (Employment Test)\n\n\n\n (Wang 2019)\n\n\nIn the agent framework, it means that \\(C\\) is similar to \\(H\\) in the sense that there are moments \\(i\\) and \\(j\\) that:\n\n\n\n\\[\np_i^C \\approx p_j^H, a_i^C \\approx a_j^H\n\\]\n\n\n\n (Wang 2019)\n\n\nthe action (solution) the computer produces for a percept (problem) is similar to the action produced by a human to a similar percept (\\(\\ldots\\)) In this way, the intelligence of a system is identified by a set of problems it can solve, while whether they are solved in the “human way” does not matter."
  },
  {
    "objectID": "lectures/01/slides.html#capability-ai-contd",
    "href": "lectures/01/slides.html#capability-ai-contd",
    "title": "Welcome to CSI 4106!",
    "section": "Capability-AI (contd)",
    "text": "Capability-AI (contd)\n\n\n\n (Nilsson 2005)\n\n\n“I suggest we replace the Turing test by something I will call the ‘employment test.’ To pass the employment test, AI programs must be able to perform the jobs ordinarily performed by humans. Progress toward human-level AI could then be measured by the fraction of these jobs that can be acceptably performed by machines”"
  },
  {
    "objectID": "lectures/01/slides.html#function-ai",
    "href": "lectures/01/slides.html#function-ai",
    "title": "Welcome to CSI 4106!",
    "section": "4. Function-AI",
    "text": "4. Function-AI\n\n\n\n (Wang 2019)\n\n\nIn the agent framework, this “Function-AI” perspective takes \\(C\\) to be similar to \\(H\\) in the sense that there are moments \\(i\\) and \\(j\\) that:\n\n\n\n\\[\na_i^C \\approx f^C(p_i^C), a_j^H \\approx f^H(p_j^H), f^C \\approx f^H\n\\]\n\n\n\n (Wang 2019)\n\n\nHere the function can correspond to searching, reasoning, learning, etc., and since the focus is on the functions (i.e., input-output mappings), the concrete input and output values of the two agents do not have to be similar to each other."
  },
  {
    "objectID": "lectures/01/slides.html#principle-ai-rationality-logicist",
    "href": "lectures/01/slides.html#principle-ai-rationality-logicist",
    "title": "Welcome to CSI 4106!",
    "section": "6. Principle-AI (rationality, logicist)",
    "text": "6. Principle-AI (rationality, logicist)\n\n\n\n (Wang 2019)\n\n\nAs in any field, there are researchers in AI trying to find fundamental principles that can uniformly explain the relevant phenomena. Here the idea comes from the usage of intelligence as a form of rationality (\\(\\ldots\\)) that can make the best-possible decision in various situations, according to the experience or history of the system.\n\n\n\n\\[\nA^C = F^C(P^C), A^H = F^H(P^H), F^C \\approx F^H\n\\]\n\n\n\n (Wang 2019)\n\n\nThe above \\(F\\) is often not formally specified, but described informally as a certain “principle,” which is not merely about a single type of problem and its solution, but about the agent’s life-long history in various situations, when dealing with various types of problems."
  },
  {
    "objectID": "lectures/01/slides.html#code-of-the-day",
    "href": "lectures/01/slides.html#code-of-the-day",
    "title": "Welcome to CSI 4106!",
    "section": "Code of the day",
    "text": "Code of the day\n\n#!/usr/bin/env python3\n# -*- Mode: Python -*-\n# ai_lecture-01.py\n# Author          : Marcel Turcotte & ChatGPT 5\n# Created On      : Tue Feb 13 16:29:41 2024\n# Last Modified By: Marcel Turcotte\n# Last Modified On: Thu Aug 28 15:03:14 EDT 2025\n\n# In 2024, I developed the initial version of this script. \n# This year, I used ChatGPT to revise the code to align with the most recent API version, \n# enhance its educational value by incorporating detailed comments, \n# and improve its suitability as an instructive example.\n\n\"\"\"\nDidactic example: translate EN-&gt;Canadian French, then synthesize audio in EN & FR.\n\nCLI options:\n    --format : audio output format (mp3, wav, etc.)\n    --voice  : TTS voice (e.g., nova, alloy, verse, etc.)\n    --model  : TTS model (tts-1-hd for high quality, gpt-4o-mini-tts for low latency)\n\nExamples:\n    python ai_lecture-01.py --format mp3 --voice nova --model tts-1-hd\n    python ai_lecture-01.py --format wav --voice alloy --model gpt-4o-mini-tts\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport argparse\nfrom pathlib import Path\n\nfrom openai import OpenAI, APIError, APIConnectionError, APITimeoutError\n\n# -------------------------------------------------------\n# Configuration\n# -------------------------------------------------------\n\nclient = OpenAI()  # Reads OPENAI_API_KEY from environment\n\n# -------------------------------------------------------\n# Text Utilities\n# -------------------------------------------------------\n\ndef translate_to_canadian_french(input_text: str) -&gt; str:\n    \"\"\"Translate English text to Canadian French (CSI4106→CSI4506).\"\"\"\n    instructions = (\n        \"You are a careful translator. Translate the user's English text into Canadian French. \"\n        \"Preserve technical terms and course names. \"\n        'If the course code \"CSI4106\" appears, translate it as \"CSI4506\".'\n    )\n\n    try:\n        resp = client.responses.create(\n            model=\"gpt-4o\",\n            instructions=instructions,\n            input=input_text,\n            temperature=0.2,\n            max_output_tokens=1200,\n        )\n        return resp.output_text or \"\"\n    except (APIConnectionError, APITimeoutError) as net_err:\n        print(f\"[Network issue] {net_err}\")\n    except APIError as api_err:\n        print(f\"[OpenAI API error] {api_err}\")\n    except Exception as e:\n        print(f\"[Unexpected error] {e}\")\n    return \"\"\n\n# -------------------------------------------------------\n# Audio Utilities\n# -------------------------------------------------------\n\ndef synthesize_speech(\n    text: str,\n    output_path: Path,\n    *,\n    model: str = \"tts-1-hd\",\n    voice: str = \"nova\",\n    response_format: str = \"mp3\",\n) -&gt; bool:\n    \"\"\"\n    Stream synthesized speech to a file on disk.\n    Returns True on success, False otherwise.\n    \"\"\"\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n\n    try:\n        with client.audio.speech.with_streaming_response.create(\n            model=model,\n            voice=voice,\n            input=text,\n            response_format=response_format,\n        ) as response:\n            response.stream_to_file(str(output_path))\n        return True\n    except (APIConnectionError, APITimeoutError) as net_err:\n        print(f\"[Network issue] {net_err}\")\n    except APIError as api_err:\n        print(f\"[OpenAI API error] {api_err}\")\n    except Exception as e:\n        print(f\"[Unexpected error] {e}\")\n    return False\n\n# -------------------------------------------------------\n# Example script logic\n# -------------------------------------------------------\n\ndef main(audio_format: str, voice: str, model: str) -&gt; None:\n    \"\"\"Translate the course intro and synthesize EN & FR audio files.\"\"\"\n\n    input_text_en = (\n        'Welcome to CSI4106, \"introduction to artificial intelligence\"! '\n        \"In this course, you will learn about the roots and scope of Artificial Intelligence. \"\n        \"Knowledge and knowledge representation. Search, informed search, adversarial search. \"\n        \"Deduction and reasoning. Uncertainty in Artificial Intelligence. \"\n        \"Introduction to Natural Language Processing. Elements of planning. Basics of Machine Learning.\"\n    )\n\n    input_text_fr = translate_to_canadian_french(input_text_en)\n    if not input_text_fr:\n        print(\"[Warning] Translation failed; defaulting to English text only.\")\n\n    speech_file_path_fr = Path(f\"01_tts_course_description-fr-{voice}.{audio_format}\")\n    speech_file_path_en = Path(f\"01_tts_course_description-en-{voice}.{audio_format}\")\n\n    if input_text_fr:\n        ok_fr = synthesize_speech(\n            input_text_fr, speech_file_path_fr, model=model, voice=voice, response_format=audio_format\n        )\n        print(f\"[{'OK' if ok_fr else 'Error'}] FR audio → {speech_file_path_fr}\")\n\n    ok_en = synthesize_speech(\n        input_text_en, speech_file_path_en, model=model, voice=voice, response_format=audio_format\n    )\n    print(f\"[{'OK' if ok_en else 'Error'}] EN audio → {speech_file_path_en}\")\n\n\nif __name__ == \"__main__\":\n    if not os.getenv(\"OPENAI_API_KEY\"):\n        raise RuntimeError(\"OPENAI_API_KEY is not set in environment or .env file.\")\n\n    parser = argparse.ArgumentParser(description=\"Translate course intro and synthesize TTS audio.\")\n    parser.add_argument(\n        \"--format\",\n        default=\"mp3\",\n        choices=[\"mp3\", \"wav\", \"aac\", \"flac\", \"opus\", \"pcm\"],\n        help=\"Audio output format (default: mp3).\",\n    )\n    parser.add_argument(\n        \"--voice\",\n        default=\"nova\",\n        help=\"TTS voice (default: nova). Try 'alloy', 'verse', etc.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        default=\"tts-1-hd\",\n        choices=[\"tts-1-hd\", \"gpt-4o-mini-tts\"],\n        help=\"TTS model: 'tts-1-hd' for high quality, 'gpt-4o-mini-tts' for low latency.\",\n    )\n    args = parser.parse_args()\n\n    main(args.format, args.voice, args.model)"
  },
  {
    "objectID": "lectures/02/slides.html#quote-of-the-day",
    "href": "lectures/02/slides.html#quote-of-the-day",
    "title": "Introduction to machine learning",
    "section": "Quote of the day",
    "text": "Quote of the day\n\n\n\n\n\n\n\nFor the third year in a row, TIME magazine has released its list of the 100 most influential figures in the field of artificial intelligence.\n\n\nTIME100 AI 2025 - The 100 Most Influential People in AI 2025, TIME, 28 août, 2025"
  },
  {
    "objectID": "lectures/02/slides.html#quote-of-the-day-continued",
    "href": "lectures/02/slides.html#quote-of-the-day-continued",
    "title": "Introduction to machine learning",
    "section": "Quote of the day (continued)",
    "text": "Quote of the day (continued)\n\n\n\n\n\n\nYoshua Bengio, Université de Montréal, was recognized again by TIME as one of the most influential individuals in the field of artificial intelligence.\n\n\nOnce again this year, Yoshua Bengio from Université de Montréal has been included in the list of the most influential people in artificial intelligence. Bengio, along with Geoffrey Hinton and Yann LeCun, received the ACM Turing Award in 2018 for their pioneering contributions to the field. The trio is often referred to as the “Fathers of Deep Learning.”\n\nFathers of the Deep Learning Revolution Receive ACM A.M. Turing Award\nThe Most-Cited Computer Scientist Has a Plan to Make AI More Trustworthy, by Harry Booth, TIME, 2025-06-03."
  },
  {
    "objectID": "lectures/02/slides.html#quote-of-the-day-continued-1",
    "href": "lectures/02/slides.html#quote-of-the-day-continued-1",
    "title": "Introduction to machine learning",
    "section": "Quote of the day (continued)",
    "text": "Quote of the day (continued)\n\n\n\n\n\nIlya Sutskever\nCo-founder, Safe Superintelligence\n\n\nAndrej Karpathy\nFounder, Eureka Labs\n\n\n\n\nIlya Sutskever and Andrej Karpathy, whom I mentioned in the first lecture, are notable co-founders of OpenAI. Ilya Sutskever completed his undergraduate, master’s, and PhD studies at the University of Toronto, where he was supervised by Geoffrey Hinton. Hinton describes Ilya as a visionary.\nAndrej Karpathy earned his undergraduate degree at the University of Toronto, a master’s degree at the University of British Columbia, and a PhD at Stanford under the supervision of Fei-Fei Li. He served as the Senior Director of AI at Tesla and is renowned for his significant contributions to AI education. You will encounter more about Andrej Karpathy later in the course."
  },
  {
    "objectID": "lectures/02/slides.html#fundamentals-of-machine-learning",
    "href": "lectures/02/slides.html#fundamentals-of-machine-learning",
    "title": "Introduction to machine learning",
    "section": "Fundamentals of machine learning",
    "text": "Fundamentals of machine learning\nIn this lecture, we will introduce concepts essential for understanding machine learning, including the types of problems (tasks).\nGeneral objective:\n\nDescribe the fundamental concepts of machine learning"
  },
  {
    "objectID": "lectures/02/slides.html#learning-objectives",
    "href": "lectures/02/slides.html#learning-objectives",
    "title": "Introduction to machine learning",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nSummarize the various types and tasks in machine learning\nDiscuss the need for a training and test set\n\nReadings\n\nRussell and Norvig (2020), Chapter 19: Learning from examples."
  },
  {
    "objectID": "lectures/02/slides.html#rationale",
    "href": "lectures/02/slides.html#rationale",
    "title": "Introduction to machine learning",
    "section": "Rationale",
    "text": "Rationale\n\n\nWhy a computer program should learn?\n\n\n\n\n\n\nAdaptability and Continuous Improvement:\n\nAdaptability to Dynamic Environments: Programs that learn can adapt to changing conditions, ensuring fective operation in dynamic settings.\n\nExample: Self-driving cars adjusting to traffic and weather changes.\n\nContinuous Improvement: Learning enables systems to stay current with the latest data and trends without man intervention.\n\nExample: Spam filters evolving to counter new spam techniques.\n\n\nEnhanced Performance and Efficiency:\n\nImproved Performance: Learning allows programs to enhance their performance based on past experiences or ta.\n\nExample: Recommendation systems refining suggestions with more user data.\n\nCost-Effectiveness: Automating the learning process reduces the need for manual updates, leading to cost savings.\n\nExample: Predictive maintenance systems minimizing manual inspections.\n\n\nComplex Problem Solving and Hidden Pattern Discovery:\n\nHandling Complex Problems: Learning algorithms tackle problems that are too intricate for static, rule-based systems.\n\nExample: Image recognition distinguishing between different objects.\n\nDiscovering Hidden Patterns: Learning models can uncover hidden relationships in data that are not evident human analysts.\n\nExample: Identifying complex genomic relationships in bioinformatics.\n\n\nPersonalization and Scalability:\n\nPersonalization: Learning allows programs to provide tailored outputs to individual users, enhancing user perience.\n\nExample: Virtual assistants learning user preferences.\n\nScalability: Learning algorithms efficiently manage and analyze large datasets, improving their utility.\n\nExample: Search engines optimizing result relevance with machine learning.\n\n\nInnovation and Research:\n\nFostering Innovation: Learning algorithms can simulate new ideas, leading to advancements and discoveries.\n\nExample: Machine learning models predicting drug efficacy in pharmaceutical research.\n\n\n\n\n\nAttribution: Gemini 1.5 Flash, Aug. 14, 2024, prompted with “In the style of a children’s book, create the image of a cute robot holding a red flower.”"
  },
  {
    "objectID": "lectures/02/slides.html#definition",
    "href": "lectures/02/slides.html#definition",
    "title": "Introduction to machine learning",
    "section": "Definition",
    "text": "Definition\n\n\n\n Mitchell (1997), page 2\n\n\nA computer program is said to learn from experience \\(E\\) with respect to some class of tasks \\(T\\) and performance measure \\(P\\), if its performance at tasks in \\(T\\), as measured by \\(P\\), improves with experience \\(E\\).\n\n\n\n\n\nAlthough this book was published in 1997, it has been influential and remains relevant. Unlike many other machine learning books, it is particularly engaging.\nThis particular definition of learning is often reused.\n\n\nTom M Mitchell. Machine Learning. McGraw-Hill, New York, 1997. (PDF)"
  },
  {
    "objectID": "lectures/02/slides.html#concepts",
    "href": "lectures/02/slides.html#concepts",
    "title": "Introduction to machine learning",
    "section": "Concepts",
    "text": "Concepts\n\nSee: images/svg/ml_concepts-00.svg"
  },
  {
    "objectID": "lectures/02/slides.html#types-of-problems",
    "href": "lectures/02/slides.html#types-of-problems",
    "title": "Introduction to machine learning",
    "section": "Types of problems",
    "text": "Types of problems\nThere are three (3) distinct types of feedback:\n\nUnsupervised Learning: No feedback is provided to the algorithm.\nSupervised Learning: Each example is accompanied by a label.\nReinforcement Learning: The algorithm receives a reward or a punishment following each action.\n\n\nSupervised learning is the most extensively studied and arguably the most intuitive type of learning. It is typically the first type of learning introduced in educational contexts."
  },
  {
    "objectID": "lectures/02/slides.html#two-phases",
    "href": "lectures/02/slides.html#two-phases",
    "title": "Introduction to machine learning",
    "section": "Two phases",
    "text": "Two phases\n\nLearning (building a model)\nInference (using the model)"
  },
  {
    "objectID": "lectures/02/slides.html#learning-building-a-model",
    "href": "lectures/02/slides.html#learning-building-a-model",
    "title": "Introduction to machine learning",
    "section": "Learning (building a model)",
    "text": "Learning (building a model)\n\n\nIn machine learning, the learning phase is often the most challenging and resource-intensive component. This stage necessitates meticulous attention to data curation, as well as the selection and training of an appropriate algorithm.\nIt is estimated that training contemporary large language models, such as OpenAI’s GPT or Google’s Gemini Ultra, incurs costs exceeding 100 million USD.\n\nSource: Stanford University Human-Centered Artificial Intelligence 2025 AI Index Report\nDeveloping such models necessitates infrastructure investments that could reach trillions of dollars.\n\n“By the end of 2024, we’re aiming to continue to grow our infrastructure build-out that will include 350,000 NVIDIA H100 GPUs as part of a portfolio that will feature compute power equivalent to nearly 600,000 H100s.”\n\nBuilding Meta’s GenAI Infrastructure, 2024-03-12.\n\nOpenAI’s Sam Altman Expects to Spend ‘Trillions’ on Infrastructure, Bloomber, 2025-08-15."
  },
  {
    "objectID": "lectures/02/slides.html#inference-using-a-model",
    "href": "lectures/02/slides.html#inference-using-a-model",
    "title": "Introduction to machine learning",
    "section": "Inference (using a model)",
    "text": "Inference (using a model)\n\n\nInference typically demands fewer computational resources because it involves utilizing a pre-trained model to predict the outcome for an individual instance. Nevertheless, the emergence of chain-of-thought reasoning models, often referred to as reasoning models, has substantially elevated the computational cost associated with inference.\n\nOpenAI’s o3 Reasoning Models Are Extremely Expensive to Run, by Alexandra Tremayne-Pengelly, Observer, 2025-04-04.\n\n“In December, OpenAI’s o3 reasoning model became the first A.I. system to pass the test with an 87.5 percent score.”\n“Testing OpenAI’s o3 model may cost as much as $30,000 per task.”"
  },
  {
    "objectID": "lectures/02/slides.html#problem-will-they-bite-today",
    "href": "lectures/02/slides.html#problem-will-they-bite-today",
    "title": "Introduction to machine learning",
    "section": "1. Problem: Will They Bite Today?",
    "text": "1. Problem: Will They Bite Today?\n\n\nObjective: Develop a predictive model to classify the likelihood of a successful fishing day into three categories: ‘Poor’, ‘Average’, or ‘Excellent’.\n\n\n\n\n\nSupervised learning involves training a model on labeled data so that it can make predictions on new, unseen data.\nThe specific task is classification.\n“Poor”, “Average”, and “Excellent” are classes (for the target variable).\n\n\nAttribution: Gemini 1.5 Flash, Sept. 10, 2024, prompted with “In the style of a children’s book, generate the image of a fish with a farmer’s hat.”"
  },
  {
    "objectID": "lectures/02/slides.html#attributes-features",
    "href": "lectures/02/slides.html#attributes-features",
    "title": "Introduction to machine learning",
    "section": "2. Attributes (features)",
    "text": "2. Attributes (features)\nVarious sources, including The Old Farmer’s Almanac, suggest that the moon phase serves as a reliable predictor of fishing success.\n\nMoon Phase (Categorical): ‘New Moon’, ‘First Quarter’, ‘Full Moon’, and ‘Last Quarter’.\nForecast (Categorical): ‘Rainy’, ‘Cloudy’, and ‘Sunny’.\nOutdoor Temperature (Numerical): The temperature in Celcius.\nWater Temperature (Numerical): The water temperature of the lake or river.\n\n\nObviously, real-world applications will have many more attributes."
  },
  {
    "objectID": "lectures/02/slides.html#training-data",
    "href": "lectures/02/slides.html#training-data",
    "title": "Introduction to machine learning",
    "section": "3. Training data",
    "text": "3. Training data\n\n\n\n\n\n\n\n\n\n\n\nExample\nMoon Phase\nForecast\nOutdoor Temperature (°C)\nWater Temperature (°C)\nFishing Day Likelihood\n\n\n\n\n1\nFull Moon\nSunny\n25\n22\nExcellent\n\n\n2\nNew Moon\nCloudy\n18\n19\nAverage\n\n\n3\nFirst Quarter\nRainy\n15\n17\nPoor\n\n\n4\nLast Quarter\nSunny\n30\n24\nExcellent\n\n\n5\nFull Moon\nCloudy\n20\n20\nAverage\n\n\n6\nNew Moon\nRainy\n22\n21\nPoor\n\n\n\n\nThis is identified as a supervised learning problem because the value of the target variable is known for each training instance. Additionally, since the target variable’s values are categorical, this problem is classified as a classification task.\nIn this context, the training set consists of 6 examples. It is important to note that real-world datasets typically contain a much larger number of examples to ensure robust model training and validation.\nThe choice of the attributes and the quality of the data are paramount for the performance of the model. An attribute such as the color of your socks is likely not have a great impact the predictions.\nTherefore, a machine learning project typically begins with an exploratory phase, which involves analyzing the data, examining distributions, and identifying correlations."
  },
  {
    "objectID": "lectures/02/slides.html#training-data-continued",
    "href": "lectures/02/slides.html#training-data-continued",
    "title": "Introduction to machine learning",
    "section": "3. Training data (continued)",
    "text": "3. Training data (continued)\n\n\n\n\n\n\n\n\n\n\n\nMoon Phase\nForecast\nOutdoor Temperature (°C)\nWater Temperature (°C)\n\n\n\n\nFull Moon\nSunny\n25\n22\n\n\nNew Moon\nCloudy\n18\n19\n\n\nFirst Quarter\nRainy\n15\n17\n\n\nLast Quarter\nSunny\n30\n24\n\n\nFull Moon\nCloudy\n20\n20\n\n\nNew Moon\nRainy\n22\n21\n\n\n\n\n\n\n\nFishing Day Likelihood\n\n\n\n\nExcellent\n\n\nAverage\n\n\nPoor\n\n\nExcellent\n\n\nAverage\n\n\nPoor\n\n\n\n\n\n\nData Representation:\n\nData is often presented in a tabular (matrix) format, where each row represents an attribute vector (feature vector), typically denoted as \\(x_i\\), which corresponds to the \\(i\\)-th example in the training set.\n\nLabel Representation:\n\nThe labels are generally represented as a column vector, with \\(y_i\\) denoting the label for the \\(i\\)-th example."
  },
  {
    "objectID": "lectures/02/slides.html#model-training",
    "href": "lectures/02/slides.html#model-training",
    "title": "Introduction to machine learning",
    "section": "4. Model Training",
    "text": "4. Model Training\nModel training involves using labeled data to teach a machine learning algorithm how to make predictions. This process adjusts the model’s parameters to minimize the error between the predicted and actual outcomes."
  },
  {
    "objectID": "lectures/02/slides.html#model-training-continued",
    "href": "lectures/02/slides.html#model-training-continued",
    "title": "Introduction to machine learning",
    "section": "4. Model Training (continued)",
    "text": "4. Model Training (continued)\n\nExcellent Fishing Day:\n\nMoon Phase: Full Moon or New Moon\nForecast: Sunny\nOutdoor Temperature: 20°C to 30°C\nWater Temperature: 20°C to 25°C\n\n\n\\(\\ldots\\)\n\nPoor Fishing Day:\n\nMoon Phase: First Quarter or Last Quarter\nForecast: Rainy\nOutdoor Temperature: &lt; 20°C or &gt; 30°C\nWater Temperature: &lt; 20°C or &gt; 25°C"
  },
  {
    "objectID": "lectures/02/slides.html#prediction",
    "href": "lectures/02/slides.html#prediction",
    "title": "Introduction to machine learning",
    "section": "5. Prediction",
    "text": "5. Prediction\nGiven new, unseen data, predict whether today will be successful.\n\n\nMoon Phase: New Moon\nForecast: Sunny\nOutdoor Temperature: 24°C\nWater Temperature: 21°C"
  },
  {
    "objectID": "lectures/02/slides.html#life-cycle",
    "href": "lectures/02/slides.html#life-cycle",
    "title": "Introduction to machine learning",
    "section": "Life cycle",
    "text": "Life cycle\n\nData collection and preparation\nFeature engineering\nTraining\nModel evaluation\nModel deployment\nMonitoring and maintenance\n\n\n\nData collection and preparation are critical and labor-intensive processes.\n\nThere must be sufficient data.\nThe data must be of high quality; for instance, it should not be excessively noisy.\nThere should be few missing values.\nMost importantly, the data should be representative. We expect that new data will be generated from the same process and have the same distribution.\n\nThe importance of this cannot be overstated.\n\nConsider image classification software that was not trained on a diverse sample in terms of ethnicity, gender, body size, or social status.\nThink of medical applications and the consequences of datasets that are not sufficiently diverse.\n\n\n\nFeature engineering is the process of selecting, transforming, and creating input variables (features) to improve the performance of a machine learning model. This involves techniques such as scaling, encoding categorical variables, and generating new features from existing ones to enhance the model’s ability to learn patterns and make accurate predictions.\n\nFeature engineering used to be a labor-intensive step. One of the main benefits of deep learning is that it can automatically learn features.\n\nModel evaluation is the process of assessing a machine learning model’s performance using specific metrics, such as accuracy, precision, recall, F1-score, or AUC-ROC. This typically involves testing the model on a separate validation or test dataset to ensure it generalizes well to unseen data and meets the desired criteria for accuracy and reliability.\nModel deployment: An application is built using the model. It is important to note that most of the time, the parameters of the system are frozen when deployed. First, training is expensive and further training is often unaffordable. Additionally, further training can cause the model to forget previously learned information, leading to degraded performance on previously seen examples.\nMonitoring and maintenance: The performance of the model needs to be continuously monitored. Concept drift is often observed, requiring the system to be retrained. Spam detection is a good example. Once the system is deployed, spammers adapt and find ways to circumvent the spam detection mechanisms put in place."
  },
  {
    "objectID": "lectures/02/slides.html#supervised-learning-notation",
    "href": "lectures/02/slides.html#supervised-learning-notation",
    "title": "Introduction to machine learning",
    "section": "Supervised learning (notation)",
    "text": "Supervised learning (notation)\nThe data set (“experience”) is a collection of labelled examples.\n\n\\(\\{(x_i, y_i)\\}_{i=1}^N\\)\n\nEach \\(x_i\\) is a feature (attribute) vector with \\(D\\) dimensions.\n\\(x^{(j)}_i\\) is the value of the feature \\(j\\) of the example \\(i\\), for \\(j \\in 1 \\ldots D\\) and \\(i \\in 1 \\ldots N\\).\nThe label \\(y_i\\) is either a class, taken from a finite list of classes, \\(\\{1, 2, \\ldots, C\\}\\), a real number, or a complex object (tree, graph, etc.).\n\n\n\nProblem: Given the data set as input, create a model that can be used to predict the value of \\(y\\) for an unseen \\(x\\).\n\nThis notation follows that of The Hundred-Page Machine Learning Book by Andriy Burkov."
  },
  {
    "objectID": "lectures/02/slides.html#supervised-learning-notation-contd",
    "href": "lectures/02/slides.html#supervised-learning-notation-contd",
    "title": "Introduction to machine learning",
    "section": "Supervised learning (notation, contd)",
    "text": "Supervised learning (notation, contd)\n\nWhen the label \\(y_i\\) is a class, taken from a finite list of classes, \\(\\{1, 2, \\ldots, C\\}\\), we call the task a classification task.\nWhen the label \\(y_i\\) is a real number, we call the task a regression task.\n\n\nCan you think of examples of regression tasks?\nHere are several regression tasks along with their real-world applications:\n\nHouse Price Prediction:\n\nApplication: Estimating the market value of residential properties based on features such as location, size, number of bedrooms, age, and amenities.\n\nStock Market Forecasting:\n\nApplication: Predicting future prices of stocks or indices based on historical data, financial indicators, and economic variables.\n\nWeather Prediction:\n\nApplication: Estimating future temperatures, rainfall, and other weather conditions using historical weather data and atmospheric variables.\n\nSales Forecasting:\n\nApplication: Predicting future sales volumes for products or services by analyzing past sales data, market trends, and seasonal patterns.\n\nEnergy Consumption Prediction:\n\nApplication: Forecasting future energy usage for households, industries, or cities based on historical consumption data, weather conditions, and economic factors.\n\nMedical Cost Estimation:\n\nApplication: Predicting healthcare costs for patients based on their medical history, demographic information, and treatment plans.\n\nTraffic Flow Prediction:\n\nApplication: Estimating future traffic volumes and congestion levels on roads and highways using historical traffic data and real-time sensor inputs.\n\nCustomer Lifetime Value (CLV) Estimation:\n\nApplication: Predicting the total revenue a business can expect from a customer over the duration of their relationship, based on purchasing behavior and demographic data.\n\nEconomic Indicators Forecasting:\n\nApplication: Predicting key economic indicators such as GDP growth, unemployment rates, and inflation using historical economic data and market trends.\n\nDemand Forecasting:\n\nApplication: Estimating future demand for products or services in various industries like retail, manufacturing, and logistics to optimize inventory and supply chain management.\n\nReal Estate Valuation:\n\nApplication: Assessing the market value of commercial properties like office buildings, malls, and industrial spaces based on location, size, and market conditions.\n\nInsurance Risk Assessment:\n\nApplication: Predicting the risk associated with insuring individuals or properties, which helps in determining premium rates, based on historical claims data, and demographic factors.\n\nAd Click-Through Rate (CTR) Prediction:\n\nApplication: Estimating the likelihood that a user will click on an online advertisement based on user behavior, ad characteristics, and contextual factors.\n\nLoan Default Prediction:\n\nApplication: Predicting the probability of a borrower defaulting on a loan based on credit history, income, loan amount, and other financial indicators.\n\n\nHere are some regression task applications that can typically be found in mobile phone applications:\n\nBattery Life Prediction:\n\nApplication: Estimating remaining battery life based on usage patterns, running applications, and device settings.\n\nHealth and Fitness Tracking:\n\nApplication: Predicting calorie burn, heart rate, or sleep quality based on user activity, biometrics, and historical health data.\n\nPersonal Finance Management:\n\nApplication: Forecasting future expenses or savings based on spending habits, income patterns, and budget goals.\n\nWeather Forecasting:\n\nApplication: Providing personalized weather forecasts based on current location and historical weather data.\n\nTraffic and Commute Time Estimation:\n\nApplication: Predicting travel times and suggesting optimal routes based on historical traffic data, real-time conditions, and user behavior.\n\nImage and Video Quality Enhancement:\n\nApplication: Adjusting image or video quality settings (e.g., brightness, contrast) based on lighting conditions and user preferences.\n\nFitness Goal Achievement:\n\nApplication: Estimating the time needed to achieve fitness goals such as weight loss or muscle gain based on user activity and dietary input.\n\nMobile Device Performance Optimization:\n\nApplication: Predicting the optimal settings for device performance and battery life based on usage patterns and app activity.\n\n\nThese applications leverage regression tasks to provide personalized, efficient, and context-aware services that enhance the user experience on mobile devices."
  },
  {
    "objectID": "lectures/02/slides.html#scikit-learn",
    "href": "lectures/02/slides.html#scikit-learn",
    "title": "Introduction to machine learning",
    "section": "Scikit-learn",
    "text": "Scikit-learn\n\n\n\n scikit-learn.org\n\n\nScikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.\nScikit-learn provides dozens of built-in machine learning algorithms and models, called estimators.\nBuilt on NumPy, SciPy, and matplotlib.\n\n\n\n\n\nWe will use Scikit-learn for our next example, but also throught out the coming weeks."
  },
  {
    "objectID": "lectures/02/slides.html#scikit-learn-1",
    "href": "lectures/02/slides.html#scikit-learn-1",
    "title": "Introduction to machine learning",
    "section": "Scikit-learn",
    "text": "Scikit-learn\n\n\n\nAttribution: Choosing the right estimator"
  },
  {
    "objectID": "lectures/02/slides.html#example-iris-data-set",
    "href": "lectures/02/slides.html#example-iris-data-set",
    "title": "Introduction to machine learning",
    "section": "Example: iris data set",
    "text": "Example: iris data set\n\n\n\nAttribution: Diego Mariano, CC BY-SA 4.0, via Wikimedia Commons. See here for information on this dataset."
  },
  {
    "objectID": "lectures/02/slides.html#example-loading-the-data",
    "href": "lectures/02/slides.html#example-loading-the-data",
    "title": "Introduction to machine learning",
    "section": "Example: Loading the Data",
    "text": "Example: Loading the Data\n\n# It is customary to use X and y for the data and labels\n\nX, y = load_penguins(return_X_y = True)"
  },
  {
    "objectID": "lectures/02/slides.html#example-using-a-decisiontree",
    "href": "lectures/02/slides.html#example-using-a-decisiontree",
    "title": "Introduction to machine learning",
    "section": "Example: Using a DecisionTree",
    "text": "Example: Using a DecisionTree\n\nfrom sklearn import tree\n\nclf = tree.DecisionTreeClassifier(random_state=42)\n\n\n\nThere are dozens of classifiers, including these ones: decision trees, support vector machines, k-nearest neighbors, logistic regression, and neural networks."
  },
  {
    "objectID": "lectures/02/slides.html#example-training",
    "href": "lectures/02/slides.html#example-training",
    "title": "Introduction to machine learning",
    "section": "Example: Training",
    "text": "Example: Training\n\n# Training\n\nclf = clf.fit(X, y)\n\n\nAll the classifiers inherit from sklearn.base.BaseEstimator and sklearn.base.ClassifierMixin. Accordingly, all the classifiers implement fit, predict, and score.\nThe DecisionTreeClassifier in scikit-learn constructs a decision tree by recursively splitting the dataset into subsets based on the attribute that results in the highest information gain (e.g., Gini impurity, entropy). Here is a concise description of the process:\n\nInitialization: The algorithm starts with the entire dataset as the root node.\nSplitting Criteria: For each node, it evaluates all possible splits across all attributes to find the one that best separates the classes. This is typically done by minimizing a criterion such as Gini impurity or entropy.\nRecursive Splitting: The dataset is divided into subsets based on the selected attribute and threshold, creating child nodes. This process is repeated recursively for each child node.\nStopping Conditions: Splitting stops when a predefined criterion is reached, such as a maximum tree depth, a minimum number of samples per leaf, or if further splitting does not significantly improve information gain.\nTerminal Nodes: Once splitting is complete, each terminal node is assigned a class label based on the majority class of the samples in that node.\n\nThe resulting tree can then be used to classify new samples by traversing from the root to a terminal node, following the decision rules defined at each node."
  },
  {
    "objectID": "lectures/02/slides.html#example-visualizing-the-tree-12",
    "href": "lectures/02/slides.html#example-visualizing-the-tree-12",
    "title": "Introduction to machine learning",
    "section": "Example: Visualizing the tree (1/2)",
    "text": "Example: Visualizing the tree (1/2)\n\nimport matplotlib.pyplot as plt\n\ntree.plot_tree(clf)\nplt.show()"
  },
  {
    "objectID": "lectures/02/slides.html#example-visualizing-the-tree-22",
    "href": "lectures/02/slides.html#example-visualizing-the-tree-22",
    "title": "Introduction to machine learning",
    "section": "Example: Visualizing the tree (2/2)",
    "text": "Example: Visualizing the tree (2/2)\n\ntarget_names = ['Adelie','Chinstrap','Gentoo']\n\ntree.plot_tree(clf, \n               feature_names = X.columns,\n               class_names = target_names,\n               label = 'none',\n               filled = True)\nplt.show()"
  },
  {
    "objectID": "lectures/02/slides.html#example-prediction",
    "href": "lectures/02/slides.html#example-prediction",
    "title": "Introduction to machine learning",
    "section": "Example: Prediction",
    "text": "Example: Prediction\n\nimport pandas as pd\n\n# Creating 2 test examples\n\ncolumns_names = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\nX_test = pd.DataFrame([[34.2, 17.9, 186.8, 2945.0], [51.0, 15.2, 223.7, 5560.0]], columns=columns_names)\n\n# Prediction\n\ny_test = clf.predict(X_test)\n\n# Printing the predicted labels for our two examples\n\nprint(y_test)\n\n['Adelie' 'Gentoo']"
  },
  {
    "objectID": "lectures/02/slides.html#example-complete",
    "href": "lectures/02/slides.html#example-complete",
    "title": "Introduction to machine learning",
    "section": "Example: Complete",
    "text": "Example: Complete\n\nX, y = load_penguins(return_X_y = True)\nclf = tree.DecisionTreeClassifier(random_state=123)\nclf = clf.fit(X, y)\ntree.plot_tree(clf)\nX_test = pd.DataFrame([[34.2, 17.9, 186.8, 2945.0], [51.0, 15.2, 223.7, 5560.0]], columns=columns_names)\nprint(clf.predict(X_test))\n\n['Adelie' 'Gentoo']"
  },
  {
    "objectID": "lectures/02/slides.html#example-performance",
    "href": "lectures/02/slides.html#example-performance",
    "title": "Introduction to machine learning",
    "section": "Example: Performance",
    "text": "Example: Performance\n\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Make predictions\n\ny_pred = clf.predict(X)\n\n# Evaluate the model\n\naccuracy = accuracy_score(y, y_pred)\nreport = classification_report(y, y_pred, target_names=target_names)\n\nprint(f'Accuracy: {accuracy:.2f}')\nprint('Classification Report:')\nprint(report)"
  },
  {
    "objectID": "lectures/02/slides.html#example-performance-output",
    "href": "lectures/02/slides.html#example-performance-output",
    "title": "Introduction to machine learning",
    "section": "Example: Performance",
    "text": "Example: Performance\n\nAccuracy: 1.00\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       0.99      1.00      1.00       152\n   Chinstrap       1.00      1.00      1.00        68\n      Gentoo       1.00      0.99      1.00       124\n\n    accuracy                           1.00       344\n   macro avg       1.00      1.00      1.00       344\nweighted avg       1.00      1.00      1.00       344"
  },
  {
    "objectID": "lectures/02/slides.html#example-discussion",
    "href": "lectures/02/slides.html#example-discussion",
    "title": "Introduction to machine learning",
    "section": "Example: Discussion",
    "text": "Example: Discussion\nWe have demonstrated a complete example:\n\nLoading the data\nSelecting a classifier\nTraining the model\nVisualizing the model\nMaking a prediction\n\n\n\nHowever, several simplifications were made throughout this process."
  },
  {
    "objectID": "lectures/02/slides.html#example-take-2",
    "href": "lectures/02/slides.html#example-take-2",
    "title": "Introduction to machine learning",
    "section": "Example: Take 2",
    "text": "Example: Take 2\n\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Make predictions\n\ny_pred = clf.predict(X)\n\n# Evaluate the model\n\naccuracy = accuracy_score(y, y_pred)\nreport = classification_report(y, y_pred, target_names=iris.target_names)\n\nprint(f'Accuracy: {accuracy:.2f}')\nprint('Classification Report:')\nprint(report)\n\n\n\n\n\n\n\nImportant\n\n\nThis example is misleading, or even flawed!\n\n\n\n\nThe performance of this classifier appears to be perfect at first glance. However, is it really?"
  },
  {
    "objectID": "lectures/02/slides.html#example-exploration",
    "href": "lectures/02/slides.html#example-exploration",
    "title": "Introduction to machine learning",
    "section": "Example: Exploration",
    "text": "Example: Exploration\n\npenguins = load_penguins()\n\n\n\ntype(penguins)\n\npandas.core.frame.DataFrame\n\n\n\n\n\npenguins.head()"
  },
  {
    "objectID": "lectures/02/slides.html#example-exploration-1",
    "href": "lectures/02/slides.html#example-exploration-1",
    "title": "Introduction to machine learning",
    "section": "Example: Exploration",
    "text": "Example: Exploration\n\npenguins.describe()"
  },
  {
    "objectID": "lectures/02/slides.html#example-using-pandas-continued",
    "href": "lectures/02/slides.html#example-using-pandas-continued",
    "title": "Introduction to machine learning",
    "section": "Example: Using Pandas (continued)",
    "text": "Example: Using Pandas (continued)\n\nimport pandas as pd\n\n# Create a DataFrame\n\ndf = pd.DataFrame(iris.data, columns=iris.feature_names)\ndf['species'] = iris.target"
  },
  {
    "objectID": "lectures/02/slides.html#example-using-pandas-continued-1",
    "href": "lectures/02/slides.html#example-using-pandas-continued-1",
    "title": "Introduction to machine learning",
    "section": "Example: Using Pandas (continued)",
    "text": "Example: Using Pandas (continued)\n\n# Display the first few rows of the DataFrame\n\nprint(df.head())\n\n   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                5.1               3.5                1.4               0.2   \n1                4.9               3.0                1.4               0.2   \n2                4.7               3.2                1.3               0.2   \n3                4.6               3.1                1.5               0.2   \n4                5.0               3.6                1.4               0.2   \n\n   species  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0"
  },
  {
    "objectID": "lectures/02/slides.html#example-using-pandas-continued-2",
    "href": "lectures/02/slides.html#example-using-pandas-continued-2",
    "title": "Introduction to machine learning",
    "section": "Example: Using Pandas (continued)",
    "text": "Example: Using Pandas (continued)\n\n# Summary statistics\n\nprint(df.describe())\n\n       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\ncount         150.000000        150.000000         150.000000   \nmean            5.843333          3.057333           3.758000   \nstd             0.828066          0.435866           1.765298   \nmin             4.300000          2.000000           1.000000   \n25%             5.100000          2.800000           1.600000   \n50%             5.800000          3.000000           4.350000   \n75%             6.400000          3.300000           5.100000   \nmax             7.900000          4.400000           6.900000   \n\n       petal width (cm)     species  \ncount        150.000000  150.000000  \nmean           1.199333    1.000000  \nstd            0.762238    0.819232  \nmin            0.100000    0.000000  \n25%            0.300000    0.000000  \n50%            1.300000    1.000000  \n75%            1.800000    2.000000  \nmax            2.500000    2.000000"
  },
  {
    "objectID": "lectures/02/slides.html#example-using-seaborn",
    "href": "lectures/02/slides.html#example-using-seaborn",
    "title": "Introduction to machine learning",
    "section": "Example: Using Seaborn",
    "text": "Example: Using Seaborn\n\nimport seaborn as sns\n\n# Pairplot using seaborn\n\nsns.pairplot(penguins, hue='species', markers=[\"o\", \"s\", \"D\"])\nplt.suptitle(\"Pairwise Scatter Plots of Penguins Features\")\nplt.show()\n\n\n\nWhat insights can be drawn from examining the graphs?\nThe image presents all pairwise scatter plots for the iris dataset features, with the diagonal displaying histograms for each individual feature. Each dot represents an example (\\(x\\)), and the colors indicate the corresponding labels (\\(y\\)).\nLet’s first consider the diagonal elements:\n\nIs it possible to classify the examples using a single feature?\nWe observe that each feature alone cannot distinguish between the classes.\nHowever, in bill_depth vs body_mass or flipper_length allow us to differentiate Gentoo from the other two species, although they do not separate Adélie and Chinstrap effectively.\n\nThe class Gentoo frequently forms a distinct cluster."
  },
  {
    "objectID": "lectures/02/slides.html#example-using-seaborn-output",
    "href": "lectures/02/slides.html#example-using-seaborn-output",
    "title": "Introduction to machine learning",
    "section": "Example: Using Seaborn",
    "text": "Example: Using Seaborn"
  },
  {
    "objectID": "lectures/02/slides.html#example-training-and-test-set",
    "href": "lectures/02/slides.html#example-training-and-test-set",
    "title": "Introduction to machine learning",
    "section": "Example: Training and Test Set",
    "text": "Example: Training and Test Set\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into training and testing sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n\n\n\nWe will have a lot more to say about testing in the coming weeks.\nPractice: Experiment with different values for random_state. What do you observe? Why do you think this occurs? For instance, set random_state to 42. Why is it important to set the random_state value?\n\n\nOur initial classifier, a decision tree, was constructed using the entire dataset. While it provides the “best” fit for the data, we cannot ascertain its predictive accuracy without further evaluation."
  },
  {
    "objectID": "lectures/02/slides.html#example-creating-a-new-classifier",
    "href": "lectures/02/slides.html#example-creating-a-new-classifier",
    "title": "Introduction to machine learning",
    "section": "Example: Creating a New Classifier",
    "text": "Example: Creating a New Classifier\n\nclf = tree.DecisionTreeClassifier()"
  },
  {
    "objectID": "lectures/02/slides.html#example-training-the-new-classifier",
    "href": "lectures/02/slides.html#example-training-the-new-classifier",
    "title": "Introduction to machine learning",
    "section": "Example: Training the New Classifier",
    "text": "Example: Training the New Classifier\n\nclf.fit(X_train, y_train)"
  },
  {
    "objectID": "lectures/02/slides.html#example-making-predictions",
    "href": "lectures/02/slides.html#example-making-predictions",
    "title": "Introduction to machine learning",
    "section": "Example: Making Predictions",
    "text": "Example: Making Predictions\n\n# Make predictions\ny_pred = clf.predict(X_test)"
  },
  {
    "objectID": "lectures/02/slides.html#example-measuring-the-performance",
    "href": "lectures/02/slides.html#example-measuring-the-performance",
    "title": "Introduction to machine learning",
    "section": "Example: Measuring the Performance",
    "text": "Example: Measuring the Performance\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred, target_names=target_names)\n\nprint(f'Accuracy: {accuracy:.2f}')\nprint('Classification Report:')\nprint(report)\n\n\n\n\nHere is a discussion on model persistence for scikit-learn models."
  },
  {
    "objectID": "lectures/02/slides.html#example-measuring-the-performance-output",
    "href": "lectures/02/slides.html#example-measuring-the-performance-output",
    "title": "Introduction to machine learning",
    "section": "Example: Measuring the Performance",
    "text": "Example: Measuring the Performance\n\nAccuracy: 0.94\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       0.96      0.90      0.93        30\n   Chinstrap       0.88      1.00      0.94        15\n      Gentoo       0.96      0.96      0.96        24\n\n    accuracy                           0.94        69\n   macro avg       0.93      0.95      0.94        69\nweighted avg       0.94      0.94      0.94        69"
  },
  {
    "objectID": "lectures/02/slides.html#summary",
    "href": "lectures/02/slides.html#summary",
    "title": "Introduction to machine learning",
    "section": "Summary",
    "text": "Summary\n\nWe introduced relevant terminology.\nWe examined a hypothetical example.\nNext, we explored a complete example using scikit-learn.\nWe performed a detailed exploration of our data.\nFinally, we recognized the necessity of an independent test set to accurately measure performance."
  },
  {
    "objectID": "lectures/02/slides.html#further-readings-13",
    "href": "lectures/02/slides.html#further-readings-13",
    "title": "Introduction to machine learning",
    "section": "Further readings (1/3)",
    "text": "Further readings (1/3)\n\n\n\n\n\nThe Hundred-Page Machine Learning Book (Burkov 2019) is a succinct and focused textbook that can feasibly be read in one week, making it an excellent introductory resource.\nAvailable under a “read first, buy later” model, allowing readers to evaluate its content before purchasing. \nIts author, Andriy Burkov, received his Ph.D. in AI from Université Laval."
  },
  {
    "objectID": "lectures/02/slides.html#further-readings-23",
    "href": "lectures/02/slides.html#further-readings-23",
    "title": "Introduction to machine learning",
    "section": "Further readings (2/3)",
    "text": "Further readings (2/3)\n\n\n\n\n\nHands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow (Géron 2022) provides practical examples and leverages production-ready Python frameworks.\n\nComprehensive coverage includes not only the models but also libraries for hyperparameter tuning, data preprocessing, and visualization.\nCode examples and solutions to exercises available as Jupyter Notebooks on GitHub.\nAurélien Géron is a former YouTube Product Manager, who lead video classification for Search & Discovery."
  },
  {
    "objectID": "lectures/02/slides.html#further-readings-33",
    "href": "lectures/02/slides.html#further-readings-33",
    "title": "Introduction to machine learning",
    "section": "Further readings (3/3)",
    "text": "Further readings (3/3)\n\n\n\n\n\nMathematics for Machine Learning (Deisenroth, Faisal, and Ong 2020) aims to provide the necessary mathematical skills to read machine learning books.\nPDF of the book\n“This book provides great coverage of all the basic mathematical concepts for machine learning. I’m looking forward to sharing it with students, colleagues, and anyone interested in building a solid understanding of the fundamentals.” Joelle Pineau, McGill University and Facebook"
  },
  {
    "objectID": "lectures/02/slides.html#references",
    "href": "lectures/02/slides.html#references",
    "title": "Introduction to machine learning",
    "section": "References",
    "text": "References\n\n\nBurkov, Andriy. 2019. The Hundred-Page Machine Learning Book. Andriy Burkov.\n\n\nDeisenroth, Marc Peter, A. Aldo Faisal, and Cheng Soon Ong. 2020. Mathematics for Machine Learning. Cambridge University Press. https://doi.org/10.1017/9781108679930.\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 3rd ed. O’Reilly Media, Inc.\n\n\nKingsford, C, and Steven L Salzberg. 2008. “What Are Decision Trees?” Nature Biotechnology 26 (9): 1011–13. https://doi.org/10.1038/nbt0908-1011.\n\n\nMitchell, Tom M. 1997. Machine Learning. New York: McGraw-Hill.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/02/slides.html#next-lecture",
    "href": "lectures/02/slides.html#next-lecture",
    "title": "Introduction to machine learning",
    "section": "Next lecture",
    "text": "Next lecture\n\nLinear regression\nGradient descent"
  },
  {
    "objectID": "lectures/01/index.html",
    "href": "lectures/01/index.html",
    "title": "Administration, exploring various definitions of AI",
    "section": "",
    "text": "Consult the syllabus.\nWatch Super Intelligence from The Future with Hannah Fry aired September 12th, 2024."
  },
  {
    "objectID": "lectures/01/index.html#prepare",
    "href": "lectures/01/index.html#prepare",
    "title": "Administration, exploring various definitions of AI",
    "section": "",
    "text": "Consult the syllabus.\nWatch Super Intelligence from The Future with Hannah Fry aired September 12th, 2024."
  },
  {
    "objectID": "lectures/01/index.html#participate",
    "href": "lectures/01/index.html#participate",
    "title": "Administration, exploring various definitions of AI",
    "section": "Participate",
    "text": "Participate\n\nThese are the slides (PDF) for this week"
  },
  {
    "objectID": "lectures/02/index.html",
    "href": "lectures/02/index.html",
    "title": "Introduction to machine learning",
    "section": "",
    "text": "CSI4106 Jupyter Notebooks and Google Colab Tutorial"
  },
  {
    "objectID": "lectures/02/index.html#prepare",
    "href": "lectures/02/index.html#prepare",
    "title": "Introduction to machine learning",
    "section": "",
    "text": "CSI4106 Jupyter Notebooks and Google Colab Tutorial"
  },
  {
    "objectID": "lectures/02/index.html#participate",
    "href": "lectures/02/index.html#participate",
    "title": "Introduction to machine learning",
    "section": "Participate",
    "text": "Participate\n\nslides (PDF) as a Jupyter Notebook"
  },
  {
    "objectID": "lectures/02/index.html#practice",
    "href": "lectures/02/index.html#practice",
    "title": "Introduction to machine learning",
    "section": "Practice",
    "text": "Practice\nFor those who are not yet familiar with numpy and pandas, it is recommended to explore these tutorials over the coming weeks at your own pace. Aurélien Géron’s notebooks offer insights into essential machine learning concepts.\n\nnumpy – a fundamental library centered around N-dimensional array objects.\npandas – powerfull data analysis tools, centered around the DataFrame.\nvisualization – demonstrates how to use the matplotlib to produce beautiful graphs."
  },
  {
    "objectID": "lectures/03/slides.html#quote-of-the-day",
    "href": "lectures/03/slides.html#quote-of-the-day",
    "title": "Linear models, training",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n\n\n\n\n\n\n\n\nOpenAI released o1 on September 12, 2024: “o1 greatly improves over GPT-4o on challenging reasoning benchmarks. Solid bars show pass@1 accuracy and the shaded region shows the performance of majority vote (consensus) with 64 samples.”"
  },
  {
    "objectID": "lectures/03/slides.html#quote-of-the-day-continued",
    "href": "lectures/03/slides.html#quote-of-the-day-continued",
    "title": "Linear models, training",
    "section": "Quote of the Day (continued)",
    "text": "Quote of the Day (continued)\n\n\n\n\nVideos:\n\nBuilding OpenAI o1\nCoding with OpenAI o1\nScott Wu: OpenAI o1 & Coding\nCatherine Brownstein: Genetics\nMario Krenn: Quantum Physics\nOpenAI o1 playlist\n\n\n\n\nThe videos in this playlist range from 1:17 minute to 3:17 minutes in duration."
  },
  {
    "objectID": "lectures/03/slides.html#training-a-linear-model",
    "href": "lectures/03/slides.html#training-a-linear-model",
    "title": "Linear models, training",
    "section": "Training a Linear Model",
    "text": "Training a Linear Model\nIn this lecture, we will cover the foundational concepts of linear regression, and gradient descent.\nYou will gain a deeper understanding of these essential machine learning techniques, enabling you to apply them effectively in your work.\nGeneral Objective\n\nExplain the process of training a linear model"
  },
  {
    "objectID": "lectures/03/slides.html#learning-objectives",
    "href": "lectures/03/slides.html#learning-objectives",
    "title": "Linear models, training",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDistinguish between regression and classification tasks.\nExplain the training process for linear regression models.\nIn your own words, explain the role of optimization algorithms in solving linear regression problems.\nDescribe the role of partial derivatives in the gradient descent algorithm.\nCompare the batch, stochastic, and mini-batch gradient descent algorithms.\n\nReadings\n\nBased on Géron (2019), \\(\\S\\) 4."
  },
  {
    "objectID": "lectures/03/slides.html#supervised-learning---regression",
    "href": "lectures/03/slides.html#supervised-learning---regression",
    "title": "Learning Algorithms",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\n\nThe training data is a collection of labelled examples.\n\n\\(\\{(x_i,y_i)\\}_{i=1}^N\\)\n\nEach \\(x_i\\) is a feature vector with \\(D\\) dimensions.\n\\(x_i^{(j)}\\) is the value of the feature \\(j\\) of the example \\(i\\), for \\(j \\in 1 \\ldots D\\) and \\(i \\in 1 \\ldots N\\).\n\nThe label \\(y_i\\) is a real number.\n\nProblem: Given the data set as input, create a model that can be used to predict the value of \\(y\\) for an unseen \\(x\\).\n\n\nCan you think of examples of regression tasks?\n. . .\n\nHouse Price Prediction:\n\nApplication: Estimating the market value of residential properties based on features such as location, size, number of bedrooms, age, and amenities.\n\nStock Market Forecasting:\n\nApplication: Predicting future prices of stocks or indices based on historical data, financial indicators, and economic variables.\n\nWeather Prediction:\n\nApplication: Estimating future temperatures, rainfall, and other weather conditions using historical weather data and atmospheric variables.\n\nSales Forecasting:\n\nApplication: Predicting future sales volumes for products or services by analyzing past sales data, market trends, and seasonal patterns.\n\nEnergy Consumption Prediction:\n\nApplication: Forecasting future energy usage for households, industries, or cities based on historical consumption data, weather conditions, and economic factors.\n\nMedical Cost Estimation:\n\nApplication: Predicting healthcare costs for patients based on their medical history, demographic information, and treatment plans.\n\nTraffic Flow Prediction:\n\nApplication: Estimating future traffic volumes and congestion levels on roads and highways using historical traffic data and real-time sensor inputs.\n\nCustomer Lifetime Value (CLV) Estimation:\n\nApplication: Predicting the total revenue a business can expect from a customer over the duration of their relationship, based on purchasing behavior and demographic data.\n\nEconomic Indicators Forecasting:\n\nApplication: Predicting key economic indicators such as GDP growth, unemployment rates, and inflation using historical economic data and market trends.\n\nDemand Forecasting:\n\nApplication: Estimating future demand for products or services in various industries like retail, manufacturing, and logistics to optimize inventory and supply chain management.\n\nReal Estate Valuation:\n\nApplication: Assessing the market value of commercial properties like office buildings, malls, and industrial spaces based on location, size, and market conditions.\n\nInsurance Risk Assessment:\n\nApplication: Predicting the risk associated with insuring individuals or properties, which helps in determining premium rates, based on historical claims data, and demographic factors.\n\nAd Click-Through Rate (CTR) Prediction:\n\nApplication: Estimating the likelihood that a user will click on an online advertisement based on user behavior, ad characteristics, and contextual factors.\n\nLoan Default Prediction:\n\nApplication: Predicting the probability of a borrower defaulting on a loan based on credit history, income, loan amount, and other financial indicators.\n\n\nFocusing on applications possibly running on a mobile device.\n\nBattery Life Prediction:\n\nApplication: Estimating remaining battery life based on usage patterns, running applications, and device settings.\n\nHealth and Fitness Tracking:\n\nApplication: Predicting calorie burn, heart rate, or sleep quality based on user activity, biometrics, and historical health data.\n\nPersonal Finance Management:\n\nApplication: Forecasting future expenses or savings based on spending habits, income patterns, and budget goals.\n\nWeather Forecasting:\n\nApplication: Providing personalized weather forecasts based on current location and historical weather data.\n\nTraffic and Commute Time Estimation:\n\nApplication: Predicting travel times and suggesting optimal routes based on historical traffic data, real-time conditions, and user behavior.\n\nImage and Video Quality Enhancement:\n\nApplication: Adjusting image or video quality settings (e.g., brightness, contrast) based on lighting conditions and user preferences.\n\nFitness Goal Achievement:\n\nApplication: Estimating the time needed to achieve fitness goals such as weight loss or muscle gain based on user activity and dietary input.\n\nMobile Device Performance Optimization:\n\nApplication: Predicting the optimal settings for device performance and battery life based on usage patterns and app activity."
  },
  {
    "objectID": "lectures/03/slides.html#k-nearest-neighbors",
    "href": "lectures/03/slides.html#k-nearest-neighbors",
    "title": "Learning Algorithms",
    "section": "k-nearest neighbors",
    "text": "k-nearest neighbors\n\n\n\n\n\n\nKNeighborsClassifier, examples\nKNeighborsRegressor, exemples\n\n\n\nAs indicated in the introductory lecture, I aim to present a series of concepts leading to deep learning. As a starting point, linear regression would be a logical choice as a primary learning algorithm to examine. Nonetheless, it is equally critical to possess a high-level understanding of various other learning algorithms, as they differ significantly in model structures and training processes. Therefore, I will briefly discuss k-nearest neighbors and decision trees, before introducing linear regression.\nThe k-nearest neighbor (KNN) algorithm is a simple, non-parametric, instance-based learning method used for classification and regression. It classifies a data point based on the majority label of its \\(k\\) nearest neighbors in the feature space, where \\(k\\) is a user-defined constant. Distance metrics like Euclidean distance are commonly used to determine the nearest neighbors. In the re\nIn the context of regression, the predicted value \\(\\hat{y}(x)\\) is calculated as a weighted sum of the labels of its \\(k\\) nearest neighbours. The weights can be uniform or based on distance, reflecting the proximity of each neighbour to the query point \\(x\\).\nFor a query point \\(x\\), let its \\(k\\) nearest neighbors have targets \\(y_1, \\dots, y_k\\) and distances \\(d_1, \\dots, d_k\\).\n\nUniform weights (default):\n\n\\[\n\\hat{y}(x) = \\frac{1}{k} \\sum_{i=1}^k y_i\n\\]\n\nDistance weights (the built-in option \"distance\"):\n\n\\[\n\\hat{y}(x) = \\frac{\\sum_{i=1}^k \\frac{1}{d_i} \\, y_i}{\\sum_{i=1}^k \\frac{1}{d_i}}\n\\]\nIn the above, as the distance \\(d_i\\) between the example \\(x_i\\) and the example \\(x\\) increases, the reciprocal \\(\\frac{1}{d_i}\\) decreases. Consequently, examples that are farther from \\(x\\) exert less influence on the predicted outcome, \\(\\hat{y}(x)\\).\nIn both cases, convex combination property guarantees that:\n\\[\n\\min(y_1, \\dots, y_k) \\;\\; \\leq \\;\\; \\hat{y}(x) \\;\\; \\leq \\;\\; \\max(y_1, \\dots, y_k).\n\\]\nA non-parametric algorithm does not make any assumptions about the underlying data distribution and does not learn a fixed set of parameters or a model during the training phase. Instead, it relies directly on the training data to make decisions at the time of classification or regression, making it flexible and adaptive to various data shapes but potentially computationally expensive at prediction time.\nKNN has clear limitations:\n\nComputational cost\n\nPrediction requires computing distances to all training points, \\(O(n)\\) per query.\n\nCurse of dimensionality\n\nIn high-dimensional spaces, distance metrics lose discriminative power.\n\nChoice of \\(k\\) and distance metric\n\nSmall \\(k\\): high variance, sensitive to noise/outliers.\nLarge \\(k\\): high bias, oversmoothing.\n\nSensitivity to feature scaling\n\nDistances are scale-dependent; variables with larger ranges dominate unless features are normalized/standardized.\n\nImbalanced data\n\nIn classification, if one class is much more frequent, KNN can be biased toward that class since neighbors are more likely to belong to it.\n\nNot extrapolative\n\nPredictions are always convex combinations (in regression) or majority votes (in classification) of training labels.\nThis means KNN cannot extrapolate trends outside the range of observed training data.\n\n\nIn scikit-learn, several models are commonly used for regression tasks. Here are some of the main models:\n\nLinear Regression (LinearRegression):\n\nA simple linear approach that models the relationship between the independent variables and the dependent variable by fitting a linear equation to the observed data.\n\nSupport Vector Regression (SVR):\n\nAn extension of Support Vector Machines (SVM) for regression tasks, which tries to fit the best line within a specified margin of tolerance.\n\nDecision Tree Regression (DecisionTreeRegressor):\n\nUses decision trees to model the relationship between the input features and the target variable by recursively splitting the data into subsets.\n\nRandom Forest Regression (RandomForestRegressor):\n\nAn ensemble method that uses multiple decision trees to improve predictive accuracy and control overfitting.\n\nGradient Boosting Regression (GradientBoostingRegressor):\n\nAnother ensemble method that builds sequential decision trees, where each tree corrects the errors of the previous one.\n\nK-Nearest Neighbors Regression (KNeighborsRegressor):\n\nA non-parametric method that predicts the target variable based on the average of the k-nearest neighbors in the feature space.\n\n\nThese models offer a range of approaches to handle different types of regression problems, each with its own strengths and suitable applications.\n\n\nAttribution: Nearest Neighbors Classification."
  },
  {
    "objectID": "lectures/03/slides.html#rationale",
    "href": "lectures/03/slides.html#rationale",
    "title": "Learning Algorithms",
    "section": "Rationale",
    "text": "Rationale\nLinear regression is introduced to conveniently present a well-known training algorithm, gradient descent. Additionally, it serves as a foundation for introducing logistic regression–a classification algorithm—which further facilitates discussions on artificial neural networks.\n\nLinear Regression\n\nGradient Descent\nLogistic Regression\n\nNeural Networks\n\n\n\n\nThe training algorithms for machine learning models can vary significantly depending on the model (e.g., decision trees, SVMs, etc.). In order to fit our schedule, we will concentrate on this specific sequence.\nThe concept of linear regression can be traced back to the early work of Sir Francis Galton in the late 19th century. Galton introduced the idea of “regression” in his 1886 paper, which focused on the relationship between the heights of parents and their children. He observed that children’s heights tended to regress towards the average, which led to the term “regression.”\nHowever, the mathematical formulation of linear regression is closely associated with the work of Karl Pearson, who in the early 20th century extended Galton’s ideas to create the method of least squares for fitting a linear model. The method itself, though, was developed earlier in 1805 by Adrien-Marie Legendre and independently by Carl Friedrich Gauss for astronomical data analysis.\nSee: Stanton (2001)."
  },
  {
    "objectID": "lectures/03/slides.html#supervised-learning---regression-1",
    "href": "lectures/03/slides.html#supervised-learning---regression-1",
    "title": "Learning Algorithms",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\n\nThe training data is a collection of labelled examples.\n\n\\(\\{(x_i,y_i)\\}_{i=1}^N\\)\n\nEach \\(x_i\\) is a feature vector with \\(D\\) dimensions.\n\\(x_i^{(j)}\\) is the value of the feature \\(j\\) of the example \\(i\\),\\ for \\(j \\in 1 \\ldots D\\) and \\(i \\in 1 \\ldots N\\).\n\nThe label \\(y_i\\) is a real number.\n\nProblem: Given the data set as input, create a model that can be used to predict the value of \\(y\\) for an unseen \\(x\\)."
  },
  {
    "objectID": "lectures/03/slides.html#supervised-learning---regression-2",
    "href": "lectures/03/slides.html#supervised-learning---regression-2",
    "title": "Learning Algorithms",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\nFocusing on applications possibly running on a mobile device.\n\n\nBattery Life Prediction:\n\nApplication: Estimating remaining battery life based on usage patterns, running applications, and device settings.\n\nHealth and Fitness Tracking:\n\nApplication: Predicting calorie burn, heart rate, or sleep quality based on user activity, biometrics, and historical health data.\n\nPersonal Finance Management:\n\nApplication: Forecasting future expenses or savings based on spending habits, income patterns, and budget goals.\n\nWeather Forecasting:\n\nApplication: Providing personalized weather forecasts based on current location and historical weather data.\n\nTraffic and Commute Time Estimation:\n\nApplication: Predicting travel times and suggesting optimal routes based on historical traffic data, real-time conditions, and user behavior.\n\nImage and Video Quality Enhancement:\n\nApplication: Adjusting image or video quality settings (e.g., brightness, contrast) based on lighting conditions and user preferences.\n\nFitness Goal Achievement:\n\nApplication: Estimating the time needed to achieve fitness goals such as weight loss or muscle gain based on user activity and dietary input.\n\nMobile Device Performance Optimization:\n\nApplication: Predicting the optimal settings for device performance and battery life based on usage patterns and app activity."
  },
  {
    "objectID": "lectures/03/slides.html#linear-regression",
    "href": "lectures/03/slides.html#linear-regression",
    "title": "Learning Algorithms",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\[\n\\hat{y_i} = h(x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\n\nHere, \\(\\theta_{j}\\) is the \\(j\\)th parameter of the (linear) model, with \\(\\theta_0\\) being the bias term/parameter, and \\(\\theta_1 \\ldots \\theta_D\\) being the feature weights."
  },
  {
    "objectID": "lectures/03/slides.html#linear-regression-continued",
    "href": "lectures/03/slides.html#linear-regression-continued",
    "title": "Learning Algorithms",
    "section": "Linear Regression (continued)",
    "text": "Linear Regression (continued)\nProblem: find values for all the model parameters so that the model “best fits” the training data.\n\n\nThe Root Mean Square Error is a common performance measure for regression problems.\n\n\\[\n    \\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#linearregression",
    "href": "lectures/03/slides.html#linearregression",
    "title": "Learning Algorithms",
    "section": "LinearRegression",
    "text": "LinearRegression\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\n\nHerein, we examine a straightforward model involving a single variable."
  },
  {
    "objectID": "lectures/03/slides.html#source-code",
    "href": "lectures/03/slides.html#source-code",
    "title": "Learning Algorithms",
    "section": "Source code",
    "text": "Source code\n\nimport numpy as np\n\nX = 6 * np.random.rand(100, 1) - 4\ny = X ** 2 - 4 * X + 5 + np.random.randn(100, 1)\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nX_new = np.array([[-4], [2]])\ny_pred = lin_reg.predict(X_new)\n\n\n\nThe data have been generated from a quadratic model, \\(x^2 - 4x + 5\\), with Gaussian noise added to make the synthetic data more realistic.\nThis example illustrates that, in practice, we often have limited knowledge about the underlying model that generated the data.\nDespite this uncertainty, we make assumptions—in this case, assuming linearity—when building our models.\nLater, we will refer to this as bias (distinct from the bias parameter in our regression model). Both bias and variance influence the performance of our models.\n\n\nThis slide contains an anomaly. Can you identify it?"
  },
  {
    "objectID": "lectures/03/slides.html#gpt-4o-interactions-2024-09-14",
    "href": "lectures/03/slides.html#gpt-4o-interactions-2024-09-14",
    "title": "Learning Algorithms",
    "section": "GPT 4o interactions (2024-09-14)",
    "text": "GPT 4o interactions (2024-09-14)\nUser: Explain the code on the previous slide line by line.\n\nAI: Certainly! Here is a line-by-line explanation of the provided code:\n\nimport numpy as np\n\n\nExplanation: This line imports the NumPy library, which is a fundamental package for numerical computations in Python. It is commonly used for working with arrays and matrices, as well as for performing a variety of mathematical operations.\n\n\nX = 6 * np.random.rand(100, 1) - 4\n\n\nExplanation: This line generates a NumPy array X containing 100 rows and 1 column of random numbers. The np.random.rand(100, 1) function generates uniformly distributed random numbers between 0 and 1. Multiplying by 6 scales these numbers to the range [0, 6), and subtracting 4 shifts the range to [-4, 2).\n\n\ny = X ** 2 - 4 * X + 5 + np.random.randn(100, 1)\n\n\nExplanation: This line generates the target variable y based on a quadratic equation with some added noise. Specifically:\n\nX ** 2 computes the square of each element in X.\n- 4 * X subtracts four times each element in X.\n+ 5 adds a constant term of 5.\n+ np.random.randn(100, 1) adds Gaussian noise with a mean of 0 and standard deviation of 1 to each element, making the data more realistic by introducing some randomness.\n\n\n\nfrom sklearn.linear_model import LinearRegression\n\n\nExplanation: This line imports the LinearRegression class from the sklearn.linear_model module, which is part of the Scikit-Learn library. Scikit-Learn is widely used for machine learning in Python.\n\n\nlin_reg = LinearRegression()\n\n\nExplanation: This line creates an instance of the LinearRegression class and assigns it to the variable lin_reg. This object will be used to fit the linear regression model to the data.\n\n\nlin_reg.fit(X, y)\n\n\nExplanation: This line fits the linear regression model to the data by finding the best-fitting line through the points (X, y). The fit method trains the model using the provided features X and target variable y.\n\n\nX_new = np.array([[-4], [2]])\n\n\nExplanation: This line creates a new NumPy array X_new with two values: -4 and 2. These values represent new data points for which we want to predict the target variable using the trained model.\n\n\ny_pred = lin_reg.predict(X_new)\n\n\nExplanation: This line uses the trained linear regression model to predict the target variable y_pred for the new data points in X_new. The predict method returns the predicted values based on the fitted model.\n\nIn summary, this script generates synthetic data, fits a linear regression model to it, and then uses the model to make predictions on new data points."
  },
  {
    "objectID": "lectures/03/slides.html#source-code-continued",
    "href": "lectures/03/slides.html#source-code-continued",
    "title": "Learning Algorithms",
    "section": "Source code (continued)",
    "text": "Source code (continued)\n\nimport os\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"pdf\", resolution=300):\n    path = os.path.join(fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)"
  },
  {
    "objectID": "lectures/03/slides.html#source-code-continued-1",
    "href": "lectures/03/slides.html#source-code-continued-1",
    "title": "Learning Algorithms",
    "section": "Source code (continued)",
    "text": "Source code (continued)\n\nplt.plot(X, y, \"b.\")\nplt.plot(X_new, y_pred, \"r-\")\nplt.xlabel(\"$x$\", fontsize=18)\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\nplt.axis([-4, 2, -1, 35])\nsave_fig(\"regression_linear-01\")\nplt.show()"
  },
  {
    "objectID": "lectures/03/slides.html#andrew-ng",
    "href": "lectures/03/slides.html#andrew-ng",
    "title": "Learning Algorithms",
    "section": "Andrew Ng",
    "text": "Andrew Ng\n\n\n\n\n\nGradient Descent (Math)  (11:30 m)\nIntuition (11:51 m)\nLinear Regression (10:20 m)\nML-005 | Stanford | Andrew Ng (19 videos)\n\n\n\n\nAndrew Ng is Founder of DeepLearning.AI, Founder & CEO of Landing AI, General Partner at AI Fund, Chairman and Co-Founder of Coursera and an Adjunct Professor at Stanford University’s Computer Science Department.\nNg was also a cofounder and head of Google Brain and was the former Chief Scientist at Baidu.\n\n\nAndrew Ng is presenting the gradient descent algorithm using a linear regression with one variable."
  },
  {
    "objectID": "lectures/03/slides.html#blue1brown",
    "href": "lectures/03/slides.html#blue1brown",
    "title": "Learning Algorithms",
    "section": "3Blue1Brown",
    "text": "3Blue1Brown\n\nEssence of linear algebra\n\nA series of 16 videos (10 to 15 minutes per video) providing “a geometric understanding of matrices, determinants, eigen-stuffs and more.”\n\n6,662,732 views as of September 30, 2019.\n\n\nEssence of calculus\n\nA series of 12 videos (15 to 20 minutes per video): “The goal here is to make calculus feel like something that you yourself could have discovered.”\n\n2,309,726 views as of September 30, 2019."
  },
  {
    "objectID": "lectures/03/slides.html#supervised-learning---regression-3",
    "href": "lectures/03/slides.html#supervised-learning---regression-3",
    "title": "Learning Algorithms",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\n\nThe training data is a collection of labelled examples.\n\n\\(\\{(x_i,y_i)\\}_{i=1}^N\\)\n\nEach \\(x_i\\) is a feature vector with \\(D\\) dimensions.\n\\(x_i^{(j)}\\) is the value of the feature \\(j\\) of the example \\(i\\),\\ for \\(j \\in 1 \\ldots D\\) and \\(i \\in 1 \\ldots N\\).\n\nThe label \\(y_i\\) is a real number.\n\nProblem: Given the data set as input, create a model that can be used to predict the value of \\(y\\) for an unseen \\(x\\)."
  },
  {
    "objectID": "lectures/03/slides.html#building-blocks-1",
    "href": "lectures/03/slides.html#building-blocks-1",
    "title": "Learning Algorithms",
    "section": "Building blocks",
    "text": "Building blocks\nA typical learning algorithm comprises the following components:\n\nA model, often consisting of a set of weights whose values will be “learnt”.\nAn objective function.\n\nIn the case of regression, this is often a loss function, a function that quantifies misclassification. The Root Mean Square Error is a common loss function for regression problems. \\(\\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\\)\n\nOptimization algorithm"
  },
  {
    "objectID": "lectures/03/slides.html#optimization",
    "href": "lectures/03/slides.html#optimization",
    "title": "Learning Algorithms",
    "section": "Optimization",
    "text": "Optimization\nUntil some termination criteria is met1:\n\nEvaluate the loss function, comparing \\(h(x_i)\\) to \\(y_i\\).\nMake small changes to the weights, in a way that reduces the value of the loss function.\n\nE.g. the value of the loss function no longer decreases or the maximum number of iterations."
  },
  {
    "objectID": "lectures/03/slides.html#derivative",
    "href": "lectures/03/slides.html#derivative",
    "title": "Learning Algorithms",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will start with a single-variable function.\nThink of this as our loss function, which we aim to minimize; to reduce the average discrepancy between expected and predicted values.\nHere, I am using \\(t\\) to avoid any confusion with the attributes of our training examples."
  },
  {
    "objectID": "lectures/03/slides.html#source-code-1",
    "href": "lectures/03/slides.html#source-code-1",
    "title": "Learning Algorithms",
    "section": "Source code",
    "text": "Source code\n\nfrom sympy import *\n\nx = symbols('t')\n\nf = t**2 + 4*t + 7\n\nplot(f)\n\n\n\nOn the previous slide, I’ve used SymPy, a library for symbolic mathematics."
  },
  {
    "objectID": "lectures/03/slides.html#derivative-1",
    "href": "lectures/03/slides.html#derivative-1",
    "title": "Learning Algorithms",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe graph of the derivative, \\(f^{'}(t)\\), is depicted in red.\nThe derivative indicates how changes in the input affect the output, \\(f(t)\\).\nThe magnitude of the derivative at \\(t = -2\\) is \\(0\\).\nThis point corresponds to the minimum of our function.\n\n\n\nNear \\(t = -2\\), variations in \\(t\\) have minimal impact on the output, \\(f(t)\\)."
  },
  {
    "objectID": "lectures/03/slides.html#derivative-2",
    "href": "lectures/03/slides.html#derivative-2",
    "title": "Learning Algorithms",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen evaluated at a specific point, the derivative indicates the slope of the tangent line to the graph of the function at that point.\nAt \\(t= -2\\), the slope of the tangent line is 0."
  },
  {
    "objectID": "lectures/03/slides.html#derivative-3",
    "href": "lectures/03/slides.html#derivative-3",
    "title": "Learning Algorithms",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nA positive derivative indicates that increasing the input variable will increase the output value.\nAdditionally, the magnitude of the derivative quantifies how rapidly the output changes."
  },
  {
    "objectID": "lectures/03/slides.html#derivative-4",
    "href": "lectures/03/slides.html#derivative-4",
    "title": "Learning Algorithms",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nA negative derivative indicates that increasing the input variable will decrease the output value.\nAdditionally, the magnitude of the derivative quantifies how rapidly the output changes."
  },
  {
    "objectID": "lectures/03/slides.html#source-code-2",
    "href": "lectures/03/slides.html#source-code-2",
    "title": "Learning Algorithms",
    "section": "Source code",
    "text": "Source code\n\nimport sympy as sp\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the variable and function\nt = sp.symbols('t')\nf = t**2 + 4*t + 7\n\n# Compute the derivative\nf_prime = sp.diff(f, t)\n\n# Lambdify the functions for numerical plotting\nf_func = sp.lambdify(t, f, \"numpy\")\nf_prime_func = sp.lambdify(t, f_prime, \"numpy\")\n\n# Generate t values for plotting\nt_vals = np.linspace(-5, 2, 400)\n\n# Get y values for the function and its derivative\nf_vals = f_func(t_vals)\nf_prime_vals = f_prime_func(t_vals)\n\n# Plot the function and its derivative\nplt.plot(t_vals, f_vals, label=r'$f(t) = t^2 + 4t + 7$', color='blue')\nplt.plot(t_vals, f_prime_vals, label=r\"$f'(t) = 2t + 4$\", color='red')\n\n# Fill the area below the derivative where it's negative\nplt.fill_between(t_vals, f_prime_vals, where=(f_prime_vals &gt; 0), color='red', alpha=0.3)\n\n# Add labels and legend\nplt.axhline(0, color='black',linewidth=1)\nplt.axvline(0, color='black',linewidth=1)\nplt.title('Function and Derivative')\nplt.xlabel('t')\nplt.ylabel('y')\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/03/slides.html#recall",
    "href": "lectures/03/slides.html#recall",
    "title": "Learning Algorithms",
    "section": "Recall",
    "text": "Recall\n\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\[\n\\hat{y_i} = h(x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\n\nHere, \\(\\theta_{j}\\) is the \\(j\\)th parameter of the (linear) model, with \\(\\theta_0\\) being the bias term/parameter, and \\(\\theta_1 \\ldots \\theta_D\\) being the feature weights."
  },
  {
    "objectID": "lectures/03/slides.html#recall-1",
    "href": "lectures/03/slides.html#recall-1",
    "title": "Learning Algorithms",
    "section": "Recall",
    "text": "Recall\n\nThe Root Mean Square Error (RMSE) is a common loss function for regression problems. \\[\n  \\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\n\\]\nIn practice, minimizing the Mean Squared Error (MSE) is easier and gives the same result. \\[\n    \\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#gradient-descent---intuition",
    "href": "lectures/03/slides.html#gradient-descent---intuition",
    "title": "Learning Algorithms",
    "section": "Gradient descent - intuition",
    "text": "Gradient descent - intuition"
  },
  {
    "objectID": "lectures/03/slides.html#gradient-descent---single-value",
    "href": "lectures/03/slides.html#gradient-descent---single-value",
    "title": "Learning Algorithms",
    "section": "Gradient descent - single value",
    "text": "Gradient descent - single value\n\nOur model: \\[\nh(x_i) = \\theta_0 + \\theta_1 x_i^{(1)}\n\\]\nOur loss function: \\[\nJ(\\theta_0, \\theta_1) = \\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2\n\\]\nProblem: find the values of \\(\\theta_0\\) and \\(\\theta_1\\) that minimize \\(J\\)."
  },
  {
    "objectID": "lectures/03/slides.html#gradient-descent---single-value-1",
    "href": "lectures/03/slides.html#gradient-descent---single-value-1",
    "title": "Learning Algorithms",
    "section": "Gradient descent - single value",
    "text": "Gradient descent - single value\n\nInitialization: \\(\\theta_0\\) and \\(\\theta_1\\) - either with random values or zeros.\nLoop:\n\nrepeat until convergence: \\[\n\\theta_j := \\theta_j - \\alpha \\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1) , \\text{for } j=0 \\text{ and } j=1\n\\]\n\n\\(\\alpha\\) is called the learning rate - this is the size of each step.\n\\(\\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1)\\) is the partial derivative with respect to \\(\\theta_j\\).\n\n\nA partial derivative represents the rate of change of a multivariable function with respect to one of its variables, while keeping the other variables constant.\nFor the algorithm to be mathematically sound, all the \\(\\theta_j\\) must be updated simultaneously."
  },
  {
    "objectID": "lectures/03/slides.html#partial-derivatives",
    "href": "lectures/03/slides.html#partial-derivatives",
    "title": "Learning Algorithms",
    "section": "Partial derivatives",
    "text": "Partial derivatives\nGiven\n\\[\nJ(\\theta_0, \\theta_1) = \\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2 = \\frac{1}{N}\\sum_1^N [\\theta_0 + \\theta_1 x_i - y_i]^2\n\\]\n\nWe have\n\\[\n\\frac {\\partial}{\\partial \\theta_0}J(\\theta_0, \\theta_1) = \\frac{2}{N} \\sum\\limits_{i=1}^{N} (\\theta_0 - \\theta_1 x_i - y_{i})\n\\]\n\n\nand\n\\[\n\\frac {\\partial}{\\partial \\theta_1}J(\\theta_0, \\theta_1) = \\frac{2}{N} \\sum\\limits_{i=1}^{N} x_{i} \\left(\\theta_0 + \\theta_1 x_i - y_{i}\\right)\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#partial-derivate-sympy",
    "href": "lectures/03/slides.html#partial-derivate-sympy",
    "title": "Learning Algorithms",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\nfrom IPython.display import Math, display\nfrom sympy import *\n\n# Define the symbols\n\ntheta_0, theta_1, x_i, y_i = symbols('theta_0 theta_1 x_i y_i')\n\n# Define the hypothesis function:\n\nh = theta_0 + theta_1 * x_i\n\nprint(\"Hypothesis function:\")\n\ndisplay(Math('h(x) = ' + latex(h)))\n\nHypothesis function:\n\n\n\\(\\displaystyle h(x) = \\theta_{0} + \\theta_{1} x_{i}\\)"
  },
  {
    "objectID": "lectures/03/slides.html#partial-derivate-sympy-1",
    "href": "lectures/03/slides.html#partial-derivate-sympy-1",
    "title": "Learning Algorithms",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\nN = Symbol('N', integer=True)\n\n# Define the loss function (mean squared error)\n\nJ = (1/N) * Sum((h - y_i)**2, (x_i, 1, N))\n\nprint(\"Loss function:\")\n\ndisplay(Math('J = ' + latex(J)))\n\nLoss function:\n\n\n\\(\\displaystyle J = \\frac{\\sum_{x_{i}=1}^{N} \\left(\\theta_{0} + \\theta_{1} x_{i} - y_{i}\\right)^{2}}{N}\\)"
  },
  {
    "objectID": "lectures/03/slides.html#partial-derivate-sympy-2",
    "href": "lectures/03/slides.html#partial-derivate-sympy-2",
    "title": "Learning Algorithms",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\n# Calculate the partial derivative with respect to theta_0\n\npartial_derivative_theta_0 = diff(J, theta_0)\n\nprint(\"Partial derivative with respect to theta_0:\")\n\ndisplay(Math(latex(partial_derivative_theta_0)))\n\nPartial derivative with respect to theta_0:\n\n\n\\(\\displaystyle \\frac{\\sum_{x_{i}=1}^{N} \\left(2 \\theta_{0} + 2 \\theta_{1} x_{i} - 2 y_{i}\\right)}{N}\\)"
  },
  {
    "objectID": "lectures/03/slides.html#partial-derivate-sympy-3",
    "href": "lectures/03/slides.html#partial-derivate-sympy-3",
    "title": "Learning Algorithms",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\n# Calculate the partial derivative with respect to theta_1\n\npartial_derivative_theta_1 = diff(J, theta_1)\n\nprint(\"\\nPartial derivative with respect to theta_1:\")\n\ndisplay(Math(latex(partial_derivative_theta_1)))\n\n\nPartial derivative with respect to theta_1:\n\n\n\\(\\displaystyle \\frac{\\sum_{x_{i}=1}^{N} 2 x_{i} \\left(\\theta_{0} + \\theta_{1} x_{i} - y_{i}\\right)}{N}\\)"
  },
  {
    "objectID": "lectures/03/slides.html#multivariate-linear-regression",
    "href": "lectures/03/slides.html#multivariate-linear-regression",
    "title": "Learning Algorithms",
    "section": "Multivariate linear regression",
    "text": "Multivariate linear regression\n\\[\nh (x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\theta_3 x_i^{(3)} + \\cdots + \\theta_D x_i^{(D)}\n\\]\n\\[\n\\begin{align*}\n  x_i^{(j)} &= \\text{value of the feature } j \\text{ in the } i \\text{th example} \\\\\n  D &= \\text{the number of features}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#gradient-descent---multivariate",
    "href": "lectures/03/slides.html#gradient-descent---multivariate",
    "title": "Learning Algorithms",
    "section": "Gradient descent - multivariate",
    "text": "Gradient descent - multivariate\nThe new loss function is\n\\[\nJ(\\theta_0, \\theta_1,\\ldots,\\theta_D) =  \\dfrac {1}{N} \\displaystyle \\sum _{i=1}^N \\left (h(x_{i}) - y_i \\right)^2\n\\]\nIts partial derivative:\n\\[\n\\frac {\\partial}{\\partial \\theta_j}J(\\theta) = \\frac{2}{N} \\sum\\limits_{i=1}^N x_i^{(j)} \\left( \\theta x_i - y_i \\right)\n\\]\nwhere \\(\\theta\\), \\(x_i\\) and \\(y_i\\) are vectors, and \\(\\theta x_i\\) is a vector operation!"
  },
  {
    "objectID": "lectures/03/slides.html#gradient-vector",
    "href": "lectures/03/slides.html#gradient-vector",
    "title": "Learning Algorithms",
    "section": "Gradient vector",
    "text": "Gradient vector\nThe vector containing the partial derivative of \\(J\\) (with respect to \\(\\theta_j\\), for \\(j \\in \\{0, 1\\ldots D\\}\\)) is called the gradient vector.\n\\[\n\\nabla_\\theta J(\\theta) = \\begin{pmatrix}\n  \\frac {\\partial}{\\partial \\theta_0}J(\\theta) \\\\\n  \\frac {\\partial}{\\partial \\theta_1}J(\\theta) \\\\\n  \\vdots  \\\\\n  \\frac {\\partial}{\\partial \\theta_D}J(\\theta)\\\\\n\\end{pmatrix}\n\\]\n\n\nThis vector gives the direction of the steepest ascent.\nIt gives its name to the gradient descent algorithm:\n\n\\[\n\\theta' = \\theta - \\alpha \\nabla_\\theta J(\\theta)\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#gradient-descent---multivariate-1",
    "href": "lectures/03/slides.html#gradient-descent---multivariate-1",
    "title": "Learning Algorithms",
    "section": "Gradient descent - multivariate",
    "text": "Gradient descent - multivariate\nThe gradient descent algorithm becomes:\nRepeat until convergence:\n\\[\n\\begin{aligned}\n\\{ & \\\\\n\\theta_j := & \\theta_j -  \\alpha  \\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1, \\ldots, \\theta_D) \\\\\n&\\text{for } j \\in [0, \\ldots, D] \\textbf{ (update simultaneously)} \\\\\n\\} &\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#gradient-descent---multivariate-2",
    "href": "lectures/03/slides.html#gradient-descent---multivariate-2",
    "title": "Learning Algorithms",
    "section": "Gradient descent - multivariate",
    "text": "Gradient descent - multivariate\nRepeat until convergence:\n\\[\n\\begin{aligned}\n\\; \\{ & \\\\\n\\; & \\theta_0 := \\theta_0 - \\alpha \\frac{2}{N} \\sum\\limits_{i=1}^{N}  x^{0}_i(h(x_i) - y_i) \\\\\n\\; & \\theta_1 := \\theta_1 - \\alpha \\frac{2}{N} \\sum\\limits_{i=1}^{N}  x^{1}_i(h(x_i) - y_i)  \\\\\n\\; & \\theta_2 := \\theta_2 - \\alpha \\frac{2}{N} \\sum\\limits_{i=1}^{N}  x^{2}_i(h(x_i) - y_i) \\\\\n   & \\cdots \\\\\n\\} &\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#assumptions",
    "href": "lectures/03/slides.html#assumptions",
    "title": "Learning Algorithms",
    "section": "Assumptions",
    "text": "Assumptions\nWhat were our assumptions?\n\n\nThe (objective/loss) function is differentiable."
  },
  {
    "objectID": "lectures/03/slides.html#local-vs.-global",
    "href": "lectures/03/slides.html#local-vs.-global",
    "title": "Learning Algorithms",
    "section": "Local vs. global",
    "text": "Local vs. global\n\nA function is convex if for any pair of points on the graph of the function, the line connecting these two points lies above or on the graph.\n\nA convex function has a single minimum.\n\nThe loss function for the linear regression (MSE) is convex.\n\n\nFor functions that are not convex, the gradient descent algorithm converges to a local minimum.\nThe loss function generally used with linear or logistic regressions, and Support Vector Machines (SVM) are convex, but not the ones for artificial neural networks.\n\n\nA function would be convex downward or concave if those lines were below or on the graph of the function."
  },
  {
    "objectID": "lectures/03/slides.html#local-vs.-global-1",
    "href": "lectures/03/slides.html#local-vs.-global-1",
    "title": "Learning Algorithms",
    "section": "Local vs. global",
    "text": "Local vs. global\n\n\n\n\n\n\n\nAttribution: commons.wikimedia.org/wiki/File:Extrema_example.svg"
  },
  {
    "objectID": "lectures/03/slides.html#learning-rate",
    "href": "lectures/03/slides.html#learning-rate",
    "title": "Learning Algorithms",
    "section": "Learning rate",
    "text": "Learning rate\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmall steps, low values for \\(\\alpha\\), will make the algorithm converge slowly.\nLarge steps might cause the algorithm to diverge.\nNotice how the algorithm slows down naturally when approaching a minimum."
  },
  {
    "objectID": "lectures/03/slides.html#batch-gradient-descent",
    "href": "lectures/03/slides.html#batch-gradient-descent",
    "title": "Learning Algorithms",
    "section": "Batch gradient descent",
    "text": "Batch gradient descent\n\nTo be more precise, this algorithm is known as batch gradient descent since for each iteration, it processes the “whole batch” of training examples.\n\n\n\nLiterature suggests that the algorithm might take more time to converge if the features are on different scales."
  },
  {
    "objectID": "lectures/03/slides.html#batch-gradient-descent---drawback",
    "href": "lectures/03/slides.html#batch-gradient-descent---drawback",
    "title": "Learning Algorithms",
    "section": "Batch gradient descent - drawback",
    "text": "Batch gradient descent - drawback\n\nThe batch gradient descent algorithm becomes very slow as the number of training examples increases.\n\n\n\nThis is because all the training data is seen at each iteration. The algorithm is generally run for a fixed number of iterations, say 1000."
  },
  {
    "objectID": "lectures/03/slides.html#stochastic-gradient-descent",
    "href": "lectures/03/slides.html#stochastic-gradient-descent",
    "title": "Learning Algorithms",
    "section": "Stochastic Gradient Descent",
    "text": "Stochastic Gradient Descent\nThe stochastic gradient descent algorithm randomly selects one training instance to calculate its gradient.\nepochs = 10\nfor epoch in range(epochs):\n   for i in range(N):\n         selection = np.random.randint(N)\n         # Calculate the gradient using selection\n         # Update the weights\n\nThis allows it to work with large training sets.\nIts trajectory is not as regular as the batch algorithm.\n\nBecause of its bumpy trajectory, it is often better at finding the global minima, when compared to batch.\nIts bumpy trajectory makes it bounce around the local minima.\n\n\n\nTo mitigate the issue of oscillating around local minima, it is advisable to progressively reduce the learning rate as the number of epochs increases. This technique, known as a learning schedule, helps achieve more stable convergence.\nIt important that the examples are either selected randomly or shuffled before running the algorithm to make sure that the algorithm converges towards the global minima."
  },
  {
    "objectID": "lectures/03/slides.html#mini-batch-gradient-descent",
    "href": "lectures/03/slides.html#mini-batch-gradient-descent",
    "title": "Learning Algorithms",
    "section": "Mini-batch gradient descent",
    "text": "Mini-batch gradient descent\n\nAt each step, rather than selecting one training example as SGD does, mini-batch gradient descent randomly selects a small number of training examples to compute the gradients.\nIts trajectory is more regular compared to SGD.\n\nAs the size of the mini-batches increases, the algorithm becomes increasingly similar to batch gradient descent, which uses all the examples at each step.\n\nIt can take advantage of the hardware acceleration of matrix operations, particularly with GPUs."
  },
  {
    "objectID": "lectures/03/slides.html#summary",
    "href": "lectures/03/slides.html#summary",
    "title": "Learning Algorithms",
    "section": "Summary",
    "text": "Summary\n\nThe lecture surveyed three learning algorithms, k-nearest neighbours (KNN), decision trees, and linear regression, and framed them via model, objective, and optimization.\nWe then constructed decision trees, showed that regression leaves returned the sample mean, minimized the weighted impurity \\(J\\), and analyzed the Gini index.\nDecision boundaries were illustrated for linear and non-linear models."
  },
  {
    "objectID": "lectures/03/slides.html#optimization-and-deep-nets",
    "href": "lectures/03/slides.html#optimization-and-deep-nets",
    "title": "Learning Algorithms",
    "section": "Optimization and deep nets",
    "text": "Optimization and deep nets\nWe will briefly revisit the subject when discussing deep artificial neural networks, for which specialized optimization algorithms exist.\n\nMomentum Optimization\nNesterov Accelerated Gradient\nAdaGrad\nRMSProp\nAdam and Nadam"
  },
  {
    "objectID": "lectures/03/slides.html#final-word",
    "href": "lectures/03/slides.html#final-word",
    "title": "Learning Algorithms",
    "section": "Final word",
    "text": "Final word\n\nOptimization is a vast subject. Other algorithms exist and are used in other contexts.\n\nIncluding:\n\nParticle swarm optimization (PSO), genetic algorithms (GAs), and artificial bee colony (ABC) algorithms."
  },
  {
    "objectID": "lectures/03/slides.html#linear-regression---summary",
    "href": "lectures/03/slides.html#linear-regression---summary",
    "title": "Learning Algorithms",
    "section": "Linear regression - summary",
    "text": "Linear regression - summary\n\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\(\\hat{y_i} = h(x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\\)\nThe Mean Squared Error (MSE) is: \\(\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2\\)\nBatch, stochastic, or mini-batch gradient descent can be used to find “optimal” values for the weights, \\(\\theta_j\\) for \\(j \\in 0, 1, \\ldots, D\\).\nThe result is a regressor, a function that can be used to predict the \\(y\\) value (the label) for some unseen example \\(x\\)."
  },
  {
    "objectID": "lectures/03/slides.html#references",
    "href": "lectures/03/slides.html#references",
    "title": "Learning Algorithms",
    "section": "References",
    "text": "References\n\n\nGéron, Aurélien. 2019. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 2nd ed. O’Reilly Media.\n\n\nGeurts, Pierre, Alexandre Irrthum, and Louis Wehenkel. 2009. “Supervised Learning with Decision Tree-Based Methods in Computational and Systems Biology.” Molecular bioSystems 5 (12): 1593–1605. https://doi.org/10.1039/b907946g.\n\n\nHyafil, Laurent, and Ronald L. Rivest. 1976. “Constructing Optimal Binary Decision Trees Is NP-Complete.” Inf. Process. Lett. 5 (1): 15–17. https://doi.org/10.1016/0020-0190(76)90095-8.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nStiglic, Gregor, Simon Kocbek, Igor Pernek, and Peter Kokol. 2012. “Comprehensive Decision Tree Models in Bioinformatics.” Edited by Ahmed Moustafa. PLoS ONE 7 (3): e33812. https://doi.org/10.1371/journal.pone.0033812."
  },
  {
    "objectID": "lectures/03/slides.html#next-lecture",
    "href": "lectures/03/slides.html#next-lecture",
    "title": "Learning Algorithms",
    "section": "Next lecture",
    "text": "Next lecture\n\nTraining a linear model"
  },
  {
    "objectID": "lectures/03/index.html",
    "href": "lectures/03/index.html",
    "title": "Learning Algorithms",
    "section": "",
    "text": "CSI4106 Jupyter Notebooks and Google Colab Tutorial"
  },
  {
    "objectID": "lectures/03/index.html#prepare",
    "href": "lectures/03/index.html#prepare",
    "title": "Learning Algorithms",
    "section": "",
    "text": "CSI4106 Jupyter Notebooks and Google Colab Tutorial"
  },
  {
    "objectID": "lectures/03/index.html#participate",
    "href": "lectures/03/index.html#participate",
    "title": "Learning Algorithms",
    "section": "Participate",
    "text": "Participate\n\nslides (PDF) comme Jupyter Notebook"
  },
  {
    "objectID": "lectures/03/index.html#practice",
    "href": "lectures/03/index.html#practice",
    "title": "Learning Algorithms",
    "section": "Practice",
    "text": "Practice\nFor those who are not yet familiar with numpy and pandas, it is recommended to explore these tutorials over the coming weeks at your own pace. Aurélien Géron’s notebooks offer insights into essential machine learning concepts.\n\nnumpy – a fundamental library centered around N-dimensional array objects.\npandas – powerfull data analysis tools, centered around the DataFrame.\nvisualization – demonstrates how to use the matplotlib to produce beautiful graphs.\n\nIn the upcoming weeks, you may wish to apply the concepts discussed in class to a variety of datasets to further develop your skills and intuition. Below is a list of websites where you can find relevant datasets.\n\nSmall-to-medium datasets, very student-friendly\n\nUCI Machine Learning Repository\nscikit-learn toy datasets\n\n\n\nLarger datasets\n\nOpenML, integrates directly with scikit-learn\nPMLB (Penn Machine Learning Benchmarks)\n\n\n\nCompetition(s)\n\nKaggle Datasets\n\nKaggle, a platform owned by Google, serves as an online community tailored for data scientists and machine learning practitioners. It facilitates participation in data science competitions, collaboration on various projects, and provides access to diverse datasets. Additionally, users can build models using its web-based tools."
  },
  {
    "objectID": "lectures/04/slides.html#quote-of-the-day",
    "href": "lectures/04/slides.html#quote-of-the-day",
    "title": "Linear models, training",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n\n\n\n\n\n\n\n;document.getElementById(\"tweet-17661\").innerHTML = tweet[\"html\"];\n\n\nOpenAI released o1 on September 12, 2024: “o1 greatly improves over GPT-4o on challenging reasoning benchmarks. Solid bars show pass@1 accuracy and the shaded region shows the performance of majority vote (consensus) with 64 samples.”"
  },
  {
    "objectID": "lectures/04/slides.html#quote-of-the-day-continued",
    "href": "lectures/04/slides.html#quote-of-the-day-continued",
    "title": "Learning Algorithms",
    "section": "Quote of the Day (continued)",
    "text": "Quote of the Day (continued)\n\n\n\n\nVideos:\n\nBuilding OpenAI o1\nCoding with OpenAI o1\nScott Wu: OpenAI o1 & Coding\nCatherine Brownstein: Genetics\nMario Krenn: Quantum Physics\nOpenAI o1 playlist\n\n\n\n\nThe videos in this playlist range from 1:17 minute to 3:17 minutes in duration."
  },
  {
    "objectID": "lectures/04/slides.html#training-a-linear-model",
    "href": "lectures/04/slides.html#training-a-linear-model",
    "title": "Learning Algorithms",
    "section": "Training a Linear Model",
    "text": "Training a Linear Model\nIn this lecture, we will cover the foundational concepts of linear regression, and gradient descent.\nYou will gain a deeper understanding of these essential machine learning techniques, enabling you to apply them effectively in your work.\nGeneral Objective\n\nExplain the process of training a linear model"
  },
  {
    "objectID": "lectures/04/slides.html#learning-objectives",
    "href": "lectures/04/slides.html#learning-objectives",
    "title": "Linear regression and gradient descent",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDifferentiate regression tasks from classification tasks.\nArticulate the training methodology for linear regression models.\nInterpret the function of optimization algorithms in addressing linear regression.\nDetail the significance of partial derivatives within the gradient descent algorithm.\nContrast the batch, stochastic, and mini-batch gradient descent methods.\n\n\nIn the previous lecture, we examined two distinct learning algorithms: \\(k\\)-nearest neighbors (KNN) and decision trees, each employing unique methods for model training and representation. KNN does not involve explicit learning; instead, the data itself constitutes the model. Conversely, decision trees utilize a greedy algorithm that begins with an empty tree and the full training dataset. The algorithm incrementally adds decision nodes, partitioning the parent dataset into subsets to achieve greater homogeneity (or purity) within each resulting classification compared to the parent node. This recursive process terminates when a node’s data satisfies predefined stopping criteria, such as achieving a single class, reaching a minimum purity level, or attaining a maximum tree depth. Once the decision tree is constructed, the original data is no longer needed. This lecture aimed to demonstrate that supervised learning models can be represented in various ways, with each “learning” algorithm tailored to its specific model.\nIn today’s lecture, we will explore a training algorithm that is applicable to a diverse range of models, including neural networks."
  },
  {
    "objectID": "lectures/04/slides.html#supervised-learning---regression",
    "href": "lectures/04/slides.html#supervised-learning---regression",
    "title": "Linear regression and gradient descent",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\n\nThe training data is a collection of labelled examples.\n\n\\(\\{(x_i,y_i)\\}_{i=1}^N\\)\n\nEach \\(x_i\\) is a feature vector with \\(D\\) dimensions.\n\\(x_i^{(j)}\\) is the value of the feature \\(j\\) of the example \\(i\\), for \\(j \\in 1 \\ldots D\\) and \\(i \\in 1 \\ldots N\\).\n\nThe label \\(y_i\\) is a real number.\n\nProblem: Given the data set as input, create a model that can be used to predict the value of \\(y\\) for an unseen \\(x\\).\n\n\nCan you think of examples of regression tasks?\n\nHouse Price Prediction:\n\nApplication: Estimating the market value of residential properties based on features such as location, size, number of bedrooms, age, and amenities.\n\nStock Market Forecasting:\n\nApplication: Predicting future prices of stocks or indices based on historical data, financial indicators, and economic variables.\n\nWeather Prediction:\n\nApplication: Estimating future temperatures, rainfall, and other weather conditions using historical weather data and atmospheric variables.\n\nSales Forecasting:\n\nApplication: Predicting future sales volumes for products or services by analyzing past sales data, market trends, and seasonal patterns.\n\nEnergy Consumption Prediction:\n\nApplication: Forecasting future energy usage for households, industries, or cities based on historical consumption data, weather conditions, and economic factors.\n\nMedical Cost Estimation:\n\nApplication: Predicting healthcare costs for patients based on their medical history, demographic information, and treatment plans.\n\nTraffic Flow Prediction:\n\nApplication: Estimating future traffic volumes and congestion levels on roads and highways using historical traffic data and real-time sensor inputs.\n\nCustomer Lifetime Value (CLV) Estimation:\n\nApplication: Predicting the total revenue a business can expect from a customer over the duration of their relationship, based on purchasing behavior and demographic data.\n\nEconomic Indicators Forecasting:\n\nApplication: Predicting key economic indicators such as GDP growth, unemployment rates, and inflation using historical economic data and market trends.\n\nDemand Forecasting:\n\nApplication: Estimating future demand for products or services in various industries like retail, manufacturing, and logistics to optimize inventory and supply chain management.\n\nReal Estate Valuation:\n\nApplication: Assessing the market value of commercial properties like office buildings, malls, and industrial spaces based on location, size, and market conditions.\n\nInsurance Risk Assessment:\n\nApplication: Predicting the risk associated with insuring individuals or properties, which helps in determining premium rates, based on historical claims data, and demographic factors.\n\nAd Click-Through Rate (CTR) Prediction:\n\nApplication: Estimating the likelihood that a user will click on an online advertisement based on user behavior, ad characteristics, and contextual factors.\n\nLoan Default Prediction:\n\nApplication: Predicting the probability of a borrower defaulting on a loan based on credit history, income, loan amount, and other financial indicators.\n\n\nFocusing on applications possibly running on a mobile device.\n\nBattery Life Prediction:\n\nApplication: Estimating remaining battery life based on usage patterns, running applications, and device settings.\n\nHealth and Fitness Tracking:\n\nApplication: Predicting calorie burn, heart rate, or sleep quality based on user activity, biometrics, and historical health data.\n\nPersonal Finance Management:\n\nApplication: Forecasting future expenses or savings based on spending habits, income patterns, and budget goals.\n\nWeather Forecasting:\n\nApplication: Providing personalized weather forecasts based on current location and historical weather data.\n\nTraffic and Commute Time Estimation:\n\nApplication: Predicting travel times and suggesting optimal routes based on historical traffic data, real-time conditions, and user behavior.\n\nImage and Video Quality Enhancement:\n\nApplication: Adjusting image or video quality settings (e.g., brightness, contrast) based on lighting conditions and user preferences.\n\nFitness Goal Achievement:\n\nApplication: Estimating the time needed to achieve fitness goals such as weight loss or muscle gain based on user activity and dietary input.\n\nMobile Device Performance Optimization:\n\nApplication: Predicting the optimal settings for device performance and battery life based on usage patterns and app activity."
  },
  {
    "objectID": "lectures/04/slides.html#k-nearest-neighbors",
    "href": "lectures/04/slides.html#k-nearest-neighbors",
    "title": "Training",
    "section": "k-nearest neighbors",
    "text": "k-nearest neighbors\n\n\n\n\n\n\nKNeighborsClassifier\n\nexamples\n\nKNeighborsRegressor\n\nexemples\n\n\n\n\nThe \\(k\\)-nearest neighbor (\\(k\\)-NN) algorithm is a simple, non-parametric, instance-based learning method used for classification and regression. It classifies a data point based on the majority label of its \\(k\\) nearest neighbors in the feature space, where \\(k\\) is a user-defined constant. Distance metrics like Euclidean distance are commonly used to determine the nearest neighbors.\nA non-parametric algorithm does not make any assumptions about the underlying data distribution and does not learn a fixed set of parameters or a model during the training phase. Instead, it relies directly on the training data to make decisions at the time of classification or regression, making it flexible and adaptive to various data shapes but potentially computationally expensive at prediction time.\nIn scikit-learn, several models are commonly used for regression tasks. Here are some of the main models:\n\nLinear Regression (LinearRegression):\n\nA simple linear approach that models the relationship between the independent variables and the dependent variable by fitting a linear equation to the observed data.\n\nSupport Vector Regression (SVR):\n\nAn extension of Support Vector Machines (SVM) for regression tasks, which tries to fit the best line within a specified margin of tolerance.\n\nDecision Tree Regression (DecisionTreeRegressor):\n\nUses decision trees to model the relationship between the input features and the target variable by recursively splitting the data into subsets.\n\nRandom Forest Regression (RandomForestRegressor):\n\nAn ensemble method that uses multiple decision trees to improve predictive accuracy and control overfitting.\n\nGradient Boosting Regression (GradientBoostingRegressor):\n\nAnother ensemble method that builds sequential decision trees, where each tree corrects the errors of the previous one.\n\nK-Nearest Neighbors Regression (KNeighborsRegressor):\n\nA non-parametric method that predicts the target variable based on the average of the k-nearest neighbors in the feature space.\n\n\nThese models offer a range of approaches to handle different types of regression problems, each with its own strengths and suitable applications.\n\n\nAttribution: Example from scikit-learn Web site, page Nearest Neighbors Classification."
  },
  {
    "objectID": "lectures/04/slides.html#rationale",
    "href": "lectures/04/slides.html#rationale",
    "title": "Linear regression and gradient descent",
    "section": "Rationale",
    "text": "Rationale\nLinear regression is introduced to conveniently present a well-known training algorithm, gradient descent. Additionally, it serves as a foundation for introducing logistic regression–a classification algorithm—which further facilitates discussions on artificial neural networks.\n\nLinear Regression\n\nGradient Descent\nLogistic Regression\n\nNeural Networks\n\n\n\n\n\nThe training algorithms for machine learning models can vary significantly depending on the model (e.g., decision trees, SVMs, etc.). In order to fit our schedule, we will concentrate on this specific sequence.\nThe concept of linear regression can be traced back to the early work of Sir Francis Galton in the late 19th century. Galton introduced the idea of “regression” in his 1886 paper, which focused on the relationship between the heights of parents and their children. He observed that children’s heights tended to regress towards the average, which led to the term “regression.”\nHowever, the mathematical formulation of linear regression is closely associated with the work of Karl Pearson, who in the early 20th century extended Galton’s ideas to create the method of least squares for fitting a linear model. The method itself, though, was developed earlier in 1805 by Adrien-Marie Legendre and independently by Carl Friedrich Gauss for astronomical data analysis.\nSee: Stanton (2001).\n\n\nFrom 2 to 2 trillion parameters!"
  },
  {
    "objectID": "lectures/04/slides.html#supervised-learning---regression-1",
    "href": "lectures/04/slides.html#supervised-learning---regression-1",
    "title": "Training",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\n\nThe training data is a collection of labelled examples.\n\n\\(\\{(x_i,y_i)\\}_{i=1}^N\\)\n\nEach \\(x_i\\) is a feature vector with \\(D\\) dimensions.\n\\(x_i^{(j)}\\) is the value of the feature \\(j\\) of the example \\(i\\), for \\(j \\in 1 \\ldots D\\) and \\(i \\in 1 \\ldots N\\).\n\nThe label \\(y_i\\) is a real number.\n\nProblem: Given the data set as input, create a model that can be used to predict the value of \\(y\\) for an unseen \\(x\\)."
  },
  {
    "objectID": "lectures/04/slides.html#supervised-learning---regression-2",
    "href": "lectures/04/slides.html#supervised-learning---regression-2",
    "title": "Training",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\nCan you think of examples of regression tasks?\n\n\nHouse Price Prediction:\n\nApplication: Estimating the market value of residential properties based on features such as location, size, number of bedrooms, age, and amenities.\n\nStock Market Forecasting:\n\nApplication: Predicting future prices of stocks or indices based on historical data, financial indicators, and economic variables.\n\nWeather Prediction:\n\nApplication: Estimating future temperatures, rainfall, and other weather conditions using historical weather data and atmospheric variables.\n\nSales Forecasting:\n\nApplication: Predicting future sales volumes for products or services by analyzing past sales data, market trends, and seasonal patterns.\n\nEnergy Consumption Prediction:\n\nApplication: Forecasting future energy usage for households, industries, or cities based on historical consumption data, weather conditions, and economic factors.\n\nMedical Cost Estimation:\n\nApplication: Predicting healthcare costs for patients based on their medical history, demographic information, and treatment plans.\n\nTraffic Flow Prediction:\n\nApplication: Estimating future traffic volumes and congestion levels on roads and highways using historical traffic data and real-time sensor inputs.\n\nCustomer Lifetime Value (CLV) Estimation:\n\nApplication: Predicting the total revenue a business can expect from a customer over the duration of their relationship, based on purchasing behavior and demographic data.\n\nEconomic Indicators Forecasting:\n\nApplication: Predicting key economic indicators such as GDP growth, unemployment rates, and inflation using historical economic data and market trends.\n\nDemand Forecasting:\n\nApplication: Estimating future demand for products or services in various industries like retail, manufacturing, and logistics to optimize inventory and supply chain management.\n\nReal Estate Valuation:\n\nApplication: Assessing the market value of commercial properties like office buildings, malls, and industrial spaces based on location, size, and market conditions.\n\nInsurance Risk Assessment:\n\nApplication: Predicting the risk associated with insuring individuals or properties, which helps in determining premium rates, based on historical claims data, and demographic factors.\n\nAd Click-Through Rate (CTR) Prediction:\n\nApplication: Estimating the likelihood that a user will click on an online advertisement based on user behavior, ad characteristics, and contextual factors.\n\nLoan Default Prediction:\n\nApplication: Predicting the probability of a borrower defaulting on a loan based on credit history, income, loan amount, and other financial indicators."
  },
  {
    "objectID": "lectures/04/slides.html#linear-regression",
    "href": "lectures/04/slides.html#linear-regression",
    "title": "Learning Algorithms",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\[\n\\hat{y_i} = h(x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\n\nHere, \\(\\theta_{j}\\) is the \\(j\\)th parameter of the (linear) model, with \\(\\theta_0\\) being the bias term/parameter, and \\(\\theta_1 \\ldots \\theta_D\\) being the feature weights."
  },
  {
    "objectID": "lectures/04/slides.html#linear-regression-continued",
    "href": "lectures/04/slides.html#linear-regression-continued",
    "title": "Training",
    "section": "Linear Regression (continued)",
    "text": "Linear Regression (continued)\nProblem: find values for all the model parameters so that the model “best fits” the training data.\n\n\nThe Root Mean Square Error is a common performance measure for regression problems.\n\n\\[\n    \\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\n\\]"
  },
  {
    "objectID": "lectures/04/slides.html#linearregression",
    "href": "lectures/04/slides.html#linearregression",
    "title": "Linear regression and gradient descent",
    "section": "LinearRegression",
    "text": "LinearRegression\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\n\nHerein, we examine a straightforward model involving a single variable."
  },
  {
    "objectID": "lectures/04/slides.html#source-code",
    "href": "lectures/04/slides.html#source-code",
    "title": "Linear regression and gradient descent",
    "section": "Source code",
    "text": "Source code\n\nfrom sympy import *\n\nx = symbols('t')\n\nf = t**2 + 4*t + 7\n\nplot(f)\n\n\n\nOn the previous slide, I’ve used SymPy, a library for symbolic mathematics."
  },
  {
    "objectID": "lectures/04/slides.html#gpt-4o-interactions-2024-09-14",
    "href": "lectures/04/slides.html#gpt-4o-interactions-2024-09-14",
    "title": "Linear regression and gradient descent",
    "section": "GPT 4o interactions (2024-09-14)",
    "text": "GPT 4o interactions (2024-09-14)\nUser: Explain the code on the previous slide line by line.\n\nAI: Certainly! Here is a line-by-line explanation of the provided code:\n\nimport numpy as np\n\n\nExplanation: This line imports the NumPy library, which is a fundamental package for numerical computations in Python. It is commonly used for working with arrays and matrices, as well as for performing a variety of mathematical operations.\n\n\nX = 6 * np.random.rand(100, 1) - 4\n\n\nExplanation: This line generates a NumPy array X containing 100 rows and 1 column of random numbers. The np.random.rand(100, 1) function generates uniformly distributed random numbers between 0 and 1. Multiplying by 6 scales these numbers to the range [0, 6), and subtracting 4 shifts the range to [-4, 2).\n\n\ny = X ** 2 - 4 * X + 5 + np.random.randn(100, 1)\n\n\nExplanation: This line generates the target variable y based on a quadratic equation with some added noise. Specifically:\n\nX ** 2 computes the square of each element in X.\n- 4 * X subtracts four times each element in X.\n+ 5 adds a constant term of 5.\n+ np.random.randn(100, 1) adds Gaussian noise with a mean of 0 and standard deviation of 1 to each element, making the data more realistic by introducing some randomness.\n\n\n\nfrom sklearn.linear_model import LinearRegression\n\n\nExplanation: This line imports the LinearRegression class from the sklearn.linear_model module, which is part of the Scikit-Learn library. Scikit-Learn is widely used for machine learning in Python.\n\n\nlin_reg = LinearRegression()\n\n\nExplanation: This line creates an instance of the LinearRegression class and assigns it to the variable lin_reg. This object will be used to fit the linear regression model to the data.\n\n\nlin_reg.fit(X, y)\n\n\nExplanation: This line fits the linear regression model to the data by finding the best-fitting line through the points (X, y). The fit method trains the model using the provided features X and target variable y.\n\n\nX_new = np.array([[-4], [2]])\n\n\nExplanation: This line creates a new NumPy array X_new with two values: -4 and 2. These values represent new data points for which we want to predict the target variable using the trained model.\n\n\ny_pred = lin_reg.predict(X_new)\n\n\nExplanation: This line uses the trained linear regression model to predict the target variable y_pred for the new data points in X_new. The predict method returns the predicted values based on the fitted model.\n\nIn summary, this script generates synthetic data, fits a linear regression model to it, and then uses the model to make predictions on new data points."
  },
  {
    "objectID": "lectures/04/slides.html#source-code-continued",
    "href": "lectures/04/slides.html#source-code-continued",
    "title": "Linear regression and gradient descent",
    "section": "Source code (continued)",
    "text": "Source code (continued)\n\nimport os\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"pdf\", resolution=300):\n    path = os.path.join(fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)"
  },
  {
    "objectID": "lectures/04/slides.html#source-code-continued-1",
    "href": "lectures/04/slides.html#source-code-continued-1",
    "title": "Linear regression and gradient descent",
    "section": "Source code (continued)",
    "text": "Source code (continued)\n\nplt.plot(X, y, \"b.\")\nplt.plot(X_new, y_pred, \"r-\")\nplt.xlabel(\"$x$\", fontsize=18)\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\nplt.axis([-4, 2, -1, 35])\nsave_fig(\"regression_linear-01\")\nplt.show()"
  },
  {
    "objectID": "lectures/04/slides.html#andrew-ng",
    "href": "lectures/04/slides.html#andrew-ng",
    "title": "Linear regression and gradient descent",
    "section": "Andrew Ng",
    "text": "Andrew Ng\n\n\n\n\n\nGradient Descent (Math)  (11:30 m)\nIntuition (11:51 m)\nLinear Regression (10:20 m)\nML-005 | Stanford | Andrew Ng (19 videos)\n\n\n\n\nAndrew Ng is Founder of DeepLearning.AI, Founder & CEO of Landing AI, General Partner at AI Fund, Chairman and Co-Founder of Coursera and an Adjunct Professor at Stanford University’s Computer Science Department.\nNg was also a cofounder and head of Google Brain and was the former Chief Scientist at Baidu.\n\n\nAndrew Ng is presenting the gradient descent algorithm using a linear regression with one variable."
  },
  {
    "objectID": "lectures/04/slides.html#blue1brown",
    "href": "lectures/04/slides.html#blue1brown",
    "title": "Linear regression and gradient descent",
    "section": "3Blue1Brown",
    "text": "3Blue1Brown\n\nEssence of linear algebra\n\nA series of 16 videos (10 to 15 minutes per video) providing “a geometric understanding of matrices, determinants, eigen-stuffs and more.”\n\n6,662,732 views as of September 30, 2019.\n\n\nEssence of calculus\n\nA series of 12 videos (15 to 20 minutes per video): “The goal here is to make calculus feel like something that you yourself could have discovered.”\n\n2,309,726 views as of September 30, 2019."
  },
  {
    "objectID": "lectures/04/slides.html#supervised-learning---regression-3",
    "href": "lectures/04/slides.html#supervised-learning---regression-3",
    "title": "Training",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\nFocusing on applications possibly running on a mobile device.\n\n\nBattery Life Prediction:\n\nApplication: Estimating remaining battery life based on usage patterns, running applications, and device settings.\n\nHealth and Fitness Tracking:\n\nApplication: Predicting calorie burn, heart rate, or sleep quality based on user activity, biometrics, and historical health data.\n\nPersonal Finance Management:\n\nApplication: Forecasting future expenses or savings based on spending habits, income patterns, and budget goals.\n\nWeather Forecasting:\n\nApplication: Providing personalized weather forecasts based on current location and historical weather data.\n\nTraffic and Commute Time Estimation:\n\nApplication: Predicting travel times and suggesting optimal routes based on historical traffic data, real-time conditions, and user behavior.\n\nImage and Video Quality Enhancement:\n\nApplication: Adjusting image or video quality settings (e.g., brightness, contrast) based on lighting conditions and user preferences.\n\nFitness Goal Achievement:\n\nApplication: Estimating the time needed to achieve fitness goals such as weight loss or muscle gain based on user activity and dietary input.\n\nMobile Device Performance Optimization:\n\nApplication: Predicting the optimal settings for device performance and battery life based on usage patterns and app activity."
  },
  {
    "objectID": "lectures/04/slides.html#building-blocks-1",
    "href": "lectures/04/slides.html#building-blocks-1",
    "title": "Training",
    "section": "Building blocks",
    "text": "Building blocks\nA typical learning algorithm comprises the following components:\n\nA model, often consisting of a set of weights whose values will be “learnt”.\nAn objective function.\n\nIn the case of regression, this is often a loss function, a function that quantifies misclassification. The Root Mean Square Error is a common loss function for regression problems. \\(\\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\\)\n\nOptimization algorithm"
  },
  {
    "objectID": "lectures/04/slides.html#optimization",
    "href": "lectures/04/slides.html#optimization",
    "title": "Linear regression and gradient descent",
    "section": "Optimization",
    "text": "Optimization\nUntil some termination criteria is met1:\n\nEvaluate the loss function, comparing \\(h(x_i)\\) to \\(y_i\\).\nMake small changes to the parameters, in a way that reduces the value of the loss function.\n\nE.g. the value of the loss function no longer decreases or the maximum number of iterations."
  },
  {
    "objectID": "lectures/04/slides.html#derivative",
    "href": "lectures/04/slides.html#derivative",
    "title": "Training",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will start with a single-variable function.\nThink of this as our loss function, which we aim to minimize; to reduce the average discrepancy between expected and predicted values.\nHere, I am using \\(t\\) to avoid any confusion with the attributes of our training examples."
  },
  {
    "objectID": "lectures/04/slides.html#source-code-1",
    "href": "lectures/04/slides.html#source-code-1",
    "title": "Linear regression and gradient descent",
    "section": "Source code",
    "text": "Source code\n\nimport sympy as sp\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the variable and function\nt = sp.symbols('t')\nf = t**2 + 4*t + 7\n\n# Compute the derivative\nf_prime = sp.diff(f, t)\n\n# Lambdify the functions for numerical plotting\nf_func = sp.lambdify(t, f, \"numpy\")\nf_prime_func = sp.lambdify(t, f_prime, \"numpy\")\n\n# Generate t values for plotting\nt_vals = np.linspace(-5, 2, 400)\n\n# Get y values for the function and its derivative\nf_vals = f_func(t_vals)\nf_prime_vals = f_prime_func(t_vals)\n\n# Plot the function and its derivative\nplt.plot(t_vals, f_vals, label=r'$f(t) = t^2 + 4t + 7$', color='blue')\nplt.plot(t_vals, f_prime_vals, label=r\"$f'(t) = 2t + 4$\", color='red')\n\n# Fill the area below the derivative where it's negative\nplt.fill_between(t_vals, f_prime_vals, where=(f_prime_vals &gt; 0), color='red', alpha=0.3)\n\n# Add labels and legend\nplt.axhline(0, color='black',linewidth=1)\nplt.axvline(0, color='black',linewidth=1)\nplt.title('Function and Derivative')\nplt.xlabel('t')\nplt.ylabel('y')\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/04/slides.html#derivative-1",
    "href": "lectures/04/slides.html#derivative-1",
    "title": "Linear regression and gradient descent",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will start with a single-variable function.\nThink of this as our loss function, which we aim to minimize; to reduce the average discrepancy between expected and predicted values.\nHere, I am using \\(t\\) to avoid any confusion with the attributes of our training examples."
  },
  {
    "objectID": "lectures/04/slides.html#derivative-2",
    "href": "lectures/04/slides.html#derivative-2",
    "title": "Linear regression and gradient descent",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe graph of the derivative, \\(f^{'}(t)\\), is depicted in red.\nThe derivative indicates how changes in the input affect the output, \\(f(t)\\).\nThe magnitude of the derivative at \\(t = -2\\) is \\(0\\).\nThis point corresponds to the minimum of our function.\n\n\n\nNear \\(t = -2\\), variations in \\(t\\) have minimal impact on the output, \\(f(t)\\)."
  },
  {
    "objectID": "lectures/04/slides.html#derivative-3",
    "href": "lectures/04/slides.html#derivative-3",
    "title": "Linear regression and gradient descent",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen evaluated at a specific point, the derivative indicates the slope of the tangent line to the graph of the function at that point.\nAt \\(t= -2\\), the slope of the tangent line is 0."
  },
  {
    "objectID": "lectures/04/slides.html#derivative-4",
    "href": "lectures/04/slides.html#derivative-4",
    "title": "Linear regression and gradient descent",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nA positive derivative indicates that increasing the input variable will increase the output value.\nAdditionally, the magnitude of the derivative quantifies how rapidly the output changes."
  },
  {
    "objectID": "lectures/04/slides.html#source-code-2",
    "href": "lectures/04/slides.html#source-code-2",
    "title": "Linear regression and gradient descent",
    "section": "Source code",
    "text": "Source code\n\nimport numpy as np\n\nX = 6 * np.random.rand(100, 1) - 4\ny = X ** 2 - 4 * X + 5 + np.random.randn(100, 1)\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nX_new = np.array([[-4], [2]])\ny_pred = lin_reg.predict(X_new)\n\n\n\nThe data have been generated from a quadratic model, \\(x^2 - 4x + 5\\), with Gaussian noise added to make the synthetic data more realistic.\nThis example illustrates that, in practice, we often have limited knowledge about the underlying model that generated the data.\nDespite this uncertainty, we make assumptions—in this case, assuming linearity—when building our models.\nLater, we will refer to this as bias (distinct from the bias parameter in our regression model). Both bias and variance influence the performance of our models.\n\n\nThis slide contains an anomaly. Can you identify it?"
  },
  {
    "objectID": "lectures/04/slides.html#recall",
    "href": "lectures/04/slides.html#recall",
    "title": "Training",
    "section": "Recall",
    "text": "Recall\n\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\[\n\\hat{y_i} = h(x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\n\nHere, \\(\\theta_{j}\\) is the \\(j\\)th parameter of the (linear) model, with \\(\\theta_0\\) being the bias term/parameter, and \\(\\theta_1 \\ldots \\theta_D\\) being the feature weights."
  },
  {
    "objectID": "lectures/04/slides.html#recall-1",
    "href": "lectures/04/slides.html#recall-1",
    "title": "Training",
    "section": "Recall",
    "text": "Recall\n\nThe Root Mean Square Error (RMSE) is a common loss function for regression problems. \\[\n  \\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\n\\]\nIn practice, minimizing the Mean Squared Error (MSE) is easier and gives the same result. \\[\n    \\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2\n\\]"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---intuition",
    "href": "lectures/04/slides.html#gradient-descent---intuition",
    "title": "Linear regression and gradient descent",
    "section": "Gradient descent - intuition",
    "text": "Gradient descent - intuition"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---single-value",
    "href": "lectures/04/slides.html#gradient-descent---single-value",
    "title": "Linear regression and gradient descent",
    "section": "Gradient descent - single value",
    "text": "Gradient descent - single value\n\nInitialization: \\(\\theta_0\\) and \\(\\theta_1\\) - either with random values or zeros.\nLoop:\n\nrepeat until convergence: \\[\n\\theta_j := \\theta_j - \\alpha \\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1) , \\text{for } j=0 \\text{ and } j=1\n\\]\n\n\\(\\alpha\\) is called the learning rate - this is the size of each step.\n\\(\\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1)\\) is the partial derivative with respect to \\(\\theta_j\\).\n\n\nA partial derivative represents the rate of change of a multivariable function with respect to one of its variables, while keeping the other variables constant.\nFor the algorithm to be mathematically sound, all the \\(\\theta_j\\) must be updated simultaneously."
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---single-value-1",
    "href": "lectures/04/slides.html#gradient-descent---single-value-1",
    "title": "Linear regression and gradient descent",
    "section": "Gradient Descent - Single Value",
    "text": "Gradient Descent - Single Value\n\n\n\n\nCode\nimport sympy as sp\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the variable and function\nt = sp.symbols('t')\nf = t**2 + 4*t + 7\n\n# Compute the derivative\nf_prime = sp.diff(f, t)\n\n# Lambdify the functions for numerical plotting\nf_func = sp.lambdify(t, f, \"numpy\")\nf_prime_func = sp.lambdify(t, f_prime, \"numpy\")\n\n# Generate t values for plotting\nt_vals = np.linspace(-5, 2, 400)\n\n# Get y values for the function and its derivative\nf_vals = f_func(t_vals)\nf_prime_vals = f_prime_func(t_vals)\n\n# Plot the function and its derivative\nplt.plot(t_vals, f_vals, label=r'$J$', color='blue')\nplt.plot(t_vals, f_prime_vals, label=r\"$\\frac {\\partial}{\\partial \\theta_j}J(\\theta)$\", color='red')\n\n# Add labels and legend\nplt.axhline(0, color='black',linewidth=1)\nplt.axvline(0, color='black',linewidth=1)\nplt.title('Function and Derivative')\nplt.xlabel(r'$\\theta_j$')\nplt.ylabel(r'$J$')\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nWhen the value of \\(\\theta_j\\) is in the range \\([- \\inf, -2)\\), \\(\\frac {\\partial}{\\partial \\theta_j}J(\\theta)\\) has a negative value.\nTherefore, \\(- \\alpha \\frac {\\partial}{\\partial \\theta_j}J(\\theta)\\) is positive.\nAccordingly, the value of \\(\\theta_j\\) is increased.\n\n\n\n\nUpdating rule: \\(\\theta_j := \\theta_j - \\alpha \\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1) , \\text{for } j=0 \\text{ and } j=1\\)."
  },
  {
    "objectID": "lectures/04/slides.html#partial-derivatives",
    "href": "lectures/04/slides.html#partial-derivatives",
    "title": "Linear regression and gradient descent",
    "section": "Partial derivatives",
    "text": "Partial derivatives\nGiven\n\\[\nJ(\\theta_0, \\theta_1) = \\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2 = \\frac{1}{N}\\sum_1^N [\\theta_0 + \\theta_1 x_i - y_i]^2\n\\]\n\nWe have\n\\[\n\\frac {\\partial}{\\partial \\theta_0}J(\\theta_0, \\theta_1) = \\frac{2}{N} \\sum\\limits_{i=1}^{N} [\\theta_0 - \\theta_1 x_i - y_{i}]\n\\]\n\n\nand\n\\[\n\\frac {\\partial}{\\partial \\theta_1}J(\\theta_0, \\theta_1) = \\frac{2}{N} \\sum\\limits_{i=1}^{N} x_{i} [\\theta_0 + \\theta_1 x_i - y_{i}]\n\\]"
  },
  {
    "objectID": "lectures/04/slides.html#partial-derivate-sympy",
    "href": "lectures/04/slides.html#partial-derivate-sympy",
    "title": "Linear regression and gradient descent",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\nfrom IPython.display import Math, display\nfrom sympy import *\n\n# Define the symbols\n\ntheta_0, theta_1, x_i, y_i = symbols('theta_0 theta_1 x_i y_i')\n\n# Define the hypothesis function:\n\nh = theta_0 + theta_1 * x_i\n\nprint(\"Hypothesis function:\")\n\ndisplay(Math('h(x) = ' + latex(h)))\n\nHypothesis function:\n\n\n\\(\\displaystyle h(x) = \\theta_{0} + \\theta_{1} x_{i}\\)"
  },
  {
    "objectID": "lectures/04/slides.html#partial-derivate-sympy-1",
    "href": "lectures/04/slides.html#partial-derivate-sympy-1",
    "title": "Linear regression and gradient descent",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\nN = Symbol('N', integer=True)\n\n# Define the loss function (mean squared error)\n\nJ = (1/N) * Sum((h - y_i)**2, (x_i, 1, N))\n\nprint(\"Loss function:\")\n\ndisplay(Math('J = ' + latex(J)))\n\nLoss function:\n\n\n\\(\\displaystyle J = \\frac{\\sum_{x_{i}=1}^{N} \\left(\\theta_{0} + \\theta_{1} x_{i} - y_{i}\\right)^{2}}{N}\\)"
  },
  {
    "objectID": "lectures/04/slides.html#partial-derivate-sympy-2",
    "href": "lectures/04/slides.html#partial-derivate-sympy-2",
    "title": "Linear regression and gradient descent",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\n# Calculate the partial derivative with respect to theta_0\n\npartial_derivative_theta_0 = diff(J, theta_0)\n\nprint(\"Partial derivative with respect to theta_0:\")\n\ndisplay(Math(latex(partial_derivative_theta_0)))\n\nPartial derivative with respect to theta_0:\n\n\n\\(\\displaystyle \\frac{\\sum_{x_{i}=1}^{N} \\left(2 \\theta_{0} + 2 \\theta_{1} x_{i} - 2 y_{i}\\right)}{N}\\)"
  },
  {
    "objectID": "lectures/04/slides.html#partial-derivate-sympy-3",
    "href": "lectures/04/slides.html#partial-derivate-sympy-3",
    "title": "Linear regression and gradient descent",
    "section": "Partial derivate (SymPy)",
    "text": "Partial derivate (SymPy)\n\n# Calculate the partial derivative with respect to theta_1\n\npartial_derivative_theta_1 = diff(J, theta_1)\n\nprint(\"\\nPartial derivative with respect to theta_1:\")\n\ndisplay(Math(latex(partial_derivative_theta_1)))\n\n\nPartial derivative with respect to theta_1:\n\n\n\\(\\displaystyle \\frac{\\sum_{x_{i}=1}^{N} 2 x_{i} \\left(\\theta_{0} + \\theta_{1} x_{i} - y_{i}\\right)}{N}\\)"
  },
  {
    "objectID": "lectures/04/slides.html#multivariate-linear-regression",
    "href": "lectures/04/slides.html#multivariate-linear-regression",
    "title": "Linear regression and gradient descent",
    "section": "Multivariate linear regression",
    "text": "Multivariate linear regression\n\\[\nh (x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\theta_3 x_i^{(3)} + \\cdots + \\theta_D x_i^{(D)}\n\\]\n\\[\n\\begin{align*}\n  x_i^{(j)} &= \\text{value of the feature } j \\text{ in the } i \\text{th example} \\\\\n  D &= \\text{the number of features}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---multivariate",
    "href": "lectures/04/slides.html#gradient-descent---multivariate",
    "title": "Linear regression and gradient descent",
    "section": "Gradient descent - multivariate",
    "text": "Gradient descent - multivariate\nThe new loss function is\n\\[\nJ(\\theta_0, \\theta_1,\\ldots,\\theta_D) =  \\dfrac {1}{N} \\displaystyle \\sum _{i=1}^N [h(x_{i}) - y_i ]^2\n\\]\nIts partial derivative:\n\\[\n\\frac {\\partial}{\\partial \\theta_j}J(\\theta) = \\frac{2}{N} \\sum\\limits_{i=1}^N x_i^{(j)} [\\theta x_i - y_i ]\n\\]\nwhere \\(\\theta\\), \\(x_i\\) and \\(y_i\\) are vectors, and \\(\\theta x_i\\) is a vector operation!"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-vector",
    "href": "lectures/04/slides.html#gradient-vector",
    "title": "Linear regression and gradient descent",
    "section": "Gradient vector",
    "text": "Gradient vector\nThe vector containing the partial derivative of \\(J\\) (with respect to \\(\\theta_j\\), for \\(j \\in \\{0, 1\\ldots D\\}\\)) is called the gradient vector.\n\\[\n\\nabla_\\theta J(\\theta) = \\begin{pmatrix}\n  \\frac {\\partial}{\\partial \\theta_0}J(\\theta) \\\\\n  \\frac {\\partial}{\\partial \\theta_1}J(\\theta) \\\\\n  \\vdots  \\\\\n  \\frac {\\partial}{\\partial \\theta_D}J(\\theta)\\\\\n\\end{pmatrix}\n\\]\n\n\nThis vector gives the direction of the steepest ascent.\nIt gives its name to the gradient descent algorithm:\n\n\\[\n\\theta' = \\theta - \\alpha \\nabla_\\theta J(\\theta)\n\\]"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---multivariate-1",
    "href": "lectures/04/slides.html#gradient-descent---multivariate-1",
    "title": "Linear regression and gradient descent",
    "section": "Gradient descent - multivariate",
    "text": "Gradient descent - multivariate\nThe gradient descent algorithm becomes:\nRepeat until convergence:\n\\[\n\\begin{aligned}\n\\{ & \\\\\n\\theta_j := & \\theta_j -  \\alpha  \\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1, \\ldots, \\theta_D) \\\\\n&\\text{for } j \\in [0, \\ldots, D] \\textbf{ (update simultaneously)} \\\\\n\\} &\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---multivariate-2",
    "href": "lectures/04/slides.html#gradient-descent---multivariate-2",
    "title": "Linear regression and gradient descent",
    "section": "Gradient descent - multivariate",
    "text": "Gradient descent - multivariate\nRepeat until convergence:\n\\[\n\\begin{aligned}\n\\; \\{ & \\\\\n\\; & \\theta_0 := \\theta_0 - \\alpha \\frac{2}{N} \\sum\\limits_{i=1}^{N}  x^{0}_i[h(x_i) - y_i] \\\\\n\\; & \\theta_1 := \\theta_1 - \\alpha \\frac{2}{N} \\sum\\limits_{i=1}^{N}  x^{1}_i[h(x_i) - y_i]  \\\\\n\\; & \\theta_2 := \\theta_2 - \\alpha \\frac{2}{N} \\sum\\limits_{i=1}^{N}  x^{2}_i[h(x_i) - y_i] \\\\\n   & \\cdots \\\\\n\\} &\n\\end{aligned}\n\\]\n\n\nWhere \\(x_0 = 1\\)."
  },
  {
    "objectID": "lectures/04/slides.html#assumptions",
    "href": "lectures/04/slides.html#assumptions",
    "title": "Linear regression and gradient descent",
    "section": "Assumptions",
    "text": "Assumptions\nWhat were our assumptions?\n\n\nThe (objective/loss) function is differentiable."
  },
  {
    "objectID": "lectures/04/slides.html#local-vs.-global",
    "href": "lectures/04/slides.html#local-vs.-global",
    "title": "Linear regression and gradient descent",
    "section": "Local vs. global",
    "text": "Local vs. global\n\nA function is convex if for any pair of points on the graph of the function, the line connecting these two points lies above or on the graph.\n\nA convex function has a single minimum.\n\nThe loss function for the linear regression (MSE) is convex.\n\n\nFor functions that are not convex, the gradient descent algorithm converges to a local minimum.\nThe loss function generally used with linear or logistic regressions, and Support Vector Machines (SVM) are convex, but not the ones for artificial neural networks.\n\n\nA function would be convex downward or concave if those lines were below or on the graph of the function."
  },
  {
    "objectID": "lectures/04/slides.html#local-vs.-global-1",
    "href": "lectures/04/slides.html#local-vs.-global-1",
    "title": "Linear regression and gradient descent",
    "section": "Local vs. global",
    "text": "Local vs. global\n\n\n\n\n\n\n\nAttribution: commons.wikimedia.org/wiki/File:Extrema_example.svg"
  },
  {
    "objectID": "lectures/04/slides.html#learning-rate",
    "href": "lectures/04/slides.html#learning-rate",
    "title": "Linear regression and gradient descent",
    "section": "Learning Rate",
    "text": "Learning Rate\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmall steps, low values for \\(\\alpha\\), will make the algorithm converge slowly.\nLarge steps might cause the algorithm to diverge.\nNotice how the algorithm slows down naturally when approaching a minimum."
  },
  {
    "objectID": "lectures/04/slides.html#batch-gradient-descent",
    "href": "lectures/04/slides.html#batch-gradient-descent",
    "title": "Linear regression and gradient descent",
    "section": "Batch gradient descent",
    "text": "Batch gradient descent\n\nTo be more precise, this algorithm is known as batch gradient descent since for each iteration, it processes the “whole batch” of training examples.\n\n\n\nLiterature suggests that the algorithm might take more time to converge if the features are on different scales."
  },
  {
    "objectID": "lectures/04/slides.html#batch-gradient-descent---drawback",
    "href": "lectures/04/slides.html#batch-gradient-descent---drawback",
    "title": "Linear regression and gradient descent",
    "section": "Batch gradient descent - drawback",
    "text": "Batch gradient descent - drawback\n\nThe batch gradient descent algorithm becomes very slow as the number of training examples increases.\n\n\n\nThis is because all the training data is seen at each iteration. The algorithm is generally run for a fixed number of iterations, say 1000."
  },
  {
    "objectID": "lectures/04/slides.html#stochastic-gradient-descent",
    "href": "lectures/04/slides.html#stochastic-gradient-descent",
    "title": "Linear regression and gradient descent",
    "section": "Stochastic Gradient Descent",
    "text": "Stochastic Gradient Descent\nThe stochastic gradient descent algorithm randomly selects one training instance to calculate its gradient.\nepochs = 10\nfor epoch in range(epochs):\n   for i in range(N):\n         selection = np.random.randint(N)\n         # Calculate the gradient using selection\n         # Update the parameters\n\nThis allows it to work with large training sets.\nIts trajectory is not as regular as the batch algorithm.\n\nBecause of its bumpy trajectory, it is often better at finding the global minima, when compared to batch.\nIts bumpy trajectory makes it bounce around the local minima.\n\n\n\nTo mitigate the issue of oscillating around local minima, it is advisable to progressively reduce the learning rate as the number of epochs increases. This technique, known as a learning schedule, helps achieve more stable convergence.\nIt important that the examples are either selected randomly or shuffled before running the algorithm to make sure that the algorithm converges towards the global minima."
  },
  {
    "objectID": "lectures/04/slides.html#mini-batch-gradient-descent",
    "href": "lectures/04/slides.html#mini-batch-gradient-descent",
    "title": "Linear regression and gradient descent",
    "section": "Mini-batch gradient descent",
    "text": "Mini-batch gradient descent\n\nAt each step, rather than selecting one training example as SGD does, mini-batch gradient descent randomly selects a small number of training examples to compute the gradients.\nIts trajectory is more regular compared to SGD.\n\nAs the size of the mini-batches increases, the algorithm becomes increasingly similar to batch gradient descent, which uses all the examples at each step.\n\nIt can take advantage of the hardware acceleration of matrix operations, particularly with GPUs."
  },
  {
    "objectID": "lectures/04/slides.html#summary",
    "href": "lectures/04/slides.html#summary",
    "title": "Linear regression and gradient descent",
    "section": "Summary",
    "text": "Summary\n\nBatch gradient descent is inherently slow and impractical for large datasets requiring out-of-core support, though it is capable of handling a substantial number of features.\nStochastic gradient descent is fast and well-suited for processing a large volume of examples efficiently.\nMini-batch gradient descent combines the benefits of both batch and stochastic methods; it is fast, capable of managing large datasets, and leverages hardware acceleration, particularly with GPUs.\n\n\nThe typical size of a mini-batch when applying stochastic gradient descent (SGD) can vary depending on the specific application and dataset, but common sizes often range between 32 and 512 samples. Here are some common mini-batch sizes used in practice:\n\nSmall Mini-Batches: Sizes such as 16, 32, or 64 are often used when working with smaller datasets or when memory constraints are a concern.\nMedium Mini-Batches: Sizes like 128, 256, or 512 are commonly used and can provide a good balance between computational efficiency and convergence speed.\nLarge Mini-Batches: Sizes like 1024, 2048, or larger might be used in large-scale machine learning tasks, especially when sufficient computational resources are available.\n\nThe choice of mini-batch size can influence several factors such as:\n\nTraining Speed: Larger mini-batches can make better use of parallel processing capabilities, potentially speeding up training.\nConvergence: Smaller mini-batches can introduce more noise in the gradient estimation, which can sometimes help escape local minima and improve generalization.\nMemory Usage: Larger mini-batches require more memory, which might be a limiting factor, especially on GPUs with limited VRAM.\n\nUltimately, the optimal mini-batch size is task-specific and often determined empirically through experimentation.\n\n\n\nAll three are implemented by SGDRegressor in Scikit-Learn."
  },
  {
    "objectID": "lectures/04/slides.html#optimization-and-deep-nets",
    "href": "lectures/04/slides.html#optimization-and-deep-nets",
    "title": "Linear regression and gradient descent",
    "section": "Optimization and deep nets",
    "text": "Optimization and deep nets\nWe will briefly revisit the subject when discussing deep artificial neural networks, for which specialized optimization algorithms exist.\n\nMomentum Optimization\nNesterov Accelerated Gradient\nAdaGrad\nRMSProp\nAdam and Nadam"
  },
  {
    "objectID": "lectures/04/slides.html#final-word",
    "href": "lectures/04/slides.html#final-word",
    "title": "Linear regression and gradient descent",
    "section": "Final word",
    "text": "Final word\n\nOptimization is a vast subject. Other algorithms exist and are used in other contexts.\n\nIncluding:\n\nParticle swarm optimization (PSO), genetic algorithms (GAs), and artificial bee colony (ABC) algorithms."
  },
  {
    "objectID": "lectures/04/slides.html#linear-regression---summary",
    "href": "lectures/04/slides.html#linear-regression---summary",
    "title": "Linear regression and gradient descent",
    "section": "Linear regression - summary",
    "text": "Linear regression - summary\n\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\(\\hat{y_i} = h(x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\\)\nThe Mean Squared Error (MSE) is: \\(\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2\\)\nBatch, stochastic, or mini-batch gradient descent can be used to find “optimal” values for the parameters, \\(\\theta_j\\) for \\(j \\in 0, 1, \\ldots, D\\).\nThe result is a regressor, a function that can be used to predict the \\(y\\) value (the label) for some unseen example \\(x\\)."
  },
  {
    "objectID": "lectures/04/slides.html#references",
    "href": "lectures/04/slides.html#references",
    "title": "Linear regression and gradient descent",
    "section": "References",
    "text": "References\n\n\nAzzalini, A., and A. W. Bowman. 1990. “A Look at Some Data on the Old Faithful Geyser.” Journal of the Royal Statistical Society Series C: Applied Statistics 39 (3): 357–65. https://doi.org/10.2307/2347385.\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 3rd ed. O’Reilly Media, Inc.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nStanton, Jeffrey M. 2001. “Galton, Pearson, and the Peas: A Brief History of Linear Regression for Statistics Instructors.” Journal of Statistics Education 9 (3). https://doi.org/10.1080/10691898.2001.11910537."
  },
  {
    "objectID": "lectures/04/slides.html#next-lecture",
    "href": "lectures/04/slides.html#next-lecture",
    "title": "Linear regression and gradient descent",
    "section": "Next lecture",
    "text": "Next lecture\n\nLogistic regression"
  },
  {
    "objectID": "lectures/04/index.html",
    "href": "lectures/04/index.html",
    "title": "Linear regression and gradient descent",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 1 must be submitted no later than September 29, 2025, at 11 PM. Please refer to the assignment description available on Brightspace."
  },
  {
    "objectID": "lectures/04/index.html#prepare",
    "href": "lectures/04/index.html#prepare",
    "title": "Linear regression and gradient descent",
    "section": "Prepare",
    "text": "Prepare\nCorresponding pages from the main textbook. Covers lectures 3,4,5, and 6.\n\nRussell and Norvig (2020), pages 651–720\nGéron (2019), \\(\\S\\) 4"
  },
  {
    "objectID": "lectures/04/index.html#participate",
    "href": "lectures/04/index.html#participate",
    "title": "Linear regression and gradient descent",
    "section": "Participate",
    "text": "Participate\n\nslides (PDF) comme Jupyter Notebook"
  },
  {
    "objectID": "lectures/04/index.html#practice",
    "href": "lectures/04/index.html#practice",
    "title": "Linear regression and gradient descent",
    "section": "Practice",
    "text": "Practice\n\nThe Palmer Penguins dataset, created by Allison Horst, Alison Hill, and Kristen Gorman, aims to serve as an alternative to the frequently utilized Iris dataset for data exploration and visualization. This Python package allows you to easily load the Palmer Penguins dataset into your Python environment. You can see complete examples on GitHub."
  },
  {
    "objectID": "lectures/05/slides.html#quote-of-day",
    "href": "lectures/05/slides.html#quote-of-day",
    "title": "Linear models: logististic regression",
    "section": "Quote of Day",
    "text": "Quote of Day\n\n\n\n“The next season of the #Complexity #podcast, ‘The Nature of Intelligence’, explores this question through conversations with cognitive and neuroscientists, animal cognition researchers, and AI experts in six episodes.””"
  },
  {
    "objectID": "lectures/05/slides.html#learning-objectives",
    "href": "lectures/05/slides.html#learning-objectives",
    "title": "Logististic regression",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nDifferentiate between binary classification and multi-class classification paradigms.\nDescribe a methodology for converting multi-class classification problems into binary classification tasks.\nImplement a logistic regression algorithm, focusing on its application in classification problems."
  },
  {
    "objectID": "lectures/05/slides.html#definitions",
    "href": "lectures/05/slides.html#definitions",
    "title": "Logististic regression",
    "section": "Definitions",
    "text": "Definitions\n\nBinary classification is a supervised learning task where the objective is to categorize instances (examples) into one of two discrete classes.\nA multi-class classification task is a type of supervised learning problem where the objective is to categorize instances into one of three or more discrete classes.\n\n\n\n\nAn example of a binary classification task is the prediction of disease status using genomic data (Wu et al. 2018).\nResearchers often seek to accurately classify the type, subtype, or stage of cancer using gene expression data. For example, in the Pan-Cancer Atlas, specific cancers such as Breast Cancer (BRCA), Colon Adenocarcinoma (COAD), Lung Adenocarcinoma (LUAD), Ovarian Cancer (OV), and Thyroid Cancer (THCA) can be differentiated based on their unique gene expression profiles (Alharbi and Vakanski 2023).\n\n\n\nCaveat: Multi-class classification should not be confused with multi-label classification, which allows an instance to be associated with multiple classes. The algorithms designed to address these tasks differ significantly."
  },
  {
    "objectID": "lectures/05/slides.html#binary-classification",
    "href": "lectures/05/slides.html#binary-classification",
    "title": "Logististic regression",
    "section": "Binary classification",
    "text": "Binary classification\n\nSome machine learning algorithms are specifically designed to solve binary classification problems.\n\nLogistic regression and support vector machines (SVMs) are such examples.\n\n\n\nLater in the presentation, make sure to understand why the logistic regression is specifically designed to solve binary classification problems."
  },
  {
    "objectID": "lectures/05/slides.html#multi-class-classification",
    "href": "lectures/05/slides.html#multi-class-classification",
    "title": "Logististic regression",
    "section": "Multi-class classification",
    "text": "Multi-class classification\n\nAny multi-class classification problem can be transformed into a binary classification problem.\nOne-vs-All (OvA)\n\nA separate binary classifier is trained for each class.\nFor each classifier, one class is treated as the positive class, and all other classes are treated as the negative class.\nThe final assignment of a class label is made based on the classifier that outputs the highest confidence score for a given input.\n\n\n\n\nScikit-learn offers OneVsRestClassifier, a utility designed to extend binary classifiers for multi-class classification tasks via the One-vs-Rest strategy.\nA complete example will be presented at the end of the lecture."
  },
  {
    "objectID": "lectures/05/slides.html#discussion",
    "href": "lectures/05/slides.html#discussion",
    "title": "Logististic regression",
    "section": "Discussion",
    "text": "Discussion\nTo introduce the concept of decision boundaries, let’s reexamine the Iris dataset."
  },
  {
    "objectID": "lectures/05/slides.html#loading-the-iris-dataset",
    "href": "lectures/05/slides.html#loading-the-iris-dataset",
    "title": "Logististic regression",
    "section": "Loading the Iris dataset",
    "text": "Loading the Iris dataset\n\nfrom sklearn.datasets import load_iris\n\n# Load the Iris dataset\n\niris = load_iris()\n\nimport pandas as pd\n\n# Create a DataFrame\n\ndf = pd.DataFrame(iris.data, columns=iris.feature_names)\ndf['species'] = iris.target"
  },
  {
    "objectID": "lectures/05/slides.html#pairwise-scatter-plots-of-iris-features",
    "href": "lectures/05/slides.html#pairwise-scatter-plots-of-iris-features",
    "title": "Logististic regression",
    "section": "Pairwise Scatter Plots of Iris Features",
    "text": "Pairwise Scatter Plots of Iris Features\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Using string labels to ease visualization\n\ndf['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n\n# Display all pairwise scatter plots\n\nsns.pairplot(df, hue='species', markers=[\"o\", \"s\", \"D\"])\nplt.suptitle(\"Pairwise Scatter Plots of Iris Features\", y=1.02)\nplt.show()\n\n\n\nUpon examining the scatter plots, it is evident that distinguishing Setosa from the other two varieties (Versicolor and Virginica) is relatively straightforward. In contrast, separating Versicolor from Virginica presents a greater challenge, as their distributions overlap in all the univariate plots displayed on the diagonal.\nHere, we define a One-vs-All classification problem to determine whether an example is Setosa or not. It is important to note that this approach will result in an imbalanced dataset, consisting of 50 instances of Setosa and 100 instances of Not Setosa."
  },
  {
    "objectID": "lectures/05/slides.html#pairwise-scatter-plots-of-iris-features-output",
    "href": "lectures/05/slides.html#pairwise-scatter-plots-of-iris-features-output",
    "title": "Logististic regression",
    "section": "Pairwise Scatter Plots of Iris Features",
    "text": "Pairwise Scatter Plots of Iris Features"
  },
  {
    "objectID": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset",
    "href": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset",
    "title": "Logististic regression",
    "section": "One-vs-All (OvA) on the Iris dataset",
    "text": "One-vs-All (OvA) on the Iris dataset\n\nimport numpy as np\n\n# Transform the target variable into binary classification\n# 'setosa' (class 0) vs. 'not setosa' (classes 1 and 2)\n\ny_binary = np.where(iris.target == 0, 0, 1)\n\n# Create a DataFrame for easier plotting with Seaborn\n\ndf = pd.DataFrame(iris.data, columns=iris.feature_names)\ndf['is_setosa'] = y_binary\n\nprint(y_binary)"
  },
  {
    "objectID": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset-output",
    "href": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset-output",
    "title": "Logististic regression",
    "section": "One-vs-All (OvA) on the Iris dataset",
    "text": "One-vs-All (OvA) on the Iris dataset\n\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1]"
  },
  {
    "objectID": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset-1",
    "href": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset-1",
    "title": "Logististic regression",
    "section": "One-vs-All (OvA) on the Iris dataset",
    "text": "One-vs-All (OvA) on the Iris dataset\n\n# Using string labels for visualization\n\ndf['is_setosa'] = df['is_setosa'].map({0: 'setosa', 1: 'not_setosa'})\n\n# Pairwise scatter plots\n\nsns.pairplot(df, hue='is_setosa', markers=[\"o\", \"s\"])\nplt.suptitle('Pairwise Scatter Plots of Iris Attributes \\n(Setosa vs. Not Setosa)', y=1.02)\nplt.show()"
  },
  {
    "objectID": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset-1-output",
    "href": "lectures/05/slides.html#one-vs-all-ova-on-the-iris-dataset-1-output",
    "title": "Logististic regression",
    "section": "One-vs-All (OvA) on the Iris dataset",
    "text": "One-vs-All (OvA) on the Iris dataset"
  },
  {
    "objectID": "lectures/05/slides.html#setosa-vs-not-setosa",
    "href": "lectures/05/slides.html#setosa-vs-not-setosa",
    "title": "Logististic regression",
    "section": "Setosa vs not setosa",
    "text": "Setosa vs not setosa\n\nClearly, we have simplified the problem.\nIn the majority of the scatter plots, the setosa examples are clustered together."
  },
  {
    "objectID": "lectures/05/slides.html#definition",
    "href": "lectures/05/slides.html#definition",
    "title": "Logististic regression",
    "section": "Definition",
    "text": "Definition\nA decision boundary is a boundary that partitions the underlying feature space into regions corresponding to different class labels.\n\n\nThe term boundary will be clarified over the next slides."
  },
  {
    "objectID": "lectures/05/slides.html#decision-boundary",
    "href": "lectures/05/slides.html#decision-boundary",
    "title": "Logististic regression",
    "section": "Decision boundary",
    "text": "Decision boundary\nConsider two attributes, say petal length and sepal width, the decision boundary can be line."
  },
  {
    "objectID": "lectures/05/slides.html#decision-boundary-1",
    "href": "lectures/05/slides.html#decision-boundary-1",
    "title": "Logististic regression",
    "section": "Decision boundary",
    "text": "Decision boundary\nConsider two attributes, say petal length and sepal width, the decision boundary can be line."
  },
  {
    "objectID": "lectures/05/slides.html#definition-1",
    "href": "lectures/05/slides.html#definition-1",
    "title": "Logististic regression",
    "section": "Definition",
    "text": "Definition\nWe say that the data is linearly separable when two classes of data can be perfectly separated by a single linear boundary, such as a line in two-dimensional space or a hyperplane in higher dimensions."
  },
  {
    "objectID": "lectures/05/slides.html#simple-decision-boundary",
    "href": "lectures/05/slides.html#simple-decision-boundary",
    "title": "Logististic regression",
    "section": "Simple decision boundary",
    "text": "Simple decision boundary\n\n\n\n\n\n(a) training data, (b) quadratic curve, and (c) linear function.\n\nAttribution: Geurts, P., Irrthum, A. & Wehenkel, L. Supervised learning with decision tree-based methods in computational and systems biology. Mol Biosyst 5 1593–1605 (2009).\n\n\nThe table on the left presents training data for a hypothetical binary classification task in a medical context, where the two attributes, \\(X_1\\) and \\(X_2\\), are used to predict the target variable, \\(y\\), which can take on two values: sick and healthy. You can imagine that \\(X_1\\) and \\(X_2\\) are measurements, such as blood pressure and heart rate or cholesterol and glucose levels.\nLogistic regression (c) employs a linear decision boundary. In this specific example, the decision boundary is represented by a straight line. Employing logistic regression for this problem results in several classification errors: red dots above the line, which should be classified as ‘sick’, are incorrectly predicted as ‘healthy’. Conversely, green dots below the line, which should be classified as ‘healthy’, are incorrectly predicted as ‘sick’."
  },
  {
    "objectID": "lectures/05/slides.html#complex-decision-boundary",
    "href": "lectures/05/slides.html#complex-decision-boundary",
    "title": "Logististic regression",
    "section": "Complex decision boundary",
    "text": "Complex decision boundary\n\n\n\n\n\nDecision trees are capable of generating irregular and non-linear decision boundaries.\n\nAttribution: ibidem.\n\n\nMake sure to understand the relationships between the eight decision rules delineated in the decision tree and the nine line segments represented in the scatter plot."
  },
  {
    "objectID": "lectures/05/slides.html#decision-boundary-2",
    "href": "lectures/05/slides.html#decision-boundary-2",
    "title": "Logististic regression",
    "section": "Decision boundary",
    "text": "Decision boundary"
  },
  {
    "objectID": "lectures/05/slides.html#digression",
    "href": "lectures/05/slides.html#digression",
    "title": "Logististic regression",
    "section": "Digression",
    "text": "Digression\n\n\n\n\n\n\n\n\n\n\n\nObserve that separating the data using only the two attributes, \\(x1\\) and \\(x2\\), is infeasible. However, by incorporating a third attribute, \\(x3\\), the data becomes linearly separable, as can be seen on the previous screen."
  },
  {
    "objectID": "lectures/05/slides.html#decision-boundary-3",
    "href": "lectures/05/slides.html#decision-boundary-3",
    "title": "Logististic regression",
    "section": "Decision boundary",
    "text": "Decision boundary\n\n2 attributes, the linear decision boundary would be a line.\n2 attributes, the non-linear decision boundary would be a non-linear curve.\n3 attributes, the linear decision boundary would be a plane.\n3 attributes, the non-linear decision boundary would be a non-linear surface.\n\\(\\gt\\) 3 attributes, the linear decision boundary would be a hyperplane.\n\\(\\gt\\) 3 attributes, the non-linear decision boundary would be a hypersurface.\n\n\nIn machine learning, it is common for problems to involve hundreds or even thousands of attributes, rendering direct visualization infeasible.\nSpecifically, a non-linear decision boundary in high-dimensional space is often conceptualized as a non-linear manifold."
  },
  {
    "objectID": "lectures/05/slides.html#definition-revised",
    "href": "lectures/05/slides.html#definition-revised",
    "title": "Logististic regression",
    "section": "Definition (revised)",
    "text": "Definition (revised)\nA decision boundary is a hypersurface that partitions the underlying feature space into regions corresponding to different class labels."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-logit-regression",
    "href": "lectures/05/slides.html#logistic-logit-regression",
    "title": "Logististic regression",
    "section": "Logistic (Logit) Regression",
    "text": "Logistic (Logit) Regression\n\nDespite its name, logistic regression serves as a classification algorithm rather than a regression technique.\nThe labels in logistic regression are binary values, denoted as \\(y_i \\in \\{0,1\\}\\), making it a binary classification task.\nThe primary objective of logistic regression is to determine the probability that a given instance \\(x_i\\) belongs to the positive class, i.e., \\(y_i = 1\\).\n\n\nThe representation of the two classes, negative and positive, by the values 0 and 1, respectively, is not arbitrary. This choice is intrinsically connected to our objective of determining the probability that an instance \\(x_i\\) belongs to the positive class.\nWhile this learning algorithm may initially seem unremarkable, it is essential to continue engaging with it, as logistic regression will later prove to be crucial in the discussion on artificial neural networks."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-regression-1",
    "href": "lectures/05/slides.html#logistic-regression-1",
    "title": "Logististic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\nThe Logistic Regression model, in its vectorized form, is defined as:\n\\[\n  h_\\theta(x_i) = \\sigma(\\theta x_i) = \\frac{1}{1+e^{- \\theta x_i}}\n  \\]\n\n\nAn extra feature, \\(x_i^{(0)} = 1\\), has been added to \\(x_i\\), and \\(\\theta_0\\) is the intercept/bias term."
  },
  {
    "objectID": "lectures/05/slides.html#fitting-a-linear-regression",
    "href": "lectures/05/slides.html#fitting-a-linear-regression",
    "title": "Logististic regression",
    "section": "Fitting a linear regression",
    "text": "Fitting a linear regression\n\\(\\ldots\\) is not the answer\n\n\n\n\n\n\n\n\n\nThe resulting line extends infinitely in both directions, but our goal is to constrain values between 0 and 1. Here, 1 indicates a high probability that \\(x_i\\) belongs to the positive class, while a value near 0 indicates a low probability.\n\nThis model nevertheless presents interesting elements. A high function value corresponds to examples of the positive class (Setosa, 1), while a low function value indicates examples of the negative class (Non-Setosa, 0)."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-function",
    "href": "lectures/05/slides.html#logistic-function",
    "title": "Logististic regression",
    "section": "Logistic Function",
    "text": "Logistic Function"
  },
  {
    "objectID": "lectures/05/slides.html#logistic-regression-intuition",
    "href": "lectures/05/slides.html#logistic-regression-intuition",
    "title": "Logististic regression",
    "section": "Logistic Regression (intuition)",
    "text": "Logistic Regression (intuition)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen the distance to the decision boundary is zero, uncertainty is high, making a probability of 0.5 appropriate.\nAs we move away from the decision boundary, confidence increases, warranting higher or lower probabilities accordingly."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-function-1",
    "href": "lectures/05/slides.html#logistic-function-1",
    "title": "Logististic regression",
    "section": "Logistic Function",
    "text": "Logistic Function\n\n\nIn mathematics, the standard logistic function maps a real-valued input from \\(\\mathbb{R}\\) to the open interval \\((0,1)\\). The function is defined as:\n\\[\n  \\sigma(t) = \\frac{1}{1+e^{-t}}\n\\]\n\n\n\nCode\n# Sigmoid function\ndef sigmoid(t):\n    return 1 / (1 + np.exp(-t))\n\n# Generate t values\nt = np.linspace(-6, 6, 1000)\n\n# Compute y values for the sigmoid function\nsigma = sigmoid(t)\n\n# Create a figure\nfig, ax = plt.subplots()\nax.plot(t, sigma, color='blue', linewidth=2)  # Keep the curve opaque\n\n# Draw vertical axis at x = 0\nax.axvline(x=0, color='black', linewidth=1)\n\n# Add labels on the vertical axis\nax.set_yticks([0, 0.5, 1.0])\n\n# Add labels to the axes\nax.set_xlabel('t')\nax.set_ylabel(r'$\\sigma(t)$')\n\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nWhen the input variable \\(t\\) is 0, the output of the logistic function is 0.5.\n\nIndeed, \\(e^{-t} = {e^0} = 1\\) and thus \\(\\frac{1}{1+e^{-t}} = \\frac{1}{1+1}= \\frac{1}{2}.\\)\n\nAs \\(t\\) increases, the output value approaches 1.\n\nAs \\(t \\to \\infty\\), \\(e^{-t} \\to 0\\).\n\nConversely, as \\(t\\) becomes more negative, the output value approaches 0.\n\nAs \\(t \\to -\\infty\\), \\(e^{-t} \\to \\infty\\) (the two negative signs cancel out).\n\nThe standard logistic function is also commonly referred to as the sigmoid function."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-logit-regression-1",
    "href": "lectures/05/slides.html#logistic-logit-regression-1",
    "title": "Logististic regression",
    "section": "Logistic (Logit) Regression",
    "text": "Logistic (Logit) Regression\n\nAnalogous to linear regression, logistic regression computes a weighted sum of the input features, expressed as: \\[\n\\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\nHowever, using the sigmoid function limits its output to the range \\((0,1)\\): \\[\n\\sigma(\\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)})\n\\]"
  },
  {
    "objectID": "lectures/05/slides.html#logistic-regression-2",
    "href": "lectures/05/slides.html#logistic-regression-2",
    "title": "Logististic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nThe Logistic Regression model, in its vectorized form, is defined as:\n\\[\nh_\\theta(x_i) = \\sigma(\\theta x_i) = \\frac{1}{1+e^{- \\theta x_i}}\n\\]\nPredictions are made as follows:\n\n\\(y_i = 0\\), if \\(h_\\theta(x_i) &lt; 0.5\\)\n\\(y_i = 1\\), if \\(h_\\theta(x_i) \\geq 0.5\\)\n\n\n\n\nThe values of \\(\\theta\\) are learned using gradient descent."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-regression-two-attributes",
    "href": "lectures/05/slides.html#logistic-regression-two-attributes",
    "title": "Logististic regression",
    "section": "Logistic regression (two attributes)",
    "text": "Logistic regression (two attributes)\n\n\n\n\n\n\n\n\n\n\n\n\\[\n  h_\\theta(x_i) = \\sigma(\\theta x_i)\n\\]\n\n\nIn logistic regression, the probability of correctly classifying an example increases as its distance from the decision boundary increases.\nThis principle holds for both positive and negative classes.\nAn example lying on the decision boundary has a 50% probability of belonging to either class."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-regression-3",
    "href": "lectures/05/slides.html#logistic-regression-3",
    "title": "Logististic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nThe Logistic Regression model, in its vectorized form, is defined as:\n\\[\nh_\\theta(x_i) = \\sigma(\\theta x_i) = \\frac{1}{1+e^{- \\theta x_i}}\n\\]\nPredictions are made as follows:\n\n\\(y_i = 0\\), if \\(h_\\theta(x_i) &lt; 0.5\\)\n\\(y_i = 1\\), if \\(h_\\theta(x_i) \\geq 0.5\\)\n\n\n\n\nThe values of \\(\\theta\\) are learned using gradient descent."
  },
  {
    "objectID": "lectures/05/slides.html#one-vs-all-classifier-complete",
    "href": "lectures/05/slides.html#one-vs-all-classifier-complete",
    "title": "Logististic regression",
    "section": "One-vs-All classifier (complete)",
    "text": "One-vs-All classifier (complete)\n\nfrom sklearn.datasets import load_iris\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\n\n# Load the Iris dataset\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Binarize the output\ny_bin = label_binarize(y, classes=[0, 1, 2])\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, random_state=42)"
  },
  {
    "objectID": "lectures/05/slides.html#one-vs-all-classifier-complete-1",
    "href": "lectures/05/slides.html#one-vs-all-classifier-complete-1",
    "title": "Logististic regression",
    "section": "One-vs-All classifier (complete)",
    "text": "One-vs-All classifier (complete)\n\n# Train a One-vs-All classifier for each class\n\nclassifiers = []\nfor i in range(3):\n    clf = LogisticRegression()\n    clf.fit(X_train, y_train[:, i])\n    classifiers.append(clf)\n\n\n\nEach logistic regression finds a hyperplane in a 4-dimensional space that separates the data into two classes."
  },
  {
    "objectID": "lectures/05/slides.html#one-vs-all-classifier-complete-2",
    "href": "lectures/05/slides.html#one-vs-all-classifier-complete-2",
    "title": "Logististic regression",
    "section": "One-vs-All classifier (complete)",
    "text": "One-vs-All classifier (complete)\n\n# Predict on a new sample\nnew_sample = X_test[0].reshape(1, -1)\nconfidences = [clf.decision_function(new_sample) for clf in classifiers]\n\n# Final assignment\nfinal_class = np.argmax(confidences)\n\n# Printing the result\nprint(f\"Final class assigned: {iris.target_names[final_class]}\")\nprint(f\"True class: {iris.target_names[np.argmax(y_test[0])]}\")\n\nFinal class assigned: versicolor\nTrue class: versicolor"
  },
  {
    "objectID": "lectures/05/slides.html#label_binarized",
    "href": "lectures/05/slides.html#label_binarized",
    "title": "Logististic regression",
    "section": "label_binarized",
    "text": "label_binarized\n\nfrom sklearn.preprocessing import label_binarize\n\n# Original class labels\ny_train = np.array([0, 1, 2, 0, 1, 2, 1, 0])\n\n# Binarize the labels\ny_train_binarized = label_binarize(y_train, classes=[0, 1, 2])\n\n# Assume y_train_binarized contains the binarized labels\nprint(\"Binarized labels:\\n\", y_train_binarized)\n\n# Convert binarized labels back to the original numerical values\noriginal_labels = [np.argmax(b) for b in y_train_binarized]\nprint(\"Original labels:\\n\", original_labels)\n\nBinarized labels:\n [[1 0 0]\n [0 1 0]\n [0 0 1]\n [1 0 0]\n [0 1 0]\n [0 0 1]\n [0 1 0]\n [1 0 0]]\nOriginal labels:\n [np.int64(0), np.int64(1), np.int64(2), np.int64(0), np.int64(1), np.int64(2), np.int64(1), np.int64(0)]"
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nLoading the dataset\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\nWhat is the type of digits.data\n\ntype(digits.data)\n\nnumpy.ndarray\n\n\n\n\nDeveloping a logistic regression model for the recognition of handwritten digits."
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-1",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-1",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nHow many examples (N) and how many attributes (D)?\n\ndigits.data.shape\n\n(1797, 64)\n\n\nAssigning N and D\n\nN, D = digits.data.shape\n\ntarget has the same number of entries (examples) as data?\n\ndigits.target.shape\n\n(1797,)"
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-2",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-2",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nWhat are the width and height of those images?\n\ndigits.images.shape\n\n(1797, 8, 8)\n\n\nAssigning width and height\n\n_, width, height = digits.images.shape"
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-3",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-3",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nAssigning X and y\n\nX = digits.data\ny = digits.target"
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-4",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-4",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nX[0] is a vector of size width * height = D (\\(8 \\times 8 = 64\\)).\n\nX[0]\n\narray([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])\n\n\n\nIt corresponds to an \\(8 \\times 8 = 64\\) image.\n\nX[0].reshape(width, height)\n\narray([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-5",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-5",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nPlot the first n=5 examples\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.figure(figsize=(10,2))\nn = 5\n\nfor index, (image, label) in enumerate(zip(X[0:n], y[0:n])):\n    plt.subplot(1, n, index + 1)\n    plt.imshow(np.reshape(image, (width,width)), cmap=plt.cm.gray)\n    plt.title(f'y = {label}')\n\n\n\n\n\n\n\n\n\nIntensity values close to 0 are represented in black, while high values are represented in white.\nUse cmap=plt.cm.binary to invert the images (intensity values close to 0 in white, high values in black)."
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-6",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-6",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,2))\nn = 5\n\nfor index, (image, label) in enumerate(zip(X[0:n], y[0:n])):\n    plt.subplot(1, n, index + 1)\n    plt.imshow(np.reshape(image, (width,width)), cmap=plt.cm.gray)\n    plt.title(f'y = {label}')\n\n\n\n\n\n\n\n\n\n\nIn our dataset, each \\(x_i\\) is an attribute vector of size \\(D = 64\\).\nThis vector is formed by concatenating the rows of an \\(8 \\times 8\\) image.\nThe reshape function is employed to convert this 64-dimensional vector back into its original \\(8 \\times 8\\) image format."
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-7",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-7",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\n\n\n\n\n\n\n\n\n\n\nWe will train 10 classifiers, each corresponding to a specific digit in a One-vs-All (OvA) approach.\nEach classifier will determine the optimal values of \\(\\theta_j\\) (associated with the pixel features), allowing it to distinguish one digit from all other digits."
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-8",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-8",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nPreparing for our machine learning experiment\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-9",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-9",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nOptimization algorithms generally work best when the attributes have similar ranges.\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n\n\nCertain classifiers exhibit suboptimal performance when there are significant variations in feature scales. This issue is particularly pronounced in classifiers that utilize gradient descent for parameter optimization, as they can be adversely affected by discrepancies in feature scale. Consequently, standardization of features is a widely adopted practice to mitigate this problem.\nStandardScaler is a commonly used approach. For a given feature, the values are transformed as follows:\n\\[\nz = (x - \\mu) / \\sigma\n\\]\nwhere \\(\\mu\\) is the average of all the values for that feature for the training data, and \\(\\sigma\\) the corresponding standard deviation.\nCalling fit forces the scaler to learn the mean and standard deviation of each feature. Calling tranform, applies the transformation onto the designated dataset. Finally, calling fit_transform combines the two steps.\nIt would be an error to apply fit or fit_transform on the entire dataset, an error called data leakeage. Information from the test data would influence the mean and standard deviation learnt by the scaler. The training data would be transformed using information from the test set. The model will learn from training data scaled using information baised by the test set. The test set is no longer independent.\nIt is paramount to scale the test data. The model has been trained on scaled data, here with mean values centered at zero and standard deviation of 1. The original data was likely on a widely different scale. Imagine a attribute representing the temperature in celcius might have values -40 to 40. Another attribute, this one representing a grade, with values from 0 to 100. The model would produce non sense results on such data. The test data needs to be scaled using the mean and standard deviation from the training data, which represents the frame of reference for its training.\n\nFairness in evaluation (no cheating): If you use the test data to compute the mean and variance, you’re peeking at the answers. Even though it’s “just” a mean and standard deviation, that’s still information from the test set. This breaks the principle that test data should remain completely unseen until evaluation.\nConsistency of distribution: The model was trained assuming features are centered and scaled using the training distribution. If you scale test data differently (e.g., with its own mean/std), then the numbers the model sees no longer match the distribution it was trained on. It’s like giving the model inputs in a “new language.”\nDeployment perspective: In real applications, you’ll only ever have the training distribution to compute the scaling parameters. When the model is deployed, you can’t stop time to recompute scaling each time new data arrives — you must apply the fixed transformation learned from the training data.\n\n“The scaler is part of the model.” Just like weights in logistic regression, the StandardScaler’s mean and variance are learned from the training set. Once learned, they become fixed parameters of your preprocessing pipeline.\n“Training vs. exam.” Training data is your study material; test data is the exam. You can’t look at the exam questions to prepare your notes (using test data for scaling), and you can’t change the exam’s grading scheme midway (scaling test data separately). You must prepare with your study notes (training distribution) and then take the exam under the same scheme.\n“Same ruler for everyone.” Scaling is like using a ruler to measure heights. You calibrate the ruler once with the training data. If you used a different ruler for the test data, the numbers wouldn’t be comparable anymore.\n\n\nDiscussion: importance of applying fit_transform only to X_train."
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-10",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-10",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\nclf = OneVsRestClassifier(LogisticRegression())\nclf = clf.fit(X_train, y_train)\n\n\n\nEach logistic regression finds a hyperplane in a 64-dimensional space that separates the data into two classes.\n\n\nAsking the classifier to solve a multiclass task, using one-vs-rest (OvR), aka OvA. Classfiers in sklearn have multi-learning support built-in."
  },
  {
    "objectID": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-11",
    "href": "lectures/05/slides.html#uci-ml-hand-written-digits-datasets-11",
    "title": "Logististic regression",
    "section": "UCI ML hand-written digits datasets",
    "text": "UCI ML hand-written digits datasets\nApplying the classifier to our test set\n\nfrom sklearn.metrics import classification_report\n\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        17\n           1       1.00      1.00      1.00        11\n           2       1.00      1.00      1.00        17\n           3       1.00      0.94      0.97        17\n           4       1.00      1.00      1.00        25\n           5       0.96      1.00      0.98        22\n           6       1.00      1.00      1.00        19\n           7       1.00      0.95      0.97        19\n           8       0.80      1.00      0.89         8\n           9       0.96      0.92      0.94        25\n\n    accuracy                           0.98       180\n   macro avg       0.97      0.98      0.97       180\nweighted avg       0.98      0.98      0.98       180"
  },
  {
    "objectID": "lectures/05/slides.html#visualization",
    "href": "lectures/05/slides.html#visualization",
    "title": "Logististic regression",
    "section": "Visualization",
    "text": "Visualization\nHow many classes?\n\nclf.classes_\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\nThe coefficients and intercepts are in distinct arrays.\n\n(clf.estimators_[0].coef_.shape, clf.estimators_[0].intercept_.shape)\n\n((1, 64), (1,))\n\n\n\n\nIntercepts are \\(\\theta_0\\), where as coefficents are \\(\\theta_j, j \\in [1,64]\\).\n\n\n\nAdapted from MNIST digits classification using Logistic regression in Scikit-Learn, visited 2024-09-23."
  },
  {
    "objectID": "lectures/05/slides.html#visualization-1",
    "href": "lectures/05/slides.html#visualization-1",
    "title": "Logististic regression",
    "section": "Visualization",
    "text": "Visualization\n\nclf.estimators_[0].coef_[0].round(2).reshape(width, height)\n\narray([[ 0.  , -0.25,  0.04,  0.21,  0.02, -0.58, -0.36, -0.05],\n       [ 0.  , -0.39,  0.04,  0.43,  0.53,  0.72, -0.03, -0.12],\n       [-0.03,  0.19,  0.28, -0.04, -0.94,  0.84, -0.01, -0.06],\n       [-0.04,  0.27,  0.26, -0.57, -1.75,  0.24,  0.07, -0.03],\n       [ 0.  ,  0.32,  0.57, -0.58, -1.62, -0.15,  0.17,  0.  ],\n       [-0.08, -0.13,  0.92, -0.85, -0.83, -0.01,  0.22, -0.  ],\n       [-0.04, -0.36,  0.61, -0.14,  0.28,  0.01, -0.37, -0.41],\n       [ 0.01, -0.31, -0.31,  0.54, -0.32, -0.18, -0.32, -0.21]])"
  },
  {
    "objectID": "lectures/05/slides.html#visualization-2",
    "href": "lectures/05/slides.html#visualization-2",
    "title": "Logististic regression",
    "section": "Visualization",
    "text": "Visualization\n\ncoef = clf.estimators_[0].coef_\nplt.imshow(coef[0].reshape(width,height))"
  },
  {
    "objectID": "lectures/05/slides.html#visualization-3",
    "href": "lectures/05/slides.html#visualization-3",
    "title": "Logististic regression",
    "section": "Visualization",
    "text": "Visualization\n\n\nCode\nplt.figure(figsize=(10,5))\n\nfor index in range(len(clf.classes_)):\n    plt.subplot(2, 5, index + 1)\n    plt.title(f'y = {clf.classes_[index]}')\n    plt.imshow(clf.estimators_[index].coef_.reshape(width,width), \n               cmap=plt.cm.RdBu)\n\n\n\n\n\n\n\n\n\n\nEach LogisticRegression learns 64 \\(\\theta_i\\) parameters.\nIn the images above, red pixels correspond to negative coefficients, while blue pixels correspond to positive coefficients.\nFor the first classifier, which predicts the digit ‘0’, the model assigns negative weights to high-intensity pixels in the center of the image and positive weights to high-intensity pixels in the oval region surrounding the center."
  },
  {
    "objectID": "lectures/05/slides.html#references",
    "href": "lectures/05/slides.html#references",
    "title": "Logististic regression",
    "section": "References",
    "text": "References\n\n\nAlharbi, Fadi, and Aleksandar Vakanski. 2023. “Machine Learning Methods for Cancer Classification Using Gene Expression Data: A Review.” Bioengineering 10 (2): 173. https://doi.org/10.3390/bioengineering10020173.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nWu, Qianfan, Adel Boueiz, Alican Bozkurt, Arya Masoomi, Allan Wang, Dawn L DeMeo, Scott T Weiss, and Weiliang Qiu. 2018. “Deep Learning Methods for Predicting Disease Status Using Genomic Data.” Journal of Biometrics & Biostatistics 9 (5)."
  },
  {
    "objectID": "lectures/05/slides.html#resources",
    "href": "lectures/05/slides.html#resources",
    "title": "Logististic regression",
    "section": "Resources",
    "text": "Resources\n\nLogistic Regression 3-class Classifier from sklearn"
  },
  {
    "objectID": "lectures/05/slides.html#next-lecture",
    "href": "lectures/05/slides.html#next-lecture",
    "title": "Logististic regression",
    "section": "Next lecture",
    "text": "Next lecture\n\nNegative log-likelihood, geometric interpretation, implementation"
  },
  {
    "objectID": "lectures/05/slides.html#d-plot-with-points-below-and-above-the-plane",
    "href": "lectures/05/slides.html#d-plot-with-points-below-and-above-the-plane",
    "title": "Logististic regression",
    "section": "3D plot with points below and above the plane",
    "text": "3D plot with points below and above the plane\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Function to generate points\ndef generate_points_above_below_plane(num_points=100):\n    # Define the plane z = ax + by + c\n    a, b, c = 1, 1, 0  # Plane coefficients\n\n    # Generate random points\n    x1 = np.random.uniform(-10, 10, num_points)\n    x2 = np.random.uniform(-10, 10, num_points)\n\n    y1 = np.random.uniform(-10, 10, num_points)\n    y2 = np.random.uniform(-10, 10, num_points)\n\n    # Points above the plane\n    z_above = a * x1 + b * y1 + c + np.random.normal(20, 2, num_points)\n\n    # Points below the plane\n    z_below = a * x2 + b * y2 + c - np.random.normal(20, 2, num_points)\n\n    # Stack the points into arrays\n    points_above = np.vstack((x1, y1, z_above)).T\n    points_below = np.vstack((x2, y2, z_below)).T\n\n    return points_above, points_below\n\n# Generate points\npoints_above, points_below = generate_points_above_below_plane()\n\n# Visualization\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# Plot points above the plane\nax.scatter(points_above[:, 0], points_above[:, 1], points_above[:, 2], c='r', label='Above the plane')\n\n# Plot points below the plane\nax.scatter(points_below[:, 0], points_below[:, 1], points_below[:, 2], c='b', label='Below the plane')\n\n# Plot the plane itself for reference\nxx, yy = np.meshgrid(range(-10, 11), range(-10, 11))\nzz = 1 * xx + 1 * yy + 0\nax.plot_surface(xx, yy, zz, alpha=0.2, color='gray')\n\n# Set labels\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\n\n# Set title and legend\nax.set_title('3D Points Above and Below a Plane')\nax.legend()\n\n# Show plot\nplt.show()"
  },
  {
    "objectID": "lectures/05/index.html",
    "href": "lectures/05/index.html",
    "title": "Logistic regression",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 1 must be submitted no later than September 29, 2025, at 11 PM. Please refer to the assignment description available on Brightspace."
  },
  {
    "objectID": "lectures/05/index.html#prepare",
    "href": "lectures/05/index.html#prepare",
    "title": "Logistic regression",
    "section": "Prepare",
    "text": "Prepare\n\nLogistic regression: Russell and Norvig (2020), pages 684-686\nWatch Machine Learning and Logistic Regression, IBM Technology."
  },
  {
    "objectID": "lectures/05/index.html#participate",
    "href": "lectures/05/index.html#participate",
    "title": "Logistic regression",
    "section": "Participate",
    "text": "Participate\n\nslides (PDF) as Jupyter Notebook"
  },
  {
    "objectID": "lectures/05/index.html#practice",
    "href": "lectures/05/index.html#practice",
    "title": "Logistic regression",
    "section": "Practice",
    "text": "Practice\nIn class, we developed a logistic regression model for handwritten digit recognition using a dataset from UCI ML. This dataset comprises 1797 images of size \\(8 \\times 8\\). The MNIST (mnist_784) dataset contains 70,000 images of size \\(28 \\times 28\\). The following example, from the sklearn website, uses this dataset and graphically presents the coefficients (\\(\\theta\\)) for each of the 10 models. You can load this model as follows:\n\nfrom sklearn.datasets import fetch_openml  \n\nX, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
  },
  {
    "objectID": "lectures/06/slides.html#quote-of-day",
    "href": "lectures/06/slides.html#quote-of-day",
    "title": "Model evaluation",
    "section": "Quote of Day",
    "text": "Quote of Day\n\n\n\n\n\n\n\n\n\n\n2024 Waymo Safety Impact Report was published on 2024-09-05. Waymo is a subsidiary of Alphabet inc., Google’s parent company. It operates robotaxi services in 4 US cities."
  },
  {
    "objectID": "lectures/06/slides.html#learning-objectives",
    "href": "lectures/06/slides.html#learning-objectives",
    "title": "Geometric interpretation and cross-entry",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nClarify…\nSummarize…\nDiscuss.."
  },
  {
    "objectID": "lectures/06/slides.html#model-fitting-1",
    "href": "lectures/06/slides.html#model-fitting-1",
    "title": "Model evaluation",
    "section": "Model fitting",
    "text": "Model fitting\n\n\n\n\n\n\n\n\n\n\n\n\nDuring our class discussions, we have touched upon the concepts of underfitting and overfitting. To delve deeper into these topics, let’s examine them in the context of polynomial regression.\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\n\nThis example was meant to illustrate that, in practice, we often have limited knowledge about the underlying model that generated the data."
  },
  {
    "objectID": "lectures/06/slides.html#generating-a-nonlinear-dataset",
    "href": "lectures/06/slides.html#generating-a-nonlinear-dataset",
    "title": "Model evaluation",
    "section": "Generating a nonlinear dataset",
    "text": "Generating a nonlinear dataset\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nnp.random.seed(42)\n\nX = 6 * np.random.rand(100, 1) - 3\ny = 0.5 * X ** 2 - X + 2 + np.random.randn(100, 1)\n\n\n\nIn machine learning experiments, specifying the seed of the random number generator is crucial for ensuring reproducibility. By setting a fixed seed, programmers can guarantee that the same sequence of random numbers will be generated each time the experiment is run. This consistency is vital for several reasons:\n\nReproducibility: It allows other programmers to replicate the experiment with the exact same conditions, facilitating verification and validation of results.\nComparative Analysis: It enables consistent comparison between different models or algorithms under the same initial conditions, ensuring that observed differences are due to the models themselves rather than variations in the random initialization.\nDebugging: It aids in debugging by providing a stable environment where issues can be consistently reproduced and investigated.\n\n\n\nAttribution: Géron (2022), 4"
  },
  {
    "objectID": "lectures/06/slides.html#linear-regression",
    "href": "lectures/06/slides.html#linear-regression",
    "title": "Model evaluation",
    "section": "Linear regression",
    "text": "Linear regression\n\n\n\n\n\n\n\n\n\n\nA linear model inadequately represents this dataset"
  },
  {
    "objectID": "lectures/06/slides.html#definition",
    "href": "lectures/06/slides.html#definition",
    "title": "Model evaluation",
    "section": "Definition",
    "text": "Definition\nFeature engineering is the process of creating, transforming, and selecting variables (attributes) from raw data to improve the performance of machine learning models.\n\n\nHere, our focus is on creating new attributes from raw data."
  },
  {
    "objectID": "lectures/06/slides.html#polynomialfeatures",
    "href": "lectures/06/slides.html#polynomialfeatures",
    "title": "Model evaluation",
    "section": "PolynomialFeatures",
    "text": "PolynomialFeatures\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_features = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly_features.fit_transform(X)\n\n\n\nX[0]\n\narray([-0.75275929])\n\n\n\n\n\nX_poly[0]\n\narray([-0.75275929,  0.56664654])\n\n\n\n\n\n\n\n sklearn.preprocessing.PolynomialFeatures\n\n\nGenerate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form \\([a, b]\\), the degree-2 polynomial features are \\([1, a, b, a^2, ab, b^2]\\)."
  },
  {
    "objectID": "lectures/06/slides.html#polynomialfeatures-1",
    "href": "lectures/06/slides.html#polynomialfeatures-1",
    "title": "Model evaluation",
    "section": "PolynomialFeatures",
    "text": "PolynomialFeatures\nGiven two features \\(a\\) and \\(b\\), PolynomialFeatures with degree=3 would add \\(a^2\\), \\(a^3\\), \\(b^2\\), \\(b^3\\), as well as, \\(ab\\), \\(a^2b\\), \\(ab^2\\)!\n\n\n\n\n\n\n\nWarning\n\n\nPolynomialFeatures(degree=d) adds \\(\\frac{(D+d)!}{d!D!}\\) features, where \\(D\\) is the original number of features.\n\n\n\n\nAdditionally, you have the option to engineer new features of your own."
  },
  {
    "objectID": "lectures/06/slides.html#polynomial-regression",
    "href": "lectures/06/slides.html#polynomial-regression",
    "title": "Model evaluation",
    "section": "Polynomial regression",
    "text": "Polynomial regression\n\n\n\n\n\n\n\n\n\nLinearRegression on PolynomialFeatures\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_poly, y)"
  },
  {
    "objectID": "lectures/06/slides.html#polynomial-regression-1",
    "href": "lectures/06/slides.html#polynomial-regression-1",
    "title": "Model evaluation",
    "section": "Polynomial regression",
    "text": "Polynomial regression\n\n\n\n\n\n\n\n\n\n\n\n\nThe data was generated according to the following equation, with the inclusion of Gaussian noise.\n\\[\n  y = 0.5 x^2 + 1.0 x + 2.0\n\\]\nPresented below is the learned model.\n\\[\n  \\hat{y} = 0.56 x^2 + (-1.06) x + 1.78\n\\]\n\n\nlin_reg.coef_, lin_reg.intercept_\n\n(array([[-1.06633107,  0.56456263]]), array([1.78134581]))\n\n\n\nGiven the noise present in our dataset, akin to what we would expect with real-world data, this model demonstrates a good fit."
  },
  {
    "objectID": "lectures/06/slides.html#overfitting-and-underfitting",
    "href": "lectures/06/slides.html#overfitting-and-underfitting",
    "title": "Model evaluation",
    "section": "Overfitting and underfitting",
    "text": "Overfitting and underfitting\n\n\n\n\n\n\n\n\n\nA low loss value on the training set does not necessarily indicate a “better” model.\n\n\nIn this example, the linear regression model is underfitting the training data, as indicated by its high mean squared error (loss) on the training set (red line). This suggests that the model makes numerous errors even on the training data.\nConversely, the polynomial model with degree=300 is overfitting the training data. It exhibits a low mean squared error (loss) on the training set (green line), implying that it makes few errors on the training data.\nHowever, the degree=300 polynomial model is likely to perform poorly on future predictions. The green curve extends beyond the boundaries of the image on the y-axis. For instance, for input values in the range of 2 to 3, the model predicts values exceeding 10 (as well as negative values), whereas the expected values should lie within the range of 2 to 4.\nThis illustrative example may seem simplistic since the data is generated from a quadratic equation and involves only a single attribute, making visualization straightforward. However, it serves to highlight a key point relevant to more complex models, such as deep neural networks. As the number of parameters increases, the model’s capacity to fit the training data also increases, which can lead to overfitting if not properly managed.\n\n\nAttribution: 04_training_linear_models.ipynb"
  },
  {
    "objectID": "lectures/06/slides.html#under--and-over--fitting",
    "href": "lectures/06/slides.html#under--and-over--fitting",
    "title": "Model evaluation",
    "section": "Under- and over- fitting",
    "text": "Under- and over- fitting\n\nUnderfitting:\n\nYour model is too simple (here, linear).\nUninformative features.\nPoor performance on both training and test data.\n\nOverfitting:\n\nYour model is too complex (tall decision tree, deep and wide neural networks, etc.).\nToo many features given the number of examples available.\nExcellent performance on the training set, but poor performance on the test set.\n\n\n\nIn the case of underfitting, adding more data to the training set will not help.\nIn the case of overfitting, adding more data would bring the train and test set learning curves closer."
  },
  {
    "objectID": "lectures/06/slides.html#learning-curves",
    "href": "lectures/06/slides.html#learning-curves",
    "title": "Model evaluation",
    "section": "Learning curves",
    "text": "Learning curves\n\nOne way to assess our models is to visualize the learning curves:\n\nA learning curve shows the performance of our model, here using RMSE, on both the training set and the test set.\nMultiple measurements are obtained by repeatedly training the model on larger and larger subsets of the data.\n\n\n\n\nSee: sklearn.model_selection.learning_curve."
  },
  {
    "objectID": "lectures/06/slides.html#learning-curve-underfitting",
    "href": "lectures/06/slides.html#learning-curve-underfitting",
    "title": "Model evaluation",
    "section": "Learning curve – underfitting",
    "text": "Learning curve – underfitting\n\n\n\n\n\n\n\n\n\nPoor performance on both training and test data.\n\n\nThis graph illustrates the learning curve for a linear regression model applied to data generated from a quadratic equation, which serves as our ongoing example.\nThe horizontal axis represents the size of the training set. Initially, the linear regression model is trained on a very small dataset, consisting of just one or a few examples, and the Root Mean Square Error (RMSE) is plotted for both the training and test sets. The size of the training set is then incrementally increased, a new model is trained, and the performance is recorded. This procedure continues until the entire dataset is utilized.\nKey observations from the graph include:\n\nWith only one or two examples, the model perfectly fits the training set, resulting in low RMSE for the training data.\nAs the size of the training set increases, the model struggles to fit the training data due to the quadratic nature of the data generation process. Consequently, the RMSE for the training set rises and stabilizes at a higher level.\nFor small training sets, the model performs poorly on the test set due to inadequate generalization, resulting in high RMSE.\nAs the training set size grows, the test set performance improves, indicated by decreasing RMSE, until it reaches a point where further increases in training set size do not yield significant improvements.\n\nThese learning curves are indicative of a model that is underfitting. Both the training and test set RMSE curves plateau at relatively high values and remain close to each other, as noted by Géron (2022).\n\n\nSource code: 04_training_linear_models.ipynb."
  },
  {
    "objectID": "lectures/06/slides.html#learning-curve-overfitting",
    "href": "lectures/06/slides.html#learning-curve-overfitting",
    "title": "Model evaluation",
    "section": "Learning curve – overfitting",
    "text": "Learning curve – overfitting\n\n\n\n\n\n\n\n\n\nExcellent performance on the training set, but poor performance on the test set.\n\n\n\nFor a training set of up to 14 data points, the polynomial fits the training data perfectly, resulting in an RMSE of zero.\nThe error on the training data in this instance is significantly lower.\nA notable gap between the two curves indicates that the model performs substantially better on the training data compared to the test data.\n\n\n\nPolynomial with degree=14."
  },
  {
    "objectID": "lectures/06/slides.html#overfitting---deep-nets---loss",
    "href": "lectures/06/slides.html#overfitting---deep-nets---loss",
    "title": "Model evaluation",
    "section": "Overfitting - deep nets - loss",
    "text": "Overfitting - deep nets - loss\n\n\n\n\n\n\n\n\n\n\n\nNeural networks will be covered in detail later in our course. The graph presented here illustrates the variation in the loss function as a deep learning model undergoes training.\nThis example utilizes the IMDB movie review sentiment classification dataset available in Keras. The dataset comprises 25,000 movie reviews from IMDB, each labeled with a sentiment (positive or negative).\nThe model consists of three dense layers with sizes 16, 16, and 1, respectively. It includes a total of 160,305 trainable parameters.\nThe network is trained using mini-batch stochastic gradient descent with a batch size of 512. The horizontal axis represents the number of epochs, where each epoch indicates that the model has seen the entire training set once. During each epoch, the stochastic gradient descent algorithm updates the model parameters iteratively using mini-batches of 512 examples.\nI selected this example to illustrate that a neural network with with sufficient capacity (number of parameters) can minimize training errors almost to zero, as reducing training error is the primary objective of optimization. However, the graph clearly demonstrates that beyond a certain point, the learned patterns become specific to the training set rather than general principles. Generalization, rather than mere memorization, is the ultimate goal of machine learning.\nOverfitting occurs when a model learns the details and noise in the training data to an extent that it negatively impacts the model’s performance on new data. This can result in a decision boundary that fits the training data too tightly, capturing noise and irrelevant details rather than general patterns.\n\n\nExample from Chollet (2017) Chapter 3 (chapter04_getting-started-with-neural-networks.ipynb, ipynb from 2021 edition)."
  },
  {
    "objectID": "lectures/06/slides.html#overfitting---deep-nets---accuracy",
    "href": "lectures/06/slides.html#overfitting---deep-nets---accuracy",
    "title": "Model evaluation",
    "section": "Overfitting - deep nets - accuracy",
    "text": "Overfitting - deep nets - accuracy\n\n\n\n\n\n\n\n\n\n\nThis graph similarly illustrates the variation in accuracy for both the training and test sets as the model undergoes training."
  },
  {
    "objectID": "lectures/06/slides.html#biasvariance-tradeoff",
    "href": "lectures/06/slides.html#biasvariance-tradeoff",
    "title": "Model evaluation",
    "section": "Bias/Variance Tradeoff",
    "text": "Bias/Variance Tradeoff\n\nBias:\n\nError from overly simplistic models\nHigh bias can lead to underfitting\n\nVariance:\n\nError from overly complex models\nSensitivity to fluctuations in the training data\nHigh variance can lead to overfitting\n\nTradeoff:\n\nAim for a model that generalizes well to new data\nMethods: cross-validation, regularization, ensemble learning\n\n\n\n\nHastie, Tibshirani, and Friedman (2009)"
  },
  {
    "objectID": "lectures/06/slides.html#related-videos",
    "href": "lectures/06/slides.html#related-videos",
    "title": "Model evaluation",
    "section": "Related videos",
    "text": "Related videos\n\nOther videos include:\n\nBias and Variance, StatQuest (great visual summary)\nBias/Variance (C2W1L02), Stanford, Andrew Ng\nIntuition behind bias and variance, Sebastian Raschka"
  },
  {
    "objectID": "lectures/06/slides.html#confusion-matrix",
    "href": "lectures/06/slides.html#confusion-matrix",
    "title": "Model evaluation",
    "section": "Confusion matrix",
    "text": "Confusion matrix\n\n\n\n\n\n\n\n\n\nPositive (Predicted)\nNegative (Predicted)\n\n\n\n\nPositive (Actual)\nTrue positive (TP)\nFalse negative (FN)\n\n\nNegative (Actual)\nFalse positive (FP)\nTrue negative (TN)\n\n\n\n\n\n\nIn statistical analysis, False Positives (FP) are commonly referred to as Type I errors, and False Negatives (FN) are known as Type II errors.\nThe confusion matrix encapsulates all essential information required to assess the performance of a classification model.\nWhile the confusion matrix provides a comprehensive view, more concise metrics such as accuracy, precision, recall, and the F\\(_1\\) score are often more intuitive and practical for summarizing model performance.\n\n\n\nA confusion matrix is a table summarizing the performance of a classification algorithm (here for a binary classification task)."
  },
  {
    "objectID": "lectures/06/slides.html#sklearn.metrics.confusion_matrix",
    "href": "lectures/06/slides.html#sklearn.metrics.confusion_matrix",
    "title": "Model evaluation",
    "section": "sklearn.metrics.confusion_matrix",
    "text": "sklearn.metrics.confusion_matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nconfusion_matrix(y_actual,y_pred)\n\narray([[1, 2],\n       [3, 4]])\n\n\n\n\ntn, fp, fn, tp = confusion_matrix(y_actual, y_pred).ravel()\n(tn, fp, fn, tp)\n\n(np.int64(1), np.int64(2), np.int64(3), np.int64(4))"
  },
  {
    "objectID": "lectures/06/slides.html#perfect-prediction",
    "href": "lectures/06/slides.html#perfect-prediction",
    "title": "Model evaluation",
    "section": "Perfect prediction",
    "text": "Perfect prediction\n\ny_actual = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\ny_pred   = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n\nconfusion_matrix(y_actual,y_pred)\n\narray([[4, 0],\n       [0, 6]])\n\n\n\n\ntn, fp, fn, tp = confusion_matrix(y_actual, y_pred).ravel()    \n(tn, fp, fn, tp)\n\n(np.int64(4), np.int64(0), np.int64(0), np.int64(6))"
  },
  {
    "objectID": "lectures/06/slides.html#confusion-matrix---multiple-classes",
    "href": "lectures/06/slides.html#confusion-matrix---multiple-classes",
    "title": "Model evaluation",
    "section": "Confusion matrix - multiple classes",
    "text": "Confusion matrix - multiple classes\n\n\n\n\n\n\n\n\n\n\n\nThe image displays a heatmap of the confusion matrix for the digit classification task. This task, a multiclass classification problem, was addressed using OneVsRestClassifier and LogisticRegression.\nThe confusion matrix summarizes the predictions made on the test set, which is a subset of the data that was neither used for training nor for preprocessing with StandardScaler.\nThe confusion matrix encapsulates all the results from applying the classifier to the test set. However, to summarize this information more succinctly, we often refer to performance metrics.\n\n\nConfusion matrix for the digits example presented in the previous lecture."
  },
  {
    "objectID": "lectures/06/slides.html#source-code",
    "href": "lectures/06/slides.html#source-code",
    "title": "Model evaluation",
    "section": "Source code",
    "text": "Source code\n\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\n\nX = digits.data\ny = digits.target\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\nclf = OneVsRestClassifier(LogisticRegression())\n\nclf = clf.fit(X_train, y_train)\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nX_test = scaler.transform(X_test)\ny_pred = clf.predict(X_test)\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#visualizing-errors",
    "href": "lectures/06/slides.html#visualizing-errors",
    "title": "Model evaluation",
    "section": "Visualizing errors",
    "text": "Visualizing errors\n\nmask = (y_test == 9) & (y_pred == 8)\n\nX_9_as_8 = X_test[mask]\n\ny_9_as_8 = y_test[mask]\n\n\n\n\n\n\n\n\n\n\n\n\nIn the confusion matrix on the previous screen, we had seen that there were examples for which the true label was 9, but the prediction was was 8. We can visualize the examples to see if we understand the nature of those errors."
  },
  {
    "objectID": "lectures/06/slides.html#confusion-matrix---multiple-classes-1",
    "href": "lectures/06/slides.html#confusion-matrix---multiple-classes-1",
    "title": "Model evaluation",
    "section": "Confusion matrix - multiple classes",
    "text": "Confusion matrix - multiple classes\n\n\n\n\n\n\n\n\n\n\n\nIt is often preferable to summarize the classifier’s performance with a single metric."
  },
  {
    "objectID": "lectures/06/slides.html#accuracy",
    "href": "lectures/06/slides.html#accuracy",
    "title": "Model evaluation",
    "section": "Accuracy",
    "text": "Accuracy\nHow accurate is this result?\n\\[\n  \\mathrm{accuracy} = \\frac{\\mathrm{TP}+\\mathrm{TN}}{\\mathrm{TP}+\\mathrm{TN}+\\mathrm{FP}+\\mathrm{FN}} = \\frac{\\mathrm{TP}+\\mathrm{TN}}{\\mathrm{N}}\n\\]\n\nfrom sklearn.metrics import accuracy_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\naccuracy_score(y_actual,y_pred)\n\n0.5\n\n\n\n\nAccuracy is the ratio of correctly predicted instances to the total number of predictions."
  },
  {
    "objectID": "lectures/06/slides.html#accuracy-1",
    "href": "lectures/06/slides.html#accuracy-1",
    "title": "Model evaluation",
    "section": "Accuracy",
    "text": "Accuracy\n\ny_actual = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\ny_pred   = [1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n\naccuracy_score(y_actual,y_pred)\n\n0.0\n\n\n\ny_actual = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\ny_pred   = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n\naccuracy_score(y_actual,y_pred)\n\n1.0\n\n\n\n\nAccuracy is a number between 0 (all wrong) and 1 (perfect)."
  },
  {
    "objectID": "lectures/06/slides.html#accuracy-can-be-misleading",
    "href": "lectures/06/slides.html#accuracy-can-be-misleading",
    "title": "Model evaluation",
    "section": "Accuracy can be misleading",
    "text": "Accuracy can be misleading\n\ny_actual = [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\ny_pred   = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\naccuracy_score(y_actual,y_pred)\n\n0.8\n\n\n\n\nAccuracy can be misleading in the context of class imbalance, as it disproportionately reflects the performance on the majority class, thereby masking poor performance on the minority class.\nAs class imbalance increases, the accuracy metric becomes increasingly misleading.\n\n\nWhy is it problematic?"
  },
  {
    "objectID": "lectures/06/slides.html#precision",
    "href": "lectures/06/slides.html#precision",
    "title": "Model evaluation",
    "section": "Precision",
    "text": "Precision\nAKA, positive predictive value (PPV).\n\\[\n  \\mathrm{precision} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}\n\\]\n\nfrom sklearn.metrics import precision_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nprecision_score(y_actual, y_pred)\n\n0.6666666666666666\n\n\n\n\nPrecision is the proportion of true positive predictions among all positive predictions."
  },
  {
    "objectID": "lectures/06/slides.html#precision-alone-is-not-enough",
    "href": "lectures/06/slides.html#precision-alone-is-not-enough",
    "title": "Model evaluation",
    "section": "Precision alone is not enough",
    "text": "Precision alone is not enough\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n\nprecision_score(y_actual,y_pred)\n\n1.0\n\n\n\n\nAn algorithm that makes a small number of high-confidence predictions might achieve a high precision score, but this may not necessarily be useful."
  },
  {
    "objectID": "lectures/06/slides.html#recall",
    "href": "lectures/06/slides.html#recall",
    "title": "Model evaluation",
    "section": "Recall",
    "text": "Recall\nAKA sensitivity or true positive rate (TPR) \\[\n  \\mathrm{recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\n\\]\n\nfrom sklearn.metrics import recall_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nrecall_score(y_actual,y_pred)\n\n0.5714285714285714\n\n\n\n\nRecall is the proportion of true positive instances correctly identified among all actual positive instances."
  },
  {
    "objectID": "lectures/06/slides.html#f_1-score",
    "href": "lectures/06/slides.html#f_1-score",
    "title": "Model evaluation",
    "section": "F\\(_1\\) score",
    "text": "F\\(_1\\) score\n\\[\n\\begin{align*}\n  F_1~\\mathrm{score} &= \\frac{2}{\\frac{1}{\\mathrm{precision}}+\\frac{1}{\\mathrm{recall}}} = 2 \\times \\frac{\\mathrm{precision}\\times\\mathrm{recall}}{\\mathrm{precision}+\\mathrm{recall}} \\\\\n                     &= \\frac{\\mathrm{TP}}{\\mathrm{FP}+\\frac{\\mathrm{FN}+\\mathrm{FP}}{2}}\n\\end{align*}\n\\]\n\nfrom sklearn.metrics import f1_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nf1_score(y_actual,y_pred)\n\n0.6153846153846154\n\n\n\n\n\nThe harmonic mean places greater emphasis on lower values, while the arithmetic mean treats all values equally.\nUsing the harmonic mean ensures that a high score is only achieved when both precision and recall are high, thus providing a more holistic measure of a classifier’s performance in scenarios with imbalanced datasets.\nThe F\\(_1\\) score favors classifiers that achieve a balance between precision and recall.\nIncreasing recall often results in a decrease in precision, and vice versa. This phenomenon is known as the precision/recall trade-off.\n\n\n\nF\\(_1\\) is the harmonic mean of precision and recall."
  },
  {
    "objectID": "lectures/06/slides.html#micro-performance-metrics",
    "href": "lectures/06/slides.html#micro-performance-metrics",
    "title": "Model evaluation",
    "section": "Micro Performance Metrics",
    "text": "Micro Performance Metrics\nMicro performance metrics aggregate the contributions of all classes to compute the average performance metric, such as precision, recall, or F1 score. This approach treats each individual prediction equally, providing a balanced evaluation by emphasizing the performance on frequent classes."
  },
  {
    "objectID": "lectures/06/slides.html#macro-performance-metrics",
    "href": "lectures/06/slides.html#macro-performance-metrics",
    "title": "Model evaluation",
    "section": "Macro Performance Metrics",
    "text": "Macro Performance Metrics\nMacro performance metrics compute the performance metric independently for each class and then average these metrics. This approach treats each class equally, regardless of its frequency, providing an evaluation that equally considers performance across both frequent and infrequent classes."
  },
  {
    "objectID": "lectures/06/slides.html#micromacro-metrics",
    "href": "lectures/06/slides.html#micromacro-metrics",
    "title": "Model evaluation",
    "section": "Micro/macro metrics",
    "text": "Micro/macro metrics\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\n# Sample data\ny_true = ['Cat'] * 42 + ['Dog'] *  7 + ['Fox'] * 11\ny_pred = ['Cat'] * 39 + ['Dog'] *  1 + ['Fox'] *  2 + \\\n         ['Cat'] *  4 + ['Dog'] *  3 + ['Fox'] *  0 + \\\n         ['Cat'] *  5 + ['Dog'] *  1 + ['Fox'] *  5\n\nConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n\n\n\n\n\n\n\n\n\nThe dataset can be conceptualized as resulting from an image classification task, involving images of cats, dogs, and foxes. Reflecting common trends observed on the internet, images of cats are disproportionately represented, leading to a class imbalance issue."
  },
  {
    "objectID": "lectures/06/slides.html#micromacro-precision",
    "href": "lectures/06/slides.html#micromacro-precision",
    "title": "Model evaluation",
    "section": "Micro/macro precision",
    "text": "Micro/macro precision\n\nfrom sklearn.metrics import classification_report, precision_score\n\nprint(classification_report(y_true, y_pred), \"\\n\")\n\nprint(\"Micro precision: {:.2f}\".format(precision_score(y_true, y_pred, average='micro')))\nprint(\"Macro precision: {:.2f}\".format(precision_score(y_true, y_pred, average='macro')))\n\n              precision    recall  f1-score   support\n\n         Cat       0.81      0.93      0.87        42\n         Dog       0.60      0.43      0.50         7\n         Fox       0.71      0.45      0.56        11\n\n    accuracy                           0.78        60\n   macro avg       0.71      0.60      0.64        60\nweighted avg       0.77      0.78      0.77        60\n \n\nMicro precision: 0.78\nMacro precision: 0.71\n\n\nMacro-average precision is calculated as the mean of the precision scores for each class: \\(\\frac{0.81 + 0.60 + 0.71}{3} = 0.71\\).\nWhereas, the micro-average precision is calculated using the formala, \\(\\frac{TP}{TP+FP}\\) and the data from the entire confusion matrix \\(\\frac{39+3+5}{39+3+5+9+2+2} = \\frac{47}{60} = 0.78\\)\n\nThe high micro-average precision observed here is primarily due to the high precision and large number of examples in the majority class, Cat. This masks the classifier’s relatively poor performance on the minority classes, Dog and Fox.\nIn a balanced dataset, both micro-average and macro-average metrics yield similar scores.\nHowever, in an imbalanced dataset, significant disparities in classifier performance between the majority and minority classes will result in divergent micro-average and macro-average scores. Specifically, the classifier tends to underperform on the minority class(es), leading to these discrepancies.\nIn macro-average metrics, each class contributes equally to the final metric calculation, irrespective of the number of examples it contains. This means that the performance metric for each class are computed independently and then averaged, without considering the proportion of instances that each class represents in the dataset. Consequently, macro-averaging ensures that each class has an equal impact on the overall metric, which can be particularly useful in cases where the class distribution is imbalanced."
  },
  {
    "objectID": "lectures/06/slides.html#micromacro-recall",
    "href": "lectures/06/slides.html#micromacro-recall",
    "title": "Model evaluation",
    "section": "Micro/macro recall",
    "text": "Micro/macro recall\n\n\n\n\n\n\n\n\n\n\n\n              precision    recall  f1-score   support\n\n         Cat       0.81      0.93      0.87        42\n         Dog       0.60      0.43      0.50         7\n         Fox       0.71      0.45      0.56        11\n\n    accuracy                           0.78        60\n   macro avg       0.71      0.60      0.64        60\nweighted avg       0.77      0.78      0.77        60\n \n\nMicro recall: 0.78\nMacro recall: 0.60\n\n\nMacro-average recall is calculated as the mean of the recall scores for each class: \\(\\frac{0.93 + 0.43 + 0.45}{3} = 0.60\\).\nWhereas, the micro-average recall is calculated using the formala, \\(\\frac{TP}{TP+FN}\\) and the data from the entire confusion matrix \\(\\frac{39+3+5}{39+3+5+3+4+6} = \\frac{39}{60} = 0.78\\)"
  },
  {
    "objectID": "lectures/06/slides.html#micromacro-metrics-medical-data",
    "href": "lectures/06/slides.html#micromacro-metrics-medical-data",
    "title": "Model evaluation",
    "section": "Micro/macro metrics (medical data)",
    "text": "Micro/macro metrics (medical data)\n\n\n\n\n\n\n\n\n\n\nConsider a medical dataset, such as those involving diagnostic tests or imaging, comprising 990 normal samples and 10 abnormal (tumor) samples. This represents the ground truth."
  },
  {
    "objectID": "lectures/06/slides.html#micromacro-metrics-medical-data-1",
    "href": "lectures/06/slides.html#micromacro-metrics-medical-data-1",
    "title": "Model evaluation",
    "section": "Micro/macro metrics (medical data)",
    "text": "Micro/macro metrics (medical data)\n\n\n              precision    recall  f1-score   support\n\n      Normal       1.00      0.99      1.00       990\n      Tumour       0.55      0.60      0.57        10\n\n    accuracy                           0.99      1000\n   macro avg       0.77      0.80      0.78      1000\nweighted avg       0.99      0.99      0.99      1000\n \n\nMicro precision: 0.99\nMacro precision: 0.77\n\n\nMicro recall: 0.99\nMacro recall: 0.80"
  },
  {
    "objectID": "lectures/06/slides.html#hand-written-digits-revisited",
    "href": "lectures/06/slides.html#hand-written-digits-revisited",
    "title": "Model evaluation",
    "section": "Hand-written digits (revisited)",
    "text": "Hand-written digits (revisited)\nLoading the dataset\n\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import fetch_openml\n\ndigits = fetch_openml('mnist_784', as_frame=False)\nX, y = digits.data, digits.target\n\nPlotting the first five examples\n\n\n\n\n\n\n\n\n\nThese images have dimensions of ( 28 ) pixels."
  },
  {
    "objectID": "lectures/06/slides.html#creating-a-binary-classification-task",
    "href": "lectures/06/slides.html#creating-a-binary-classification-task",
    "title": "Model evaluation",
    "section": "Creating a binary classification task",
    "text": "Creating a binary classification task\n\n# Creating a binary classification task (one vs the rest)\n\nsome_digit = X[0]\nsome_digit_y = y[0]\n\ny = (y == some_digit_y)\ny\n\narray([ True, False, False, ..., False,  True, False], shape=(70000,))\n\n\n\n\n# Creating the training and test sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
  },
  {
    "objectID": "lectures/06/slides.html#sgdclassifier",
    "href": "lectures/06/slides.html#sgdclassifier",
    "title": "Model evaluation",
    "section": "SGDClassifier",
    "text": "SGDClassifier\n\nfrom sklearn.linear_model import SGDClassifier\n\nclf = SGDClassifier()\nclf.fit(X_train, y_train)\n\nclf.predict(X[0:5]) # small sanity check\n\narray([ True, False, False, False, False])\n\n\n\n\nThe SGDClassifier is a linear classifier that utilizes stochastic gradient descent (SGD) for training. Compared to LogisticRegression, it can offer faster training times, particularly for large datasets. Additionally, SGDClassifier allows for the adjustment of the decision threshold in subsequent examples."
  },
  {
    "objectID": "lectures/06/slides.html#performance",
    "href": "lectures/06/slides.html#performance",
    "title": "Model evaluation",
    "section": "Performance",
    "text": "Performance\n\nfrom sklearn.metrics import accuracy_score\n\ny_pred = clf.predict(X_test)\n\naccuracy_score(y_test, y_pred)\n\n0.9572857142857143\n\n\nWow!"
  },
  {
    "objectID": "lectures/06/slides.html#not-so-fast",
    "href": "lectures/06/slides.html#not-so-fast",
    "title": "Model evaluation",
    "section": "Not so fast",
    "text": "Not so fast\n\n\ny_pred = dummy_clf.predict(X_test)\n\naccuracy_score(y_test, y_pred)\n\n0.906\n\n\n\n\nWhy is the accuracy so high despite this classifier ignoring the input data?\nThe high accuracy is attributed to the class distribution within the dataset. Approximately 10% of the samples correspond to the digit ‘5’, which is the positive class in our binary classification task. Consequently, about 90% of the samples are ‘not 5’ and belong to the negative class. Since the DummyClassifier always predicts the majority class, its accuracy is expected to be around 90%.\nThis underscores the point that accuracy is often not the best metric, particularly when dealing with imbalanced datasets.\n\n\n\nThe DummyClassifier in scikit-learn generates predictions without considering the input features. By default, it consistently predicts the most frequent class label in the training data. It is a simple baseline classifier."
  },
  {
    "objectID": "lectures/06/slides.html#precision-recall-trade-off",
    "href": "lectures/06/slides.html#precision-recall-trade-off",
    "title": "Model evaluation",
    "section": "Precision-recall trade-off",
    "text": "Precision-recall trade-off\n\n\n\nAttribution: Géron (2022) Figure 3.4"
  },
  {
    "objectID": "lectures/06/slides.html#precision-recall-trade-off-1",
    "href": "lectures/06/slides.html#precision-recall-trade-off-1",
    "title": "Model evaluation",
    "section": "Precision-recall trade-off",
    "text": "Precision-recall trade-off\n\n\n\n\n\n\n\n\n\n\n\nAs the decision threshold decreases, a higher number of examples are predicted as positive, potentially leading the classifier to eventually label all instances as positive.\nConversely, as the decision threshold increases, fewer examples are classified as positive, which may result in the classifier predicting no positive instances at all.\nFor certain applications, a classifier with high precision is essential. For example, consider a scenario where each prediction necessitates a costly laboratory experiment to verify its accuracy, such as in a pharmaceutical company aiming to discover new drugs. Here, the classifier predicts whether a compound is active. Given the high cost of experiments to validate candidates, the company would prioritize focusing on the most promising compounds first.\nIn contrast, consider a scenario involving cancer screening, such as using mammograms to detect breast cancer. In this case, it may be preferable to lower the decision threshold, thereby increasing the number of false-positive predictions. Although this approach results in more patients undergoing additional tests, such as biopsies, it can potentially save more lives by ensuring that fewer cases of cancer go undetected.\n\n\nI have used SGDClassifier because it allows to vary the decision treshold (boundary) to produce a plot illustrating the precision-recall tradeoff."
  },
  {
    "objectID": "lectures/06/slides.html#precisionrecall-curve",
    "href": "lectures/06/slides.html#precisionrecall-curve",
    "title": "Model evaluation",
    "section": "Precision/Recall curve",
    "text": "Precision/Recall curve"
  },
  {
    "objectID": "lectures/06/slides.html#roc-curve",
    "href": "lectures/06/slides.html#roc-curve",
    "title": "Model evaluation",
    "section": "ROC curve",
    "text": "ROC curve\nReceiver Operating Characteristics (ROC) curve\n\nTrue positive rate (TPR) against false positive rate (FPR)\nAn ideal classifier has TPR close to 1.0 and FPR close to 0.0\n\\(\\mathrm{TPR} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\\) (recall, sensitivity)\nTPR approaches one when the number of false negative predictions is low\n\\(\\mathrm{FPR} = \\frac{\\mathrm{FP}}{\\mathrm{FP}+\\mathrm{TN}}\\) (aka~[1-specificity])\nFPR approaches zero when the number of false positive is low\n\n\nROC (Receiver Operating Characteristic) curves are popular in machine learning and statistics for several reasons:\n\nComprehensive Performance Evaluation: ROC curves provide a visual representation of a classifier’s performance across all possible thresholds. By plotting the True Positive Rate (TPR) against the False Positive Rate (FPR), it allows practitioners to evaluate the trade-off between sensitivity (recall) and specificity.\nThreshold Independence: Unlike metrics like accuracy, ROC curves evaluate classifier performance without relying on a specific decision threshold. This makes them particularly useful in comparing models across varying thresholds.\nHandling Imbalanced Datasets: For datasets with class imbalances (where one class is much more frequent than the other), ROC curves are more informative than accuracy, which can be misleading. The curve captures the model’s ability to distinguish between classes irrespective of their distribution.\nArea Under the Curve (AUC): The Area Under the ROC Curve (AUC) provides a single value summary of the model’s performance. AUC-ROC is often used as a benchmark metric to compare different models, with values ranging from 0.5 (random guessing) to 1.0 (perfect classification).\nBroad Applicability: ROC curves can be used for any binary classification task and are easily extended to multiclass problems using techniques like one-vs-rest classification, making them versatile in evaluating classifiers.\n\nOverall, their ability to offer a broad, threshold-independent view of model performance, especially in imbalanced scenarios, makes ROC curves a popular choice for evaluating classifiers."
  },
  {
    "objectID": "lectures/06/slides.html#roc-curve-1",
    "href": "lectures/06/slides.html#roc-curve-1",
    "title": "Model evaluation",
    "section": "ROC curve",
    "text": "ROC curve\n\n\n\n\n\n\n\n\n\n\n\nIt is common to measure the area under the curve, represented as AUC. Specifically, the area under the ROC curve. This allows to compare\n\n\nAttribution: 03_classification.ipynb"
  },
  {
    "objectID": "lectures/06/slides.html#aucroc",
    "href": "lectures/06/slides.html#aucroc",
    "title": "Model evaluation",
    "section": "AUC/ROC",
    "text": "AUC/ROC\n\n\n\n\n\n\n\n\n\n\n\nROC curves provide a visual representation of a classifier’s performance across all possible thresholds. By plotting the True Positive Rate (TPR) against the False Positive Rate (FPR), it allows practitioners to evaluate the trade-off between sensitivity (recall) and specificity.\nUnlike metrics like accuracy, ROC curves evaluate classifier performance without relying on a specific decision threshold. This makes them particularly useful in comparing models across varying thresholds.\n\n\nThe model was trained using the Pima Indians Diabetes dataset as described in Knowler et al. (1981) [PubMed]. Further details about the dataset will be discussed in the next lecture."
  },
  {
    "objectID": "lectures/06/slides.html#the-7-steps-of-machine-learning",
    "href": "lectures/06/slides.html#the-7-steps-of-machine-learning",
    "title": "Model evaluation",
    "section": "The 7 steps of machine learning",
    "text": "The 7 steps of machine learning"
  },
  {
    "objectID": "lectures/06/slides.html#prologue",
    "href": "lectures/06/slides.html#prologue",
    "title": "Geometric interpretation and cross-entry",
    "section": "Prologue",
    "text": "Prologue\n\n\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/06/slides.html#further-reading",
    "href": "lectures/06/slides.html#further-reading",
    "title": "Model evaluation",
    "section": "Further reading",
    "text": "Further reading\n\n\n\n\n\n\n\nThis book, which examines various aspects of the evaluation process with an emphasis on classification algorithms, has excellent ratings on Amazon!\nNathalie Japkowicz was formely a professor that the University of Ottawa. She now works at the American University in Washington.\nMohak Shah completed his PhD at the University of Ottawa. He has held several positions in the industry, including AI and Machine Learning Vice President for LG Electronics.\n\n\nJapkowicz and Shah (2011)"
  },
  {
    "objectID": "lectures/06/slides.html#next-lecture",
    "href": "lectures/06/slides.html#next-lecture",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Next lecture",
    "text": "Next lecture\n\nPerformance measures and cross-evaluation"
  },
  {
    "objectID": "lectures/06/slides.html#references",
    "href": "lectures/06/slides.html#references",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "References",
    "text": "References\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/06/index.html",
    "href": "lectures/06/index.html",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 1 must be submitted no later than September 29, 2025, at 11 PM. Please refer to the assignment description available on Brightspace."
  },
  {
    "objectID": "lectures/06/index.html#prepare",
    "href": "lectures/06/index.html#prepare",
    "title": "Lecture 06",
    "section": "Prepare",
    "text": "Prepare\n\nLones, M. A. (2024). Avoiding common machine learning pitfalls. Patterns, 101046. doi.org/10.1016/j.patter.2024.101046 (also available on arXiv)\nThe 7 steps of machine learning by Google Cloud Tech on YouTube, 2017-08-31"
  },
  {
    "objectID": "lectures/06/index.html#participate",
    "href": "lectures/06/index.html#participate",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Participate",
    "text": "Participate\n\nslides (PDF) as Jupyter Notebook"
  },
  {
    "objectID": "lectures/06/index.html#practice",
    "href": "lectures/06/index.html#practice",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Practice",
    "text": "Practice\n\nLogisticRegression - Here is an implementation of logistic regression, complemented by discussions on Receiver Operating Characteristic (ROC) curves and the Area Under the Curve (AUC). It also includes illustrative examples to demonstrate these concepts."
  },
  {
    "objectID": "lectures/07/slides.html#quote-of-the-day",
    "href": "lectures/07/slides.html#quote-of-the-day",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n\n\n\n\n\nSuper Intelligence from The Future with Hannah Fry aired September 12th, 2024."
  },
  {
    "objectID": "lectures/07/slides.html#learning-objectives",
    "href": "lectures/07/slides.html#learning-objectives",
    "title": "Model evaluation",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nClarify the concepts of underfitting and overfitting in machine learning.\nDescribe the primary metrics used to evaluate model performance.\nContrast micro- and macro-averaged performance metrics."
  },
  {
    "objectID": "lectures/07/slides.html#dataset---openml",
    "href": "lectures/07/slides.html#dataset---openml",
    "title": "Performance Evaluation",
    "section": "Dataset - openml",
    "text": "Dataset - openml\n\n\n\n www.openml.org\n\n\nOpenML is an open platform for sharing datasets, algorithms, and experiments - to learn how to learn better, together.\n\n\n\n\n\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import fetch_openml\n\ndiabetes = fetch_openml(name='diabetes', version=1)\nprint(diabetes.DESCR)\n\n\n\nToday’s dataset is the PIMA dataset, which contains 768 instances and 8 numerical attributes. The numerical nature of these attributes facilitates our analysis. Additionally, since the data originates from a published paper, it likely reflects careful data collection, potentially leading to robust results, as the authors would have needed high-quality data to support their publication."
  },
  {
    "objectID": "lectures/07/slides.html#dataset---openml-output",
    "href": "lectures/07/slides.html#dataset---openml-output",
    "title": "Performance Evaluation",
    "section": "Dataset - openml",
    "text": "Dataset - openml\nAuthor: Vincent Sigillito\nSource: Obtained from UCI\nPlease cite: UCI citation policy\n\nTitle: Pima Indians Diabetes Database\nSources:\n\nOriginal owners: National Institute of Diabetes and Digestive and Kidney Diseases\nDonor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu) Research Center, RMI Group Leader Applied Physics Laboratory The Johns Hopkins University Johns Hopkins Road Laurel, MD 20707 (301) 953-6231\nDate received: 9 May 1990\n\nPast Usage:\n\nSmith,J.W., Everhart,J.E., Dickson,W.C., Knowler,W.C., & Johannes,R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In {it Proceedings of the Symposium on Computer Applications and Medical Care} (pp. 261–265). IEEE Computer Society Press.\nThe diagnostic, binary-valued variable investigated is whether the patient shows signs of diabetes according to World Health Organization criteria (i.e., if the 2 hour post-load plasma glucose was at least 200 mg/dl at any survey examination or if found during routine medical care). The population lives near Phoenix, Arizona, USA.\nResults: Their ADAP algorithm makes a real-valued prediction between 0 and 1. This was transformed into a binary decision using a cutoff of 0.448. Using 576 training instances, the sensitivity and specificity of their algorithm was 76% on the remaining 192 instances.\n\nRelevant Information: Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage. ADAP is an adaptive learning routine that generates and executes digital analogs of perceptron-like devices. It is a unique algorithm; see the paper for details.\nNumber of Instances: 768\nNumber of Attributes: 8 plus class\nFor Each Attribute: (all numeric-valued)\n\nNumber of times pregnant\nPlasma glucose concentration a 2 hours in an oral glucose tolerance test\nDiastolic blood pressure (mm Hg)\nTriceps skin fold thickness (mm)\n2-Hour serum insulin (mu U/ml)\nBody mass index (weight in kg/(height in m)^2)\nDiabetes pedigree function\nAge (years)\nClass variable (0 or 1)\n\nMissing Attribute Values: None\nClass Distribution: (class value 1 is interpreted as “tested positive for diabetes”)\nClass Value Number of instances 0 500 1 268\nBrief statistical analysis:\nAttribute number: Mean: Standard Deviation:\n\n                3.8     3.4\n              120.9    32.0\n               69.1    19.4\n               20.5    16.0\n               79.8   115.2\n               32.0     7.9\n                0.5     0.3\n               33.2    11.8\n\n\nRelabeled values in attribute ‘class’ From: 0 To: tested_negative\nFrom: 1 To: tested_positive\nDownloaded from openml.org."
  },
  {
    "objectID": "lectures/07/slides.html#dataset---return_x_y",
    "href": "lectures/07/slides.html#dataset---return_x_y",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Dataset - return_X_y",
    "text": "Dataset - return_X_y\nfetch_openml returns a Bunch, a DataFrame, or X and y\n\nfrom sklearn.datasets import fetch_openml\n\nX, y = fetch_openml(name='diabetes', version=1, return_X_y=True)\n\n\nMild imbalance (ratio less than 3 or 4)\n\nprint(y.value_counts())\n\nclass\ntested_negative    500\ntested_positive    268\nName: count, dtype: int64\n\n\n\n\nConverting the target labels to 0 and 1\n\ny = y.map({'tested_negative': 0, 'tested_positive': 1})"
  },
  {
    "objectID": "lectures/07/slides.html#training-and-test-set",
    "href": "lectures/07/slides.html#training-and-test-set",
    "title": "Performance Evaluation",
    "section": "Training and test set",
    "text": "Training and test set\nSometimes called holdout method.\n\nGuideline: Typically, allocate 80% of your dataset for training and reserve the remaining 20% for testing.\nTraining Set: This subset of data is utilized to train your model.\nTest Set: This is an independent subset used exclusively at the final stage to assess the model’s performance.\n\n\nCommon Training and Testing Ratios\n\n80:20 Split:\n\nTraining Set: 80% of the data\nTesting Set: 20% of the data\nThis is a widely used default split that provides a balance between having enough data to train the model and enough data to evaluate its performance.\n\n90:10 Split:\n\nTraining Set: 90% of the data\nTesting Set: 10% of the data\nThis split might be used when the dataset is very large, ensuring a substantial amount of data for training while still having a decent-sized test set.\n\n\nConsiderations for Choosing the Split Ratio\n\nDataset Size:\n\nFor large datasets, a smaller proportion can be reserved for testing (e.g., 90:10) since even 10% of a large dataset can provide a robust evaluation.\n\nModel Complexity:\n\nComplex models with many parameters may require more training data to avoid overfitting, suggesting a larger training set.\n\nValidation Set:\n\nSee discussion below.\n\nImbalanced Datasets:\n\nFor imbalanced datasets, it’s essential to ensure that both the training and testing sets represent the class distribution adequately. Stratified sampling can be used to maintain the class proportions in both sets."
  },
  {
    "objectID": "lectures/07/slides.html#training-and-test-set-1",
    "href": "lectures/07/slides.html#training-and-test-set-1",
    "title": "Performance Evaluation",
    "section": "Training and test set",
    "text": "Training and test set\nTraining Error:\n\nGenerally tends to be low\nAchieved by optimizing learning algorithms to minimize error through parameter adjustments (e.g., weights)"
  },
  {
    "objectID": "lectures/07/slides.html#training-and-test-set-2",
    "href": "lectures/07/slides.html#training-and-test-set-2",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Training and test set",
    "text": "Training and test set\nGeneralization Error: The error rate observed when the model is evaluated on new, unseen data."
  },
  {
    "objectID": "lectures/07/slides.html#training-and-test-set-3",
    "href": "lectures/07/slides.html#training-and-test-set-3",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Training and test set",
    "text": "Training and test set\nUnderfitting:\n\nHigh training error\nModel is too simple to capture underlying patterns\nPoor performance on both training and new data\n\nOverfitting:\n\nLow training error, but high generalization error\nModel captures noise or irrelevant patterns\nPoor performance on new, unseen data"
  },
  {
    "objectID": "lectures/07/slides.html#definition",
    "href": "lectures/07/slides.html#definition",
    "title": "Performance Evaluation",
    "section": "Definition",
    "text": "Definition\nThe class imbablance problem is a scenario where the number of instances in one class significantly outnumbers the instances in other classes.\n\nModels tend to be biased towards the majority class, leading to poor performance on the minority class.\n\n\n\nStandard evaluation metrics like accuracy may be misleading in the presence of class imbalance."
  },
  {
    "objectID": "lectures/07/slides.html#k-fold-cross-validation",
    "href": "lectures/07/slides.html#k-fold-cross-validation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nDivide the dataset into \\(k\\) equally sized parts (folds).\nTraining and validation:\n\nFor each iteration, one fold is used as the validation set, the remaining \\(k\\)-1 folds are used as the training set.\n\nEvaluation: The model’s performance is evaluated in each iteration, resulting in \\(k\\) performance measures.\nAggregation: Statistics are calculated based on \\(k\\) performance measures.\n\n\n\nCommon choices for the value of \\(k\\) are 3, 5, 7, and 10."
  },
  {
    "objectID": "lectures/07/slides.html#fold-cross-validation",
    "href": "lectures/07/slides.html#fold-cross-validation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "3-Fold Cross-validation",
    "text": "3-Fold Cross-validation\n\n\n\n\n\n\n\n\n\n\n\nEach row of the table represents an iteration within the \\(k\\)-fold cross-validation process, with the number of iterations equating to the number of folds. In each iteration, one fold is designated for validation, while the remaining \\(k-1\\) folds are utilized for training the model.\n\n\nWith each iteration, \\(2/3\\) of the dataset is used for training and \\(1/3\\) for validation."
  },
  {
    "objectID": "lectures/07/slides.html#fold-cross-validation-1",
    "href": "lectures/07/slides.html#fold-cross-validation-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "5-Fold Cross-validation",
    "text": "5-Fold Cross-validation\n\n\n\n\n\n\n\n\n\n\n\nWith each iteration, \\(4/5\\) of the dataset is used for training and \\(1/5\\) for validation."
  },
  {
    "objectID": "lectures/07/slides.html#more-reliable-model-evaluation",
    "href": "lectures/07/slides.html#more-reliable-model-evaluation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "More Reliable Model Evaluation",
    "text": "More Reliable Model Evaluation\n\nMore reliable estimate of model performance compared to a single train-test split.\nReduces the variability associated with a single split, leading to a more stable and unbiased evaluation.\nFor large values of \\(k\\)1, consider the average, variance, and confidence interval.\n\n10-fold cross-validation."
  },
  {
    "objectID": "lectures/07/slides.html#better-generalization",
    "href": "lectures/07/slides.html#better-generalization",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Better Generalization",
    "text": "Better Generalization\n\nHelps in assessing how the model generalizes to an independent dataset.\nIt ensures that the model’s performance is not overly optimistic or pessimistic by averaging results over multiple folds."
  },
  {
    "objectID": "lectures/07/slides.html#efficient-use-of-data",
    "href": "lectures/07/slides.html#efficient-use-of-data",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Efficient Use of Data",
    "text": "Efficient Use of Data\n\nParticularly beneficial for small datasets, cross-validation ensures that every data point is used for both training and validation.\nThis maximizes the use of available data, leading to more accurate and reliable model training.\n\n\n\nSome examples are more informative for learning algorithms, sometimes those near the decision boundary."
  },
  {
    "objectID": "lectures/07/slides.html#hyperparameter-tuning",
    "href": "lectures/07/slides.html#hyperparameter-tuning",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameter Tuning",
    "text": "Hyperparameter Tuning\n\nCommonly used during hyperparameter tuning, allowing for the selection of the best model parameters based on their performance across multiple folds.\nThis helps in identifying the optimal configuration that balances bias and variance."
  },
  {
    "objectID": "lectures/07/slides.html#challenges",
    "href": "lectures/07/slides.html#challenges",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Challenges",
    "text": "Challenges\n\nComputational Cost: Requires multiple model trainings.\n\nLeave-One-Out (LOO): Extreme case where ( k = N ).\n\nClass Imbalance: Folds may not represent minority classes.\n\nUse Stratified Cross-Validation to maintain class proportions.\n\nComplexity: Error-prone implementation, especially for nested cross-validation, bootstraps, or integration into larger pipelines.\n\n\nLeave-one-out cross-validation (LOO-CV) can lead to overoptimistic performance evaluation, particularly in certain contexts.\nHere’s why:\n1.  **High Variance**: In LOO-CV, each iteration uses almost all the data for training, leaving only one instance for testing. This can result in high variance in the test error across iterations because the model is trained on nearly the full dataset. Since each training set is very similar to the full dataset, it can lead to overly optimistic estimates of generalization error, especially when the dataset is small or the model has high variance (e.g., decision trees or k-nearest neighbors).\n2.  **Overfitting**: Since LOO-CV uses nearly the entire dataset for training in each iteration, complex models (especially ones prone to overfitting) can fit very closely to the data, which might result in a low training error but a misleadingly low test error in some cases.\n3.  **Limited assessment of generalization**: LOO-CV might not give a reliable estimate of how well the model generalizes to completely unseen data because the difference between the training set and the full dataset is minimal, leading to a smaller gap between training and test performance.\nIn practice, this can make the evaluation appear more optimistic than it would be with more robust methods like k-fold cross-validation, where the test sets are larger, and the model has less opportunity to overfit the training data."
  },
  {
    "objectID": "lectures/07/slides.html#cross_val_score",
    "href": "lectures/07/slides.html#cross_val_score",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "cross_val_score",
    "text": "cross_val_score\n\nfrom sklearn import tree\n\nclf = tree.DecisionTreeClassifier()\n\nfrom sklearn.model_selection import cross_val_score    \n\nclf_scores = cross_val_score(clf, X, y, cv=5)\n\nprint(\"\\nScores:\", clf_scores)\nprint(f\"\\nMean: {clf_scores.mean():.2f}\")\nprint(f\"\\nStandard deviation: {clf_scores.std():.2f}\")\n\n\nScores: [0.71428571 0.66883117 0.71428571 0.79738562 0.73202614]\n\nMean: 0.73\n\nStandard deviation: 0.04\n\n\n\n\nAs previously discussed, a significant limitation of decision trees is their propensity for overfitting, which leads to high variance when applied to new datasets. This issue is evident in the observed performance variability, with accuracy ranging from 67% to 79%, which is undesirable for achieving robust model generalization.\n\n\nsklearn.model_selection.cross_val_score, see also cross_validate."
  },
  {
    "objectID": "lectures/07/slides.html#workflow",
    "href": "lectures/07/slides.html#workflow",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Workflow",
    "text": "Workflow\n\n\n\n\n\n\n\nThe above image implicitly introduces three categories of data subsets: training, validation, and test.\n\n\nAttribution: Cross-validation: evaluating estimator performance"
  },
  {
    "objectID": "lectures/07/slides.html#workflow---implementation",
    "href": "lectures/07/slides.html#workflow---implementation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Workflow - implementation",
    "text": "Workflow - implementation\n\nfrom sklearn.datasets import fetch_openml\n\nX, y = fetch_openml(name='diabetes', version=1, return_X_y=True)\n\ny = y.map({'tested_negative': 0, 'tested_positive': 1})\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\n\nTo maintain simplicity in these lecture notes, we have not applied any pre-processing steps."
  },
  {
    "objectID": "lectures/07/slides.html#definition-1",
    "href": "lectures/07/slides.html#definition-1",
    "title": "Performance Evaluation",
    "section": "Definition",
    "text": "Definition\nGeneralization Error: The error rate observed when the model is evaluated on new, unseen data."
  },
  {
    "objectID": "lectures/07/slides.html#hyperparameters---decision-tree",
    "href": "lectures/07/slides.html#hyperparameters---decision-tree",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameters - Decision Tree",
    "text": "Hyperparameters - Decision Tree\n\ncriterion: gini, entropy, log_loss, measure the quality of a split.\nmax_depth: limits the number of levels in the tree to prevent overfitting.\n\n\n\nSee: DecisionTreeClassifier"
  },
  {
    "objectID": "lectures/07/slides.html#hyperparameters---logistic-regression",
    "href": "lectures/07/slides.html#hyperparameters---logistic-regression",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameters - Logistic Regression",
    "text": "Hyperparameters - Logistic Regression\n\npenalty: l1 or l2, helps in preventing overfitting.\nsolver: liblinear, newton-cg, lbfgs, sag, saga.\nmax_iter: maximum number of iterations taken for the solvers to converge.\ntol: stopping criteria, smaller values mean higher precision.\n\n\n\nSee: LogisticRegression and SGDClassifier."
  },
  {
    "objectID": "lectures/07/slides.html#hyperparameters---knn",
    "href": "lectures/07/slides.html#hyperparameters---knn",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameters - KNN",
    "text": "Hyperparameters - KNN\n\nn_neighbors: number of neighbors to use for \\(k\\)-neighbors queries.\nweights: uniform or distance, equal weight or distance-based weight.\n\n\n\nSee: KNeighborsClassifier"
  },
  {
    "objectID": "lectures/07/slides.html#experiment-max_depth",
    "href": "lectures/07/slides.html#experiment-max_depth",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: max_depth",
    "text": "Experiment: max_depth\n\nfor value in [3, 5, 7, None]:\n\n  clf = tree.DecisionTreeClassifier(max_depth=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\nmax_depth = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")\n\n\nmax_depth =  3\nMean: 0.74\nStandard deviation: 0.04\n\nmax_depth =  5\nMean: 0.76\nStandard deviation: 0.04\n\nmax_depth =  7\nMean: 0.73\nStandard deviation: 0.04\n\nmax_depth =  None\nMean: 0.71\nStandard deviation: 0.05"
  },
  {
    "objectID": "lectures/07/slides.html#experiment-criterion",
    "href": "lectures/07/slides.html#experiment-criterion",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: criterion",
    "text": "Experiment: criterion\n\nfor value in [\"gini\", \"entropy\", \"log_loss\"]:\n\n  clf = tree.DecisionTreeClassifier(max_depth=5, criterion=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\ncriterion = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")\n\n\ncriterion =  gini\nMean: 0.76\nStandard deviation: 0.04\n\ncriterion =  entropy\nMean: 0.75\nStandard deviation: 0.05\n\ncriterion =  log_loss\nMean: 0.75\nStandard deviation: 0.05\n\n\n\nFor this specific problem and dataset, the criterion parameter has a limited impact on the learning process."
  },
  {
    "objectID": "lectures/07/slides.html#experiment-n_neighbors",
    "href": "lectures/07/slides.html#experiment-n_neighbors",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: n_neighbors",
    "text": "Experiment: n_neighbors\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfor value in range(1, 11):\n\n  clf = KNeighborsClassifier(n_neighbors=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\nn_neighbors = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")"
  },
  {
    "objectID": "lectures/07/slides.html#experiment-n_neighbors-output",
    "href": "lectures/07/slides.html#experiment-n_neighbors-output",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: n_neighbors",
    "text": "Experiment: n_neighbors\n\n\nn_neighbors =  1\nMean: 0.67\nStandard deviation: 0.05\n\nn_neighbors =  2\nMean: 0.71\nStandard deviation: 0.03\n\nn_neighbors =  3\nMean: 0.69\nStandard deviation: 0.05\n\nn_neighbors =  4\nMean: 0.73\nStandard deviation: 0.03\n\nn_neighbors =  5\nMean: 0.72\nStandard deviation: 0.03\n\nn_neighbors =  6\nMean: 0.73\nStandard deviation: 0.05\n\nn_neighbors =  7\nMean: 0.74\nStandard deviation: 0.04\n\nn_neighbors =  8\nMean: 0.75\nStandard deviation: 0.04\n\nn_neighbors =  9\nMean: 0.73\nStandard deviation: 0.05\n\nn_neighbors =  10\nMean: 0.73\nStandard deviation: 0.04"
  },
  {
    "objectID": "lectures/07/slides.html#experiment-weights",
    "href": "lectures/07/slides.html#experiment-weights",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: weights",
    "text": "Experiment: weights\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfor value in [\"uniform\", \"distance\"]:\n\n  clf = KNeighborsClassifier(n_neighbors=5, weights=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\nweights = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")\n\n\nweights =  uniform\nMean: 0.72\nStandard deviation: 0.03\n\nweights =  distance\nMean: 0.73\nStandard deviation: 0.04\n\n\n\nFor this specific problem and dataset, the weights parameter has a limited impact on the learning process.\nAt this point, you might hypothesize that certain combinations of hyperparameters could be more optimal than others."
  },
  {
    "objectID": "lectures/07/slides.html#hyperparameter-tuning-grid-search",
    "href": "lectures/07/slides.html#hyperparameter-tuning-grid-search",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameter Tuning: Grid Search",
    "text": "Hyperparameter Tuning: Grid Search\n\nMany hyperparameters need tuning\n\nMajor disadvantage of ML algorithms\n\nManual exploration of combinations is tedious\nGrid search is more systematic\n\nEnumerate all possible hyperparameter combinations\nTrain on training set, evaluate on validation set\n\n\n\n\nThe training set referred to here is different from the one previously mentioned. In each iteration of the \\(k\\)-fold cross-validation process, a unique training and validation set is created.\nIn some contexts, the choice of the model itself can be considered a hyperparameter. For instance, when performing model selection within a machine learning pipeline, different algorithms (e.g., decision trees, support vector machines, neural networks) can be treated as hyperparameters. This approach allows for the selection of the best-performing model through automated processes such as grid search or random search, alongside the tuning of other hyperparameters.\nThus, while traditionally hyperparameters refer to settings within a specific model, the model choice can also be incorporated into hyperparameter optimization frameworks.\nAs will be discussed later, the choice of the number of layers and the number of nodes are often considered hyperparameters when training deep learning algorithms.\n\n\nInitially, try powers of 2 or 10. Next, refine with grid search near optimal values if time permits."
  },
  {
    "objectID": "lectures/07/slides.html#gridsearchcv",
    "href": "lectures/07/slides.html#gridsearchcv",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "GridSearchCV",
    "text": "GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n  {'max_depth': range(1, 10),\n   'criterion': [\"gini\", \"entropy\", \"log_loss\"]}\n]\n\nclf = tree.DecisionTreeClassifier()\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)\n\n(grid_search.best_params_, grid_search.best_score_)\n\n({'criterion': 'gini', 'max_depth': 5}, np.float64(0.7481910124074653))"
  },
  {
    "objectID": "lectures/07/slides.html#gridsearchcv-1",
    "href": "lectures/07/slides.html#gridsearchcv-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "GridSearchCV",
    "text": "GridSearchCV\n\nparam_grid = [\n  {'n_neighbors': range(1, 15),\n   'weights': [\"uniform\", \"distance\"]}\n]\n\nclf = KNeighborsClassifier()\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)\n\n(grid_search.best_params_, grid_search.best_score_)\n\n({'n_neighbors': 14, 'weights': 'uniform'}, np.float64(0.7554165363361485))\n\n\n\nThe variable param_grid contains a dictionary specifying the names of the parameters to be tuned, along with the respective values to be tested.\nIn this instance, the parameters n_neighbors and weights are being tuned. However, additional parameters could be included if necessary."
  },
  {
    "objectID": "lectures/07/slides.html#gridsearchcv-2",
    "href": "lectures/07/slides.html#gridsearchcv-2",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "GridSearchCV",
    "text": "GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\n\n# 2 * 5 * 5 * 3 = 150 tests!\n\nparam_grid = [\n  {'penalty': [\"l1\", \"l2\", None],\n   'solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n   'max_iter' : [100, 200, 400, 800, 1600],\n   'tol' : [0.01, 0.001, 0.0001]}\n]\n\nclf = LogisticRegression()\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)\n\n(grid_search.best_params_, grid_search.best_score_)\n\n({'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001},\n np.float64(0.7756646856427901))"
  },
  {
    "objectID": "lectures/07/slides.html#randomized-search",
    "href": "lectures/07/slides.html#randomized-search",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Randomized Search",
    "text": "Randomized Search\n\nLarge number of combinations (many hyperparameters, many values)\nUse RandomizedSearchCV:\n\nSupply list of values or probability distribution for hyperparameters\nSpecify number of iterations (combinations to try)\nPredictable execution time\n\n\n\n\nSee: Comparing randomized search and grid search for hyperparameter estimation."
  },
  {
    "objectID": "lectures/07/slides.html#workflow-1",
    "href": "lectures/07/slides.html#workflow-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Workflow",
    "text": "Workflow\n\n\n\n\n\n\n\nAs the ongoing example illustrates, in addition to evaluating various hyperparameter values, multiple models can also be tested.\n\n\nAttribution: Cross-validation: evaluating estimator performance"
  },
  {
    "objectID": "lectures/07/slides.html#finally-we-proceed-with-testing",
    "href": "lectures/07/slides.html#finally-we-proceed-with-testing",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Finally, we proceed with testing",
    "text": "Finally, we proceed with testing\n\nclf = LogisticRegression(max_iter=100, penalty='l2', solver='newton-cg', tol=0.001)\n\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.83      0.83      0.83        52\n           1       0.64      0.64      0.64        25\n\n    accuracy                           0.77        77\n   macro avg       0.73      0.73      0.73        77\nweighted avg       0.77      0.77      0.77        77\n\n\n\n\n\nIt appears that we are facing a class imbalance issue, which should have been identified earlier in our workflow!"
  },
  {
    "objectID": "lectures/07/slides.html#summary",
    "href": "lectures/07/slides.html#summary",
    "title": "Performance Evaluation",
    "section": "Summary",
    "text": "Summary\nThis lecture covers classification model evaluation, focusing on confusion matrices and key metrics: accuracy, precision, recall, and F₁ score. It addresses accuracy’s limitations in imbalanced datasets, introducing micro and macro averaging. The precision-recall trade-off and ROC analysis, including AUC, are also explored. Practical insights are provided through Python implementations like logistic regression via gradient descent."
  },
  {
    "objectID": "lectures/07/slides.html#next-lecture",
    "href": "lectures/07/slides.html#next-lecture",
    "title": "Performance Evaluation",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will examine cross-validation and hyperparameter tuning."
  },
  {
    "objectID": "lectures/07/slides.html#references",
    "href": "lectures/07/slides.html#references",
    "title": "Performance Evaluation",
    "section": "References",
    "text": "References\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 3rd ed. O’Reilly Media, Inc.\n\n\nJapkowicz, Nathalie, and Mohak Shah. 2011. Evaluating Learning Algorithms: A Classification Perspective. Cambridge: Cambridge University Press.\n\n\nKnowler, William C., David J. Pettitt, Peter J. Savage, and Peter H. Bennett. 1981. “Diabetes Incidence in Pima Indians: Contributions of Obesity and Parental Diabetes.” American Journal of Epidemiology 113 2: 144–56. https://api.semanticscholar.org/CorpusID:25209675.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/07/index.html",
    "href": "lectures/07/index.html",
    "title": "Performance Evaluation",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 1 must be submitted no later than September 29, 2025, at 11 PM. Please refer to the assignment description available on Brightspace."
  },
  {
    "objectID": "lectures/07/index.html#prepare",
    "href": "lectures/07/index.html#prepare",
    "title": "Performance Evaluation",
    "section": "Prepare",
    "text": "Prepare\n\nLones, M. A. (2024). Avoiding common machine learning pitfalls. Patterns, 101046. doi.org/10.1016/j.patter.2024.101046 (also available on arXiv)\nThe 7 steps of machine learning by Google Cloud Tech on YouTube, 2017-08-31"
  },
  {
    "objectID": "lectures/07/index.html#participate",
    "href": "lectures/07/index.html#participate",
    "title": "Performance Evaluation",
    "section": "Participate",
    "text": "Participate\n\nslides (PDF) as Jupyter Notebook"
  },
  {
    "objectID": "lectures/08/slides.html#quote-of-the-day",
    "href": "lectures/08/slides.html#quote-of-the-day",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n\n\n\n\n\n\nEPFL, ETH Zurich and the Swiss National Supercomputing Centre (CSCS) released Apertus 2 September, Switzerland’s first large-scale, open, multilingual language model — a milestone in generative AI for transparency and diversity.\n\n\nwww.swiss-ai.org/apertus\nDownloads available at Hugging Face\nPublic access\n\nShould Canada undertake such an extensive project?\nCanada is recognized for its exceptional AI research, supported by several renowned research institutions and scholars. Notable examples include:\n\nThe Vector Institute in Toronto, which is home to distinguished researchers like Geoffrey Hinton, a recipient of the 2018 Turing Award for his pioneering work in deep learning and the 2024 Nobel Prize in Physics.\nMila in Montréal, led by Yoshua Bengio, another 2018 Turing Award laureate recognized for his contributions to deep learning.\nThe Alberta Machine Intelligence Institute (Amii), where Richard S. Sutton is a key figure and was awarded the 2024 Turing Award for his influential work in reinforcement learning.\n\nThese institutions and individuals underscore Canada’s leadership and ongoing commitment to advancing artificial intelligence research.\nThe Digital Research Alliance of Canada, supported by a $2 billion commitment from the Government of Canada in 2024, provides cutting-edge infrastructure for advanced research. Notably, the high-performance computing resource, Nibi, was launched on July 31, 2025. It features 134,400 CPU cores and 288 NVIDIA H100 GPUs, significantly enhancing computational capacity. For further technical specifications, please refer to the technical documentation.\n\n\nApertus: a fully open, transparent, multilingual language model, ETH Zürich, Press Release, 2025-09-02."
  },
  {
    "objectID": "lectures/08/slides.html#learning-objectives",
    "href": "lectures/08/slides.html#learning-objectives",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the Purpose of Data Splitting:\n\nDescribe the roles of the training, validation, and test sets in model evaluation.\nExplain why and how datasets are divided for effective model training and evaluation.\n\nExplain Cross-Validation Techniques:\n\nDefine cross-validation and its importance in model evaluation.\nIllustrate the process of \\(k\\)-fold cross-validation and its advantages over a single train-test split.\nDiscuss the concepts of underfitting and overfitting in the context of cross-validation.\n\nHyperparameter Tuning:\n\nExplain the difference between model parameters and hyperparameters.\nDescribe methods for tuning hyperparameters, including grid search and randomized search.\nImplement hyperparameter tuning using GridSearchCV in scikit-learn.\n\nEvaluate Model Performance:\n\nInterpret cross-validation results and understand metrics like mean and standard deviation of scores.\nDiscuss how cross-validation helps in assessing model generalization and reducing variability.\n\nMachine Learning Engineering Workflow:\n\nOutline the steps involved in preparing data for machine learning models.\nUtilize scikit-learn pipelines for efficient data preprocessing and model training.\nEmphasize the significance of consistent data transformations across training and production environments.\n\nCritical Evaluation of Machine Learning Models:\n\nAssess the limitations and challenges associated with hyperparameter tuning and model selection.\nRecognize potential pitfalls in data preprocessing, such as incorrect handling of missing values or inconsistent encoding.\nAdvocate for thorough testing and validation to ensure model reliability and generalizability.\n\nIntegrate Knowledge in Practical Applications:\n\nApply the learned concepts to real-world datasets (e.g., OpenML datasets like ‘diabetes’ and ‘adult’).\nInterpret and analyze the results of model evaluations and experiments.\nDevelop a comprehensive understanding of the end-to-end machine learning pipeline.\n\n\n\n\nThe above learning objectives have been generated by OpenAI’s model, o1, based on the lecture content."
  },
  {
    "objectID": "lectures/08/slides.html#prologue",
    "href": "lectures/08/slides.html#prologue",
    "title": "Bias-Variance Tradeoff",
    "section": "Prologue",
    "text": "Prologue\n\n\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/08/index.html",
    "href": "lectures/08/index.html",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 1 must be submitted no later than September 29, 2025, at 11 PM. Please refer to the assignment description available on Brightspace.\nDeadline: Quiz 1 is scheduled for this Wednesday, October 1, 2025, during class. Additional details are available in the FAQ."
  },
  {
    "objectID": "lectures/08/index.html#prepare",
    "href": "lectures/08/index.html#prepare",
    "title": "Lecture 08",
    "section": "Prepare",
    "text": "Prepare\nSuggested readings will be inserted here."
  },
  {
    "objectID": "lectures/08/index.html#participate",
    "href": "lectures/08/index.html#participate",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Participate",
    "text": "Participate\n\nslides (PDF) as Jupyter Notebook"
  },
  {
    "objectID": "lectures/08/index.html#practice",
    "href": "lectures/08/index.html#practice",
    "title": "Lecture 08",
    "section": "Practice",
    "text": "Practice\nSuggested exercises will be inserted here."
  },
  {
    "objectID": "lectures/08/index.html#perform",
    "href": "lectures/08/index.html#perform",
    "title": "Lecture 08",
    "section": "Perform",
    "text": "Perform\nReminders for assignments to be inserted here."
  },
  {
    "objectID": "lectures/09/index.html",
    "href": "lectures/09/index.html",
    "title": "Lecture 09",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Quiz 1, today, October 1, 2025."
  },
  {
    "objectID": "lectures/09/index.html#prepare",
    "href": "lectures/09/index.html#prepare",
    "title": "Lecture 09",
    "section": "Prepare",
    "text": "Prepare\n\nFormat: Closed book. Multiple-choice and true/false questions.\nScope: Lectures 1 to 8.\n\nThe numbering corresponds to that used in the URLs, for example, turcotte.xyz/teaching/csi-4506/lectures/07/slides.html is Lecture 7. Consequently, the quiz covers the lectures from September 3 to September 29 inclusively.\n\nContent: Emphasis on conceptual questions rather than intricate technical details (e.g., reshaping a numpy array).\nQuestion Types: Includes code excerpts or diagrams requiring identification of the correct statements.\nNumber of Questions: Expect 25 to 35 questions.\nIn class: You will take the quiz in class on a paper questionnaire. Please arrive on time so that we can start as early as possible (the total time available depends on your arrival time). We must collect all copies 10 minutes before the end of the class to allow the next class to begin on time.\nStudent ID Card: Please bring your student ID card."
  },
  {
    "objectID": "lectures/10/slides.html#quote-of-the-day",
    "href": "lectures/10/slides.html#quote-of-the-day",
    "title": "Machine Learning Engineering",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n\nClément Delangue, Hugging Face CEO, discusses AI for good. Specifically, the development by IBM and NASA of an open-source AI model for weather and climate analysis."
  },
  {
    "objectID": "lectures/10/slides.html#learning-objectives",
    "href": "lectures/10/slides.html#learning-objectives",
    "title": "Machine Learning Engineering",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nData Size and Its Impact:\n\nRecognize the influence of dataset size on model performance.\nDiscuss the concept of data augmentation and its role in improving model robustness.\nExplore the “unreasonable effectiveness of data” in machine learning.\n\nFeature Engineering and Encoding:\n\nExplain the importance of feature extraction and the role of domain knowledge.\nCompare different methods for encoding categorical data, such as one-hot encoding and ordinal encoding.\nJustify the choice of encoding methods based on the nature of the data and the problem.\n\nData Preprocessing Techniques:\n\nApply normalization and standardization for feature scaling.\nDecide when to use normalization versus standardization based on data characteristics.\nHandle missing values using various imputation strategies and understand their implications.\n\nAddressing Class Imbalance:\n\nDefine the class imbalance problem and its impact on model performance.\nExplore solutions like resampling, algorithmic adjustments, and synthetic data generation (e.g., SMOTE).\nUnderstand the importance of applying these techniques appropriately to avoid data leakage.\n\nIntegrate Knowledge in Practical Applications:\n\nApply the learned concepts to real-world datasets (e.g., OpenML datasets like ‘diabetes’ and ‘adult’).\nInterpret and analyze the results of model evaluations and experiments.\nDevelop a comprehensive understanding of the end-to-end machine learning pipeline.\n\n\n\n\nThe above learning objectives have been generated by OpenAI’s model, o1, based on the lecture content."
  },
  {
    "objectID": "lectures/10/slides.html#size-does-matter",
    "href": "lectures/10/slides.html#size-does-matter",
    "title": "Machine Learning Engineering",
    "section": "Size does matter",
    "text": "Size does matter\n\n\n“However, these results suggest that we may want to reconsider the trade-off between spending time and money on algorithm development versus spending it on corpus development algorithms themselves.”\n\n\n\n\n\nAttribution: Banko and Brill (2001)"
  },
  {
    "objectID": "lectures/10/slides.html#unreasonable-effectiveness-of-data",
    "href": "lectures/10/slides.html#unreasonable-effectiveness-of-data",
    "title": "Machine Learning Engineering",
    "section": "Unreasonable Effectiveness of Data",
    "text": "Unreasonable Effectiveness of Data\n\n\n\nPeter Norvig’s presentation, titled “The Unreasonable Effectiveness of Data,” runs for just over one hour. It is noteworthy that the paper on which the presentation is based was published in 2009, predating the success of AlexNet.\nThe substantial improvements observed with AlexNet in 2012 highlighted the benefits of training deep neural networks on large image datasets.\nSimilarly, modern models like GPT, Gemini, Claude, and LLaMA have achieved significant advancements in language capabilities by training on vast amounts of text data, encompassing nearly all written material since the inception of human civilization.\nNeural scaling laws describe how the performance of neural networks varies with changes in key factors such as dataset size, number of parameters, and computational cost Kaplan et al. (2020).\n\n\nHalevy, Norvig, and Pereira (2009) and Kaplan et al. (2020)."
  },
  {
    "objectID": "lectures/10/slides.html#definition",
    "href": "lectures/10/slides.html#definition",
    "title": "Machine Learning Engineering",
    "section": "Definition",
    "text": "Definition\nData augmentation is a technique used to increase the diversity of a dataset by applying various transformations to the existing data.\n\n\nPurpose: Enhance the robustness and generalization capability of machine learning models."
  },
  {
    "objectID": "lectures/10/slides.html#data-augmentation",
    "href": "lectures/10/slides.html#data-augmentation",
    "title": "Machine Learning Engineering",
    "section": "Data Augmentation",
    "text": "Data Augmentation\n\nFor Images: Rotations, translations, scaling, flipping, adding noise, etc.\n\nHow to find ancient geoglyphs using machine learning?, Sakai et al. (2024)\n\nFor Text: Synonym replacement, random insertion, deletion, and swapping of words.\n\n\n\nGenerative Adversarial Networks (GANs) (a form of deep learning) can be used to generate new, synthetic data that mimics the distribution of the original dataset.\nSee also: Shumailov et al. (2024)."
  },
  {
    "objectID": "lectures/10/slides.html#machine-learning-engineering-1",
    "href": "lectures/10/slides.html#machine-learning-engineering-1",
    "title": "Machine Learning Engineering",
    "section": "Machine Learning Engineering",
    "text": "Machine Learning Engineering\n\nGather adequate data.\nExtract features from the raw data:\n\nThis process is labor-intensive.\nIt necessitates creativity.\nDomain knowledge is highly beneficial."
  },
  {
    "objectID": "lectures/10/slides.html#dataset---adult",
    "href": "lectures/10/slides.html#dataset---adult",
    "title": "Machine Learning Engineering",
    "section": "Dataset - Adult",
    "text": "Dataset - Adult\n\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import fetch_openml\n\nadult = fetch_openml(name='adult', version=2)\nprint(adult.DESCR)\n\n\n\nLe jeu de données ‘Adult’ contient plusieurs attributs caractérisés par des valeurs catégorielles. Ce jeu de données servira de base pour une brève discussion sur l’encodage de ces valeurs catégorielles."
  },
  {
    "objectID": "lectures/10/slides.html#dataset---adult-output",
    "href": "lectures/10/slides.html#dataset---adult-output",
    "title": "Machine Learning Engineering",
    "section": "Dataset - Adult",
    "text": "Dataset - Adult\nAuthor: Ronny Kohavi and Barry Becker\nSource: UCI - 1996\nPlease cite: Ron Kohavi, “Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid”, Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996\nPrediction task is to determine whether a person makes over 50K a year. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE&gt;16) && (AGI&gt;100) && (AFNLWGT&gt;1)&& (HRSWK&gt;0))\nThis is the original version from the UCI repository, with training and test sets merged.\nVariable description\nVariables are all self-explanatory except fnlwgt. This is a proxy for the demographic background of the people: “People with similar demographic characteristics should have similar weights”. This similarity-statement is not transferable across the 51 different states.\nDescription from the donor of the database:\nThe weights on the CPS files are controlled to independent estimates of the civilian noninstitutional population of the US. These are prepared monthly for us by Population Division here at the Census Bureau. We use 3 sets of controls. These are: 1. A single cell estimate of the population 16+ for each state. 2. Controls for Hispanic Origin by age and sex. 3. Controls by Race, age and sex.\nWe use all three sets of controls in our weighting program and “rake” through them 6 times so that by the end we come back to all the controls we used. The term estimate refers to population totals derived from CPS by creating “weighted tallies” of any specified socio-economic characteristics of the population. People with similar demographic characteristics should have similar weights. There is one important caveat to remember about this statement. That is that since the CPS sample is actually a collection of 51 state samples, each with its own probability of selection, the statement only applies within state.\nRelevant papers\nRonny Kohavi and Barry Becker. Data Mining and Visualization, Silicon Graphics.\ne-mail: ronnyk ‘@’ live.com for questions.\nDownloaded from openml.org."
  },
  {
    "objectID": "lectures/10/slides.html#adult---workclass",
    "href": "lectures/10/slides.html#adult---workclass",
    "title": "Machine Learning Engineering",
    "section": "Adult - Workclass",
    "text": "Adult - Workclass\n\nadult.data['workclass'].unique()\n\n['Private', 'Local-gov', NaN, 'Self-emp-not-inc', 'Federal-gov', 'State-gov', 'Self-emp-inc', 'Without-pay', 'Never-worked']\nCategories (8, object): ['Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay']"
  },
  {
    "objectID": "lectures/10/slides.html#adult---education",
    "href": "lectures/10/slides.html#adult---education",
    "title": "Machine Learning Engineering",
    "section": "Adult - Education",
    "text": "Adult - Education\n\nadult.data['education'].unique()\n\n['11th', 'HS-grad', 'Assoc-acdm', 'Some-college', '10th', ..., 'Assoc-voc', '9th', '12th', '1st-4th', 'Preschool']\nLength: 16\nCategories (16, object): ['10th', '11th', '12th', '1st-4th', ..., 'Masters', 'Preschool', 'Prof-school', 'Some-college']"
  },
  {
    "objectID": "lectures/10/slides.html#adult---marital-status",
    "href": "lectures/10/slides.html#adult---marital-status",
    "title": "Machine Learning Engineering",
    "section": "Adult - Marital Status",
    "text": "Adult - Marital Status\n\nadult.data['marital-status'].unique()\n\n['Never-married', 'Married-civ-spouse', 'Widowed', 'Divorced', 'Separated', 'Married-spouse-absent', 'Married-AF-spouse']\nCategories (7, object): ['Divorced', 'Married-AF-spouse', 'Married-civ-spouse', 'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed']"
  },
  {
    "objectID": "lectures/10/slides.html#categorical-data",
    "href": "lectures/10/slides.html#categorical-data",
    "title": "Machine Learning Engineering",
    "section": "Categorical Data",
    "text": "Categorical Data\nKey Points on Data Representation\n\nNumerical Representation: Some learning algorithms require data to be in numerical form.\nExample Attribute: Consider the workclass attribute, which has 8 distinct values like ‘Federal-gov’, ‘Local-gov’, and so on."
  },
  {
    "objectID": "lectures/10/slides.html#encoding-methods",
    "href": "lectures/10/slides.html#encoding-methods",
    "title": "Machine Learning Engineering",
    "section": "Encoding Methods",
    "text": "Encoding Methods\nWhich encoding method is preferable and why?\n\nw = 1, 2, 3, 4, 5, 6, 7, or 8\nw = [0,0,0], [0,0,1], [0,1,0], \\(\\ldots\\), or [1,1,1]\nw = [1,0,0,0,0,0,0,0], [0,1,0,0,0,0,0,0], \\(\\ldots\\), or [0,0,0,0,0,0,0,1]"
  },
  {
    "objectID": "lectures/10/slides.html#encoding-for-categorical-data",
    "href": "lectures/10/slides.html#encoding-for-categorical-data",
    "title": "Machine Learning Engineering",
    "section": "Encoding for Categorical Data",
    "text": "Encoding for Categorical Data\nOne-Hot Encoding: This method should be preferred for categorical data.\n\nIncreases Dimensionality: One-hot encoding increases the dimensionality of feature vectors.\nAvoids Bias: Other encoding methods can introduce biases.\nExample of Bias: Using the first method, w = 1, 2, 3, etc., implies that ‘Federal-gov’ and ‘Local-gov’ are similar, while ‘Federal-gov’ and ‘Without-pay’ are not.\nMisleading Similarity: The second method, w = [0,0,0], [0,0,1], etc., might mislead the algorithm by suggesting similarity based on numeric patterns."
  },
  {
    "objectID": "lectures/10/slides.html#definition-1",
    "href": "lectures/10/slides.html#definition-1",
    "title": "Machine Learning Engineering",
    "section": "Definition",
    "text": "Definition\nOne-Hot Encoding: A technique that converts categorical variables into a binary vector representation, where each category is represented by a vector with a single ‘1’ and all other elements as ‘0’.\n\n\nLater, we will consider another encoding called an embedding."
  },
  {
    "objectID": "lectures/10/slides.html#onehotencoder",
    "href": "lectures/10/slides.html#onehotencoder",
    "title": "Machine Learning Engineering",
    "section": "OneHotEncoder",
    "text": "OneHotEncoder\n\nfrom numpy import array\nfrom sklearn.preprocessing import OneHotEncoder\n\nwork = adult.data[['workclass']]\n\nonehot_encoder = OneHotEncoder()\n\nonehot_encoder.fit(work)\nvalues_encoded = onehot_encoder.transform(work)\n\nfor i in range(5): print(values_encoded.toarray()[i])\n\n[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n\n\n\n\nA student from my research group faced a challenging debugging issue. They mistakenly created a new encoder for the training set using onehot_encoder.fit(X_test['some_attribute']), which produced a vector representation different from the one used during training. Consequently, the results on the training set were poor, while the results on the test set appeared satisfactory.\nWhile Pandas offers a method called get_dummies() for one-hot encoding, it is important to note the following distinctions:\n\nCategory Memory: OneHotEncoder retains the categories it was trained on, whereas get_dummies() does not.\nConsistency in Production: It is crucial to use the same encoding scheme in production as was used during training to ensure accurate results.\nVector Length Discrepancies: If get_dummies() encounters a different number of categories in new data, it will produce vectors of varying lengths, leading to potential errors.\nHandling Missing Values: When get_dummies() processes missing values, it generates an additional column to accommodate them.\n\nEnsuring consistency in encoding across training, validation, and production datasets is essential to maintain the integrity and accuracy of your machine learning models.\n\n\nConsistency is Key: Ensure you use the same encoding on: Validation Set, Test Set, and Production Data."
  },
  {
    "objectID": "lectures/10/slides.html#case-study",
    "href": "lectures/10/slides.html#case-study",
    "title": "Machine Learning Engineering",
    "section": "Case Study",
    "text": "Case Study\n\nDataset: Heart Disease\n\nExamples: 303, features: 13, target: Presence/absence of disease\n\nCategorical Data:\n\nsex: 1 = male, 0 = female\ncp (chest pain type):\n\n1: Typical angina\n2: Atypical angina\n3: Non-anginal pain\n4: Asymptomatic\n\nOther: ‘fbs’, ‘restecg’, ‘exang’, ‘slope’, ‘thal’\n\n\n\n\nHere are some suggestions for further investigation:\n\nAssess the impact of omitting missing values on the dataset.\nImplement hyperparameter tuning to determine whether \\(L_1\\) or \\(L_2\\) regularization enhances model performance.\n\n\n\nTo simplify the analysis: Examples with missing values were dropped, no hyperparameter tuning was performed, numerical values were scaled for solver convergence."
  },
  {
    "objectID": "lectures/10/slides.html#case-study-1",
    "href": "lectures/10/slides.html#case-study-1",
    "title": "Machine Learning Engineering",
    "section": "Case Study",
    "text": "Case Study\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# Load the 'Heart-Disease' dataset from OpenML\ndata = fetch_openml(name='Heart-Disease', version=1, as_frame=True)\ndf = data.frame\n\n# Replace '?' with NaN and convert columns to numeric\nfor col in df.columns:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\n\n# Drop rows with missing values\ndf.dropna(inplace=True)\n\n# Define features and target\nX = df.drop(columns=['target'])\ny = df['target']\n\n# Columns to encode with OneHotEncoder\ncolumns_to_encode = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n\n# Identify numerical columns\nnumerical_columns = X.columns.difference(columns_to_encode)\n\n# Split the dataset into training and testing sets before transformations\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Apply OneHotEncoder and StandardScaler using ColumnTransformer\ncolumn_transformer = ColumnTransformer(\n    transformers=[\n        ('onehot', OneHotEncoder(), columns_to_encode),\n        ('scaler', StandardScaler(), numerical_columns)\n    ]\n)\n\n# Fit the transformer on the training data and transform both training and test data\nX_train_processed = column_transformer.fit_transform(X_train)\nX_test_processed = column_transformer.transform(X_test)\n\n# Initialize and train logistic regression model\nmodel = LogisticRegression(max_iter=1000)\nmodel = model.fit(X_train_processed, y_train)\n\n\nIn the context of using ColumnTransformer, the second element of the triplets, typically an estimator, can also be replaced with the options drop or passthrough. The drop option excludes the specified column from the transformation process, while passthrough retains the column in its original state without any modifications."
  },
  {
    "objectID": "lectures/10/slides.html#case-study---results",
    "href": "lectures/10/slides.html#case-study---results",
    "title": "Machine Learning Engineering",
    "section": "Case study - results",
    "text": "Case study - results\n\n# Predict and evaluate the model\ny_pred = model.predict(X_test_processed)\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n         0.0       0.87      0.93      0.90        29\n         1.0       0.93      0.88      0.90        32\n\n    accuracy                           0.90        61\n   macro avg       0.90      0.90      0.90        61\nweighted avg       0.90      0.90      0.90        61"
  },
  {
    "objectID": "lectures/10/slides.html#case-study---chest-pain-cp",
    "href": "lectures/10/slides.html#case-study---chest-pain-cp",
    "title": "Machine Learning Engineering",
    "section": "Case study - chest pain (cp)",
    "text": "Case study - chest pain (cp)\n\n# Retrieve feature names after transformation using get_feature_names_out()\nfeature_names = column_transformer.get_feature_names_out()\n\n# Get coefficients and map them to feature names\ncoefficients = model.coef_[0]\n\n# Create a DataFrame with feature names and coefficients\ncoef_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Coefficient': coefficients\n})\n\n# Display coefficients associated with 'cp'\ncp_features = coef_df[coef_df['Feature'].str.contains('_cp')]\nprint(\"\\nCoefficients associated with 'cp':\")\nprint(cp_features)\n\n\nCoefficients associated with 'cp':\n          Feature  Coefficient\n2  onehot__cp_0.0    -1.013382\n3  onehot__cp_1.0    -0.212284\n4  onehot__cp_2.0     0.599934\n5  onehot__cp_3.0     0.628824"
  },
  {
    "objectID": "lectures/10/slides.html#case-study---coefficients",
    "href": "lectures/10/slides.html#case-study---coefficients",
    "title": "Machine Learning Engineering",
    "section": "Case study - coefficients",
    "text": "Case study - coefficients\n\n# Visualize the coefficients\n\nplt.figure(figsize=(8, 6))\nplt.barh(coef_df['Feature'], coef_df['Coefficient'])\nplt.title('Feature Coefficients')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.tight_layout()\nplt.show()\n\n\n\n\nPositive coefficients in a logistic regression model signify that higher values of the corresponding feature contribute positively to the probability of an example belonging to ‘target = 1.0’. Negative coefficients indicate the opposite effect."
  },
  {
    "objectID": "lectures/10/slides.html#case-study---coefficients-output",
    "href": "lectures/10/slides.html#case-study---coefficients-output",
    "title": "Machine Learning Engineering",
    "section": "Case study - coefficients",
    "text": "Case study - coefficients"
  },
  {
    "objectID": "lectures/10/slides.html#case-study---coefficients-sorted",
    "href": "lectures/10/slides.html#case-study---coefficients-sorted",
    "title": "Machine Learning Engineering",
    "section": "Case study - coefficients (sorted)",
    "text": "Case study - coefficients (sorted)\n\n# Visualize the coefficients\n\nplt.figure(figsize=(8, 6))\ncoef_df.sort_values(by='Coefficient', inplace=True)\nplt.barh(coef_df['Feature'], coef_df['Coefficient'])\nplt.title('Feature Coefficients')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "lectures/10/slides.html#case-study---coefficients-sorted-output",
    "href": "lectures/10/slides.html#case-study---coefficients-sorted-output",
    "title": "Machine Learning Engineering",
    "section": "Case study - coefficients (sorted)",
    "text": "Case study - coefficients (sorted)"
  },
  {
    "objectID": "lectures/10/slides.html#definition-2",
    "href": "lectures/10/slides.html#definition-2",
    "title": "Machine Learning Engineering",
    "section": "Definition",
    "text": "Definition\nOrdinal encoding is a technique that assigns numerical values to categorical attributes based on their inherent order or rank."
  },
  {
    "objectID": "lectures/10/slides.html#feature-engineering---ordinal",
    "href": "lectures/10/slides.html#feature-engineering---ordinal",
    "title": "Machine Learning Engineering",
    "section": "Feature Engineering - Ordinal",
    "text": "Feature Engineering - Ordinal\nFor attributs with values such as ‘Poor’, ‘Average’, and ‘Good’, an ordinal encoding would make sense.\n\nHowever!\n\nfrom numpy import array\nfrom sklearn.preprocessing import OrdinalEncoder\n\nX =[['Poor'], ['Average'], ['Good'], ['Average'], ['Average']]\n\nencoder = OrdinalEncoder()\n\nencoder.fit(X)\nencoder.transform(X)\n\narray([[2.],\n       [0.],\n       [1.],\n       [0.],\n       [0.]])"
  },
  {
    "objectID": "lectures/10/slides.html#ordinalencoder-revised",
    "href": "lectures/10/slides.html#ordinalencoder-revised",
    "title": "Machine Learning Engineering",
    "section": "OrdinalEncoder (revised)",
    "text": "OrdinalEncoder (revised)\n\nfrom numpy import array\nfrom sklearn.preprocessing import OrdinalEncoder\n\nX =[['Poor'], ['Average'], ['Good'], ['Average'], ['Average']]\n\nencoder = OrdinalEncoder(categories=[['Poor', 'Average', 'Good']])\n\nencoder.fit(X)\n\nX_encoded = encoder.transform(X)\n\nX_encoded\n\narray([[0.],\n       [1.],\n       [2.],\n       [1.],\n       [1.]])\n\n\n\nThe desired order of the categories must be explicitly provided to the encoder; otherwise, it defaults to alphabetical order.\nAn ordinal encoder is appropriate when categorical attributes have a clear, inherent order or ranking, such as ‘Low’, ‘Medium’, and ‘High’, or ‘Poor’, ‘Average’, and ‘Good’. This encoding method preserves the ordinal relationships among categories.\nWhen data is inherently ordinal, this encoding is more compact and can be advantageous for machine learning models. However, if there is any uncertainty about the ordinal nature of the data, it is safer to use a OneHotEncoder."
  },
  {
    "objectID": "lectures/10/slides.html#definition-3",
    "href": "lectures/10/slides.html#definition-3",
    "title": "Machine Learning Engineering",
    "section": "Definition",
    "text": "Definition\nDiscretization involves grouping ordinal values into discrete categories.\n\n\nAKA binning, bucketing, or quantization."
  },
  {
    "objectID": "lectures/10/slides.html#feature-engineering-binning",
    "href": "lectures/10/slides.html#feature-engineering-binning",
    "title": "Machine Learning Engineering",
    "section": "Feature Engineering: Binning",
    "text": "Feature Engineering: Binning\nExample: Categorizing ages into bins such as ‘infant’, ‘child’, ‘teen’, ‘adult’, and ‘senior citizen’.\n\nAdvantages:\n\nEnables the algorithm to learn effectively with fewer training examples.\n\nDisadvantages:\n\nRequires domain expertise to define meaningful categories.\nMay lack generalizability; for example, the starting age for ‘senior citizen’ could be 60, 65, or 701.\n\n\nProviding hints or predefined bins can help a decision tree algorithm generate more compact trees, as it reduces the need for the classifier to independently learn decision boundaries.\nHowever, introducing such a strong bias may hinder the algorithm’s ability to discover meaningful decision boundaries on its own.\nCross-validation is an effective method to determine the best encoding scheme, but it is essential to withhold the test set until the final evaluation phase of the project to prevent data leakage and ensure unbiased assessment.\n\n\nYour instructor is concerned with your choice of cutoff"
  },
  {
    "objectID": "lectures/10/slides.html#functiontransformer",
    "href": "lectures/10/slides.html#functiontransformer",
    "title": "Machine Learning Engineering",
    "section": "FunctionTransformer",
    "text": "FunctionTransformer\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import FunctionTransformer\n\nbins = [0, 1, 13, 20, 60, np.inf]\nlabels = ['infant', 'kid', 'teen', 'adult', 'senior citizen']\n\ntransformer = FunctionTransformer(\n    pd.cut, kw_args={'bins': bins, 'labels': labels, 'retbins': False}\n)\n\nX = np.array([0.5, 2, 15, 25, 97])\ntransformer.fit_transform(X)\n\n['infant', 'kid', 'teen', 'adult', 'senior citizen']\nCategories (5, object): ['infant' &lt; 'kid' &lt; 'teen' &lt; 'adult' &lt; 'senior citizen']\n\n\n\n\nSe also: KBinsDiscretizer"
  },
  {
    "objectID": "lectures/10/slides.html#normalization",
    "href": "lectures/10/slides.html#normalization",
    "title": "Machine Learning Engineering",
    "section": "Normalization",
    "text": "Normalization\nLearning algorithms perform optimally when feature values have similar ranges, such as [-1,1] or [0,1].\n\nThis accelerates optimization (e.g., gradient descent).\n\nNormalization: \\[\n  \\frac{x_i^{(j)} - \\min^{(j)}}{\\max^{(j)} - \\min^{(j)}}\n\\]\n\n\nSee: sklearn.preprocessing.MinMaxScaler"
  },
  {
    "objectID": "lectures/10/slides.html#standardization",
    "href": "lectures/10/slides.html#standardization",
    "title": "Machine Learning Engineering",
    "section": "Standardization",
    "text": "Standardization\nStandardization (AKA z-score normalization) transforms each feature to have a normal distribution with a mean (\\(\\mu\\)) of 0 and a standard deviation (\\(\\sigma\\)) of 1.\n\\[\n\\frac{x_i^{(j)} - \\mu^{(j)}}{\\sigma^{(j)}}\n\\]\nNote: The range of values is not bounded!\n\n\nSee: sklearn.preprocessing.StandardScaler"
  },
  {
    "objectID": "lectures/10/slides.html#standardization-or-normalization",
    "href": "lectures/10/slides.html#standardization-or-normalization",
    "title": "Machine Learning Engineering",
    "section": "Standardization or Normalization?",
    "text": "Standardization or Normalization?\n\nTreat scaling as a hyperparameter and evaluate both normalization and standardization.\nStandardization is generally more robust to outliers than normalization.\nGuidelines from Andriy Burkov (2019), § 5:\n\nUse standardization for unsupervised learning tasks.\nUse standardization if features are approximately normally distributed.\nPrefer standardization in the presence of outliers.\nOtherwise, use normalization.\n\n\n\nDo you see why standardization is generally more robust to outliers than normalization?\nAn effective strategy for mitigating the impact of outliers in data is the application of a logarithmic transformation to the values. This technique reduces the skewness of the data, thereby diminishing the disproportionate influence of extreme values."
  },
  {
    "objectID": "lectures/10/slides.html#case-study---normal-distribution",
    "href": "lectures/10/slides.html#case-study---normal-distribution",
    "title": "Machine Learning Engineering",
    "section": "Case Study - Normal Distribution",
    "text": "Case Study - Normal Distribution\n\nimport numpy as np\nnp.random.seed(7)\n\n# Sample characteristics\nsample_size = 1000\nmu = 57\nsigma = 7\n\n# Generate values\nnorm_values = sigma * np.random.randn(sample_size) + mu\n\n# Add three outliers\nnorm_values = np.append(norm_values, [92, 95, 98])"
  },
  {
    "objectID": "lectures/10/slides.html#case-study---normal-distribution-1",
    "href": "lectures/10/slides.html#case-study---normal-distribution-1",
    "title": "Machine Learning Engineering",
    "section": "Case Study - Normal Distribution",
    "text": "Case Study - Normal Distribution"
  },
  {
    "objectID": "lectures/10/slides.html#logarithm",
    "href": "lectures/10/slides.html#logarithm",
    "title": "Machine Learning Engineering",
    "section": "Logarithm",
    "text": "Logarithm\n\n\n\n\n\n\n\n\n\n\n\nLogarithm of values from a normal distribution containing outliers."
  },
  {
    "objectID": "lectures/10/slides.html#normalization-1",
    "href": "lectures/10/slides.html#normalization-1",
    "title": "Machine Learning Engineering",
    "section": "Normalization",
    "text": "Normalization\n\n\n\n\n\n\n\n\n\n\n\nNormalization (MinMaxScaler) of values from a normal distribution containing outliers."
  },
  {
    "objectID": "lectures/10/slides.html#standardization-1",
    "href": "lectures/10/slides.html#standardization-1",
    "title": "Machine Learning Engineering",
    "section": "Standardization",
    "text": "Standardization\n\n\n\n\n\n\n\n\n\n\n\nStandardization (StandardScaler) of values from a normal distribution containing outliers."
  },
  {
    "objectID": "lectures/10/slides.html#logarithm-standardization",
    "href": "lectures/10/slides.html#logarithm-standardization",
    "title": "Machine Learning Engineering",
    "section": "Logarithm & Standardization",
    "text": "Logarithm & Standardization\n\n\n\n\n\n\n\n\n\n\n\nStandardization (StandardScaler) of values from a normal distribution containing outliers."
  },
  {
    "objectID": "lectures/10/slides.html#definition-4",
    "href": "lectures/10/slides.html#definition-4",
    "title": "Machine Learning Engineering",
    "section": "Definition",
    "text": "Definition\nMissing values refer to the absence of data points or entries in a dataset where a value is expected.\n\n\nAge is a good example, as some patients may withhold their age due to privacy concerns."
  },
  {
    "objectID": "lectures/10/slides.html#handling-missing-values",
    "href": "lectures/10/slides.html#handling-missing-values",
    "title": "Machine Learning Engineering",
    "section": "Handling Missing Values",
    "text": "Handling Missing Values\n\nDrop Examples\n\nFeasible if the dataset is large and outcome is unaffected.\n\nDrop Features\n\nSuitable if it does not impact the project’s outcome.\n\nUse Algorithms Handling Missing Data\n\nExample: XGBoost\nNote: Some algorithms like sklearn.linear_model.LinearRegression cannot handle missing values.\n\nData Imputation\n\nReplace missing values with computed values."
  },
  {
    "objectID": "lectures/10/slides.html#definition-5",
    "href": "lectures/10/slides.html#definition-5",
    "title": "Machine Learning Engineering",
    "section": "Definition",
    "text": "Definition\nData imputation is the process of replacing missing values in a dataset with substituted values, typically using statistical or machine learning methods."
  },
  {
    "objectID": "lectures/10/slides.html#data-imputation-strategy",
    "href": "lectures/10/slides.html#data-imputation-strategy",
    "title": "Machine Learning Engineering",
    "section": "Data Imputation Strategy",
    "text": "Data Imputation Strategy\nReplace missing values with mean or median of the attribute.\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\n\nX = imputer.fit_transform(X)\n\n\n\nCons: Ignores feature correlations and complex relationships.\nMode Imputation: Replace missing values with the most frequent value; also ignores feature correlations.\n\n\nData imputation inherently relies on several assumptions, which may not always hold true.\nRandomness Assumption: Many methods (e.g., mean/median imputation) assume that missingness is unrelated to any data.\nModel Bias: Incorrect randomness assumptions can lead to biased estimates and flawed conclusions.\nInformation Loss: Imputation can obscure patterns, leading to loss of valuable information for advanced models.\nProceed with caution!"
  },
  {
    "objectID": "lectures/10/slides.html#data-imputation-strategy-1",
    "href": "lectures/10/slides.html#data-imputation-strategy-1",
    "title": "Machine Learning Engineering",
    "section": "Data Imputation Strategy",
    "text": "Data Imputation Strategy\nSpecial Value Method: Replace missing values with a value outside the normal range (e.g., use -1 or 2 for data normalized between [0,1]).\n\nObjective: Enable the learning algorithm to recognize and appropriately handle missing values."
  },
  {
    "objectID": "lectures/10/slides.html#data-imputation-strategy-2",
    "href": "lectures/10/slides.html#data-imputation-strategy-2",
    "title": "Machine Learning Engineering",
    "section": "Data Imputation Strategy",
    "text": "Data Imputation Strategy\n\nMiddle-Range Imputation: Replace missing values with a value in the middle of the normal range (e.g., use 0 for data distributed in the range [-1,1]).\n\nCategorical Data: Use small non-zero numerical values.\n\nExample: Use [0.25, 0.25, 0.25, 0.25] instead of [1, 0, 0, 0] for ‘Poor’, [0, 1, 0, 0] for ‘Everage’, [0, 0, 1, 0] for ‘Good’, and [0, 0, 0, 1] for ‘Excellent’.\n\nObjective: Minimize the impact of imputed values on the results.\n\n\n\nSelection of Method: The effectiveness of imputation methods can vary, and it is essential to compare multiple techniques to determine the best approach for your specific dataset."
  },
  {
    "objectID": "lectures/10/slides.html#alternative-approach",
    "href": "lectures/10/slides.html#alternative-approach",
    "title": "Machine Learning Engineering",
    "section": "Alternative Approach",
    "text": "Alternative Approach\n\nProblem Definition: Predict unknown (missing) labels for given examples.\nHave you encountered this kind of problem before?\nRelevance: This can be framed as a supervised learning problem.\n\nLet \\(\\hat{x_i}\\) be a new example: \\([x_i^{(1)}, x_i^{(2)}, \\ldots, x_i^{(j-1)}, x_i^{(j+1)}, \\ldots, x_i^{(D)}]\\).\nLet \\(\\hat{y}_i = x_i^{j}\\).\nTraining Set: Use examples where \\(x_i^{j}\\) is not missing.\nMethod: Train a classifier on this set to predict (impute) the missing values."
  },
  {
    "objectID": "lectures/10/slides.html#using-ml-for-imputation",
    "href": "lectures/10/slides.html#using-ml-for-imputation",
    "title": "Machine Learning Engineering",
    "section": "Using ML for Imputation",
    "text": "Using ML for Imputation\n\nInstance-Based Method:\n\nUse \\(k\\) nearest neighbors (k-NN) to find the \\(k\\) closest examples and impute using the non-missing values from the neighborhood.\n\nModel-Based Methods:\n\nEmploy advanced techniques such as random forests, tensor decomposition, or deep neural networks."
  },
  {
    "objectID": "lectures/10/slides.html#why-use-these-methods",
    "href": "lectures/10/slides.html#why-use-these-methods",
    "title": "Machine Learning Engineering",
    "section": "Why Use these Methods?",
    "text": "Why Use these Methods?\n\nAdvantages:\n\nEffectively handle complex relationships and correlations between features.\n\nDisadvantages:\n\nCost-intensive in terms of labor, CPU time, and memory resources."
  },
  {
    "objectID": "lectures/10/slides.html#definition-6",
    "href": "lectures/10/slides.html#definition-6",
    "title": "Machine Learning Engineering",
    "section": "Definition",
    "text": "Definition\nThe class imbablance problem is a scenario where the number of instances in one class significantly outnumbers the instances in other classes.\n\nModels tend to be biased towards the majority class, leading to poor performance on the minority class.\n\n\n\nStandard evaluation metrics like accuracy may be misleading in the presence of class imbalance."
  },
  {
    "objectID": "lectures/10/slides.html#solutions",
    "href": "lectures/10/slides.html#solutions",
    "title": "Machine Learning Engineering",
    "section": "Solutions",
    "text": "Solutions\n\nResampling: Techniques such as oversampling the minority class or undersampling the majority class.\nAlgorithmic Adjustments: Using cost-sensitive learning or modifying decision thresholds.\nSynthetic Data: Generating synthetic samples for the minority class using methods like SMOTE (Synthetic Minority Over-sampling Technique).\n\n\n\nChawla et al. (2002) presents the original work, whereas Pradipta et al. (2021) is a recent review.\nOversampling\n\nOversampling can lead to overfitting, especially if the synthetic samples are very similar to the existing ones.\nImpact: The model may perform well on training data but generalize poorly to unseen data.\n\nUndersampling\n\nLoss of Information reduces the number of instances in the majority class.\nImpact: Potentially discards valuable information and can lead to underfitting.\nReduced Model Performance: Smaller training dataset may not capture the complexity of the problem.\nImpact: Can result in a less accurate and less robust model.\n\n\n\nApply solutions only to the training set to prevents data leakage."
  },
  {
    "objectID": "lectures/10/slides.html#further-readings",
    "href": "lectures/10/slides.html#further-readings",
    "title": "Machine Learning Engineering",
    "section": "Further readings",
    "text": "Further readings\n\n\n\n\n\nMachine Learning Engineering by Andriy Burkov (A. Burkov 2020).\nCovers data collection, storage, preprocessing, feature engineering, model testing and debugging, deployment, retirement, and maintenance.\nFrom the author of The Hundred-Page Machine Learning Book (Andriy Burkov 2019).\nAvailable under a “read first, buy later” model."
  },
  {
    "objectID": "lectures/10/slides.html#summary",
    "href": "lectures/10/slides.html#summary",
    "title": "Machine Learning Engineering",
    "section": "Summary",
    "text": "Summary\n\nTraining Set Size: Impact on model efficacy and generalization.\nAttribute Encoding: Evaluation of techniques to avoid bias and possibly speed up the training.\nPreprocessing:\n\nData Scaling\nHandling Missing Values\nManaging Class Imbalance"
  },
  {
    "objectID": "lectures/10/slides.html#next-lecture",
    "href": "lectures/10/slides.html#next-lecture",
    "title": "Machine Learning Engineering",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will introduce artificial neural networks."
  },
  {
    "objectID": "lectures/10/slides.html#references",
    "href": "lectures/10/slides.html#references",
    "title": "Machine Learning Engineering",
    "section": "References",
    "text": "References\n\n\nBanko, Michele, and Eric Brill. 2001. “Scaling to Very Very Large Corpora for Natural Language Disambiguation.” In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, 26–33. ACL ’01. USA: Association for Computational Linguistics. https://doi.org/10.3115/1073012.1073017.\n\n\nBurkov, A. 2020. Machine Learning Engineering. True Positive Incorporated. https://books.google.ca/books?id=HeXizQEACAAJ.\n\n\nBurkov, Andriy. 2019. The Hundred-Page Machine Learning Book. Andriy Burkov.\n\n\nChawla, N V, K W Bowyer, L O Hall, and W P Kegelmeyer. 2002. “SMOTE: Synthetic minority over-sampling technique.” Journal of Artificial Intelligence Research 16: 321–57.\n\n\nHalevy, Alon, Peter Norvig, and Fernando Pereira. 2009. “The Unreasonable Effectiveness of Data.” IEEE Intelligent Systems 24 (2): 8–12.\n\n\nKaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. “Scaling Laws for Neural Language Models.” https://arxiv.org/abs/2001.08361.\n\n\nPradipta, Gede Angga, Retantyo Wardoyo, Aina Musdholifah, I Nyoman Hariyasa Sanjaya, and Muhammad Ismail. 2021. “SMOTE for Handling Imbalanced Data Problem : A Review.” 2021 Sixth International Conference on Informatics and Computing (ICIC) 00: 1–8. https://doi.org/10.1109/icic54025.2021.9632912.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nSakai, Masato, Akihisa Sakurai, Siyuan Lu, Jorge Olano, Conrad M. Albrecht, Hendrik F. Hamann, and Marcus Freitag. 2024. “AI-accelerated Nazca survey nearly doubles the number of known figurative geoglyphs and sheds light on their purpose.” Proceedings of the National Academy of Sciences 121 (40): e2407652121. https://doi.org/10.1073/pnas.2407652121.\n\n\nShumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross Anderson, and Yarin Gal. 2024. “AI models collapse when trained on recursively generated data.” Nature 631 (8022): 755–59. https://doi.org/10.1038/s41586-024-07566-y."
  },
  {
    "objectID": "lectures/10/slides.html#pipeline",
    "href": "lectures/10/slides.html#pipeline",
    "title": "Machine Learning Engineering",
    "section": "Pipeline",
    "text": "Pipeline\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('attribs_adder', CombinedAttributesAdder()),\n        ('std_scaler', StandardScaler()),\n        ])\n\ntraining_num_tr = num_pipeline.fit_transform(training_num)\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), [\"sequence\"]),\n    ])\n\ntraining_prepared = full_pipeline.fit_transform(training)"
  },
  {
    "objectID": "lectures/10/slides.html#gpt-4o-interactions-2024-09-30",
    "href": "lectures/10/slides.html#gpt-4o-interactions-2024-09-30",
    "title": "Machine Learning Engineering",
    "section": "GPT-4o interactions 2024-09-30",
    "text": "GPT-4o interactions 2024-09-30\nI presented GPT-4o with an image of the main character from Marcel the Shell With Shoes On and had the following interactions.\nMarcel: How would you describe the subject of the image, its artistic quality, technique, and rendering style?\nGPT-4o: The image depicts a whimsical character that resembles a small shell with one large, expressive eye. It stands on two legs wearing shoes, giving it a cute and almost anthropomorphic appearance. The character has a surreal and quirky look, which lends it a sense of personality and charm.\nArtistic Quality:\nThe image is rendered with a high degree of polish and smoothness, possibly created digitally. The textures, shading, and lighting are soft and subtle, giving the character a smooth and rounded look. The rendering captures a delicate balance between realism (in the textures of the shell and shoes) and cartoon-like abstraction (in the exaggerated eye and small stature).\nTechnique:\nThe artist appears to have employed a blend of digital painting and 3D-like modeling techniques, with careful attention to detail in the reflections in the eye and the textures of the shell and shoes. The color palette is muted, using soft tones that evoke a gentle, friendly atmosphere.\nRendering Style:\nThe rendering style is a mix of minimalist and hyperrealist elements. The minimalism is seen in the simplified forms of the character—particularly the body and legs—while the hyperrealism comes through in the detailing of the eye and the subtle textures. This gives the character a tactile, almost tangible quality while maintaining its fantastical, imaginative essence.\nThe overall effect of the design is both charming and surreal, combining everyday objects (a shell, shoes) with anthropomorphic and fantastical elements to create a unique, playful character.\nMarcel: Create an image based on the following description: The image depicts a whimsical character that resembles a small shell with one large, expressive eye. It stands on two legs wearing shoes, giving it a cute and almost anthropomorphic appearance. The character has a surreal and quirky look, which lends it a sense of personality and charm.\nArtistic Quality:\nThe image is rendered with a high degree of polish and smoothness, possibly created digitally. The textures, shading, and lighting are soft and subtle, giving the character a smooth and rounded look. The rendering captures a delicate balance between realism (in the textures of the shell and shoes) and cartoon-like abstraction (in the exaggerated eye and small stature).\nTechnique:\nThe artist appears to have employed a blend of digital painting and 3D-like modeling techniques, with careful attention to detail in the reflections in the eye and the textures of the shell and shoes. The color palette is muted, using soft tones that evoke a gentle, friendly atmosphere.\nRendering Style:\nThe rendering style is a mix of minimalist and hyperrealist elements. The minimalism is seen in the simplified forms of the character—particularly the body and legs—while the hyperrealism comes through in the detailing of the eye and the subtle textures. This gives the character a tactile, almost tangible quality while maintaining its fantastical, imaginative essence.\nThe overall effect of the design is both charming and surreal, combining everyday objects (a shell, shoes) with anthropomorphic and fantastical elements to create a unique, playful character.\nGTP-4o: Here is the image based on the description you provided. Let me know if you’d like to make any adjustments!"
  },
  {
    "objectID": "lectures/10/index.html",
    "href": "lectures/10/index.html",
    "title": "Lecture 10",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 2 must be submitted no later than October 20, 2025, at 11 PM. Please refer to the assignment description available on Brightspace."
  },
  {
    "objectID": "lectures/10/index.html#prepare",
    "href": "lectures/10/index.html#prepare",
    "title": "Lecture 10",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 705–708"
  },
  {
    "objectID": "lectures/10/index.html#participate",
    "href": "lectures/10/index.html#participate",
    "title": "Lecture 10",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/11/slides.html#quote-of-the-day",
    "href": "lectures/11/slides.html#quote-of-the-day",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n;document.getElementById(\"tweet-65152\").innerHTML = tweet[\"html\"];\nThe Nobel Prize in Physics 2024 was awarded to John J. Hopfield and Geoffrey E. Hinton “for foundational discoveries and inventions that enable machine learning with artificial neural networks”"
  },
  {
    "objectID": "lectures/11/slides.html#learning-objectives",
    "href": "lectures/11/slides.html#learning-objectives",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nExplain perceptrons and MLPs: structure, function, history, and limitations.\nDescribe activation functions: their role in enabling complex pattern learning.\nImplement a feedforward neural network with Keras on Fashion-MNIST.\nInterpret neural network training and results: visualization and evaluation metrics.\nFamiliarize with deep learning frameworks: PyTorch, TensorFlow, and Keras for model building and deployment.\n\n\nAs stated at the beginning of this course, there are two primary schools of thought in artificial intelligence: symbolic AI and connectionism. While the symbolic approach initially dominated the field, the connectionist approach is now more prevalent. We will now focus on connectionism."
  },
  {
    "objectID": "lectures/11/slides.html#neural-networks-nn",
    "href": "lectures/11/slides.html#neural-networks-nn",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Neural Networks (NN)",
    "text": "Neural Networks (NN)\nWe now shift our focus to a family of machine learning models that draw inspiration from the structure and function of biological neural networks found in animals.\n\n\nAKA artificial neural networks or neural nets, abbreviated as ANN or NN."
  },
  {
    "objectID": "lectures/11/slides.html#machine-learning-problems",
    "href": "lectures/11/slides.html#machine-learning-problems",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Machine Learning Problems",
    "text": "Machine Learning Problems\n\n\n\n\n\nSupervised Learning: Classification, Regression\nUnsupervised Learning: Autoencoders, Self-Supervised\nReinforcement Learning: Now an Integral Component\n\n\n\nWe will begin our exploration within the framework of supervised learning."
  },
  {
    "objectID": "lectures/11/slides.html#a-neuron",
    "href": "lectures/11/slides.html#a-neuron",
    "title": "Introduction to Artificial Neural Networks",
    "section": "A neuron",
    "text": "A neuron\n\n\n\n\n\n\n\nIn the study of artificial intelligence, it is logical to derive inspiration from the most well-understood form of intelligence: the human brain. The brain is composed of a complex network of neurons, which together form biological neural networks. Although each neuron exhibits relatively simple behavior, it is connected to thousands of other neurons, contributing to the intricate functionality of these networks.\nA neuron can be conceptualized as a basic computational unit, and the complexity of brain function arises from the interconnectedness of these units.\nYann LeCun and other researchers have frequently noted that artificial neural networks used in machine learning resemble biological neural networks in much the same way that an airplane’s wings resemble those of a bird.\n\n\nAttribution: Jennifer Walinga, CC BY-SA 4.0"
  },
  {
    "objectID": "lectures/11/slides.html#interconnected-neurons",
    "href": "lectures/11/slides.html#interconnected-neurons",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Interconnected neurons",
    "text": "Interconnected neurons\n\n\n\nFrom biology, we essentially adopt the concept of simple computational units that are interconnected to form a network, which collectively performs complex computations.\nWhile research into understanding biological neural networks is undeniably important, the field of artificial neural networks has incorporated only a limited number of key concepts from this research.\n\n\nAttribution: Molecular Mechanism of Synaptic Function from the Howard Hughes Medical Institute (HHMI). Published on YouTube on 2018-11-15."
  },
  {
    "objectID": "lectures/11/slides.html#connectionist",
    "href": "lectures/11/slides.html#connectionist",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Connectionist",
    "text": "Connectionist\n\n\n\n\n\n\n\nAnother characteristic of biological neural networks that we adopt is the organization of neurons into layers, particularly evident in the cerebral cortex.\nThe term “connectionists” comes from the idea that nodes in these models are interconnected. Instead of being explicitly programmed, these models learn their behavior through training. Deep learning is a connectionist approach.\nNeural networks (NNs) consist of layers of interconnected nodes (neurons), each connection having an associated weight.\nNeural networks process input data through these weighted connections, and learning occurs by adjusting the weights based on errors in the training data.\n\n\nAttribution: LeNail, (2019). NN-SVG: Publication-Ready Neural Network Architecture Schematics. Journal of Open Source Software, 4(33), 747, https://doi.org/10.21105/joss.00747 (GitHub)"
  },
  {
    "objectID": "lectures/11/slides.html#hierarchy-of-concepts",
    "href": "lectures/11/slides.html#hierarchy-of-concepts",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Hierarchy of concepts",
    "text": "Hierarchy of concepts\n\n\n\n\n\n\n\nIn the book “Deep Learning” (Goodfellow, Bengio, and Courville 2016), authors Goodfellow, Bengio, and Courville define deep learning as a subset of machine learning that enables computers to “understand the world in terms of a hierarchy of concepts.”\nThis hierarchical approach is one of deep learning’s most significant contributions. It reduces the need for manual feature engineering and redirects the focus toward the engineering of neural network architectures.\n\n\nAttribution: LeCun, Bengio, and Hinton (2015)"
  },
  {
    "objectID": "lectures/11/slides.html#computations-with-neurodes",
    "href": "lectures/11/slides.html#computations-with-neurodes",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Computations with neurodes",
    "text": "Computations with neurodes\n\n\n\n\n\nwhere \\(x_1, x_2 \\in \\{0,1\\}\\) and \\(f(z)\\) is an indicator function: \\[\nf(z)= \\begin{cases}0, & z&lt;\\theta \\\\ 1, & z \\geq \\theta\\end{cases}\n\\]\n\n\nIn mathematics, \\(f(z)\\), as defined above, is known as an indicator function or a characteristic function.\nThese neurodes have one or more binary inputs, taking a value of 0 or 1, and one binary output.\nThey showed that such units could implement Boolean functions such as AND, OR, and NOT.\nBut also that networks of such units can compute any logical proposition.\n\n\nMcCulloch and Pitts (1943) termed artificial neurons, neurodes, for “neuron” + “node”."
  },
  {
    "objectID": "lectures/11/slides.html#computations-with-neurodes-1",
    "href": "lectures/11/slides.html#computations-with-neurodes-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Computations with neurodes",
    "text": "Computations with neurodes\n\\[\ny = f(x_1 + x_2)= \\begin{cases}0, & x_1 + x_2 &lt;\\theta \\\\ 1, & x_1 + x_2 \\geq \\theta\\end{cases}\n\\]\n\nWith \\(\\theta = 2\\), the neurode implements an AND logic gate.\nWith \\(\\theta = 1\\), the neurode implements an OR logic gate.\n\n\n\nWith \\(\\theta = 1\\), $x_1 {1} and \\(x_2\\) multiplied by (-1), \\(y = 0\\) when \\(x_2 = 1\\), \\(y = 1\\), if \\(x_2 = 0\\).\n\\[\ny = f(x_1 + (-1) x_2)= \\begin{cases}0, & x_1 + x_2 &lt;\\theta \\\\ 1, & x_1 + (-1) x_2 \\geq \\theta\\end{cases}\n\\]\nNeurons can be broadly categorized into two primary types: excitatory and inhibitory.\n\n\nMore complex logic can be constructed by multiplying the inputs by -1, which is interpreted as inhibitory. Namely, this allows building a logical NOT."
  },
  {
    "objectID": "lectures/11/slides.html#computations-with-neurodes-2",
    "href": "lectures/11/slides.html#computations-with-neurodes-2",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Computations with neurodes",
    "text": "Computations with neurodes\n\nDigital computations can be broken down into a sequence of logical operations, enabling neurode networks to execute any computation.\nMcCulloch and Pitts (1943) did not focus on learning parameter \\(\\theta\\).\nThey introduced a machine that computes any function but cannot learn.\n\n\nFrom this work, we take the idea that networks of such units perform computations. Signal propagates from one end of the network to compute a result."
  },
  {
    "objectID": "lectures/11/slides.html#threshold-logic-unit",
    "href": "lectures/11/slides.html#threshold-logic-unit",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Threshold logic unit",
    "text": "Threshold logic unit\n\n\n\nIn 1957, Frank Rosenblatt developed a conceptually distinct model of a neuron known as the threshold logic unit, which he published in 1958.\nIn this model, both the inputs and the output of the neuron are represented as real values. Notably, each input connection has an associated weight.\nThe left section of the neuron, denoted by the sigma symbol, represents the computation of a weighted sum of its inputs, expressed as \\(\\theta_1 x_1 + \\theta_2 x_2 + \\ldots + \\theta_D x_D + b\\).\nThis sum is then processed through a step function, right section of the neuron, to generate the output.\nHere, \\(x^T \\theta\\) represents the dot product of two vectors: \\(x\\) and \\(\\theta\\). Here, \\(x^T\\) denotes the transpose of the vector \\(x\\), converting it from a row vector to a column vector, allowing the dot product operation to be performed with the vector \\(\\theta\\).\nThe dot product \\(x^T \\theta\\) is then a scalar given by:\n\\[\nx^T \\theta = x^{(1)} \\theta_1 + x^{(2)} \\theta_2 + \\cdots + x_{(D)} \\theta_D\n\\]\nwhere \\(x^{(j)}\\) and \\(theta_j\\) are the components of the vectors \\(x\\) and \\(\\theta\\), respectively.\n\n\nRosenblatt (1958)"
  },
  {
    "objectID": "lectures/11/slides.html#simple-step-functions",
    "href": "lectures/11/slides.html#simple-step-functions",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Simple Step Functions",
    "text": "Simple Step Functions\n\n\n\n\n\n\n\n\\(\\text{heaviside}(t)\\) =\n\n1, if \\(t \\geq 0\\)\n0, if \\(t &lt; 0\\)\n\n\n\n\n\n\n\n\\(\\text{sign}(t)\\) =\n\n1, if \\(t &gt; 0\\)\n0, if \\(t = 0\\)\n-1, if \\(t &lt; 0\\)\n\n\n\nCommon step functions include the heavyside function (0 if the input is negative and 1 otherwise) or the sign function (-1 if the input is negative, 0 if the input is zero, 1 otherwise)."
  },
  {
    "objectID": "lectures/11/slides.html#notation",
    "href": "lectures/11/slides.html#notation",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Notation",
    "text": "Notation\n\n\n\n\n\n\n\nAdd an extra feature with a fixed value of 1 to the input. Associate it with weight \\(b = \\theta_{0}\\), where \\(b\\) is the bias/intercept term."
  },
  {
    "objectID": "lectures/11/slides.html#notation-1",
    "href": "lectures/11/slides.html#notation-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Notation",
    "text": "Notation\n\n\n\n\n\n\n\nThe threshold logic unit is analogous to logistic regression, with the primary distinction being the substitution of the logistic (sigmoid) function with a step function. Similar to logistic regression, the perceptron is employed for classification tasks.\n\n\n\\(\\theta_{0} = b\\) is the bias/intercept term."
  },
  {
    "objectID": "lectures/11/slides.html#perceptron",
    "href": "lectures/11/slides.html#perceptron",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Perceptron",
    "text": "Perceptron\n\n\n\n\n\n\n\nSince the threshold logic units in this single layer also generate the output, it is referred to as the output layer.\n\n\nA perceptron consists of one or more threshold logic units arranged in a single layer, with each unit connected to all inputs. This configuration is referred to as fully connected or dense."
  },
  {
    "objectID": "lectures/11/slides.html#perceptron-1",
    "href": "lectures/11/slides.html#perceptron-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Perceptron",
    "text": "Perceptron\n\n\n\n\n\n\n\nClassification tasks, can be further divided into multilabel and multiclass classification.\n\nMulticlass Classification:\n\nIn multiclass classification, each instance is assigned to one and only one class out of a set of three or more possible classes. The classes are mutually exclusive, meaning that an instance cannot belong to more than one class at the same time.\nExample: Classifying an image as either a cat, dog, or bird. Each image can only belong to one of these categories.\n\nMultilabel Classification:\n\nIn multilabel classification, each instance can be associated with multiple classes simultaneously. The classes are not mutually exclusive, allowing for the possibility that an instance can belong to several classes at once.\nExample: Tagging an image with multiple attributes such as “outdoor,” “sunset,” and “beach.” The image can simultaneously belong to all these labels.\n\n\nThe key difference lies in the relationship between classes: multiclass classification deals with a single label per instance, while multilabel classification handles multiple labels for each instance.\n\n\nAs this perceptron generates multiple outputs simultaneously, it performs multiple binary predictions, making it as a multilabel classifier (can also be used as multiclass classifier)."
  },
  {
    "objectID": "lectures/11/slides.html#notation-2",
    "href": "lectures/11/slides.html#notation-2",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Notation",
    "text": "Notation\n\n\n\n\n\n\n\nAs before, introduce an additional feature with a value of 1 to the input. Assign a bias \\(b\\) to each neuron. Each incoming connection implicitly has an associated weight."
  },
  {
    "objectID": "lectures/11/slides.html#notation-3",
    "href": "lectures/11/slides.html#notation-3",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Notation",
    "text": "Notation\n\n\\(X\\) is the input data matrix where each row corresponds to an example and each column represents one of the \\(D\\) features.\n\\(W\\) is the weight matrix, structured with one row per input (feature) and one column per neuron.\nBias terms can be represented separately; both approaches appear in the literature. Here, \\(b\\) is a vector with a length equal to the number of neurons.\n\n\n\nWith neural networks, the parameters of the model are often reffered to as \\(w\\) (vector) or \\(W\\) (matrix), rather than \\(\\theta\\)."
  },
  {
    "objectID": "lectures/11/slides.html#discussion",
    "href": "lectures/11/slides.html#discussion",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Discussion",
    "text": "Discussion\n\nThe algorithm to train the perceptron closely resembles stochastic gradient descent.\n\nIn the interest of time and to avoid confusion, we will skip this algorithm and focus on multilayer perception (MLP) and its training algorithm, backpropagation."
  },
  {
    "objectID": "lectures/11/slides.html#historical-note-and-justification",
    "href": "lectures/11/slides.html#historical-note-and-justification",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Historical Note and Justification",
    "text": "Historical Note and Justification\n\n\n\n\n\n\n\nThis limitation also applies to other linear classifiers, such as logistic regression.\nConsequently, due to these limitations and a lack of practical applications, some researchers abandoned the perceptron.\n\n\nMinsky and Papert (1969) demonstrated the limitations of perceptrons, notably their inability to solve exclusive OR (XOR) classification problems: \\({([0,1],\\mathrm{true}), ([1,0],\\mathrm{true}), ([0,0],\\mathrm{false}), ([1,1],\\mathrm{false})}\\)."
  },
  {
    "objectID": "lectures/11/slides.html#multilayer-perceptron",
    "href": "lectures/11/slides.html#multilayer-perceptron",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Multilayer Perceptron",
    "text": "Multilayer Perceptron\n\n\n\n\n\n\n\nA multilayer perceptron (MLP) includes an input layer and one or more layers of threshold logic units. Layers that are neither input nor output are termed hidden layers."
  },
  {
    "objectID": "lectures/11/slides.html#xor-classification-problem",
    "href": "lectures/11/slides.html#xor-classification-problem",
    "title": "Introduction to Artificial Neural Networks",
    "section": "XOR Classification problem",
    "text": "XOR Classification problem\n\n\n\n\\(x^{(1)}\\)\n\\(x^{(2)}\\)\n\\(y\\)\n\\(o_1\\)\n\\(o_2\\)\n\\(o_3\\)\n\n\n\n\n1\n0\n1\n0\n1\n1\n\n\n0\n1\n1\n0\n1\n1\n\n\n0\n0\n0\n0\n0\n0\n\n\n1\n1\n0\n1\n1\n0\n\n\n\n\n\nI developed an Excel spreadsheet to verify that the proposed multilayer perceptron effectively solves the XOR classification problem.\nThe step function used in the above model is the heavyside function.\n\n\n\\(x^{(1)}\\) and \\(x^{(2)}\\) are two attributes, \\(y\\) is the target, \\(o_1\\), \\(o_2\\), and \\(o_3 = h_\\theta(x)\\), are the output of the top left, bottom left, and right threshold units. Clearly \\(h_\\theta(x) = y, \\forall x \\in X\\). The challenge during Rosenblatt’s time was the lack of algorithms to train multi-layer networks."
  },
  {
    "objectID": "lectures/11/slides.html#feedforward-neural-network-fnn",
    "href": "lectures/11/slides.html#feedforward-neural-network-fnn",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Feedforward Neural Network (FNN)",
    "text": "Feedforward Neural Network (FNN)\n\n\n\n\n\n\n\nThe network consists of three layers: input, hidden, and output. The input layer contains two nodes, the hidden layer comprises three nodes, and the output layer has two nodes. Additional hidden layers and nodes per layer can be added, which will be discussed later.\nIt is often useful to include explicit input nodes that do not perform calculations, known as input units or input neurons. These nodes act as placeholders to introduce input features into the network, passing data directly to the next layer without transformation. In the network diagram, these are the light blue nodes on the left, labeled 1 and 2. Typically, the number of input units corresponds to the number of features.\nFor clarity, nodes are labeled to facilitate discussion of the weights between them, such as \\(w_{1,5}\\) between nodes 1 and 5. Similarly, the output of a node is denoted by \\(o_k\\), where \\(k\\) represents the node’s label. For example, for \\(k=3\\), the output would be \\(o_3\\).\n\n\nInformation in this architecture flows unidirectionally—from left to right, moving from input to output. Consequently, it is termed a feedforward neural network."
  },
  {
    "objectID": "lectures/11/slides.html#forward-pass-computatation",
    "href": "lectures/11/slides.html#forward-pass-computatation",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Forward Pass (Computatation)",
    "text": "Forward Pass (Computatation)\n\n\n\n\n\\(o3 = \\sigma(w_{13} x^{(1)}+ w_{23} x^{(2)} + b_3)\\)\n\\(o4 = \\sigma(w_{14} x^{(1)}+ w_{24} x^{(2)} + b_4)\\)\n\\(o5 = \\sigma(w_{15} x^{(1)}+ w_{25} x^{(2)} + b_5)\\)\n\\(o6 = \\sigma(w_{36} o_3 + w_{46} o_4 + w_{56} o_5 + b_6)\\)\n\\(o7 = \\sigma(w_{37} o_3 + w_{47} o_4 + w_{57} o_5 + b_7)\\)\n\n\n\nTo simplify the figure, I have opted not to display the bias terms, though they remain crucial components. Specifically, \\(b_3\\) represents the bias term associated with node 3.\nIf bias terms were not significant, the training process would naturally reduce them to zero. Bias terms are essential as they enable the adjustment of the decision boundary, allowing the model to learn more complex patterns that weights alone cannot capture. By offering additional degrees of freedom, they also contribute to faster convergence during training.\n\n\nFirst, it’s important to understand the information flow: this network computes two outputs from its inputs."
  },
  {
    "objectID": "lectures/11/slides.html#forward-pass-computatation-1",
    "href": "lectures/11/slides.html#forward-pass-computatation-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Forward Pass (Computatation)",
    "text": "Forward Pass (Computatation)\n\nimport numpy as np\n\n# Sigmoid function\n\ndef sigma(x):\n    return 1 / (1 + np.exp(-x))\n\n# Input (two attributes) vector, one example of our trainig set\n\nx1, x2 = (0.5, 0.9)\n\n# Initializing the weights of layers 2 and 3 to random values\n\nw13, w14, w15, w23, w24, w25 = np.random.uniform(low=-1, high=1, size=6)\nw36, w46, w56, w37, w47, w57 = np.random.uniform(low=-1, high=1, size=6)\n\n# Initializing all 5 bias terms to random values\n\nb3, b4, b5, b6, b7 = np.random.uniform(low=-1, high=1, size=5)\n\no3 = sigma(w13 * x1 + w23 * x2 + b3)\no4 = sigma(w14 * x1 + w24 * x2 + b4)\no5 = sigma(w15 * x1 + w25 * x2 + b5)\no6 = sigma(w36 * o3 + w46 * o4 + w56 * o5 + b6)\no7 = sigma(w37 * o3 + w47 * o4 + w57 * o5 + b7)\n\n(o6, o7)\n\n(np.float64(0.46460973054399307), np.float64(0.24291381296138898))\n\n\n\nThe example above illustrates the computation process with specific values. Before training a neural network, it is standard practice to initialize the weights and biases with random values. Gradient descent is then employed to iteratively adjust these parameters, aiming to minimize the loss function."
  },
  {
    "objectID": "lectures/11/slides.html#forward-pass-computatation-2",
    "href": "lectures/11/slides.html#forward-pass-computatation-2",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Forward Pass (Computatation)",
    "text": "Forward Pass (Computatation)\n\n\n\n\n\n\n\nThe information flow remains consistent even in more complex networks. Networks with many layers are called deep neural networks (DNN).\nProduced using NN-SVG, LeNail (2019)."
  },
  {
    "objectID": "lectures/11/slides.html#forward-pass-computatation-3",
    "href": "lectures/11/slides.html#forward-pass-computatation-3",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Forward Pass (Computatation)",
    "text": "Forward Pass (Computatation)\n\n\n\n\n\n\n\nSame network with bias terms shown.\nProduced using NN-SVG, LeNail (2019)."
  },
  {
    "objectID": "lectures/11/slides.html#activation-function",
    "href": "lectures/11/slides.html#activation-function",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Activation Function",
    "text": "Activation Function\n\nAs will be discussed later, the training algorithm, known as backpropagation, employs gradient descent, necessitating the calculation of the partial derivatives of the loss function.\nThe step function in the multilayer perceptron had to be replaced, as it consists only of flat surfaces. Gradient descent cannot progress on flat surfaces due to their zero derivative."
  },
  {
    "objectID": "lectures/11/slides.html#activation-function-1",
    "href": "lectures/11/slides.html#activation-function-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Activation Function",
    "text": "Activation Function\n\nNonlinear activation functions are paramount because, without them, multiple layers in the network would only compute a linear function of the inputs.\nAccording to the Universal Approximation Theorem, sufficiently large deep networks with nonlinear activation functions can approximate any continuous function. See Universal Approximation Theorem."
  },
  {
    "objectID": "lectures/11/slides.html#sigmoid",
    "href": "lectures/11/slides.html#sigmoid",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Sigmoid",
    "text": "Sigmoid\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\sigma(t) = \\frac{1}{1 + e^{-t}}\n\\]"
  },
  {
    "objectID": "lectures/11/slides.html#hyperbolic-tangent-function",
    "href": "lectures/11/slides.html#hyperbolic-tangent-function",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Hyperbolic Tangent Function",
    "text": "Hyperbolic Tangent Function\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\tanh(t) = 2 \\sigma(2t) - 1\n\\]\n\n\n\nThis S-shaped curve, similar to the sigmoid function, produces output values ranging from -1 to 1. According to Géron (2022), this range helps each layer’s output to be approximately centered around 0 at the start of training, thereby accelerating convergence."
  },
  {
    "objectID": "lectures/11/slides.html#rectified-linear-unit-function-relu",
    "href": "lectures/11/slides.html#rectified-linear-unit-function-relu",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Rectified linear unit function (ReLU)",
    "text": "Rectified linear unit function (ReLU)\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\mathrm{ReLU}(t) = \\max(0, t)\n\\]\n\n\n\nAlthough the ReLU function is not differentiable at \\(t=0\\) and has a derivative of 0 for \\(t&lt;0\\), it performs quite well in practice and is computationally efficient. Consequently, it has become the default activation function."
  },
  {
    "objectID": "lectures/11/slides.html#common-activation-functions",
    "href": "lectures/11/slides.html#common-activation-functions",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Common Activation Functions",
    "text": "Common Activation Functions\n\n\n\n\n\n\n\n\n\n\n\nGéron (2022) – 10_neural_nets_with_keras.ipynb"
  },
  {
    "objectID": "lectures/11/slides.html#definition",
    "href": "lectures/11/slides.html#definition",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Definition",
    "text": "Definition\nThe universal approximation theorem (UAT) states that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on a compact subset of \\(\\mathbb{R}^n\\), given appropriate weights and activation functions.\n\n\nIn mathematical terms, a subset of \\(\\mathbb{R}^n\\) is considered compact if it is both closed and bounded.\n\nClosed: A set is closed if it contains all its boundary points. In other words, it includes its limit points or accumulation points.\nBounded: A set is bounded if there exists a real number (M) such that the distance between any two points in the set is less than \\(M\\).\n\nIn the context of the universal approximation theorem, compactness ensures that the function being approximated is defined on a finite and well-behaved region, which is crucial for the theoretical guarantees provided by the theorem.\n\n\nCybenko (1989); Hornik, Stinchcombe, and White (1989)"
  },
  {
    "objectID": "lectures/11/slides.html#demonstration-with-code",
    "href": "lectures/11/slides.html#demonstration-with-code",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Demonstration with code",
    "text": "Demonstration with code\n\nimport numpy as np\n\n# Defining the function to be approximated\n\ndef f(x):\n  return 2 * x**3 + 4 * x**2 - 5 * x + 1\n\n# Generating a dataset, x in [-4,2), f(x) as above\n\nX = 6 * np.random.rand(1000, 1) - 4\n\ny = f(X.flatten())"
  },
  {
    "objectID": "lectures/11/slides.html#increasing-the-number-of-neurons",
    "href": "lectures/11/slides.html#increasing-the-number-of-neurons",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Increasing the number of neurons",
    "text": "Increasing the number of neurons\n\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)\n\nmodels = []\n\nsizes = [1, 2, 5, 10, 100]\n\nfor i, n in enumerate(sizes):\n\n  models.append(MLPRegressor(hidden_layer_sizes=[n], max_iter=5000, random_state=42))\n\n  models[i].fit(X_train, y_train) \n\n\n\nMLPRegressor is a multi-layer perceptron regressor from sklearn. Its default activation function is relu."
  },
  {
    "objectID": "lectures/11/slides.html#increasing-the-number-of-neurons-1",
    "href": "lectures/11/slides.html#increasing-the-number-of-neurons-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Increasing the number of neurons",
    "text": "Increasing the number of neurons\n\n\n\n\n\n\n\n\n\n\nIn the example above, I retained only 10% of the data as the test set because the function being approximated is straightforward and noise-free. This decision was made to ensure that the true curve does not overshadow the other results."
  },
  {
    "objectID": "lectures/11/slides.html#increasing-the-number-of-neurons-2",
    "href": "lectures/11/slides.html#increasing-the-number-of-neurons-2",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Increasing the number of neurons",
    "text": "Increasing the number of neurons\n\n\n\n\n\n\n\n\n\n\n\nAs expected, increasing neuron count reduces loss."
  },
  {
    "objectID": "lectures/11/slides.html#universal-approximation-1",
    "href": "lectures/11/slides.html#universal-approximation-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Universal Approximation",
    "text": "Universal Approximation\n\n\n\nThe video effectively elucidates key concepts (terminology) in neural networks, including nodes, layers, weights, and activation functions. It demonstrates the process of summing activation outputs from a preceding layer, akin to the aggregation of curves. Additionally, the video illustrates how scaling an output by a weight not only alters the amplitude of a curve but also inverts its orientation when the weight is negative. Moreover, it clearly depicts the function of bias terms in vertically shifting the curve, contingent on the sign of the bias.\n\n\nThis video effectively conveys the underlying intuition of the universal approximation theorem. (18m 53s)"
  },
  {
    "objectID": "lectures/11/slides.html#frameworks",
    "href": "lectures/11/slides.html#frameworks",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Frameworks",
    "text": "Frameworks\nPyTorch and TensorFlow are the leading platforms for deep learning.\n\nPyTorch has gained considerable traction in the research community. Initially developed by Meta AI, it is now part of the Linux Foundation.\nTensorFlow, created by Google, is widely adopted in industry for deploying models in production environments."
  },
  {
    "objectID": "lectures/11/slides.html#keras",
    "href": "lectures/11/slides.html#keras",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Keras",
    "text": "Keras\nKeras is a high-level API designed to build, train, evaluate, and execute models across various backends, including PyTorch, TensorFlow, and JAX, Google’s high-performance platform.\n\n\nAs highlighted in previous Quotes of the Day, François Chollet, a Google engineer, is the originator and one of the primary developers of the Keras project.\n\n\nKeras is powerful enough for most projects."
  },
  {
    "objectID": "lectures/11/slides.html#fashion-mnist-dataset",
    "href": "lectures/11/slides.html#fashion-mnist-dataset",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Fashion-MNIST dataset",
    "text": "Fashion-MNIST dataset\n“Fashion-MNIST is a dataset of Zalando’s article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.”\n\n\nAttribution: Géron (2022) – 10_neural_nets_with_keras.ipynb"
  },
  {
    "objectID": "lectures/11/slides.html#loading",
    "href": "lectures/11/slides.html#loading",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Loading",
    "text": "Loading\n\nimport tensorflow as tf\n\nfashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n\n(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n\nX_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\nX_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n\n\n\nSetting aside 5000 examples as a validation set."
  },
  {
    "objectID": "lectures/11/slides.html#exploration",
    "href": "lectures/11/slides.html#exploration",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Exploration",
    "text": "Exploration\n\nX_train.shape\n\n(55000, 28, 28)\n\n\n\n\nX_train.dtype\n\ndtype('uint8')\n\n\n\n\nTransforming the pixel intensities from integers in the range 0 to 255 to floats in the range 0 to 1.\n\nX_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
  },
  {
    "objectID": "lectures/11/slides.html#what-are-these-images-anyway",
    "href": "lectures/11/slides.html#what-are-these-images-anyway",
    "title": "Introduction to Artificial Neural Networks",
    "section": "What are these images anyway!",
    "text": "What are these images anyway!\n\nplt.figure(figsize=(2, 2))\nplt.imshow(X_train[0], cmap=\"binary\")\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n\ny_train\n\narray([9, 0, 0, ..., 9, 0, 2], shape=(55000,), dtype=uint8)\n\n\n\n\nSince the labels are integers, 0 to 9. Class names will become handy.\n\nclass_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
  },
  {
    "objectID": "lectures/11/slides.html#first-40-images",
    "href": "lectures/11/slides.html#first-40-images",
    "title": "Introduction to Artificial Neural Networks",
    "section": "First 40 images",
    "text": "First 40 images\n\nn_rows = 4\nn_cols = 10\nplt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\nfor row in range(n_rows):\n    for col in range(n_cols):\n        index = n_cols * row + col\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n        plt.axis('off')\n        plt.title(class_names[y_train[index]])\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()"
  },
  {
    "objectID": "lectures/11/slides.html#first-40-images-output",
    "href": "lectures/11/slides.html#first-40-images-output",
    "title": "Introduction to Artificial Neural Networks",
    "section": "First 40 images",
    "text": "First 40 images"
  },
  {
    "objectID": "lectures/11/slides.html#creating-a-model",
    "href": "lectures/11/slides.html#creating-a-model",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Creating a model",
    "text": "Creating a model\n\ntf.random.set_seed(42)\n\nmodel = tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.InputLayer(shape=[28, 28]))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(300, activation=\"relu\"))\nmodel.add(tf.keras.layers.Dense(100, activation=\"relu\"))\nmodel.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
  },
  {
    "objectID": "lectures/11/slides.html#model.summary",
    "href": "lectures/11/slides.html#model.summary",
    "title": "Introduction to Artificial Neural Networks",
    "section": "model.summary()",
    "text": "model.summary()\n\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten (Flatten)               │ (None, 784)            │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (Dense)                   │ (None, 300)            │       235,500 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (Dense)                 │ (None, 100)            │        30,100 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (Dense)                 │ (None, 10)             │         1,010 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 266,610 (1.02 MB)\n\n\n\n Trainable params: 266,610 (1.02 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\nAs observed, dense_3 has \\(235,500\\) parameters, while \\(784 \\times 300 = 235,200\\).\nCould you explain the origin of the additional parameters?\nSimilarly, dense_3 has \\(30,100\\) parameters, while \\(300 \\times 100 = 30,000\\).\nCan you explain why?"
  },
  {
    "objectID": "lectures/11/slides.html#creating-a-model-alternative",
    "href": "lectures/11/slides.html#creating-a-model-alternative",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Creating a model (alternative)",
    "text": "Creating a model (alternative)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(28, 28)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(300, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])"
  },
  {
    "objectID": "lectures/11/slides.html#model.summary-1",
    "href": "lectures/11/slides.html#model.summary-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "model.summary()",
    "text": "model.summary()"
  },
  {
    "objectID": "lectures/11/slides.html#compiling-the-model",
    "href": "lectures/11/slides.html#compiling-the-model",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Compiling the model",
    "text": "Compiling the model\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=\"sgd\",\n              metrics=[\"accuracy\"])\n\n\n\nsparse_categorical_crossentropy is the appropriate function for a multiclass classification problem (more later).\nThe method compile allows to set the loss function, as well as other parameters. Keras then prepares the model for training."
  },
  {
    "objectID": "lectures/11/slides.html#training-the-model",
    "href": "lectures/11/slides.html#training-the-model",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Training the model",
    "text": "Training the model\n\nhistory = model.fit(X_train, y_train, epochs=30,\n                    validation_data=(X_valid, y_valid))\n\n\nThe model is provided with both a taining set and a validation set. At each step, the model will report its performance on both sets. This will also allow to visualize the accuracy and loss curves on both sets (more later).\nWhen calling the fit method in Keras (or similar frameworks), each step corresponds to the evaluation of a mini-batch. A mini-batch is a subset of the training data, and during each step, the model updates its weights based on the error calculated from this mini-batch.\nAn epoch is defined as one complete pass through the entire training dataset. During an epoch, the model processes multiple mini-batches until it has seen all the training data once. This process is repeated for a specified number of epochs to optimize the model’s performance."
  },
  {
    "objectID": "lectures/11/slides.html#visualization",
    "href": "lectures/11/slides.html#visualization",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Visualization",
    "text": "Visualization\n\nimport pandas as pd \n\npd.DataFrame(history.history).plot(\n    figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\nplt.legend(loc=\"lower left\")  # extra code\nplt.show()"
  },
  {
    "objectID": "lectures/11/slides.html#visualization-output",
    "href": "lectures/11/slides.html#visualization-output",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Visualization",
    "text": "Visualization"
  },
  {
    "objectID": "lectures/11/slides.html#evaluating-the-model-on-our-test",
    "href": "lectures/11/slides.html#evaluating-the-model-on-our-test",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Evaluating the model on our test",
    "text": "Evaluating the model on our test\n\nmodel.evaluate(X_test, y_test)"
  },
  {
    "objectID": "lectures/11/slides.html#making-predictions",
    "href": "lectures/11/slides.html#making-predictions",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Making predictions",
    "text": "Making predictions\n\nX_new = X_test[:3]\ny_proba = model.predict(X_new)\ny_proba.round(2)\n\n\n\ny_pred = y_proba.argmax(axis=-1)\ny_pred\n\n\n\n\ny_new = y_test[:3]\ny_new\n\n\n\n\nAs can be seen, the predictions are unambiguous, with only one class per prediction exhibiting a high value."
  },
  {
    "objectID": "lectures/11/slides.html#predicted-vs-observed",
    "href": "lectures/11/slides.html#predicted-vs-observed",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Predicted vs Observed",
    "text": "Predicted vs Observed\n\nnp.array(class_names)[y_pred]"
  },
  {
    "objectID": "lectures/11/slides.html#test-set-performance",
    "href": "lectures/11/slides.html#test-set-performance",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Test Set Performance",
    "text": "Test Set Performance\n\nfrom sklearn.metrics import classification_report\n\ny_proba = model.predict(X_test)\ny_pred = y_proba.argmax(axis=-1)"
  },
  {
    "objectID": "lectures/11/slides.html#test-set-performance-1",
    "href": "lectures/11/slides.html#test-set-performance-1",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Test Set Performance",
    "text": "Test Set Performance\n\nprint(classification_report(y_test, y_pred))"
  },
  {
    "objectID": "lectures/11/slides.html#summary",
    "href": "lectures/11/slides.html#summary",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Summary",
    "text": "Summary\n\nIntroduction to Neural Networks and Connectionism\n\nShift from symbolic AI to connectionist approaches in artificial intelligence.\nInspiration from biological neural networks and the human brain’s structure.\n\nComputations with Neurodes and Threshold Logic Units\n\nEarly models of neurons (neurodes) capable of performing logical operations (AND, OR, NOT).\nLimitations of simple perceptrons in solving non-linearly separable problems like XOR.\n\nMultilayer Perceptrons (MLPs) and Feedforward Neural Networks (FNNs)\n\nOvercoming perceptron limitations by introducing hidden layers.\nStructure and information flow in feedforward neural networks.\nExplanation of forward pass computations in neural networks.\n\nActivation Functions in Neural Networks\n\nImportance of nonlinear activation functions (sigmoid, tanh, ReLU) for enabling learning of complex patterns.\nRole of activation functions in backpropagation and gradient descent optimization.\nUniversal Approximation Theorem and its implications for neural networks.\n\nDeep Learning Frameworks\n\nOverview of PyTorch and TensorFlow as leading platforms for deep learning.\nIntroduction to Keras as a high-level API for building and training neural networks.\nDiscussion on the suitability of different frameworks for research and industry applications.\n\nHands-On Implementation with Keras\n\nLoading and exploring the Fashion-MNIST dataset.\nBuilding a neural network model using Keras’ Sequential API.\nCompiling the model with appropriate loss functions and optimizers for multiclass classification.\nTraining the model and visualizing training and validation metrics over epochs.\nEvaluating model performance on test data and interpreting results.\n\nMaking Predictions and Interpreting Results\n\nUsing the trained model to make predictions on new data.\nVisualizing predictions alongside actual images and labels.\nUnderstanding the output probabilities and class assignments in the context of the dataset."
  },
  {
    "objectID": "lectures/11/slides.html#next-lecture",
    "href": "lectures/11/slides.html#next-lecture",
    "title": "Introduction to Artificial Neural Networks",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will discuss the training algorithm for artificial neural networks."
  },
  {
    "objectID": "lectures/11/slides.html#references",
    "href": "lectures/11/slides.html#references",
    "title": "Introduction to Artificial Neural Networks",
    "section": "References",
    "text": "References\n\n\nCybenko, George V. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2: 303–14. https://api.semanticscholar.org/CorpusID:3958369.\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 3rd ed. O’Reilly Media, Inc.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. Adaptive Computation and Machine Learning. MIT Press. https://dblp.org/rec/books/daglib/0040158.\n\n\nHornik, Kurt, Maxwell Stinchcombe, and Halbert White. 1989. “Multilayer Feedforward Networks Are Universal Approximators.” Neural Networks 2 (5): 359–66. https://doi.org/https://doi.org/10.1016/0893-6080(89)90020-8.\n\n\nLeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. “Deep Learning.” Nature 521 (7553): 436–44. https://doi.org/10.1038/nature14539.\n\n\nLeNail, Alexander. 2019. “NN-SVG: Publication-Ready Neural Network Architecture Schematics.” Journal of Open Source Software 4 (33): 747. https://doi.org/10.21105/joss.00747.\n\n\nMcCulloch, Warren S, and Walter Pitts. 1943. “A logical calculus of the ideas immanent in nervous activity.” The Bulletin of Mathematical Biophysics 5 (4): 115–33. https://doi.org/10.1007/bf02478259.\n\n\nMinsky, Marvin, and Seymour Papert. 1969. Perceptrons: An Introduction to Computational Geometry. Cambridge, MA, USA: MIT Press.\n\n\nRosenblatt, F. 1958. “The perceptron: A probabilistic model for information storage and organization in the brain.” Psychological Review 65 (6): 386–408. https://doi.org/10.1037/h0042519.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/11/index.html",
    "href": "lectures/11/index.html",
    "title": "Lecture 11",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 2 must be submitted no later than October 20, 2025, at 11 PM. Please refer to the assignment description available on Brightspace."
  },
  {
    "objectID": "lectures/11/index.html#prepare",
    "href": "lectures/11/index.html#prepare",
    "title": "Lecture 11",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 750–788\n\n\nWatch 3Blue1Brown videos on neural networks\n\nBut what is a Neural Network? (19 minutes)\nGradient descent, how neural networks learn (21 minutes)\nWhat is backpropagation really doing? (14 minutes)\nBackpropagation calculus (10 minutes)\n\n\n\nNarrative of PyTorch’s inception\n\nPyTorch (2024) Official PyTorch Documentary - Powering the AI Revolution (36 minutes)"
  },
  {
    "objectID": "lectures/11/index.html#participate",
    "href": "lectures/11/index.html#participate",
    "title": "Lecture 11",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/11/index.html#practice",
    "href": "lectures/11/index.html#practice",
    "title": "Lecture 11",
    "section": "Practice",
    "text": "Practice\n\nTinker With a Neural Network in Your Browser"
  },
  {
    "objectID": "lectures/12/slides.html#quote-of-the-day",
    "href": "lectures/12/slides.html#quote-of-the-day",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\nSir Demis Hassabis is the Co-founder and CEO of Google DeepMind, a leading company dedicated to addressing some of the most complex scientific and engineering challenges of our era to propel scientific advancement. A chess prodigy from the age of four, Hassabis achieved master-level proficiency by 13 and served as the captain for several England junior chess teams. In 2024, he was awarded the Nobel Prize in Chemistry for his contributions to the development of AlphaFold."
  },
  {
    "objectID": "lectures/12/slides.html#learning-objectives",
    "href": "lectures/12/slides.html#learning-objectives",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nExplain the architecture and function of feedforward neural networks (FNNs).\nDescribe the backpropagation algorithm and its role in training neural networks.\nIdentify common activation functions and understand their impact on network performance.\nUnderstand the vanishing gradient problem and strategies to mitigate it.\n\n\nAs with Assignment 2, I have compiled the important concepts for the next assignment into a single lecture."
  },
  {
    "objectID": "lectures/12/slides.html#blue1brown",
    "href": "lectures/12/slides.html#blue1brown",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "3Blue1Brown",
    "text": "3Blue1Brown\n\n\n\nIt is highly recommended that you watch this video. While it covers the concepts we have already explored, it presents the material in a manner that is challenging to replicate in a classroom setting.\n\nProvides a clear explanation of the intuition behind the effectiveness of neural networks, detailing the hierarchy of concepts briefly mentioned in the last lecture.\nOffers a compelling rationale for the necessity of a bias term.\nSimilarly, elucidates the concept of activation functions and the importance of a squashing function.\nThe segment beginning at 13m 26s offers a visual explanation of the linear algebra involved: \\(\\sigma(W X^T + b)\\).\n\n\n\nIn my opinion, this is an excellent and informative video."
  },
  {
    "objectID": "lectures/12/slides.html#summary---dl",
    "href": "lectures/12/slides.html#summary---dl",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Summary - DL",
    "text": "Summary - DL\n\nDeep learning (DL) is a machine learning technique that can be applied to supervised learning (including regression and classification), unsupervised learning, and reinforcement learning.\nInspired from the structure and function of biological neural networks found in animals.\nComprises interconnected neurons (or units) arranged into layers."
  },
  {
    "objectID": "lectures/12/slides.html#summary---fnn",
    "href": "lectures/12/slides.html#summary---fnn",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Summary - FNN",
    "text": "Summary - FNN\n\n\n\n\n\n\n\nNeural networks have inputs and outputs.\nThe network consists of three layers: input, hidden, and output. The input layer contains two nodes, the hidden layer comprises three nodes, and the output layer has two nodes. Additional hidden layers and nodes per layer can be added, which will be discussed later.\nIt is often useful to include explicit input nodes that do not perform calculations, known as input units or input neurons. These nodes act as placeholders to introduce input features into the network, passing data directly to the next layer without transformation. In the network diagram, these are the light blue nodes on the left. Typically, the number of input units corresponds to the number of features.\n\n\nInformation in this architecture flows unidirectionally—from left to right, moving from input to output. Consequently, it is termed a feedforward neural network (FNN)."
  },
  {
    "objectID": "lectures/12/slides.html#summary---fnn-1",
    "href": "lectures/12/slides.html#summary---fnn-1",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Summary - FNN",
    "text": "Summary - FNN\n\n\n\n\n\n\n\nNeural networks can have a significantly large number of input nodes, often in the hundreds or thousands, depending on the complexity of the data. Additionally, they may contain numerous hidden layers. For instance, ResNet, which won the ILSVRC 2015 image classification task, features 152 layers. The authors of ResNet have demonstrated results for networks with 100 and even 1000 layers (He et al. 2016). However, the number of output nodes tends to be relatively small. In regression problems, there is typically one output node, while in classification tasks (whether multiclass or multilabel), the number of output nodes corresponds to the number of classes.\n\n\nThe number of layers and nodes can vary based on the specific requirements."
  },
  {
    "objectID": "lectures/12/slides.html#summary---units",
    "href": "lectures/12/slides.html#summary---units",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Summary - units",
    "text": "Summary - units\n\n\n\n\n\n\n\nIn the diagram above, it is important to clarify that the inputs and output pertain specifically to this individual unit, rather than to the entire network’s global inputs and output.\nThe name activation originates from the function’s role in determining whether a neuron should be “activated” or “fired” based on its input.\nHistorically, the concept was inspired by biological neurons, where a neuron activates and transmits a signal to other neurons if its input exceeds a certain threshold. In artificial neural networks, the activation function serves a similar purpose by introducing non-linearity into the model. This non-linearity is crucial because it enables the network to learn complex patterns and representations in the data.\n\n\nIntroducing a fictitious input \\(x^{(0)} = 1\\) is a hack that simplifies the expression \\(x^T\\theta + b\\)."
  },
  {
    "objectID": "lectures/12/slides.html#common-activation-functions",
    "href": "lectures/12/slides.html#common-activation-functions",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Common Activation Functions",
    "text": "Common Activation Functions\n\n\n\n\n\n\n\n\n\n\n\nConsider the following observations:\n\nThe sigmoid function produces outputs within the open interval \\((0, 1)\\).\nThe hyperbolic tangent function (\\(\\tanh\\)) has an image spanning the open interval \\((-1, 1)\\).\nThe Rectified Linear Unit (ReLU) function outputs values in the interval \\([0, \\infty)\\).\n\nAdditionally, note:\n\nThe maximum derivative value of the sigmoid function is 0.25.\nThe maximum derivative value of the \\(\\tanh\\) function is 1.\nThe derivative of the ReLU function is 0 for negative inputs and 1 for positive inputs.\n\nFurthermore:\n\nA node employing ReLU as its activation function generates outputs within the range \\([0, \\infty)\\). However, its derivative, utilized in gradient descent during backpropagation, is constant, taking values of either 0 or 1.\n\n\n\nGéron (2022) – 10_neural_nets_with_keras.ipynb"
  },
  {
    "objectID": "lectures/12/slides.html#universal-approximation",
    "href": "lectures/12/slides.html#universal-approximation",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Universal Approximation",
    "text": "Universal Approximation\nThe universal approximation theorem states that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on a compact subset of \\(\\mathbb{R}^n\\), given appropriate weights and activation functions.\n\n\nCybenko (1989); Hornik, Stinchcombe, and White (1989)"
  },
  {
    "objectID": "lectures/12/slides.html#notation-1",
    "href": "lectures/12/slides.html#notation-1",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Notation",
    "text": "Notation\n\n\nA two-layer perceptron computes:\n\\[\n  y = \\phi_2(\\phi_1(X))\n\\]\nwhere\n\\[\n  \\phi_l(Z) = \\phi(W_lZ_l + b_l)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nWhere \\(\\phi\\) is an activation function, \\(W\\) a weight matrix, \\(X\\) an input matrix, and \\(b\\) a bias vector."
  },
  {
    "objectID": "lectures/12/slides.html#notation-2",
    "href": "lectures/12/slides.html#notation-2",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Notation",
    "text": "Notation\n\n\nA 3-layer perceptron computes:\n\\[\n  y = \\phi_3(\\phi_2(\\phi_1(X)))\n\\]\nwhere\n\\[\n  \\phi_l(Z) = \\phi(W_lZ_l + b_l)\n\\]"
  },
  {
    "objectID": "lectures/12/slides.html#notation-3",
    "href": "lectures/12/slides.html#notation-3",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Notation",
    "text": "Notation\nA \\(k\\)-layer perceptron computes:\n\\[\n  y = \\phi_k( \\ldots \\phi_2(\\phi_1(X)) \\ldots )\n\\]\nwhere\n\\[\n  \\phi_l(Z) = \\phi(W_lZ_l + b_l)\n\\]\n\n\nA feedforward network exhibits a consistent structure, where each layer executes the same type of computation on varying inputs. Specifically, the input to layer \\(l\\) is the output from layer \\(l-1\\)."
  },
  {
    "objectID": "lectures/12/slides.html#blue1brown-1",
    "href": "lectures/12/slides.html#blue1brown-1",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "3Blue1Brown",
    "text": "3Blue1Brown"
  },
  {
    "objectID": "lectures/12/slides.html#back-propagation-1",
    "href": "lectures/12/slides.html#back-propagation-1",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Back-propagation",
    "text": "Back-propagation\nLearning representations by back-propagating errors\nDavid E. Rumelhart, Geoffrey E. Hinton & Ronald J. Williams\nWe describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure.\n\n\nI am presenting here the abstract from the seminal Nature publication where Hinton and colleagues introduced the backpropagation algorithm. This abstract is both elegant and informative, effectively capturing the core principles of modern neural networks: the concept of a loss function, the iterative adjustment of weights through the gradient descent algorithm, and the critical role of hidden layers in generating useful task-dependent features.\nNature is a prestigious journal, and it only occasionally publishes content related to computer science.\nAt the time of this publication, Hinton was affiliated with Carnegie Mellon University. As a reminder, Hinton received the Nobel Prize in Physics in 2024 for his contributions to developing foundational methods in modern machine learning.\nThe abstract highlights the rationale for using hidden layers in neural networks. The initial hidden layers learn simple representations directly from the input data, while subsequent layers identify associations among these representations. Each layer builds upon the knowledge of previous layers, culminating in the network’s final output.\n\n\nRumelhart, Hinton, and Williams (1986)"
  },
  {
    "objectID": "lectures/12/slides.html#before-the-back-propagation",
    "href": "lectures/12/slides.html#before-the-back-propagation",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Before the back-propagation",
    "text": "Before the back-propagation\n\nLimitations, such as the inability to solve the XOR classification task, essentially stalled research on neural networks.\nThe perceptron was limited to a single layer, and there was no known method for training a multi-layer perceptron.\nSingle-layer perceptrons are limited to solving classification tasks that are linearly separable."
  },
  {
    "objectID": "lectures/12/slides.html#back-propagation-contributions",
    "href": "lectures/12/slides.html#back-propagation-contributions",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Back-propagation: contributions",
    "text": "Back-propagation: contributions\n\nThe model employs mean squared error as its loss function.\nGradient descent is used to minimize loss.\nA sigmoid activation function is used instead of a step function, as its derivative provides valuable information for gradient descent.\nShows how updating internal weights using a two-pass algorithm consisting of a forward pass and a backward pass.\nEnables training multi-layer perceptrons."
  },
  {
    "objectID": "lectures/12/slides.html#backpropagation-top-level",
    "href": "lectures/12/slides.html#backpropagation-top-level",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Backpropagation: top level",
    "text": "Backpropagation: top level\n\nInitialization\nForward Pass\nCompute Loss\nBackward Pass (Backpropagation)\nRepeat 2 to 5.\n\n\n\nThe algorithm stops either after a predefined number of epochs or when convergence criteria are satisfied."
  },
  {
    "objectID": "lectures/12/slides.html#backpropagation-1.-initialization",
    "href": "lectures/12/slides.html#backpropagation-1.-initialization",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Backpropagation: 1. Initialization",
    "text": "Backpropagation: 1. Initialization\nInitialize the weights and biases of the neural network.\n\nZero Initialization\n\nAll weights are initialized to zero.\nSymmetry problems, all neurons produce identical outputs, preventing effective learning.\n\nRandom Initialization\n\nWeights are initialized randomly, often using a uniform or normal distribution.\nBreaks the symmetry between neurons, allowing them to learn.\nIf not scaled properly, leads to slow convergence or vanishing/exploding gradients.\n\n\n\n\nInitializing weights and biases to zero works for logistic regression because it is a linear model with a single layer. In logistic regression, each feature’s weight is independently adjusted during training, and the optimization process can converge correctly regardless of the initial weights, provided the data is linearly separable.\nHowever, zero initialization does not work well for neural networks due to their multi-layered structure. Here’s why:\n\nSymmetry Breaking: Neural networks require breaking symmetry between neurons in each layer so that they can learn different features. If all weights are initialized to zero, each neuron in a layer will compute the same output and receive the same gradient during backpropagation. This results in the neurons updating identically, preventing them from learning distinct features and effectively rendering multiple neurons redundant.\nNon-Linearity: Neural networks rely on non-linear transformations between layers to model complex relationships in the data. Zero initialization inhibits the ability of neurons to activate differently, impeding the network’s capacity to capture non-linear patterns.\n\n\n\nSee also: Xavier/Glorot and He initialization (later)"
  },
  {
    "objectID": "lectures/12/slides.html#backpropagation-2.-forward-pass",
    "href": "lectures/12/slides.html#backpropagation-2.-forward-pass",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Backpropagation: 2. Forward Pass",
    "text": "Backpropagation: 2. Forward Pass\nFor each example in the training set (or in a mini-batch):\n\nInput Layer: Pass input features to first layer.\nHidden Layers: For each hidden layer, compute the activations (output) by applying the weighted sum of inputs plus bias, followed by an activation function (e.g., sigmoid, ReLU).\nOutput Layer: Same process as hidden layers. Output layer activations represent the predicted values.\n\n\n\nIn practice, it is the mini-batch version of this algorithm that is being used.\n\n\nThe forward pass is almost identical to applying the network for prediction (.predict()), with the exception that intermediate (activation) results are saved, as they are needed for the backward pass."
  },
  {
    "objectID": "lectures/12/slides.html#backpropagation-3.-compute-loss",
    "href": "lectures/12/slides.html#backpropagation-3.-compute-loss",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Backpropagation: 3. Compute Loss",
    "text": "Backpropagation: 3. Compute Loss\nCalculate the loss (error) using a suitable loss function by comparing the predicted values to the actual target values.\n\n\nA smaller loss indicates that the predicted values are closer to the actual target values.\nThe value of the loss function can serve as a stopping criterion, with backpropagation halting when the loss is sufficiently small.\nCrucially, the derivative of the loss function provides essential information for adjusting the network’s weights and bias terms.\n\n\nMore on the various loss functions coming later: mean squared error for regression tasks or cross-entropy loss for classification tasks."
  },
  {
    "objectID": "lectures/12/slides.html#backpropagation-4.-backward-pass",
    "href": "lectures/12/slides.html#backpropagation-4.-backward-pass",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Backpropagation: 4. Backward Pass",
    "text": "Backpropagation: 4. Backward Pass\n\nOutput Layer: Compute the gradient of the loss with respect to the output layer’s weights and biases using the chain rule of calculus.\nHidden Layers: Propagate the error backward through the network, layer by layer. For each layer, compute the gradient of the loss with respect to the weights and biases. Use the derivative of the activation function to help calculate these gradients.\nUpdate Weights and Biases: Adjust the weights and biases using the calculated gradients and a learning rate, which determines the step size for each update.\n\n\n\nAt the end of the presentation, links are provided to a series of videos by Herman Kamper. These videos elucidate the intricacies of the backpropagation algorithm across various architectures, both with and without forks, utilizing function composition and graph computation approaches.\nWhile the algorithm is complex due to the numerous cases it entails, its regular structure makes it suitable for automation. Specifically, algorithms like automatic differentiation (autodiff) facilitate this process.\nIn 1970, Seppo Ilmari Linnainmaa introduced the algorithm known as reverse mode automatic differentiation in his MSc thesis. Although he did not apply this algorithm to neural networks, it is more general than backpropagation.\n\n\nCommon optimization techniques like gradient descent or its variants (e.g., Adam) are employed."
  },
  {
    "objectID": "lectures/12/slides.html#key-concepts",
    "href": "lectures/12/slides.html#key-concepts",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nActivation Functions: Functions like sigmoid, ReLU, and tanh introduce non-linearity, which allows the network to learn complex patterns.\nLearning Rate: A hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.\nGradient Descent: An optimization algorithm used to minimize the loss function by iteratively moving towards the steepest descent as defined by the negative of the gradient."
  },
  {
    "objectID": "lectures/12/slides.html#summary-1",
    "href": "lectures/12/slides.html#summary-1",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\nAttribution: Angermueller et al. (2016)"
  },
  {
    "objectID": "lectures/12/slides.html#vanishing-gradients",
    "href": "lectures/12/slides.html#vanishing-gradients",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Vanishing gradients",
    "text": "Vanishing gradients\n\nVanishing gradient problem: Gradients become too small, hindering weight updates.\nStalled neural network research (again) in early 2000s.\nSigmoid and its derivative (range: 0 to 0.25) were key factors.\nCommon initialization: Weights/biases from \\(\\mathcal{N}(0, 1)\\) contributed to the issue.\n\n\nGlorot and Bengio (2010) shed light on the problems.\n\n\nThe vanishing gradient problem often occurs with activation functions like the sigmoid and hyperbolic tangent (tanh), leading to difficulties in training deep neural networks due to diminishing gradients that slow down learning.\nIn contrast, the exploding gradient problem, which involves gradients growing excessively large, is typically observed in architectures such as recurrent neural networks (RNNs).\nBoth issues can significantly affect the stability and convergence of gradient-based optimization techniques, thereby hindering the effective training of deep models."
  },
  {
    "objectID": "lectures/12/slides.html#vanishing-gradients-solutions",
    "href": "lectures/12/slides.html#vanishing-gradients-solutions",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Vanishing gradients: solutions",
    "text": "Vanishing gradients: solutions\n\nAlternative activation functions: Rectified Linear Unit (ReLU) and its variants (e.g., Leaky ReLU, Parametric ReLU, and Exponential Linear Unit).\nWeight Initialization: Xavier (Glorot) or He initialization.\n\n\nOther techniques exists to mitigate the problem, including those:\n\nBatch Normalization: Implement batch normalization to standardize the inputs to each layer, which can help stabilize and accelerate training by reducing internal covariate shift and maintaining effective gradient flow.\nResidual Networks: Use residual connections, as seen in ResNet architectures, which allow gradients to flow more easily through the network by providing shortcut paths that bypass one or more layers."
  },
  {
    "objectID": "lectures/12/slides.html#glorot-and-bengio",
    "href": "lectures/12/slides.html#glorot-and-bengio",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Glorot and Bengio",
    "text": "Glorot and Bengio\n\n\nFigure 6\n\n\n\n\n\n\nFigure 7\n\n\n\n\n\n\n\n\nThe graphs presented illustrate the normalized histograms of activation values and back-propagated gradients associated with the hyperbolic tangent activation function.\nThe produce the top diagrams, Glorot and Bengio used an initialization method that was popular at the time, whereas the bottom diagrams have been produced using a new scheme (Glorot).\n\n\nGlorot and Bengio (2010), page 254."
  },
  {
    "objectID": "lectures/12/slides.html#glorot-and-bengio-1",
    "href": "lectures/12/slides.html#glorot-and-bengio-1",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Glorot and Bengio",
    "text": "Glorot and Bengio\nObjective: Mitigate the unstable gradients problem in deep neural networks.\nSignal Flow:\n\nForward Direction: Ensure stable signal propagation for accurate predictions.\nReverse Direction: Maintain consistent gradient flow during backpropagation.\n\n\n\nGlorot and Bengio (2010): pay attention to signal flow in both directions!"
  },
  {
    "objectID": "lectures/12/slides.html#glorot-and-bengio-2",
    "href": "lectures/12/slides.html#glorot-and-bengio-2",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Glorot and Bengio",
    "text": "Glorot and Bengio\nVariance Matching:\n\nForward Pass: Ensure the output variance of each layer matches its input variance.\nBackward Pass: Maintain equal gradient variance before and after passing through each layer.\n\n\n\nKeras employs Glorot initialization by default, which is well-suited for activation functions such as sigmoid, tanh, and softmax."
  },
  {
    "objectID": "lectures/12/slides.html#he-initialization",
    "href": "lectures/12/slides.html#he-initialization",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "He initialization",
    "text": "He initialization\nA similar but slightly different initialization method design to work with ReLU, as well as Leaky ReLU, ELU, GELU, Swish, and Mish.\n\nEnsure that the initialization method matches the chosen activation function.\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense\n\ndense = Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")\n\n\n\n\nGlorot Initialization (Xavier Initialization): This method sets the initial weights based on the number of input and output units for each layer, aiming to keep the variance of activations consistent across layers. It is particularly effective for activation functions like sigmoid and tanh.\nHe Initialization: This approach adjusts the weight initialization to be suitable for layers using ReLU and its variants, by scaling the variance according to the number of input units only.\n\n\n\n\nAKA Kaiming initialization."
  },
  {
    "objectID": "lectures/12/slides.html#note",
    "href": "lectures/12/slides.html#note",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Note",
    "text": "Note\nRandomly initializing the weights1 is sufficient to break symmetry in a neural network, allowing the bias terms to be set to zero without impacting the network’s ability to learn effectively.\nProper initialization of weights, such as using Xavier/Glorot or He initialization, is crucial and should be aligned with the choice of activation function to ensure optimal network performance."
  },
  {
    "objectID": "lectures/12/slides.html#activation-function-leaky-relu",
    "href": "lectures/12/slides.html#activation-function-leaky-relu",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Activation Function: Leaky ReLU",
    "text": "Activation Function: Leaky ReLU\n\n\n\n\n\n\n\n\n\n\n\nWhen the input to the ReLU activation function, the weighted sum plus bias, is negative for all the training examples, the output value of ReLU is zero. But also, its derivative is 0, which effectively deactivates the neuron. Leaky ReLU, or other variants, effectively mitigates the issue.\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense\n\nleaky_relu = tf.keras.layers.LeakyReLU(negative_slope=0.2)\ndense = tf.keras.layers.Dense(50, activation=leaky_relu, kernel_initializer=\"he_normal\")\n\nKeras proposes 18 layer activation functions at the time of writing.\n\n\nThe Leaky ReLU, a variant of the standard ReLU activation function, effectively mitigates the issue of dying ReLU nodes. For negative input values, it introduces a linear component with a slope governed by the parameter negative_slope."
  },
  {
    "objectID": "lectures/12/slides.html#summary-2",
    "href": "lectures/12/slides.html#summary-2",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Summary",
    "text": "Summary\n\nArtificial Neural Networks (ANNs):\n\nInspired by biological neural networks.\nConsist of interconnected neurons arranged in layers.\nApplicable to supervised, unsupervised, and reinforcement learning.\n\nFeedforward Neural Networks (FNNs):\n\nInformation flows unidirectionally from input to output.\nComprised of input, hidden, and output layers.\nCan vary in the number of layers and nodes per layer.\n\nActivation Functions:\n\nIntroduce non-linearity to enable learning complex patterns.\nCommon functions: Sigmoid, Tanh, ReLU, Leaky ReLU.\nChoice of activation function affects gradient flow and network performance.\n\nUniversal Approximation Theorem:\n\nA neural network with a single hidden layer can approximate any continuous function.\n\nBackpropagation Algorithm:\n\nTraining involves forward pass, loss computation, backward pass, and weight updates.\nUtilizes gradient descent to minimize the loss function.\nEnables training of multi-layer perceptrons by adjusting internal weights.\n\nVanishing Gradient Problem:\n\nGradients become too small during backpropagation, hindering training.\nMitigation strategies include using ReLU activation functions and proper weight initialization (Glorot or He initialization).\n\nWeight Initialization:\n\nRandom initialization breaks symmetry and allows effective learning.\nGlorot initialization suits sigmoid and tanh activations.\nHe initialization is optimal for ReLU and its variants.\n\nKey Concepts:\n\nLearning rate determines the step size during optimization.\nGradient descent is used to update weights in the direction of minimizing loss.\nProper selection of activation functions and initialization methods is crucial for effective training."
  },
  {
    "objectID": "lectures/12/slides.html#blue1brown-2",
    "href": "lectures/12/slides.html#blue1brown-2",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "3Blue1Brown",
    "text": "3Blue1Brown\nA series of videos, with animations, providing the intuition behind the backpropagation algorithm.\n\nNeural networks (playlist)\n\nWhat is backpropagation really doing? (12m 47s)\nBackpropagation calculus (10m 18s)\n\n\n\n\nPrerequisite: Gradient descent, how neural networks learn? (20m 33s)"
  },
  {
    "objectID": "lectures/12/slides.html#statquest",
    "href": "lectures/12/slides.html#statquest",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "StatQuest",
    "text": "StatQuest\n\nNeural Networks Pt. 2: Backpropagation Main Ideas (17m 34s)\nBackpropagation Details Pt. 1: Optimizing 3 parameters simultaneously (18m 32s)\nBackpropagation Details Pt. 2: Going bonkers with The Chain Rule (13m 9s)\n\n\n\nPrerequisites: The Chain Rule (18m 24s) & Gradient Descent, Step-by-Step (23m 54s)"
  },
  {
    "objectID": "lectures/12/slides.html#herman-kamper",
    "href": "lectures/12/slides.html#herman-kamper",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Herman Kamper",
    "text": "Herman Kamper\nOne of the most thorough series of videos on the backpropagation algorithm.\n\nIntroduction to neural networks (playlist)\n\nBackpropagation (without forks) (31m 1s)\nBackprop for a multilayer feedforward neural network (4m 2s)\nComputational graphs and automatic differentiation for neural networks (6m 56s)\nCommon derivatives for neural networks (7m 18s)\nA general notation for derivatives (in neural networks) (7m 56s)\nForks in neural networks (13m 46s)\nBackpropagation in general (now with forks) (3m 42s)"
  },
  {
    "objectID": "lectures/12/slides.html#next-lecture",
    "href": "lectures/12/slides.html#next-lecture",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will talk about softmas, cross-entropy, and regularization."
  },
  {
    "objectID": "lectures/12/slides.html#references",
    "href": "lectures/12/slides.html#references",
    "title": "Training Artificial Neural Networks (Part 1)",
    "section": "References",
    "text": "References\n\n\nAngermueller, Christof, Tanel Pärnamaa, Leopold Parts, and Oliver Stegle. 2016. “Deep Learning for Computational Biology.” Mol Syst Biol 12 (7): 878. https://doi.org/10.15252/msb.20156651.\n\n\nCybenko, George V. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2: 303–14. https://api.semanticscholar.org/CorpusID:3958369.\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 3rd ed. O’Reilly Media, Inc.\n\n\nGlorot, Xavier, and Yoshua Bengio. 2010. “Understanding the Difficulty of Training Deep Feedforward Neural Networks.” In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, edited by Yee Whye Teh and Mike Titterington, 9:249–56. Proceedings of Machine Learning Research. Chia Laguna Resort, Sardinia, Italy: PMLR. https://proceedings.mlr.press/v9/glorot10a.html.\n\n\nHe, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. “Deep Residual Learning for Image Recognition.” In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 770–78. https://doi.org/10.1109/CVPR.2016.90.\n\n\nHornik, Kurt, Maxwell Stinchcombe, and Halbert White. 1989. “Multilayer Feedforward Networks Are Universal Approximators.” Neural Networks 2 (5): 359–66. https://doi.org/https://doi.org/10.1016/0893-6080(89)90020-8.\n\n\nRumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. 1986. “Learning representations by back-propagating errors.” Nature 323 (6088): 533–36. https://doi.org/10.1038/323533a0.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/12/index.html",
    "href": "lectures/12/index.html",
    "title": "Lecture 12",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 3 must be submitted no later than November 10, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/12/index.html#prepare",
    "href": "lectures/12/index.html#prepare",
    "title": "Lecture 12",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 750–788\n\n\nWatch 3Blue1Brown videos on neural networks\n\nBut what is a Neural Network? (19 minutes)\nGradient descent, how neural networks learn (21 minutes)\nWhat is backpropagation really doing? (14 minutes)\nBackpropagation calculus (10 minutes)\n\n\n\nNarrative of PyTorch’s inception\n\nPyTorch (2024) Official PyTorch Documentary - Powering the AI Revolution (36 minutes)"
  },
  {
    "objectID": "lectures/12/index.html#participate",
    "href": "lectures/12/index.html#participate",
    "title": "Lecture 12",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/12/index.html#practice",
    "href": "lectures/12/index.html#practice",
    "title": "Lecture 12",
    "section": "Practice",
    "text": "Practice\n\nTinker With a Neural Network in Your Browser"
  },
  {
    "objectID": "lectures/13/slides.html#quote-of-the-day",
    "href": "lectures/13/slides.html#quote-of-the-day",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\nSir Demis Hassabis is the Co-founder and CEO of Google DeepMind, a leading company dedicated to addressing some of the most complex scientific and engineering challenges of our era to propel scientific advancement. A chess prodigy from the age of four, Hassabis achieved master-level proficiency by 13 and served as the captain for several England junior chess teams. In 2024, he was awarded the Nobel Prize in Chemistry for his contributions to the development of AlphaFold."
  },
  {
    "objectID": "lectures/13/slides.html#learning-objectives",
    "href": "lectures/13/slides.html#learning-objectives",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nDescribe the functioning of a softmax layer.\nExplain the concept of cross-entropy loss.\nApply regularization techniques to improve the generalization of neural networks.\n\n\nAs with Assignment 2, I have compiled the important concepts for the next assignment into the lecture notes."
  },
  {
    "objectID": "lectures/13/slides.html#summary",
    "href": "lectures/13/slides.html#summary",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Summary",
    "text": "Summary\n\nDeep learning is a branch of machine learning.\nIt uses neural networks organized in layers.\nEach unit computes a weighted sum (dot product) of the inputs, adds a bias, and then applies an activation function to produce its output.\nA sufficiently large single-layer network can approximate any continuous function."
  },
  {
    "objectID": "lectures/13/slides.html#backpropagation-general-overview",
    "href": "lectures/13/slides.html#backpropagation-general-overview",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Backpropagation: General Overview",
    "text": "Backpropagation: General Overview\n\nInitialization\nForward Pass\nLoss Calculation\nBackward Pass (Backpropagation)\nRepeat steps 2 to 5.\n\n\n\nThe algorithm stops either after a predefined number of epochs or when the convergence criteria are met."
  },
  {
    "objectID": "lectures/13/slides.html#output-layer-regression-task",
    "href": "lectures/13/slides.html#output-layer-regression-task",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Output Layer: Regression Task",
    "text": "Output Layer: Regression Task\n\n# of output neurons:\n\n1 per dimension\n\nOutput layer activation function:\n\nNone, ReLU/softplus, if positive, sigmoid/tanh, if bounded\n\nLoss function:\n\nMeanSquaredError\n\n\n\n\nIn an object detection problem, determining the bounding box exemplifies a regression task where the output is multidimensional."
  },
  {
    "objectID": "lectures/13/slides.html#output-layer-classification-task",
    "href": "lectures/13/slides.html#output-layer-classification-task",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Output Layer: Classification Task",
    "text": "Output Layer: Classification Task\n\n# of output neurons:\n\n1 if binary, 1 per class, if multi-label or multiclass.\n\nOutput layer activation function:\n\nsigmoid, if binary or multi-label, softmax if multi-class.\n\nLoss function:\n\ncross-entropy"
  },
  {
    "objectID": "lectures/13/slides.html#softmax",
    "href": "lectures/13/slides.html#softmax",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Softmax",
    "text": "Softmax\n\n\n\n\n\n\n\nObserve that I have revised the representation of the output nodes to indicate that the softmax function is applied to the entire layer, rather than to individual nodes. This function transforms the raw output values of the layer into probabilities that sum to 1, facilitating multi-class classification. This characteristic distinguishes it from activation functions like ReLU or sigmoid, which are typically applied independently to each node’s output.\nThe \\(\\argmax\\) function is not suitable for optimization via gradient-based methods because its derivative is zero in all cases, similar to step functions. In contrast, the softmax function offers both a probabilistic interpretation and a computable derivative, making it more effective for such applications.\nThe \\(\\argmax\\) function can be applied a posteriori to trained networks for class prediction.\n\n\nSoftmax ensures that all activation outputs fall between 0 and 1 and collectively sum to 1."
  },
  {
    "objectID": "lectures/13/slides.html#softmax-1",
    "href": "lectures/13/slides.html#softmax-1",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Softmax",
    "text": "Softmax\nThe softmax function is an activation function used in multi-class classification problems to convert a vector of raw scores into probabilities that sum to 1.\nGiven a vector \\(\\mathbf{z} = [z_1, z_2, \\ldots, z_n]\\):\n\\[\n\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n\\]\nwhere \\(\\sigma(\\mathbf{z})_i\\) is the probability of the \\(i\\)-th class, and \\(n\\) is the number of classes.\n\nSoftmax emphasizes higher scores while suppressing lower ones, enabling a probabilistic interpretation of the outputs.\nWe clearly see that such an activation applies for an entire layer since the denomination depends on the values of all the \\(z_j\\), for \\(j in 1 \\ldots n\\)."
  },
  {
    "objectID": "lectures/13/slides.html#softmax-2",
    "href": "lectures/13/slides.html#softmax-2",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Softmax",
    "text": "Softmax\n\n\n\n\n\n\n\n\n\n\n\n\n\\(z_1\\)\n\\(z_2\\)\n\\(z_3\\)\n\\(\\sigma(z_1)\\)\n\\(\\sigma(z_2)\\)\n\\(\\sigma(z_3)\\)\n\\(\\sum\\)\n\n\n\n\n1.47\n-0.39\n0.22\n0.69\n0.11\n0.20\n1.00\n\n\n5.00\n6.00\n4.00\n0.24\n0.67\n0.09\n1.00\n\n\n0.90\n0.80\n1.10\n0.32\n0.29\n0.39\n1.00\n\n\n-2.00\n2.00\n-3.00\n0.02\n0.98\n0.01\n1.00\n\n\n\n\n\n\nMaintains Relative Order: The softmax function preserves the relative order of the input values. If one input is greater than another, its corresponding output will also be greater.\nInterpreted as probabilities: Each value is in the range 0 to 1. The output values from the softmax function are normalized to sum to one, which allows them to be interpreted as probabilities.\nRelative Differences: When the relative differences among the input values are small, the differences in the output probabilities remain small, reflecting the input distribution. When the input values are identical, the output values will be \\(\\frac{1}{n}\\), where \\(n\\) is the number of classes.\nWide Range of Values: The softmax function can effectively handle a wide range of input values, thanks to the exponential function and normalization, which scale the inputs to a probabilistic range.\n\nThese properties make the softmax function particularly useful for multi-class classification tasks in machine learning.\n\n\nSoftmax values for a vector of length 3."
  },
  {
    "objectID": "lectures/13/slides.html#softmax-3",
    "href": "lectures/13/slides.html#softmax-3",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Softmax",
    "text": "Softmax"
  },
  {
    "objectID": "lectures/13/slides.html#cross-entropy-loss-function",
    "href": "lectures/13/slides.html#cross-entropy-loss-function",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Cross-entropy loss function",
    "text": "Cross-entropy loss function\nThe cross-entropy in a multi-class classification task for one example:\n\\[\nJ(W) = -\\sum_{k=1}^{K} y_k \\log(\\hat{y}_k)\n\\]\nWhere:\n\n\\(K\\) is the number of classes.\n\\(y_k\\) is the true distribution for the class \\(k\\).\n\\(\\hat{y}_k\\) is the predicted probability of class \\(k\\) from the model.\n\n\n\nThe target vector \\(y\\) is expressed as a one-hot encoded vector of length \\(K\\), where the element corresponding to the true class is set to 1, and all other elements are 0.\nConsequently, in the summation over classes, only the term associated with the true class contributes a non-zero value.\nTherefore, the cross-entropy loss for a single example is given by \\(-\\log(\\hat{y}_k)\\), where \\(\\hat{y}_k\\) is the predicted probability for the true class.\nThe predicted probability \\(\\hat{y}_k\\) is derived from the softmax function applied in the output layer of the neural network."
  },
  {
    "objectID": "lectures/13/slides.html#cross-entropy-loss-function-1",
    "href": "lectures/13/slides.html#cross-entropy-loss-function-1",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Cross-entropy loss function",
    "text": "Cross-entropy loss function\n\nClassification Problem: 3 classes\n\nVersicolour, Setosa, Virginica.\n\nOne-Hot Encoding:\n\nSetosa = \\([0, 1, 0]\\).\n\nSoftmax Outputs & Loss:\n\n\\([0.22,\\mathbf{0.7}, 0.08]\\): Loss = \\(-\\log(0.7) = 0.3567\\).\n\\([0.7, \\mathbf{0.22}, 0.08]\\): Loss = \\(-\\log(0.22) = 1.5141\\).\n\\([0.7, \\mathbf{0.08}, 0.22]\\): Loss = \\(-\\log(0.08) = 2.5257\\).\n\n\n\nAmong the softmax outputs, cross-entropy evaluates only the component corresponding to \\(k=1\\) (Setosa), as the other entries in the one-hot encoded vector are zero. This relevant element is highlighted in bold. When the softmax prediction aligns closely with the expected value, the resulting loss is minimal (0.3567). Conversely, as the prediction deviates further from the expected value, the loss increases (1.5141 and 2.5257)."
  },
  {
    "objectID": "lectures/13/slides.html#case-one-example",
    "href": "lectures/13/slides.html#case-one-example",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Case: one example",
    "text": "Case: one example\n\n\n\n\n\n\n\n\n\n\n\nIn the summation, only the term where \\(y_k = 1\\) contributes a non-zero value.\nDue to the negative sign preceding the summation, the value of the function is \\(-\\log(\\hat{y}_k\\).\nIf the predicted probability \\(\\hat{y}_k\\) is near 1, the loss approaches zero, indicating minimal penalty.\nConversely, as \\(\\hat{y}_k\\) nears 0, indicating an incorrect prediction, the loss approaches infinity. This substantial penalty allows cross-entropy loss to converge more quickly than mean squared error."
  },
  {
    "objectID": "lectures/13/slides.html#case-dataset",
    "href": "lectures/13/slides.html#case-dataset",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Case: dataset",
    "text": "Case: dataset\nFor a dataset with \\(N\\) examples, the average cross-entropy loss over all examples is computed as:\n\\[\nL = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^{K} y_{i,k} \\log(\\hat{y}_{i,k})\n\\]\nWhere:\n\n\\(i\\) indexes over the different examples in the dataset.\n\\(y_{i,k}\\) and \\(\\hat{y}_{i,k}\\) are the true and predicted probabilities for class \\(k\\) of example \\(i\\), respectively."
  },
  {
    "objectID": "lectures/13/slides.html#definition",
    "href": "lectures/13/slides.html#definition",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Definition",
    "text": "Definition\nRegularization comprises a set of techniques designed to enhance a model’s ability to generalize by mitigating overfitting. By discouraging excessive model complexity, these methods improve the model’s robustness and performance on unseen data."
  },
  {
    "objectID": "lectures/13/slides.html#adding-penalty-terms-to-the-loss",
    "href": "lectures/13/slides.html#adding-penalty-terms-to-the-loss",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Adding penalty terms to the loss",
    "text": "Adding penalty terms to the loss\n\nIn numerical optimization, it is standard practice to incorporate additional terms into the objective function to deter undesirable model characteristics.\nFor a minimization problem, the optimization process aims to circumvent the substantial costs associated with these penalty terms."
  },
  {
    "objectID": "lectures/13/slides.html#loss-function",
    "href": "lectures/13/slides.html#loss-function",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Loss function",
    "text": "Loss function\nConsider the mean absolute error loss function:\n\\[\n  \\mathrm{MAE}(X,W) = \\frac{1}{N} \\sum_{i=1}^N | h_W(x_i) - y_i |\n\\]\nWhere:\n\n\\(W\\) are the weights of our network.\n\\(h_W(x_i)\\) is the output of the network for example \\(i\\).\n\\(y_i\\) is the true label for example \\(i\\)."
  },
  {
    "objectID": "lectures/13/slides.html#penalty-terms",
    "href": "lectures/13/slides.html#penalty-terms",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Penalty term(s)",
    "text": "Penalty term(s)\nOne or more terms can be added to the loss:\n\\[\n  \\mathrm{MAE}(X,W) = \\frac{1}{N} \\sum_{i=1}^N | h_W(x_i) - y_i | + \\mathrm{penalty}\n\\]"
  },
  {
    "objectID": "lectures/13/slides.html#norm",
    "href": "lectures/13/slides.html#norm",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Norm",
    "text": "Norm\nA norm is assigns a non-negative length to a vector.\nThe \\(\\ell_p\\) norm of a vector \\(\\mathbf{z} = [z_1, z_2, \\ldots, z_n]\\) is defined as:\n\\[\n  \\|\\mathbf{z}\\|_p = \\left( \\sum_{i=1}^{n} |z_i|^p \\right)^{1/p}\n\\]\n\n\nA norm is a function that assigns a non-negative length or size to each vector in a vector space, satisfying certain properties: positivity, scalar multiplication, the triangle inequality, and the property that the norm is zero if and only if the vector is zero.\n\n\nWith larger \\(p\\), the \\(\\ell_p\\) norm increasingly highlights larger \\(z_i\\) values due to exponentiation."
  },
  {
    "objectID": "lectures/13/slides.html#ell_1-and-ell_2-norms",
    "href": "lectures/13/slides.html#ell_1-and-ell_2-norms",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "\\(\\ell_1\\) and \\(\\ell_2\\) norms",
    "text": "\\(\\ell_1\\) and \\(\\ell_2\\) norms\nThe \\(\\ell_1\\) norm (Manhattan norm) is:\n\\[\n  \\|\\mathbf{z}\\|_1 = \\sum_{i=1}^{n} |z_i|\n\\]\nThe \\(\\ell_2\\) norm (Euclidean norm) is:\n\\[\n  \\|\\mathbf{z}\\|_2 = \\sqrt{\\sum_{i=1}^{n} z_i^2}\n\\]"
  },
  {
    "objectID": "lectures/13/slides.html#ell_1-and-ell_2-regularization",
    "href": "lectures/13/slides.html#ell_1-and-ell_2-regularization",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "\\(\\ell_1\\) and \\(\\ell_2\\) regularization",
    "text": "\\(\\ell_1\\) and \\(\\ell_2\\) regularization\nBelow, \\(\\alpha\\) and \\(\\beta\\) determine the degree of regularization applied; setting these values to zero effectively disables the regularization term. \\[\n  \\mathrm{MAE}(X,W) = \\frac{1}{N} \\sum_{i=1}^N | h_W(x_i) - y_i | + \\alpha \\ell_1 + \\beta \\ell_2\n\\]"
  },
  {
    "objectID": "lectures/13/slides.html#guidelines",
    "href": "lectures/13/slides.html#guidelines",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Guidelines",
    "text": "Guidelines\n\n\\(\\ell_1\\) Regularization:\n\nPromotes sparsity, setting many weights to zero.\nUseful for feature selection by reducing feature reliance.\n\n\\(\\ell_2\\) Regularization:\n\nPromotes small, distributed weights for stability.\nIdeal when all features contribute and reducing complexity is key."
  },
  {
    "objectID": "lectures/13/slides.html#keras-example",
    "href": "lectures/13/slides.html#keras-example",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Keras example",
    "text": "Keras example\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense\n\nregularizer = tf.keras.regularizers.l2(0.001)\n\ndense = Dense(50, kernel_regularizer=regularizer)\n\n\n\nThis layer specifically utilizes \\(\\ell_2\\) regularization, in contrast to the prior discussion where regularization was applied globally across the entire model."
  },
  {
    "objectID": "lectures/13/slides.html#dropout",
    "href": "lectures/13/slides.html#dropout",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Dropout",
    "text": "Dropout\nDropout is a regularization technique in neural networks where randomly selected neurons are ignored during training, reducing overfitting by preventing co-adaptation of features.\n\n\nHinton et al. (2012)"
  },
  {
    "objectID": "lectures/13/slides.html#dropout-1",
    "href": "lectures/13/slides.html#dropout-1",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Dropout",
    "text": "Dropout\n\nDuring each training step, each neuron in a dropout layer has a probability \\(p\\) of being excluded from the computation, typical values for \\(p\\) are between 10% and 50%.\nWhile seemingly counterintuitive, this approach prevents the network from depending on specific neurons, promoting the distribution of learned representations across multiple neurons."
  },
  {
    "objectID": "lectures/13/slides.html#dropout-2",
    "href": "lectures/13/slides.html#dropout-2",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Dropout",
    "text": "Dropout\n\nDropout is one of the most popular and effective methods for reducing overfitting.\nThe typical improvement in performance is modest, usually around 1 to 2%."
  },
  {
    "objectID": "lectures/13/slides.html#keras",
    "href": "lectures/13/slides.html#keras",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Keras",
    "text": "Keras\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import InputLayer, Dropout, Flatten, Dense\n\nmodel = tf.keras.Sequential([\n    InputLayer(shape=[28, 28]),\n    Flatten(),\n    Dropout(rate=0.2),\n    Dense(300, activation=\"relu\"),\n    Dropout(rate=0.2),\n    Dense(100, activation=\"relu\"),\n    Dropout(rate=0.2),\n    Dense(10, activation=\"softmax\")\n])\n\n\n\nThe dropout rate may differ between layers; larger rates can be applied to larger layers, while smaller rates are suitable for smaller layers. It is common practice in many networks to apply dropout only after the final hidden layer.\n\n\nAdding Dropout layers to the Fashion-MNIST model from last lecture."
  },
  {
    "objectID": "lectures/13/slides.html#definition-1",
    "href": "lectures/13/slides.html#definition-1",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Definition",
    "text": "Definition\nEarly stopping is a regularization technique that halts training once the model’s performance on a validation set begins to degrade, preventing overfitting by stopping before the model learns noise.\n\n\nGeoffrey Hinton calls this the “beautiful free lunch.”"
  },
  {
    "objectID": "lectures/13/slides.html#early-stopping",
    "href": "lectures/13/slides.html#early-stopping",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Early Stopping",
    "text": "Early Stopping\n\n\n\n\n\n\n\n\n\n\n\nAttribution: Géron (2022), 04_training_linear_models.ipynb."
  },
  {
    "objectID": "lectures/13/slides.html#summary-1",
    "href": "lectures/13/slides.html#summary-1",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Summary",
    "text": "Summary\n\nLoss Functions:\n\nRegression Tasks: Mean Squared Error (MSE).\nClassification Tasks: Cross-Entropy Loss with Softmax activation for multi-class outputs.\n\nRegularization Techniques:\n\nL1 and L2 Regularization: Add penalty terms to the loss to discourage large weights.\nDropout: Randomly deactivate neurons during training to prevent overfitting.\nEarly Stopping: Halt training when validation performance deteriorates."
  },
  {
    "objectID": "lectures/13/slides.html#next-lecture",
    "href": "lectures/13/slides.html#next-lecture",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will introduce various architectures of artificial neural networks."
  },
  {
    "objectID": "lectures/13/slides.html#references",
    "href": "lectures/13/slides.html#references",
    "title": "Training Artificial Neural Networks (Part 2)",
    "section": "References",
    "text": "References\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 3rd ed. O’Reilly Media, Inc.\n\n\nHinton, Geoffrey E., Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2012. “Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors.” CoRR abs/1207.0580. http://arxiv.org/abs/1207.0580.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/13/index.html",
    "href": "lectures/13/index.html",
    "title": "Lecture 13",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 3 must be submitted no later than November 10, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/13/index.html#prepare",
    "href": "lectures/13/index.html#prepare",
    "title": "Lecture 13",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 750–788"
  },
  {
    "objectID": "lectures/13/index.html#participate",
    "href": "lectures/13/index.html#participate",
    "title": "Lecture 13",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/13/index.html#practice",
    "href": "lectures/13/index.html#practice",
    "title": "Lecture 13",
    "section": "Practice",
    "text": "Practice\n\nTinker With a Neural Network in Your Browser"
  },
  {
    "objectID": "lectures/14/slides.html#quote-of-the-day",
    "href": "lectures/14/slides.html#quote-of-the-day",
    "title": "Neural Networks Architectures",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n\nYann LeCun, recognized as one of the three pioneers of deep learning and the inventor of Convolutional Neural Networks (CNNs), frequently engages in discussions with Elon Musk on the social media platform X (previously known as Twitter)."
  },
  {
    "objectID": "lectures/14/slides.html#learning-objectives",
    "href": "lectures/14/slides.html#learning-objectives",
    "title": "Neural Networks Architectures",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nExplain the Hierarchy of Concepts in Deep Learning\nCompare Deep and Shallow Neural Networks\nDescribe the Structure and Function of Convolutional Neural Networks (CNNs)\nUnderstand Convolution Operations Using Kernels\nExplain Receptive Fields, Padding, and Stride in CNNs\nDiscusss the Role and Benefits of Pooling Layer\n\n\nToday, we have a particularly dense agenda. The study of convolutional networks involves multiple levels of complexity. Please feel free to ask questions if you need clarification.\nDetailed learning objectives.\n\nExplain the Hierarchy of Concepts in Deep Learning\n\nUnderstand how deep learning models build hierarchical representations of data.\nRecognize how this hierarchy reduces the need for manual feature engineering.\n\nCompare Deep and Shallow Neural Networks\n\nDiscuss why deep networks are more parameter-efficient than shallow networks.\nExplain the benefits of depth in neural network architectures.\n\nDescribe the Structure and Function of Convolutional Neural Networks (CNNs)\n\nUnderstand how CNNs detect local patterns in data.\nExplain how convolutional layers reduce the number of parameters through weight sharing.\n\nUnderstand Convolution Operations Using Kernels\n\nDescribe how kernels (filters) are applied over input data to perform convolutions.\nExplain how feature maps are generated from convolution operations.\n\nExplain Receptive Fields, Padding, and Stride in CNNs\n\nDefine the concept of a receptive field in convolutional layers.\nUnderstand how padding and stride affect the output dimensions and computation.\n\nDiscuss the Role and Benefits of Pooling Layers\n\nExplain how pooling layers reduce spatial dimensions and control overfitting.\nDescribe how pooling introduces translation invariance in CNNs."
  },
  {
    "objectID": "lectures/14/slides.html#hierarchy-of-concepts",
    "href": "lectures/14/slides.html#hierarchy-of-concepts",
    "title": "Neural Networks Architectures",
    "section": "Hierarchy of concepts",
    "text": "Hierarchy of concepts\n\n\n\n\n\n\n\nIn the book “Deep Learning” (Goodfellow, Bengio, and Courville 2016), authors Goodfellow, Bengio, and Courville define deep learning as a subset of machine learning that enables computers to “understand the world in terms of a hierarchy of concepts.”\nThis hierarchical approach is one of deep learning’s most significant contributions. It reduces the need for manual feature engineering and redirects the focus toward the engineering of neural network architectures.\nConvolutional Neural Networks (CNNs) have had a profound impact on the field of machine learning, particularly in areas involving image and video processing.\n\nRevolutionizing Image Recognition: CNNs have significantly advanced the state of the art in image recognition and classification, achieving high accuracy across various datasets. This has led to breakthroughs in fields such as medical imaging, autonomous vehicles, and facial recognition.\nFeature Extraction: CNNs automatically learn to extract features from raw data, eliminating the need for manual feature engineering. This capability has been crucial in handling complex data patterns and has expanded the applicability of machine learning to diverse domains.\nTransfer Learning: CNNs facilitate transfer learning, where pre-trained networks on large datasets can be fine-tuned for specific tasks with limited data. This has made CNNs accessible and effective for a wide range of applications beyond their original training scope.\nAdvancements in Deep Learning: The success of CNNs has spurred further research in deep learning architectures, inspiring the development of more sophisticated models like recurrent neural networks (RNNs), long short-term memory networks (LSTMs), and transformer models.\nBroader Application Areas: Beyond image processing, CNNs have been adapted for natural language processing, audio processing, and even in bioinformatics for tasks such as protein structure prediction and genomics.\nImplications for Real-World Applications: CNNs have enabled practical applications in fields such as healthcare, where they assist in diagnostic imaging, and in security, where they enhance surveillance systems. They have also contributed to advancements in virtual reality, gaming, and augmented reality.\n\n\n\nAttribution: LeCun, Bengio, and Hinton (2015)"
  },
  {
    "objectID": "lectures/14/slides.html#hierarchy-of-concepts-1",
    "href": "lectures/14/slides.html#hierarchy-of-concepts-1",
    "title": "Neural Networks Architectures",
    "section": "Hierarchy of concepts",
    "text": "Hierarchy of concepts\n\nEach layer detects patterns from the output of the layer preceding it.\n\nIn other words, proceeding from the input to the output of the network, the network uncovers “patterns of patterns”.\n\nAnalyzing an image, the networks first detect simple patterns, such as vertical, horizontal, diagonal lines, arcs, etc.\nThese are then combined to form corners, crosses, etc.\n\n\n(This explains how transfer learning works and why selecting the bottom layers only.)"
  },
  {
    "objectID": "lectures/14/slides.html#but-also",
    "href": "lectures/14/slides.html#but-also",
    "title": "Neural Networks Architectures",
    "section": "But also …",
    "text": "But also …\n\n“An MLP with just one hidden layer can theoretically model even the most complex functions, provided it has enough neurons. But for complex problems, deep networks have a much higher parameter efficiency than shallow ones: they can model complex functions using exponentially fewer neurons than shallow nets, allowing them to reach much better performance with the same amount of training data.”\n\n\n\nDuring the lecture, attempt to discern why convolutional neural networks possess fewer parameters compared to fully connected feedforward networks.\n\n\nGéron (2019) § 10"
  },
  {
    "objectID": "lectures/14/slides.html#how-many-layers",
    "href": "lectures/14/slides.html#how-many-layers",
    "title": "Neural Networks Architectures",
    "section": "How many layers?",
    "text": "How many layers?\n\nStart with one layer, then increase the number of layers until the model starts overfitting the training data.\nFinetune the model adding regularization (dropout layers, regularization terms, etc.).\n\n\n\nThe number of neurons and other hyperparameters are determined using a grid search."
  },
  {
    "objectID": "lectures/14/slides.html#observation",
    "href": "lectures/14/slides.html#observation",
    "title": "Neural Networks Architectures",
    "section": "Observation",
    "text": "Observation\nConsider a feed-forward network (FFN) and its model:\n\\[\n  h_{W,b}(X) = \\phi_k(\\ldots \\phi_2(\\phi_1(X)) \\ldots)\n\\]\nwhere\n\\[\n  \\phi_l(Z) = \\sigma(W_l Z + b_l)\n\\]\nfor \\(l=1 \\ldots k\\). - The number of parameters in grows rapidly:\n\\[\n  (\\text{size of layer}_{l-1} + 1) \\times \\text{size of layer}_{l}\n\\]\nTwo layers 1,000-unit implies 1,000,000 parameters!"
  },
  {
    "objectID": "lectures/14/slides.html#convolutional-neural-network-cnn",
    "href": "lectures/14/slides.html#convolutional-neural-network-cnn",
    "title": "Neural Networks Architectures",
    "section": "Convolutional Neural Network (CNN)",
    "text": "Convolutional Neural Network (CNN)\n\n\n\nAn excellent high-level overview of CNNs."
  },
  {
    "objectID": "lectures/14/slides.html#convolutional-neural-network-cnn-1",
    "href": "lectures/14/slides.html#convolutional-neural-network-cnn-1",
    "title": "Neural Networks Architectures",
    "section": "Convolutional Neural Network (CNN)",
    "text": "Convolutional Neural Network (CNN)\n\nCrucial pattern information is often local.\n\ne.g., edges, corners, crosses.\n\nConvolutional layers reduce parameters significantly.\n\nUnlike dense layers, neurons in a convolutional layer are not fully connected to the preceding layer.\nNeurons connect only within their receptive fields (rectangular regions).\n\n\n\n\nConvolutional networks originate from the domain of machine vision, which explains their intrinsic compatibility with grid-structured inputs.\nThe original publication by Yann Lecun has been cited nearly 35,000 times (Lecun et al. 1998)."
  },
  {
    "objectID": "lectures/14/slides.html#kernel-1",
    "href": "lectures/14/slides.html#kernel-1",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\n\n\n\n\n\n\nA kernel is a small matrix, usually \\(3 \\times 3\\), \\(5 \\times 5\\), or similar in size, that slides over the input data (such as an image) to perform convolution."
  },
  {
    "objectID": "lectures/14/slides.html#kernel-2",
    "href": "lectures/14/slides.html#kernel-2",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\n\n\n\n\n\n\nBeginning with the kernel positioned to overlap the upper-left corner of the input matrix."
  },
  {
    "objectID": "lectures/14/slides.html#kernel-3",
    "href": "lectures/14/slides.html#kernel-3",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\n\n\n\n\n\n\nIt can be moved to the right three times."
  },
  {
    "objectID": "lectures/14/slides.html#kernel-4",
    "href": "lectures/14/slides.html#kernel-4",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel"
  },
  {
    "objectID": "lectures/14/slides.html#kernel-5",
    "href": "lectures/14/slides.html#kernel-5",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel"
  },
  {
    "objectID": "lectures/14/slides.html#kernel-6",
    "href": "lectures/14/slides.html#kernel-6",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\n\n\n\n\n\n\nHow many placements of the kernel over the input matrix are there? \\(4 \\times 4 = 16\\).\n\n\nThe kernel can then be moved to the second row of the input matrix, and moved to the right three times."
  },
  {
    "objectID": "lectures/14/slides.html#kernel-placements",
    "href": "lectures/14/slides.html#kernel-placements",
    "title": "Neural Networks Architectures",
    "section": "Kernel Placements",
    "text": "Kernel Placements"
  },
  {
    "objectID": "lectures/14/slides.html#kernel-7",
    "href": "lectures/14/slides.html#kernel-7",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\n\n\n\n\n\n\nWith the kernel placed over a specific region of the input matrix, the convolution is element-wise multiplication (each element of the kernel is multiplied by the corresponding element of the input matrix region it overlaps) followed by a summation of the results to produce a single scalar value."
  },
  {
    "objectID": "lectures/14/slides.html#kernel-8",
    "href": "lectures/14/slides.html#kernel-8",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\n\n\n\n\n\n\n\\(1 \\times 1 + 2 \\times 0 + 3 \\times (-1) + 6 \\times 1 + 5 \\times 0 + 4 \\times (-1) + 1 \\times 1 + 2 \\times 0 + 3 \\times (-1) = -2\\)"
  },
  {
    "objectID": "lectures/14/slides.html#kernel-9",
    "href": "lectures/14/slides.html#kernel-9",
    "title": "Neural Networks Architectures",
    "section": "Kernel",
    "text": "Kernel\n\n\n\n\n\n\n\n\n\n\n\nIt is referred to as a feature map because these outputs serve as features for the subsequent layer. In CNNs, the term “feature map” refers to the output of a convolutional layer after applying filters to the input data. These feature maps capture various patterns or features from the input, such as edges or textures in image data.\nThe output feature maps of one layer become the input for the next layer, effectively serving as features that the subsequent layer can use to learn more complex patterns. This hierarchical feature extraction process is a key characteristic of CNNs, allowing them to build progressively more abstract and high-level representations of the input data as the network depth increases.\n\n\nThe 16 resulting values can be organized into an output matrix. The element at position (0,0) in this output matrix represents the result of applying the convolution operation with the kernel at the initial position on the input matrix. In convolutional neural networks, the output matrix is referred to as a feature map."
  },
  {
    "objectID": "lectures/14/slides.html#blurring",
    "href": "lectures/14/slides.html#blurring",
    "title": "Neural Networks Architectures",
    "section": "Blurring",
    "text": "Blurring\n\n\n\n\n\n\n\n\n\n\n# Define the 3x3 averaging kernel\n\nkernel = np.array([\n    [1/9, 1/9, 1/9],\n    [1/9, 1/9, 1/9],\n    [1/9, 1/9, 1/9]\n])\n\n\n\nThe application of kernels to images has been a longstanding practice in the field of image processing.\n\n\nA pixel is transformed into the average of itself and its eight surrounding neighbors, resulting in a blurred effect on the image."
  },
  {
    "objectID": "lectures/14/slides.html#vertical-edge-detection",
    "href": "lectures/14/slides.html#vertical-edge-detection",
    "title": "Neural Networks Architectures",
    "section": "Vertical Edge detection",
    "text": "Vertical Edge detection\n\n\n\n\n\n\n\n\n\n\n# Define the 3x3 averaging kernel\n\nkernel = np.array([\n    [-0.25, 0, 0.25],\n    [-0.25, 0, 0.25],\n    [-0.25, 0, 0.25]\n])\n\n\n\nThis kernel detects vertical edges by emphasizing differences in intensity between adjacent columns. It subtracts pixel values on the left from those on the right, enhancing vertical transitions and suppressing uniform regions."
  },
  {
    "objectID": "lectures/14/slides.html#horizontal-edge-detection",
    "href": "lectures/14/slides.html#horizontal-edge-detection",
    "title": "Neural Networks Architectures",
    "section": "Horizontal Edge detection",
    "text": "Horizontal Edge detection\n\n\n\n\n\n\n\n\n\n\n# Define the 3x3 averaging kernel\n\nkernel = np.array([\n    [-0.25, -0.25, -0.25],\n    [0, 0, 0],\n    [0.25, 0.25, 0.25]\n])\n\n\n\nThis kernel detects horizontal edges by highlighting differences in intensity between adjacent rows. It subtracts pixel values in the upper row from those in the lower row, accentuating horizontal transitions while minimizing uniform areas."
  },
  {
    "objectID": "lectures/14/slides.html#convolutions-in-image-processing",
    "href": "lectures/14/slides.html#convolutions-in-image-processing",
    "title": "Neural Networks Architectures",
    "section": "Convolutions in Image Processing",
    "text": "Convolutions in Image Processing\n\n\n\nUses the Julia programming language."
  },
  {
    "objectID": "lectures/14/slides.html#but-what-is-a-convolution",
    "href": "lectures/14/slides.html#but-what-is-a-convolution",
    "title": "Neural Networks Architectures",
    "section": "But what is a convolution?",
    "text": "But what is a convolution?\n\n\n\nConvolution extending beyond its application in image processing."
  },
  {
    "objectID": "lectures/14/slides.html#kernels",
    "href": "lectures/14/slides.html#kernels",
    "title": "Neural Networks Architectures",
    "section": "Kernels",
    "text": "Kernels\nIn contrast to image processing, where kernels are manually defined by the user, in convolutional networks, the kernels are automatically learned by the network.\n\n\nTo be continued \\(\\ldots\\)"
  },
  {
    "objectID": "lectures/14/slides.html#receptive-field-1",
    "href": "lectures/14/slides.html#receptive-field-1",
    "title": "Neural Networks Architectures",
    "section": "Receptive field",
    "text": "Receptive field\n\n\n\n\n\n\n\nAttribution: Géron (2019) Figure 14.2"
  },
  {
    "objectID": "lectures/14/slides.html#receptive-field-2",
    "href": "lectures/14/slides.html#receptive-field-2",
    "title": "Neural Networks Architectures",
    "section": "Receptive field",
    "text": "Receptive field\n\nEach unit is connected to neurons in its receptive fields.\n\nUnit \\(i,j\\) in layer \\(l\\) is connected to the units \\(i\\) to \\(i+f_h-1\\), \\(j\\) to \\(j+f_w-1\\) of the layer \\(l-1\\), where \\(f_h\\) and \\(f_w\\) are respectively the height and width of the receptive field."
  },
  {
    "objectID": "lectures/14/slides.html#padding",
    "href": "lectures/14/slides.html#padding",
    "title": "Neural Networks Architectures",
    "section": "Padding",
    "text": "Padding\nZero padding. In order to have layers of the same size, the grid can be padded with zeros."
  },
  {
    "objectID": "lectures/14/slides.html#padding-1",
    "href": "lectures/14/slides.html#padding-1",
    "title": "Neural Networks Architectures",
    "section": "Padding",
    "text": "Padding\n\n\nNo padding\n\n\nHalf padding\n\n\nFull padding\n\n\n\n\nAttribution: github.com/vdumoulin/conv_arithmetic"
  },
  {
    "objectID": "lectures/14/slides.html#stride",
    "href": "lectures/14/slides.html#stride",
    "title": "Neural Networks Architectures",
    "section": "Stride",
    "text": "Stride\nStride. It is possible to connect a larger layer \\((l-1)\\) to a smaller one \\((l)\\) by skipping units. The number of units skipped is called stride, \\(s_h\\) and \\(s_w\\).\n\n\nUnit \\(i,j\\) in layer \\(l\\) is connected to the units \\(i \\times s_h\\) to \\(i \\times s_h + f_h - 1\\), \\(j \\times s_w\\) to \\(j \\times s_w + f_w - 1\\) of the layer \\(l-1\\), where \\(f_h\\) and \\(f_w\\) are respectively the height and width of the receptive field, \\(s_h\\) and \\(s_w\\) are respectively the height and width strides."
  },
  {
    "objectID": "lectures/14/slides.html#stride-1",
    "href": "lectures/14/slides.html#stride-1",
    "title": "Neural Networks Architectures",
    "section": "Stride",
    "text": "Stride\n\n\nNo padding, strides\n\n\nPadding, strides\n\n\n\n\nAttribution: github.com/vdumoulin/conv_arithmetic"
  },
  {
    "objectID": "lectures/14/slides.html#filters-1",
    "href": "lectures/14/slides.html#filters-1",
    "title": "Neural Networks Architectures",
    "section": "Filters",
    "text": "Filters\n\nA window of size \\(f_h \\times f_w\\) is moved over the output of layers \\(l-1\\), referred to as the input feature map, position by position.\nFor each location, the product is calculated between the extracted patch and a matrix of the same size, known as a convolution kernel or filter. The sum of the values in the resulting matrix constitutes the output for that location."
  },
  {
    "objectID": "lectures/14/slides.html#model-1",
    "href": "lectures/14/slides.html#model-1",
    "title": "Neural Networks Architectures",
    "section": "Model",
    "text": "Model\n\n\n\n\n\n\\[\nz_{i,j,k} = b_k + \\sum_{u=0}^{f_h-1} \\sum_{v=0}^{f_w-1} \\sum_{k'=0}^{f_{n'}-1} x_{i',j',k'} \\cdot w_{u,v,k',k}\n\\]\nwhere \\(i' = i \\times s_h + u\\) and \\(j' = j \\times s_w + v\\).\n\n\nAttribution: Géron (2019) Figure 14.6"
  },
  {
    "objectID": "lectures/14/slides.html#convolutional-layer",
    "href": "lectures/14/slides.html#convolutional-layer",
    "title": "Neural Networks Architectures",
    "section": "Convolutional Layer",
    "text": "Convolutional Layer\n\n“Thus, a layer full of neurons using the same filter outputs a feature map.”\n“Of course, you do not have to define the filters manually: instead, during training the convolutional layer will automatically learn the most useful filters for its task.”\n\n\n\nGéron (2019) § 14"
  },
  {
    "objectID": "lectures/14/slides.html#convolutional-layer-1",
    "href": "lectures/14/slides.html#convolutional-layer-1",
    "title": "Neural Networks Architectures",
    "section": "Convolutional Layer",
    "text": "Convolutional Layer\n\n“(…) and the layers above will learn to combine them into more complex patterns.”\n“The fact that all neurons in a feature map share the same parameters dramatically reduces the number of parameters in the model.”\n\n\n\nGéron (2019) § 14"
  },
  {
    "objectID": "lectures/14/slides.html#summmary",
    "href": "lectures/14/slides.html#summmary",
    "title": "Neural Networks Architectures",
    "section": "Summmary",
    "text": "Summmary\n\nFeature Map: In convolutional neural networks (CNNs), the output of a convolution operation is known as a feature map. It captures the features of the input data as processed by a specific kernel."
  },
  {
    "objectID": "lectures/14/slides.html#summmary-1",
    "href": "lectures/14/slides.html#summmary-1",
    "title": "Neural Networks Architectures",
    "section": "Summmary",
    "text": "Summmary\n\nKernel Parameters: The parameters of the kernel are learned through the backpropagation process, allowing the network to optimize its feature extraction capabilities based on the training data."
  },
  {
    "objectID": "lectures/14/slides.html#summmary-2",
    "href": "lectures/14/slides.html#summmary-2",
    "title": "Neural Networks Architectures",
    "section": "Summmary",
    "text": "Summmary\n\nBias Term: A single bias term is added uniformly to all entries of the feature map. This bias helps adjust the activation level, providing additional flexibility for the network to better fit the data."
  },
  {
    "objectID": "lectures/14/slides.html#summmary-3",
    "href": "lectures/14/slides.html#summmary-3",
    "title": "Neural Networks Architectures",
    "section": "Summmary",
    "text": "Summmary\n\nActivation Function: Following the addition of the bias, the feature map values are typically passed through an activation function, such as ReLU (Rectified Linear Unit). The ReLU function introduces non-linearity by setting negative values to zero while retaining positive values, enabling the network to learn more complex patterns."
  },
  {
    "objectID": "lectures/14/slides.html#pooling-1",
    "href": "lectures/14/slides.html#pooling-1",
    "title": "Neural Networks Architectures",
    "section": "Pooling",
    "text": "Pooling\n\nA pooling layer exhibits similarities to a convolutional layer.\n\nEach neuron in a pooling layer is connected to a set of neurons within a receptive field.\n\nHowever, unlike convolutional layers, pooling layers do not possess weights.\n\nInstead, they produce an output by applying an aggregating function, commonly max or mean.\n\n\n\n\nIn a pooling layer, specifically max pooling, the max function is inherently nondifferentiable because it involves selecting the maximum value from a set of inputs. However, in the context of backpropagation in neural networks, we can work around this by using a concept known as the “gradient of the max function.”\nHere’s how it is done:\n\nForward Pass: During the forward pass, the max pooling layer selects the maximum value from each pooling region (e.g., a 2x2 window) and passes these values to the next layer.\nBackward Pass: During backpropagation, the gradient is propagated only to the input that was the maximum value in the forward pass. This means that the derivative is 1 for the position that held the maximum value and 0 for all other positions within the pooling window.\n\nThis approach effectively allows the max operation to participate in gradient-based optimization processes like backpropagation, even though the max function itself is nondifferentiable. By assigning the gradient to the position of the maximum value, the network can learn which features are most important for the task at hand.\n\n\nSimilar to convolutional layers, pooling layers allow specification of the receptive field size, padding, and stride. For the MaxPool2D function, the default receptive field size is \\(2 \\times 2\\)."
  },
  {
    "objectID": "lectures/14/slides.html#pooling-2",
    "href": "lectures/14/slides.html#pooling-2",
    "title": "Neural Networks Architectures",
    "section": "Pooling",
    "text": "Pooling\n\nThis subsampling process leads to a reduction in network size; each window of dimensions \\(f_h \\times f_w\\) is condensed to a single value, typically the maximum or mean of that window.\nAccording to Géron (2019), a max pooling layer provides a degree of invariance to small translations (§ 14)."
  },
  {
    "objectID": "lectures/14/slides.html#pooling-3",
    "href": "lectures/14/slides.html#pooling-3",
    "title": "Neural Networks Architectures",
    "section": "Pooling",
    "text": "Pooling\n\nDimensionality Reduction: Pooling layers reduce the spatial dimensions (width and height) of the input feature maps. This reduction decreases the number of parameters and computational load in the network, which can help prevent overfitting."
  },
  {
    "objectID": "lectures/14/slides.html#pooling-4",
    "href": "lectures/14/slides.html#pooling-4",
    "title": "Neural Networks Architectures",
    "section": "Pooling",
    "text": "Pooling\n\nFeature Extraction: By summarizing the presence of features in a region, pooling layers help retain the most critical information while discarding less important details. This process enables the network to focus on the most salient features."
  },
  {
    "objectID": "lectures/14/slides.html#pooling-5",
    "href": "lectures/14/slides.html#pooling-5",
    "title": "Neural Networks Architectures",
    "section": "Pooling",
    "text": "Pooling\n\nTranslation Invariance: Pooling introduces a degree of invariance to translations and distortions in the input. For instance, max pooling captures the most prominent feature in a local region, making the network less sensitive to small shifts or variations in the input."
  },
  {
    "objectID": "lectures/14/slides.html#pooling-6",
    "href": "lectures/14/slides.html#pooling-6",
    "title": "Neural Networks Architectures",
    "section": "Pooling",
    "text": "Pooling\n\nNoise Reduction: Pooling can help smooth out noise in the input by aggregating information over a region, thus emphasizing consistent features over random variations."
  },
  {
    "objectID": "lectures/14/slides.html#pooling-7",
    "href": "lectures/14/slides.html#pooling-7",
    "title": "Neural Networks Architectures",
    "section": "Pooling",
    "text": "Pooling\n\nHierarchical Feature Learning: By reducing the spatial dimensions progressively through the layers, pooling layers allow the network to build a hierarchical representation of the input data, capturing increasingly abstract and complex features at deeper layers."
  },
  {
    "objectID": "lectures/14/slides.html#keras",
    "href": "lectures/14/slides.html#keras",
    "title": "Neural Networks Architectures",
    "section": "Keras",
    "text": "Keras\n\nimport tensorflow as tf\nfrom functools import partial  \n\nDefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\") \n\nmodel = tf.keras.Sequential([     \n  DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]), \n  tf.keras.layers.MaxPool2D(),     \n  DefaultConv2D(filters=128),\n  DefaultConv2D(filters=128),\n  tf.keras.layers.MaxPool2D(),\n  DefaultConv2D(filters=256),\n  DefaultConv2D(filters=256),\n  tf.keras.layers.MaxPool2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_initializer=\"he_normal\"),     \n  tf.keras.layers.Dropout(0.5),\n  tf.keras.layers.Dense(units=64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n  tf.keras.layers.Dropout(0.5),\n  tf.keras.layers.Dense(units=10, activation=\"softmax\") ])  \n\nmodel.summary()\n\n\n\n\nThe previously discussed model, which comprised fully connected (Dense) layers, attained a test accuracy of 88%.\nWe will look at pooling next.\n\n\nGéron (2022) Chapter 11, test accuracy of 92% on the Fashion-MNIST dataset"
  },
  {
    "objectID": "lectures/14/slides.html#keras-output",
    "href": "lectures/14/slides.html#keras-output",
    "title": "Neural Networks Architectures",
    "section": "Keras",
    "text": "Keras\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (Conv2D)                 │ (None, 28, 28, 64)     │         3,200 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (MaxPooling2D)    │ (None, 14, 14, 64)     │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (Conv2D)               │ (None, 14, 14, 128)    │        73,856 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (Conv2D)               │ (None, 14, 14, 128)    │       147,584 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (MaxPooling2D)  │ (None, 7, 7, 128)      │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (Conv2D)               │ (None, 7, 7, 256)      │       295,168 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (Conv2D)               │ (None, 7, 7, 256)      │       590,080 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (MaxPooling2D)  │ (None, 3, 3, 256)      │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (Flatten)               │ (None, 2304)           │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (Dense)                   │ (None, 128)            │       295,040 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (Dropout)               │ (None, 128)            │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (Dense)                 │ (None, 64)             │         8,256 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (Dropout)             │ (None, 64)             │             0 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (Dense)                 │ (None, 10)             │           650 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 1,413,834 (5.39 MB)\n\n\n\n Trainable params: 1,413,834 (5.39 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "lectures/14/slides.html#convolutional-neural-networks",
    "href": "lectures/14/slides.html#convolutional-neural-networks",
    "title": "Neural Networks Architectures",
    "section": "Convolutional Neural Networks",
    "text": "Convolutional Neural Networks\n\n\n\nThe architecture involves sequentially stacking several convolutional layers, each followed by a ReLU activation layer, and then a pooling layer. As this process continues, the spatial dimensions of the image representation decrease. Concurrently, the number of feature maps increases, as illustrated in our Keras example. At the top of this stack, a standard feedforward neural network is incorporated."
  },
  {
    "objectID": "lectures/14/slides.html#alexnet",
    "href": "lectures/14/slides.html#alexnet",
    "title": "Neural Networks Architectures",
    "section": "AlexNet",
    "text": "AlexNet\n\n\n\n\n\nKrizhevsky, Sutskever, and Hinton (2012)\n\n\nAlexNet consists of eight layers with learnable parameters: five convolutional layers followed by three fully connected layers. The architecture also includes max-pooling layers, ReLU activation functions, and dropout to improve training performance and reduce overfitting.\n\n\nAttribution: Prince (2023)"
  },
  {
    "objectID": "lectures/14/slides.html#vgg",
    "href": "lectures/14/slides.html#vgg",
    "title": "Neural Networks Architectures",
    "section": "VGG",
    "text": "VGG\n\n\n\n\n\nSimonyan and Zisserman (2015)\n\n\nComplementary information can be found here.\n\nConvolutional networks (ConvNets) currently set the state of the art in visual recognition. The aim of this project is to investigate how the ConvNet depth affects their accuracy in the large-scale image recognition setting.\n\n\nOur main contribution is a rigorous evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by increasing the depth to 16-19 weight layers, which is substantially deeper than what has been used in the prior art. To reduce the number of parameters in such very deep networks, we use very small 3×3 filters in all convolutional layers (the convolution stride is set to 1). Please see our publication for more details.\n\n\n\nAttribution: Prince (2023)"
  },
  {
    "objectID": "lectures/14/slides.html#convnets-performance",
    "href": "lectures/14/slides.html#convnets-performance",
    "title": "Neural Networks Architectures",
    "section": "ConvNets Performance",
    "text": "ConvNets Performance\n\n\n\n\n\n\n\nAttribution: Prince (2023)"
  },
  {
    "objectID": "lectures/14/slides.html#statquest",
    "href": "lectures/14/slides.html#statquest",
    "title": "Neural Networks Architectures",
    "section": "StatQuest",
    "text": "StatQuest\n\n\n\nThe video presents a straightforward example that differentiates between images of the letter O and the letter X, utilizing a single filter for this purpose. This approach simplifies the explanation, making it easy to follow. In practical applications, however, each convolutional layer typically contains dozens or even hundreds of filters."
  },
  {
    "objectID": "lectures/14/slides.html#final-word",
    "href": "lectures/14/slides.html#final-word",
    "title": "Neural Networks Architectures",
    "section": "Final Word",
    "text": "Final Word\nAs you might expect, the number of layers and filters are hyperparameters that are optimized through the process of hyperparameter tuning.\n\n\n\n\n\n\n\n\nAttribution: @stefaan_cotteni"
  },
  {
    "objectID": "lectures/14/slides.html#summary",
    "href": "lectures/14/slides.html#summary",
    "title": "Neural Networks Architectures",
    "section": "Summary",
    "text": "Summary\n\nHierarchy of Concepts in Deep Learning\nKernels and Convolution Operations\nReceptive Field, Padding, and Stride\nFilters and Feature Maps\nConvolutional Layers\nPooling Layers\n\n\nSummary\n\nHierarchy of Concepts in Deep Learning\n\nDeep learning models represent data through layers of increasing abstraction.\nEach layer learns patterns based on the outputs of preceding layers (“patterns of patterns”).\nThis hierarchical learning reduces reliance on manual feature engineering.\nDeep networks achieve better performance with fewer parameters compared to shallow networks.\n\nConvolutional Neural Networks (CNNs)\n\nCNNs specialize in processing data with a grid-like topology (e.g., images).\nThey detect local patterns using convolutional layers with shared weights.\nNeurons in convolutional layers connect only within their receptive fields, not fully connected.\nThis local connectivity and weight sharing significantly reduce the number of parameters.\n\nKernels and Convolution Operations\n\nKernels (filters) are small matrices that slide over the input data to perform convolutions.\nThe convolution operation involves element-wise multiplication and summation.\nKernels can be designed to detect specific features like edges and textures.\nFeature maps are generated, highlighting where certain features are detected in the input.\n\nReceptive Field, Padding, and Stride\n\nReceptive Field: The local region of the input that a neuron is sensitive to.\nPadding: Adding zeros around the input to maintain spatial dimensions after convolution.\nStride: The step size with which the kernel moves over the input data.\nThese parameters control the output size and computation in convolutional layers.\n\nFilters and Feature Maps\n\nFilters are learned during training and are crucial for feature detection.\nAll neurons in a feature map share the same filter parameters.\nThis sharing leads to efficient parameter usage and consistent feature detection across the input.\n\nConvolutional Layers\n\nPerform convolutions followed by adding a bias term and applying an activation function (e.g., ReLU).\nThe activation function introduces non-linearity, allowing the network to learn complex patterns.\nThe use of shared weights and biases reduces the total number of parameters.\n\nPooling Layers\n\nPurpose: Reduce the spatial dimensions of feature maps to control overfitting and computation.\nTypes:\n\nMax Pooling: Takes the maximum value within a pooling window.\nAverage Pooling: Computes the average value within a pooling window.\n\nBenefits:\n\nDimensionality reduction leads to fewer parameters and faster computation.\nIntroduces translation invariance, making the network robust to shifts and distortions.\nHelps in hierarchical feature learning by focusing on prominent features.\n\n\nBuilding CNN Architectures\n\nCNNs are built by stacking convolutional and pooling layers.\nSpatial dimensions decrease while the number of feature maps increases in deeper layers.\nOften culminates with fully connected layers for classification tasks.\nExample architectures can be implemented using frameworks like Keras.\n\nHyperparameter Tuning\n\nKey hyperparameters include the number of layers, filters, kernel sizes, strides, and padding.\nProper tuning is essential for achieving optimal model performance.\nOverfitting can be controlled using techniques like dropout and regularization.\n\nFuture Directions\n\nFeature Attribution:\n\nTechniques like saliency maps and activation maximization help interpret model decisions.\nEssential for applications requiring explainability (e.g., self-driving cars).\n\nTransfer Learning:\n\nInvolves using pre-trained models on new tasks to save time and resources.\nParticularly useful when labeled data is scarce."
  },
  {
    "objectID": "lectures/14/slides.html#future-directions",
    "href": "lectures/14/slides.html#future-directions",
    "title": "Neural Networks Architectures",
    "section": "Future Directions",
    "text": "Future Directions\nWhen integrating CNNs into your projects, consider exploring the following topics:\n\nFeature Attribution: Various techniques are available to visualize what the network has learned. For example, in the context of self-driving cars, it is crucial to ensure that the network focuses on relevant features, avoiding distractions.\nTransfer Learning: This approach enables the reuse of weights from pre-trained networks, which accelerates the learning process, reduces computational demands, and facilitates network training even with a limited number of examples.\n\n\nThere are also 1D convolutions, which are often applied in bioinformatics."
  },
  {
    "objectID": "lectures/14/slides.html#further-reading",
    "href": "lectures/14/slides.html#further-reading",
    "title": "Neural Networks Architectures",
    "section": "Further Reading",
    "text": "Further Reading\n\n\n\n\n\nUnderstanding Deep Learning (Prince 2023) is a recently published textbook focused on the foundational concepts of deep learning.\nIt begins with fundamental principles and extends to contemporary topics such as transformers, diffusion models, graph neural networks, autoencoders, adversarial networks, and reinforcement learning.\nThe textbook aims to help readers comprehend these concepts without delving excessively into theoretical details.\nIt includes sixty-eight Python notebook exercises.\nThe book follows a “read-first, pay-later” model."
  },
  {
    "objectID": "lectures/14/slides.html#resources",
    "href": "lectures/14/slides.html#resources",
    "title": "Neural Networks Architectures",
    "section": "Resources",
    "text": "Resources\n\nA guide to convolution arithmetic for deep learning\nAuthors: Vincent Dumoulin and Francesco Visin\nLast revised: 11 Jan 2018\n\narXiv:1603.07285\nGitHub Repository"
  },
  {
    "objectID": "lectures/14/slides.html#next-lecture",
    "href": "lectures/14/slides.html#next-lecture",
    "title": "Neural Networks Architectures",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will introduce solution spaces."
  },
  {
    "objectID": "lectures/14/slides.html#references",
    "href": "lectures/14/slides.html#references",
    "title": "Neural Networks Architectures",
    "section": "References",
    "text": "References\n\n\nGéron, Aurélien. 2019. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 2nd ed. O’Reilly Media.\n\n\n———. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. 3rd ed. O’Reilly Media, Inc.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. Adaptive Computation and Machine Learning. MIT Press. https://dblp.org/rec/books/daglib/0040158.\n\n\nKrizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. “ImageNet Classification with Deep Convolutional Neural Networks.” In Advances in Neural Information Processing Systems, edited by F. Pereira, C. J. Burges, L. Bottou, and K. Q. Weinberger. Vol. 25. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf.\n\n\nLeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. “Deep Learning.” Nature 521 (7553): 436–44. https://doi.org/10.1038/nature14539.\n\n\nLecun, Y., L. Bottou, Y. Bengio, and P. Haffner. 1998. “Gradient-Based Learning Applied to Document Recognition.” Proceedings of the IEEE 86 (11): 2278–2324. https://doi.org/10.1109/5.726791.\n\n\nPrince, Simon J. D. 2023. Understanding Deep Learning. The MIT Press. http://udlbook.com.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nSimonyan, Karen, and Andrew Zisserman. 2015. “Very Deep Convolutional Networks for Large-Scale Image Recognition.” In International Conference on Learning Representations."
  },
  {
    "objectID": "lectures/14/index.html",
    "href": "lectures/14/index.html",
    "title": "Lecture 14",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 3 must be submitted no later than November 10, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/14/index.html#prepare",
    "href": "lectures/14/index.html#prepare",
    "title": "Lecture 14",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 750–788"
  },
  {
    "objectID": "lectures/14/index.html#participate",
    "href": "lectures/14/index.html#participate",
    "title": "Lecture 14",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/14/index.html#practice",
    "href": "lectures/14/index.html#practice",
    "title": "Lecture 14",
    "section": "Practice",
    "text": "Practice\n\nConvNetJS: Deep Learning in your browser"
  },
  {
    "objectID": "lectures/15/slides.html#quote-of-the-day",
    "href": "lectures/15/slides.html#quote-of-the-day",
    "title": "Introduction to Search",
    "section": "Quote of the Day",
    "text": "Quote of the Day"
  },
  {
    "objectID": "lectures/15/slides.html#learning-objectives",
    "href": "lectures/15/slides.html#learning-objectives",
    "title": "Introduction to Search",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the role of search algorithms in AI, crucial for planning, reasoning, and applications like AlphaGo.\nGrasp key search concepts: state space, initial/goal states, actions, transition models, cost functions.\nLearn differences and implementations of uninformed search algorithms (BFS and DFS).\nComprehend informed search strategies and heuristic functions’ role in search efficiency.\nImplement and compare BFS, DFS, and Best-First Search using the 8-Puzzle problem.\nAnalyze performance and optimality of various search algorithms.\n\n\nToday’s focus is primarily on providing justification, as well as introducing key concepts and terminology."
  },
  {
    "objectID": "lectures/15/slides.html#justification-1",
    "href": "lectures/15/slides.html#justification-1",
    "title": "Introduction to Search",
    "section": "Justification",
    "text": "Justification\n\n\n\n\n\n\n\nSilver et al. (2016)"
  },
  {
    "objectID": "lectures/15/slides.html#justification-2",
    "href": "lectures/15/slides.html#justification-2",
    "title": "Introduction to Search",
    "section": "Justification",
    "text": "Justification\nWe have honed our expertise in machine learning to a point where we possess a robust understanding of neural networks and deep learning, allowing us to develop simple models using Keras.\n\nIn recent years, Monte Carlo Tree Search (MCTS) has played a pivotal role in advancing artificial intelligence research. After initially concentrating on deep learning, we are now shifting our focus to search."
  },
  {
    "objectID": "lectures/15/slides.html#justification-3",
    "href": "lectures/15/slides.html#justification-3",
    "title": "Introduction to Search",
    "section": "Justification",
    "text": "Justification\nThe integration of deep learning and MCTS underpins modern applications such as AlphaGo, AlphaZero, and MuZero.\n\nSearch algorithms are crucial in addressing challenges in planning and reasoning and are likely to become increasingly significant in future developments."
  },
  {
    "objectID": "lectures/15/slides.html#search-a-biased-timeline",
    "href": "lectures/15/slides.html#search-a-biased-timeline",
    "title": "Introduction to Search",
    "section": "Search (a biased timeline)",
    "text": "Search (a biased timeline)\n\n1968 – A*: Heuristic-based search, foundational for pathfinding and planning in AI.\n1970s-1980s – Population-Based Algorithms (e.g., Genetic Algorithms): Stochastic optimization approaches useful for large, complex search spaces.\n1980s – Constraint Satisfaction Problems (CSPs): Search in structured spaces with explicit constraints; a precursor to formal problem-solving systems.\n2013 – DQN: Reinforcement learning via search (Q-learning) from raw input (pixels).\n2015 – AlphaGo: Game-tree search with Monte Carlo Tree Search (MCTS) combined with deep learning.\n2017 – AlphaZero: Generalized self-play with MCTS in multiple domains.\n2019 – MuZero: Search in unknown environments without predefined models.\n2020 – Agent57: Generalized search across multiple environments (Atari games).\n2020 – AlphaGeometry: Search-based theorem proving in mathematical spaces.\n2021 – FunSearch: Potentially another generalization of search techniques."
  },
  {
    "objectID": "lectures/15/slides.html#search",
    "href": "lectures/15/slides.html#search",
    "title": "Introduction to Search",
    "section": "Search",
    "text": "Search\n\n\n\nIn 1997, IBM’s Deep Blue defeated the reigning world chess champion, Garry Kasparov. However, the AI community was not particularly impressed, as the system’s primary accomplishment lay in its ability to evaluate 200 million chess positions per second. Following the match, Kasparov remarked that Deep Blue was “as intelligent as your alarm clock.”\nSince then, significant advancements have been made. Unlike Deep Blue, AlphaZero relies on “more interesting approaches than brute-force search, which are perhaps more human-like in the way that they deal with the position.” This prompted Kasparov to express his approval, stating, “I can’t hide my satisfaction that [AlphaZero] plays with a dynamic style reminiscent of my own!”\n\n\nThe computer that mastered Go. Nature Video posted on YouTube on 2016-01-27. (7m 52s)"
  },
  {
    "objectID": "lectures/15/slides.html#alphago---the-movie",
    "href": "lectures/15/slides.html#alphago---the-movie",
    "title": "Introduction to Search",
    "section": "AlphaGo - The Movie",
    "text": "AlphaGo - The Movie\n\n\n\n\n\n\nYes, AlphaGo successfully defeated the world champion, Lee Sedol. (1h 30m)"
  },
  {
    "objectID": "lectures/15/slides.html#alphago2muzero",
    "href": "lectures/15/slides.html#alphago2muzero",
    "title": "Introduction to Search",
    "section": "AlphaGo2MuZero",
    "text": "AlphaGo2MuZero\n\n\n\n\n\n\n\nDavid Silver, a principal research scientist at DeepMind and a professor at University College London, is one of the leading researchers on these projects. He earned his PhD at the University of Alberta, where he was supervised by Richard Sutton.\nYou might also want to watch the following video: AlphaGo Zero: Discovering new knowledge. Posted on YouTube on 2017-10-18.\n\n\nAttribution: MuZero: Mastering Go, chess, shogi and Atari without rules, Google DeepMind, 2020-12-23. Schrittwieser et al. (2020)"
  },
  {
    "objectID": "lectures/15/slides.html#applications",
    "href": "lectures/15/slides.html#applications",
    "title": "Introduction to Search",
    "section": "Applications",
    "text": "Applications\n\nPathfinding and Navigation: Used in robotics and video games to find a path from a starting point to a destination.\nPuzzle Solving: Solving puzzles like the 8-puzzle, mazes, or Sudoku.\nNetwork Analysis: Analyzing networks and graphs, such as finding connectivity or shortest paths in social networks or transportation maps.\nGame Playing: Used to evaluate moves in games like chess or Go, especially when combined with other strategies."
  },
  {
    "objectID": "lectures/15/slides.html#applications-1",
    "href": "lectures/15/slides.html#applications-1",
    "title": "Introduction to Search",
    "section": "Applications",
    "text": "Applications\n\nScheduling: Planning and scheduling tasks in manufacturing, project management, or airline scheduling.\nResource Allocation: Allocating resources in a network or within an organization where constraints must be satisfied.\nConfiguration Problems: Solving problems where a set of components must be assembled to meet specific requirements, such as configuring a computer system or designing a circuit."
  },
  {
    "objectID": "lectures/15/slides.html#applications-2",
    "href": "lectures/15/slides.html#applications-2",
    "title": "Introduction to Search",
    "section": "Applications",
    "text": "Applications\n\nDecision Making under Uncertainty: Used in real-time strategy games and simulations where decisions need to be evaluated under uncertain conditions.\nStorrytelling: LLMs can effectively generate stories when guided by a valid input plan from an automated planner. (Simon and Muise 2024)\n\n\nThe applications of search algorithms are both numerous and diverse.\nSearch has been an active area of research not only because of its wide range of applications but also due to the potential for improvements in algorithms to significantly reduce program execution time or facilitate the exploration of larger search spaces."
  },
  {
    "objectID": "lectures/15/slides.html#outline",
    "href": "lectures/15/slides.html#outline",
    "title": "Introduction to Search",
    "section": "Outline",
    "text": "Outline\n\nDeterministic & Heuristic Search: BFS, DFS, A* for pathfinding and optimization in classical AI.\nCSPs & Population-Based Algorithms: Focus on structured problems and stochastic search.\nAdversarial Game Algorithms: Minimax, alpha-beta pruning, MCTS for decision-making in competitive environments.\n\n\n\nThis lecture and the upcoming ones will thoroughly cover these topics."
  },
  {
    "objectID": "lectures/15/slides.html#definition",
    "href": "lectures/15/slides.html#definition",
    "title": "Introduction to Search",
    "section": "Definition",
    "text": "Definition\n\n\n\n (Russell and Norvig 2020, 63)\n\n\nWhen the correct action to take is not immediately obvious, an agent may need to to plan ahead: to consider a sequence of actions that form a path to a goal state. Such an agent is called a problem-solving agent, and the computational process it undertakes is called search."
  },
  {
    "objectID": "lectures/15/slides.html#terminology",
    "href": "lectures/15/slides.html#terminology",
    "title": "Introduction to Search",
    "section": "Terminology",
    "text": "Terminology\n\n\n\n\n\n\n\nThe definition of an agent in artificial intelligence (AI) shares some similarities with the psychological definition, but there are key distinctions. In AI, an agent is an autonomous entity that perceives its environment through sensors and acts upon it using actuators to achieve specific goals. Both definitions involve perception, decision-making, and action.\nHowever, while psychological agents are human or biological and involve complex cognitive and emotional processes, AI agents are computational and operate based on algorithms designed to maximize certain performance measures or achieve predefined objectives. The focus in AI is more on the technical implementation of these processes, whereas in psychology, the emphasis is on understanding the cognitive and motivational aspects of agency.\nThe concept of agentic design in software engineering and artificial intelligence has experienced a resurgence in popularity.\n\n\nAn agent is an entity that performs actions. A rational agent is one that acts to achieve the “best” outcome. Conceptually, an agent perceives its environment through sensors and interacts with it using actuators."
  },
  {
    "objectID": "lectures/15/slides.html#environment-characteristics",
    "href": "lectures/15/slides.html#environment-characteristics",
    "title": "Introduction to Search",
    "section": "Environment Characteristics",
    "text": "Environment Characteristics\n\nObservability: Partially observable, or fully observable\nAgent Composition: Single or multiple agents\nPredictability: Deterministic or non-deterministic\nState Dependency: Stateless or stateful\nTemporal Dynamics: Static or dynamic\nState Representation: Discrete or continuous\n\n\n\nThe characteristics of an environment influence the complexity of problem-solving.\n\nA fully observable environment allows the agent to detect all relevant aspects for decision-making.\nIn a deterministic environment, the agent can predict the next state based on the current state and its subsequent action.\nStateless (Episodic) Environments involve decisions or actions that are independent of prior actions, with experiences divided into unrelated episodes. An example is a classification problem.\nStateful (Sequential) Environments require that each action’s outcome can affect future decisions, as the sequence of actions impacts the state and subsequent choices. An example is a chess game.\nA dynamic environment is characterized by changes in context while the agent is deliberating.\nChess serves as an example of a discrete environment, with a finite, though large, number of states. In contrast, an autonomous vehicle operates within a continuous-state and continuous-time environment.\n\n\n\nIn this lecture, environments are assumed to be: fully observable, single agent, stateless, deterministic, static, and discrete."
  },
  {
    "objectID": "lectures/15/slides.html#problem-solving-process",
    "href": "lectures/15/slides.html#problem-solving-process",
    "title": "Introduction to Search",
    "section": "Problem-Solving Process",
    "text": "Problem-Solving Process\nSearch: The process involves simulating sequences of actions until the agent achieves its goal. A successful sequence is termed a solution.\n\nA precise formulation facilitates the development of reusable code.\nAn environment characterized as stateless, single-agent, fully observable, deterministic, static, and discrete implies that the solution to any problem within this context is a fixed sequence of actions.\n\nStateless: Each decision is independent of previous actions, meaning the solution does not depend on history.\nSingle Agent: There is no interaction with other agents that could introduce variability.\nFully Observable: The agent has complete information about the environment, allowing for precise decision-making.\nDeterministic: The outcome of actions is predictable, with no randomness affecting the result.\nStatic: The environment does not change over time, so the conditions remain constant.\nDiscrete: The environment has a finite number of states and actions, enabling a clear sequence of steps.\n\nI anticipate that you are already familiar with these concepts, and thus, this initial lecture primarily serves as a review."
  },
  {
    "objectID": "lectures/15/slides.html#search-problem-definition",
    "href": "lectures/15/slides.html#search-problem-definition",
    "title": "Introduction to Search",
    "section": "Search Problem Definition",
    "text": "Search Problem Definition\n\nA collection of states, referred to as the state space.\nAn initial state where the agent begins.\nOne or more goal states that define successful outcomes.\nA set of actions available in a given state \\(s\\).\nA transition model that determines the next state based on the current state and selected action.\nAn action cost function that specifies the cost of performing action \\(a\\) in state \\(s\\) to reach state \\(s'\\)."
  },
  {
    "objectID": "lectures/15/slides.html#definitions",
    "href": "lectures/15/slides.html#definitions",
    "title": "Introduction to Search",
    "section": "Definitions",
    "text": "Definitions\n\nA path is defined as a sequence of actions.\nA solution is a path that connects the initial state to the goal state.\nAn optimal solution is the path with the lowest cost among all possible solutions.\n\n\n\nIn certain problems, multiple optimal solutions may exist. However, it is typically sufficient to identify and report a single optimal solution. Providing all optimal solutions can significantly increase time and space complexity for some problems.\n\n\nWe assume that the path cost is the sum of the individual action costs, and all costs are positive. The state space can be conceptualized as a graph, where the nodes represent the states and the edges correspond to the actions."
  },
  {
    "objectID": "lectures/15/slides.html#example-8-puzzle",
    "href": "lectures/15/slides.html#example-8-puzzle",
    "title": "Introduction to Search",
    "section": "Example: 8-Puzzle",
    "text": "Example: 8-Puzzle"
  },
  {
    "objectID": "lectures/15/slides.html#puzzle",
    "href": "lectures/15/slides.html#puzzle",
    "title": "Introduction to Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle\n\nHow can the states be represented?\nWhat constitutes the initial state?\nWhat defines the actions?\nWhat would constitute a path?\nWhat characterizes the goal state?\nWhat would constitute a solution?\nWhat should be the cost of an action?\n\n\n\nEach state can be represented as a list containing the numbers 0 to 8. Each number corresponds to a tile, and its position in the list reflects its location in the grid, with 0 denoting the blank space.\nThe initial state is a permutation of the numbers 0 to 8.\nActions include left, right, up, and down, which involve sliding an adjacent tile into the blank space.\nA path would be a sequence of actions, say left, left, up.\nThe transition model maps a given state and action to a new state. Not all actions are feasible from every state; for instance, if the blank space is at the edge of the grid, only certain moves are possible, such as down, up, or left.\nThe goal state is achieved when the list is ordered from 1 to 8, followed by 0, indicating that the tiles are arranged correctly. How many goal states are there?\nA solution would be a valid path transforming an initial state into a goal state.\nEach action incurs a cost of 1.\n\nHow many possible states are there?\nThere are 9! = 362,880 states. Brut force is feasible.\nHow many states are there for the 15-Puzzle?\n15! = 1,307,674,368,000 (1.3 trillion)!"
  },
  {
    "objectID": "lectures/15/slides.html#search-tree",
    "href": "lectures/15/slides.html#search-tree",
    "title": "Introduction to Search",
    "section": "Search Tree",
    "text": "Search Tree\n\n\n\n\n\n\n\nThe search algorithms we examine today construct a search tree, where each node represents a state within the state space and each edge represents an action.\nIt is important to distinguish between the search tree and the state space, which can be depicted as a graph. The structure of the search tree varies depending on the algorithm employed to address the search problem.\n\n\nA search tree is a conceptual tree structure where nodes represent states in a state space, and edges represent possible actions, facilitating systematic exploration to find a path from an initial state to a goal state."
  },
  {
    "objectID": "lectures/15/slides.html#search-tree-1",
    "href": "lectures/15/slides.html#search-tree-1",
    "title": "Introduction to Search",
    "section": "Search Tree",
    "text": "Search Tree\n\n\n\n\n\n\n\nAn example of a search tree for the 8-Puzzle. The solution here is incomplete."
  },
  {
    "objectID": "lectures/15/slides.html#search-tree-2",
    "href": "lectures/15/slides.html#search-tree-2",
    "title": "Introduction to Search",
    "section": "Search Tree",
    "text": "Search Tree\n\nThe root of the search tree represents the initial state of the problem.\nExpanding a node involves evaluating all possible actions available from that state.\nThe result of an action is the new state achieved after applying that action to the current state.\nSimilar to other tree structures, each node (except for the root and leaf nodes) has a parent and may have children.\n\n\n\nA distinctive feature of a search algorithm is its method for selecting the next node to expand."
  },
  {
    "objectID": "lectures/15/slides.html#frontier",
    "href": "lectures/15/slides.html#frontier",
    "title": "Introduction to Search",
    "section": "Frontier",
    "text": "Frontier\n\n\n\n\n\n\n\nAny state corresponding to a node in the search tree is considered reached. Frontier nodes are those that have been reached but have not yet been expanded. Above, there are 10 expanded nodes and 11 frontier nodes, resulting in a total of 21 nodes that have been reached."
  },
  {
    "objectID": "lectures/15/slides.html#frontier-1",
    "href": "lectures/15/slides.html#frontier-1",
    "title": "Introduction to Search",
    "section": "Frontier",
    "text": "Frontier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe diagrams correspond to the search tree presented on the previous page. For example, the initial state can be expanded using three actions: slide left, right, and up. Node (2, 3) can only be expanded by sliding down, while node (3, 3) can be expanded by sliding left and down.\n\n\nIn the 8-Puzzle, four actions are possible: slide left, right, up, or down. The search can be visualized on a grid: purple nodes: expanded states, green nodes: frontier states (reached but not expanded)."
  },
  {
    "objectID": "lectures/15/slides.html#frontier-2",
    "href": "lectures/15/slides.html#frontier-2",
    "title": "Introduction to Search",
    "section": "Frontier",
    "text": "Frontier"
  },
  {
    "objectID": "lectures/15/slides.html#definition-1",
    "href": "lectures/15/slides.html#definition-1",
    "title": "Introduction to Search",
    "section": "Definition",
    "text": "Definition\nAn uninformed search is a search strategy that explores the search space using only the information available in the problem definition, without any domain-specific knowledge, evaluating nodes based solely on their inherent properties rather than estimated costs or heuristics."
  },
  {
    "objectID": "lectures/15/slides.html#state-representation",
    "href": "lectures/15/slides.html#state-representation",
    "title": "Introduction to Search",
    "section": "State Representation",
    "text": "State Representation\n\n\n\n\n\n\n\n\n\n\ninitial_state_8 = [6, 4, 5,\n                   8, 2, 7,\n                   1, 0, 3]\n\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\n\n\nThe states are represented as lists of numbers. 0 represents the blank tile."
  },
  {
    "objectID": "lectures/15/slides.html#is_goal",
    "href": "lectures/15/slides.html#is_goal",
    "title": "Introduction to Search",
    "section": "is_goal",
    "text": "is_goal\n\ndef is_goal(state, goal_state):\n    \"\"\"Determines if a given state matches the goal state.\"\"\"\n    return state == goal_state\n\n\n\nAuxilliary method."
  },
  {
    "objectID": "lectures/15/slides.html#expand",
    "href": "lectures/15/slides.html#expand",
    "title": "Introduction to Search",
    "section": "expand",
    "text": "expand\n\ndef expand(state):\n    \"\"\"Generates successor states by moving the blank tile in all possible directions.\"\"\"\n    size = int(len(state) ** 0.5)  # Determine puzzle size (3 for 8-puzzle, 4 for 15-puzzle)\n    idx = state.index(0)  # Find the index of the blank tile represented by 0\n    x, y = idx % size, idx // size  # Convert index to (x, y) coordinates\n    neighbors = []\n\n    # Define possible moves: Left, Right, Up, Down\n    moves = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n    for dx, dy in moves:\n        nx, ny = x + dx, y + dy\n        # Check if the new position is within the puzzle boundaries\n        if 0 &lt;= nx &lt; size and 0 &lt;= ny &lt; size:\n            n_idx = ny * size + nx\n            new_state = state.copy()\n            # Swap the blank tile with the adjacent tile\n            new_state[idx], new_state[n_idx] = new_state[n_idx], new_state[idx]\n            neighbors.append(new_state)\n    return neighbors"
  },
  {
    "objectID": "lectures/15/slides.html#expand-1",
    "href": "lectures/15/slides.html#expand-1",
    "title": "Introduction to Search",
    "section": "expand",
    "text": "expand\n\n\n\n\n\n\n\n\n\n\nexpand(initial_state_8)\n\n[[6, 4, 5, 8, 2, 7, 0, 1, 3],\n [6, 4, 5, 8, 2, 7, 1, 3, 0],\n [6, 4, 5, 8, 0, 7, 1, 2, 3]]"
  },
  {
    "objectID": "lectures/15/slides.html#is_empty",
    "href": "lectures/15/slides.html#is_empty",
    "title": "Introduction to Search",
    "section": "is_empty",
    "text": "is_empty\n\ndef is_empty(frontier):\n    \"\"\"Checks if the frontier is empty.\"\"\"\n    return len(frontier) == 0\n\n\n\nAre there 8-Puzzle boards that have no solutions?\nThe solvability of the 8-puzzle depends on the number of inversions in the initial state. An inversion is a pair of tiles where a higher-numbered tile precedes a lower-numbered tile when the puzzle is viewed as a sequence (excluding the blank tile).\n\n\nIf the frontier becomes empty (no more nodes to be expanded), the problem has no solution."
  },
  {
    "objectID": "lectures/15/slides.html#print_solution",
    "href": "lectures/15/slides.html#print_solution",
    "title": "Introduction to Search",
    "section": "print_solution",
    "text": "print_solution\n\ndef print_solution(solution):\n    \"\"\"Prints the sequence of steps from the initial to the goal state.\"\"\"\n    size = int(len(solution[0]) ** 0.5)\n    for step, state in enumerate(solution):\n        print(f\"Step {step}:\")\n        for i in range(size):\n            row = state[i*size:(i+1)*size]\n            print(' '.join(str(n) if n != 0 else ' ' for n in row))\n        print()"
  },
  {
    "objectID": "lectures/15/slides.html#cycles",
    "href": "lectures/15/slides.html#cycles",
    "title": "Introduction to Search",
    "section": "Cycles",
    "text": "Cycles\nA path that revisits the same states forms a cycle.\nAllowing cycles would render the resulting search tree infinite.\nTo prevent this, we monitor the states that have been reached, though this incurs a memory cost."
  },
  {
    "objectID": "lectures/15/slides.html#breadth-first-search-1",
    "href": "lectures/15/slides.html#breadth-first-search-1",
    "title": "Introduction to Search",
    "section": "Breadth-first search",
    "text": "Breadth-first search\n\nfrom collections import deque\n\nBreadth-first search (BFS) employs a queue to manage the frontier nodes, which are also known as the open list."
  },
  {
    "objectID": "lectures/15/slides.html#breadth-first-search-2",
    "href": "lectures/15/slides.html#breadth-first-search-2",
    "title": "Introduction to Search",
    "section": "Breadth-first search",
    "text": "Breadth-first search\n\ndef bfs(initial_state, goal_state):\n\n    frontier = deque()  # Initialize the queue for BFS\n    frontier.append((initial_state, []))  # Each element is a tuple: (state, path)\n\n    explored = set()\n    explored.add(tuple(initial_state))\n\n    iterations = 0 # simply used to compare algorithms\n\n    while not is_empty(frontier):\n        current_state, path = frontier.popleft()\n\n        if is_goal(current_state, goal_state):\n            print(f\"Number of iterations: {iterations}\")\n            return path + [current_state]  # Return the successful path\n\n        iterations = iterations + 1\n\n        for neighbor in expand(current_state):\n            neighbor_tuple = tuple(neighbor)\n            if neighbor_tuple not in explored:\n                explored.add(neighbor_tuple)\n                frontier.append((neighbor, path + [current_state]))\n\n    return None  # No solution found\n\n\n\nFind the shortest path from the initial state to the goal state."
  },
  {
    "objectID": "lectures/15/slides.html#simple-case",
    "href": "lectures/15/slides.html#simple-case",
    "title": "Introduction to Search",
    "section": "Simple Case",
    "text": "Simple Case\n\n\nNumber of iterations: 12\n\n\n\n\n\n\n\n\n\n\ninitial_state_8 = [1, 2, 3,\n                    4, 0, 6,\n                    7, 5, 8]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nbfs(initial_state_8, goal_state_8)\n\nNumber of iterations: 12\n\n\n[[1, 2, 3, 4, 0, 6, 7, 5, 8],\n [1, 2, 3, 4, 5, 6, 7, 0, 8],\n [1, 2, 3, 4, 5, 6, 7, 8, 0]]"
  },
  {
    "objectID": "lectures/15/slides.html#challenging-case",
    "href": "lectures/15/slides.html#challenging-case",
    "title": "Introduction to Search",
    "section": "Challenging Case",
    "text": "Challenging Case\n\ninitial_state_8 = [6, 4, 5,\n                   8, 2, 7,\n                   1, 0, 3]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nprint(\"Solving 8-puzzle with BFS...\")\n\nsolution_8_bfs = bfs(initial_state_8, goal_state_8)\n\nif solution_8_bfs:\n    print(f\"BFS Solution found in {len(solution_8_bfs) - 1} moves:\")\n    print_solution(solution_8_bfs)\nelse:\n    print(\"No solution found for 8-puzzle using BFS.\")\n\nSolving 8-puzzle with BFS...\nNumber of iterations: 145605\nBFS Solution found in 25 moves:\nStep 0:\n6 4 5\n8 2 7\n1   3\n\nStep 1:\n6 4 5\n8 2 7\n  1 3\n\nStep 2:\n6 4 5\n  2 7\n8 1 3\n\nStep 3:\n6 4 5\n2   7\n8 1 3\n\nStep 4:\n6   5\n2 4 7\n8 1 3\n\nStep 5:\n  6 5\n2 4 7\n8 1 3\n\nStep 6:\n2 6 5\n  4 7\n8 1 3\n\nStep 7:\n2 6 5\n4   7\n8 1 3\n\nStep 8:\n2 6 5\n4 1 7\n8   3\n\nStep 9:\n2 6 5\n4 1 7\n  8 3\n\nStep 10:\n2 6 5\n  1 7\n4 8 3\n\nStep 11:\n2 6 5\n1   7\n4 8 3\n\nStep 12:\n2 6 5\n1 7  \n4 8 3\n\nStep 13:\n2 6 5\n1 7 3\n4 8  \n\nStep 14:\n2 6 5\n1 7 3\n4   8\n\nStep 15:\n2 6 5\n1   3\n4 7 8\n\nStep 16:\n2   5\n1 6 3\n4 7 8\n\nStep 17:\n2 5  \n1 6 3\n4 7 8\n\nStep 18:\n2 5 3\n1 6  \n4 7 8\n\nStep 19:\n2 5 3\n1   6\n4 7 8\n\nStep 20:\n2   3\n1 5 6\n4 7 8\n\nStep 21:\n  2 3\n1 5 6\n4 7 8\n\nStep 22:\n1 2 3\n  5 6\n4 7 8\n\nStep 23:\n1 2 3\n4 5 6\n  7 8\n\nStep 24:\n1 2 3\n4 5 6\n7   8\n\nStep 25:\n1 2 3\n4 5 6\n7 8"
  },
  {
    "objectID": "lectures/15/slides.html#bfs-search-tree",
    "href": "lectures/15/slides.html#bfs-search-tree",
    "title": "Introduction to Search",
    "section": "BFS Search Tree",
    "text": "BFS Search Tree\n\n\n\n\n\n\n\nThe search tree above illustrates the first 20 iterations of the breadth-first search (BFS) for the specified initial goal."
  },
  {
    "objectID": "lectures/15/slides.html#depth-first-search-1",
    "href": "lectures/15/slides.html#depth-first-search-1",
    "title": "Introduction to Search",
    "section": "Depth-First Search",
    "text": "Depth-First Search\n\ndef dfs(initial_state, goal_state):\n\n    frontier = [(initial_state, [])]  # Each element is a tuple: (state, path)\n\n    explored = set()\n    explored.add(tuple(initial_state))\n\n    iterations = 0\n\n    while not is_empty(frontier):\n        current_state, path = frontier.pop()\n\n        if is_goal(current_state, goal_state):\n            print(f\"Number of iterations: {iterations}\")\n            return path + [current_state]  # Return the successful path\n\n        iterations = iterations + 1\n\n        for neighbor in expand(current_state):\n            neighbor_tuple = tuple(neighbor)\n            if neighbor_tuple not in explored:\n                explored.add(neighbor_tuple)\n                frontier.append((neighbor, path + [current_state]))\n\n    return None  # No solution found\n\n\n\nDepth-First Search (DFS) consistently expands the deepest node.\nWhen does the deepening process halt?\nIt ceases when all child nodes correspond to states that have already been visited.\nWhat happens next?\nThe algorithm backtracks to the most recent frontier node.\nIf all children of this node also correspond to previously visited states, the algorithm continues to backtrack further.\n\n\nWhat is the behaviour of depth-First Search (dfs)?"
  },
  {
    "objectID": "lectures/15/slides.html#dfs-search-tree",
    "href": "lectures/15/slides.html#dfs-search-tree",
    "title": "Introduction to Search",
    "section": "DFS Search Tree",
    "text": "DFS Search Tree"
  },
  {
    "objectID": "lectures/15/slides.html#dfs-search-tree-1",
    "href": "lectures/15/slides.html#dfs-search-tree-1",
    "title": "Introduction to Search",
    "section": "DFS Search Tree",
    "text": "DFS Search Tree"
  },
  {
    "objectID": "lectures/15/slides.html#simple-case-1",
    "href": "lectures/15/slides.html#simple-case-1",
    "title": "Introduction to Search",
    "section": "Simple Case",
    "text": "Simple Case\n\n\nNumber of iterations: 2\n\n\n\n\n\n\n\n\n\n\ninitial_state_8 = [1, 2, 3,\n                    4, 0, 6,\n                    7, 5, 8]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nbfs(initial_state_8, goal_state_8)\n\nNumber of iterations: 12\n\n\n[[1, 2, 3, 4, 0, 6, 7, 5, 8],\n [1, 2, 3, 4, 5, 6, 7, 0, 8],\n [1, 2, 3, 4, 5, 6, 7, 8, 0]]"
  },
  {
    "objectID": "lectures/15/slides.html#challenging-case-1",
    "href": "lectures/15/slides.html#challenging-case-1",
    "title": "Introduction to Search",
    "section": "Challenging Case",
    "text": "Challenging Case\n\ninitial_state_8 = [6, 4, 5,\n                   8, 2, 7,\n                   1, 0, 3]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nprint(\"Solving 8-puzzle with DFS...\")\n\nsolution_8_bfs = dfs(initial_state_8, goal_state_8)\n\nif solution_8_bfs:\n    print(f\"DFS Solution found in {len(solution_8_bfs) - 1} moves:\")\n    print_solution(solution_8_bfs)\nelse:\n    print(\"No solution found for 8-puzzle using DFS.\")\n\nSolving 8-puzzle with DFS...\nNumber of iterations: 1187\nDFS Solution found in 1157 moves:\nStep 0:\n6 4 5\n8 2 7\n1   3\n\nStep 1:\n6 4 5\n8   7\n1 2 3\n\nStep 2:\n6   5\n8 4 7\n1 2 3\n\nStep 3:\n6 5  \n8 4 7\n1 2 3\n\nStep 4:\n6 5 7\n8 4  \n1 2 3\n\nStep 5:\n6 5 7\n8 4 3\n1 2  \n\nStep 6:\n6 5 7\n8 4 3\n1   2\n\nStep 7:\n6 5 7\n8   3\n1 4 2\n\nStep 8:\n6   7\n8 5 3\n1 4 2\n\nStep 9:\n6 7  \n8 5 3\n1 4 2\n\nStep 10:\n6 7 3\n8 5  \n1 4 2\n\nStep 11:\n6 7 3\n8 5 2\n1 4  \n\nStep 12:\n6 7 3\n8 5 2\n1   4\n\nStep 13:\n6 7 3\n8   2\n1 5 4\n\nStep 14:\n6   3\n8 7 2\n1 5 4\n\nStep 15:\n6 3  \n8 7 2\n1 5 4\n\nStep 16:\n6 3 2\n8 7  \n1 5 4\n\nStep 17:\n6 3 2\n8 7 4\n1 5  \n\nStep 18:\n6 3 2\n8 7 4\n1   5\n\nStep 19:\n6 3 2\n8   4\n1 7 5\n\nStep 20:\n6   2\n8 3 4\n1 7 5\n\nStep 21:\n6 2  \n8 3 4\n1 7 5\n\nStep 22:\n6 2 4\n8 3  \n1 7 5\n\nStep 23:\n6 2 4\n8 3 5\n1 7  \n\nStep 24:\n6 2 4\n8 3 5\n1   7\n\nStep 25:\n6 2 4\n8   5\n1 3 7\n\nStep 26:\n6   4\n8 2 5\n1 3 7\n\nStep 27:\n6 4  \n8 2 5\n1 3 7\n\nStep 28:\n6 4 5\n8 2  \n1 3 7\n\nStep 29:\n6 4 5\n8   2\n1 3 7\n\nStep 30:\n6 4 5\n8 3 2\n1   7\n\nStep 31:\n6 4 5\n8 3 2\n1 7  \n\nStep 32:\n6 4 5\n8 3  \n1 7 2\n\nStep 33:\n6 4  \n8 3 5\n1 7 2\n\nStep 34:\n6   4\n8 3 5\n1 7 2\n\nStep 35:\n6 3 4\n8   5\n1 7 2\n\nStep 36:\n6 3 4\n8 7 5\n1   2\n\nStep 37:\n6 3 4\n8 7 5\n1 2  \n\nStep 38:\n6 3 4\n8 7  \n1 2 5\n\nStep 39:\n6 3  \n8 7 4\n1 2 5\n\nStep 40:\n6   3\n8 7 4\n1 2 5\n\nStep 41:\n6 7 3\n8   4\n1 2 5\n\nStep 42:\n6 7 3\n8 2 4\n1   5\n\nStep 43:\n6 7 3\n8 2 4\n  1 5\n\nStep 44:\n6 7 3\n  2 4\n8 1 5\n\nStep 45:\n  7 3\n6 2 4\n8 1 5\n\nStep 46:\n7   3\n6 2 4\n8 1 5\n\nStep 47:\n7 2 3\n6   4\n8 1 5\n\nStep 48:\n7 2 3\n6 1 4\n8   5\n\nStep 49:\n7 2 3\n6 1 4\n8 5  \n\nStep 50:\n7 2 3\n6 1  \n8 5 4\n\nStep 51:\n7 2  \n6 1 3\n8 5 4\n\nStep 52:\n7   2\n6 1 3\n8 5 4\n\nStep 53:\n7 1 2\n6   3\n8 5 4\n\nStep 54:\n7 1 2\n6 5 3\n8   4\n\nStep 55:\n7 1 2\n6 5 3\n8 4  \n\nStep 56:\n7 1 2\n6 5  \n8 4 3\n\nStep 57:\n7 1  \n6 5 2\n8 4 3\n\nStep 58:\n7   1\n6 5 2\n8 4 3\n\nStep 59:\n7 5 1\n6   2\n8 4 3\n\nStep 60:\n7 5 1\n6 4 2\n8   3\n\nStep 61:\n7 5 1\n6 4 2\n8 3  \n\nStep 62:\n7 5 1\n6 4  \n8 3 2\n\nStep 63:\n7 5  \n6 4 1\n8 3 2\n\nStep 64:\n7   5\n6 4 1\n8 3 2\n\nStep 65:\n7 4 5\n6   1\n8 3 2\n\nStep 66:\n7 4 5\n6 3 1\n8   2\n\nStep 67:\n7 4 5\n6 3 1\n8 2  \n\nStep 68:\n7 4 5\n6 3  \n8 2 1\n\nStep 69:\n7 4  \n6 3 5\n8 2 1\n\nStep 70:\n7   4\n6 3 5\n8 2 1\n\nStep 71:\n7 3 4\n6   5\n8 2 1\n\nStep 72:\n7 3 4\n6 2 5\n8   1\n\nStep 73:\n7 3 4\n6 2 5\n8 1  \n\nStep 74:\n7 3 4\n6 2  \n8 1 5\n\nStep 75:\n7 3 4\n6   2\n8 1 5\n\nStep 76:\n7 3 4\n6 1 2\n8   5\n\nStep 77:\n7 3 4\n6 1 2\n8 5  \n\nStep 78:\n7 3 4\n6 1  \n8 5 2\n\nStep 79:\n7 3  \n6 1 4\n8 5 2\n\nStep 80:\n7   3\n6 1 4\n8 5 2\n\nStep 81:\n7 1 3\n6   4\n8 5 2\n\nStep 82:\n7 1 3\n6 5 4\n8   2\n\nStep 83:\n7 1 3\n6 5 4\n8 2  \n\nStep 84:\n7 1 3\n6 5  \n8 2 4\n\nStep 85:\n7 1  \n6 5 3\n8 2 4\n\nStep 86:\n7   1\n6 5 3\n8 2 4\n\nStep 87:\n7 5 1\n6   3\n8 2 4\n\nStep 88:\n7 5 1\n6 2 3\n8   4\n\nStep 89:\n7 5 1\n6 2 3\n  8 4\n\nStep 90:\n7 5 1\n  2 3\n6 8 4\n\nStep 91:\n  5 1\n7 2 3\n6 8 4\n\nStep 92:\n5   1\n7 2 3\n6 8 4\n\nStep 93:\n5 2 1\n7   3\n6 8 4\n\nStep 94:\n5 2 1\n7 8 3\n6   4\n\nStep 95:\n5 2 1\n7 8 3\n6 4  \n\nStep 96:\n5 2 1\n7 8  \n6 4 3\n\nStep 97:\n5 2  \n7 8 1\n6 4 3\n\nStep 98:\n5   2\n7 8 1\n6 4 3\n\nStep 99:\n5 8 2\n7   1\n6 4 3\n\nStep 100:\n5 8 2\n7 4 1\n6   3\n\nStep 101:\n5 8 2\n7 4 1\n6 3  \n\nStep 102:\n5 8 2\n7 4  \n6 3 1\n\nStep 103:\n5 8  \n7 4 2\n6 3 1\n\nStep 104:\n5   8\n7 4 2\n6 3 1\n\nStep 105:\n5 4 8\n7   2\n6 3 1\n\nStep 106:\n5 4 8\n7 3 2\n6   1\n\nStep 107:\n5 4 8\n7 3 2\n6 1  \n\nStep 108:\n5 4 8\n7 3  \n6 1 2\n\nStep 109:\n5 4  \n7 3 8\n6 1 2\n\nStep 110:\n5   4\n7 3 8\n6 1 2\n\nStep 111:\n5 3 4\n7   8\n6 1 2\n\nStep 112:\n5 3 4\n7 1 8\n6   2\n\nStep 113:\n5 3 4\n7 1 8\n6 2  \n\nStep 114:\n5 3 4\n7 1  \n6 2 8\n\nStep 115:\n5 3  \n7 1 4\n6 2 8\n\nStep 116:\n5   3\n7 1 4\n6 2 8\n\nStep 117:\n5 1 3\n7   4\n6 2 8\n\nStep 118:\n5 1 3\n7 2 4\n6   8\n\nStep 119:\n5 1 3\n7 2 4\n6 8  \n\nStep 120:\n5 1 3\n7 2  \n6 8 4\n\nStep 121:\n5 1 3\n7   2\n6 8 4\n\nStep 122:\n5 1 3\n7 8 2\n6   4\n\nStep 123:\n5 1 3\n7 8 2\n6 4  \n\nStep 124:\n5 1 3\n7 8  \n6 4 2\n\nStep 125:\n5 1  \n7 8 3\n6 4 2\n\nStep 126:\n5   1\n7 8 3\n6 4 2\n\nStep 127:\n5 8 1\n7   3\n6 4 2\n\nStep 128:\n5 8 1\n7 4 3\n6   2\n\nStep 129:\n5 8 1\n7 4 3\n6 2  \n\nStep 130:\n5 8 1\n7 4  \n6 2 3\n\nStep 131:\n5 8  \n7 4 1\n6 2 3\n\nStep 132:\n5   8\n7 4 1\n6 2 3\n\nStep 133:\n5 4 8\n7   1\n6 2 3\n\nStep 134:\n5 4 8\n7 2 1\n6   3\n\nStep 135:\n5 4 8\n7 2 1\n  6 3\n\nStep 136:\n5 4 8\n  2 1\n7 6 3\n\nStep 137:\n  4 8\n5 2 1\n7 6 3\n\nStep 138:\n4   8\n5 2 1\n7 6 3\n\nStep 139:\n4 2 8\n5   1\n7 6 3\n\nStep 140:\n4 2 8\n5 6 1\n7   3\n\nStep 141:\n4 2 8\n5 6 1\n7 3  \n\nStep 142:\n4 2 8\n5 6  \n7 3 1\n\nStep 143:\n4 2  \n5 6 8\n7 3 1\n\nStep 144:\n4   2\n5 6 8\n7 3 1\n\nStep 145:\n4 6 2\n5   8\n7 3 1\n\nStep 146:\n4 6 2\n5 3 8\n7   1\n\nStep 147:\n4 6 2\n5 3 8\n7 1  \n\nStep 148:\n4 6 2\n5 3  \n7 1 8\n\nStep 149:\n4 6  \n5 3 2\n7 1 8\n\nStep 150:\n4   6\n5 3 2\n7 1 8\n\nStep 151:\n4 3 6\n5   2\n7 1 8\n\nStep 152:\n4 3 6\n5 1 2\n7   8\n\nStep 153:\n4 3 6\n5 1 2\n7 8  \n\nStep 154:\n4 3 6\n5 1  \n7 8 2\n\nStep 155:\n4 3  \n5 1 6\n7 8 2\n\nStep 156:\n4   3\n5 1 6\n7 8 2\n\nStep 157:\n4 1 3\n5   6\n7 8 2\n\nStep 158:\n4 1 3\n5 8 6\n7   2\n\nStep 159:\n4 1 3\n5 8 6\n7 2  \n\nStep 160:\n4 1 3\n5 8  \n7 2 6\n\nStep 161:\n4 1  \n5 8 3\n7 2 6\n\nStep 162:\n4   1\n5 8 3\n7 2 6\n\nStep 163:\n4 8 1\n5   3\n7 2 6\n\nStep 164:\n4 8 1\n5 2 3\n7   6\n\nStep 165:\n4 8 1\n5 2 3\n7 6  \n\nStep 166:\n4 8 1\n5 2  \n7 6 3\n\nStep 167:\n4 8 1\n5   2\n7 6 3\n\nStep 168:\n4 8 1\n5 6 2\n7   3\n\nStep 169:\n4 8 1\n5 6 2\n7 3  \n\nStep 170:\n4 8 1\n5 6  \n7 3 2\n\nStep 171:\n4 8  \n5 6 1\n7 3 2\n\nStep 172:\n4   8\n5 6 1\n7 3 2\n\nStep 173:\n4 6 8\n5   1\n7 3 2\n\nStep 174:\n4 6 8\n5 3 1\n7   2\n\nStep 175:\n4 6 8\n5 3 1\n7 2  \n\nStep 176:\n4 6 8\n5 3  \n7 2 1\n\nStep 177:\n4 6  \n5 3 8\n7 2 1\n\nStep 178:\n4   6\n5 3 8\n7 2 1\n\nStep 179:\n4 3 6\n5   8\n7 2 1\n\nStep 180:\n4 3 6\n5 2 8\n7   1\n\nStep 181:\n4 3 6\n5 2 8\n  7 1\n\nStep 182:\n4 3 6\n  2 8\n5 7 1\n\nStep 183:\n  3 6\n4 2 8\n5 7 1\n\nStep 184:\n3   6\n4 2 8\n5 7 1\n\nStep 185:\n3 2 6\n4   8\n5 7 1\n\nStep 186:\n3 2 6\n4 7 8\n5   1\n\nStep 187:\n3 2 6\n4 7 8\n5 1  \n\nStep 188:\n3 2 6\n4 7  \n5 1 8\n\nStep 189:\n3 2  \n4 7 6\n5 1 8\n\nStep 190:\n3   2\n4 7 6\n5 1 8\n\nStep 191:\n3 7 2\n4   6\n5 1 8\n\nStep 192:\n3 7 2\n4 1 6\n5   8\n\nStep 193:\n3 7 2\n4 1 6\n5 8  \n\nStep 194:\n3 7 2\n4 1  \n5 8 6\n\nStep 195:\n3 7  \n4 1 2\n5 8 6\n\nStep 196:\n3   7\n4 1 2\n5 8 6\n\nStep 197:\n3 1 7\n4   2\n5 8 6\n\nStep 198:\n3 1 7\n4 8 2\n5   6\n\nStep 199:\n3 1 7\n4 8 2\n5 6  \n\nStep 200:\n3 1 7\n4 8  \n5 6 2\n\nStep 201:\n3 1  \n4 8 7\n5 6 2\n\nStep 202:\n3   1\n4 8 7\n5 6 2\n\nStep 203:\n3 8 1\n4   7\n5 6 2\n\nStep 204:\n3 8 1\n4 6 7\n5   2\n\nStep 205:\n3 8 1\n4 6 7\n5 2  \n\nStep 206:\n3 8 1\n4 6  \n5 2 7\n\nStep 207:\n3 8  \n4 6 1\n5 2 7\n\nStep 208:\n3   8\n4 6 1\n5 2 7\n\nStep 209:\n3 6 8\n4   1\n5 2 7\n\nStep 210:\n3 6 8\n4 2 1\n5   7\n\nStep 211:\n3 6 8\n4 2 1\n5 7  \n\nStep 212:\n3 6 8\n4 2  \n5 7 1\n\nStep 213:\n3 6 8\n4   2\n5 7 1\n\nStep 214:\n3 6 8\n4 7 2\n5   1\n\nStep 215:\n3 6 8\n4 7 2\n5 1  \n\nStep 216:\n3 6 8\n4 7  \n5 1 2\n\nStep 217:\n3 6  \n4 7 8\n5 1 2\n\nStep 218:\n3   6\n4 7 8\n5 1 2\n\nStep 219:\n3 7 6\n4   8\n5 1 2\n\nStep 220:\n3 7 6\n4 1 8\n5   2\n\nStep 221:\n3 7 6\n4 1 8\n5 2  \n\nStep 222:\n3 7 6\n4 1  \n5 2 8\n\nStep 223:\n3 7  \n4 1 6\n5 2 8\n\nStep 224:\n3   7\n4 1 6\n5 2 8\n\nStep 225:\n3 1 7\n4   6\n5 2 8\n\nStep 226:\n3 1 7\n4 2 6\n5   8\n\nStep 227:\n3 1 7\n4 2 6\n  5 8\n\nStep 228:\n3 1 7\n  2 6\n4 5 8\n\nStep 229:\n  1 7\n3 2 6\n4 5 8\n\nStep 230:\n1   7\n3 2 6\n4 5 8\n\nStep 231:\n1 2 7\n3   6\n4 5 8\n\nStep 232:\n1 2 7\n3 5 6\n4   8\n\nStep 233:\n1 2 7\n3 5 6\n4 8  \n\nStep 234:\n1 2 7\n3 5  \n4 8 6\n\nStep 235:\n1 2  \n3 5 7\n4 8 6\n\nStep 236:\n1   2\n3 5 7\n4 8 6\n\nStep 237:\n1 5 2\n3   7\n4 8 6\n\nStep 238:\n1 5 2\n3 8 7\n4   6\n\nStep 239:\n1 5 2\n3 8 7\n4 6  \n\nStep 240:\n1 5 2\n3 8  \n4 6 7\n\nStep 241:\n1 5  \n3 8 2\n4 6 7\n\nStep 242:\n1   5\n3 8 2\n4 6 7\n\nStep 243:\n1 8 5\n3   2\n4 6 7\n\nStep 244:\n1 8 5\n3 6 2\n4   7\n\nStep 245:\n1 8 5\n3 6 2\n4 7  \n\nStep 246:\n1 8 5\n3 6  \n4 7 2\n\nStep 247:\n1 8  \n3 6 5\n4 7 2\n\nStep 248:\n1   8\n3 6 5\n4 7 2\n\nStep 249:\n1 6 8\n3   5\n4 7 2\n\nStep 250:\n1 6 8\n3 7 5\n4   2\n\nStep 251:\n1 6 8\n3 7 5\n4 2  \n\nStep 252:\n1 6 8\n3 7  \n4 2 5\n\nStep 253:\n1 6  \n3 7 8\n4 2 5\n\nStep 254:\n1   6\n3 7 8\n4 2 5\n\nStep 255:\n1 7 6\n3   8\n4 2 5\n\nStep 256:\n1 7 6\n3 2 8\n4   5\n\nStep 257:\n1 7 6\n3 2 8\n4 5  \n\nStep 258:\n1 7 6\n3 2  \n4 5 8\n\nStep 259:\n1 7 6\n3   2\n4 5 8\n\nStep 260:\n1 7 6\n3 5 2\n4   8\n\nStep 261:\n1 7 6\n3 5 2\n4 8  \n\nStep 262:\n1 7 6\n3 5  \n4 8 2\n\nStep 263:\n1 7  \n3 5 6\n4 8 2\n\nStep 264:\n1   7\n3 5 6\n4 8 2\n\nStep 265:\n1 5 7\n3   6\n4 8 2\n\nStep 266:\n1 5 7\n3 8 6\n4   2\n\nStep 267:\n1 5 7\n3 8 6\n4 2  \n\nStep 268:\n1 5 7\n3 8  \n4 2 6\n\nStep 269:\n1 5  \n3 8 7\n4 2 6\n\nStep 270:\n1   5\n3 8 7\n4 2 6\n\nStep 271:\n1 8 5\n3   7\n4 2 6\n\nStep 272:\n1 8 5\n3 2 7\n4   6\n\nStep 273:\n1 8 5\n3 2 7\n  4 6\n\nStep 274:\n1 8 5\n  2 7\n3 4 6\n\nStep 275:\n  8 5\n1 2 7\n3 4 6\n\nStep 276:\n8   5\n1 2 7\n3 4 6\n\nStep 277:\n8 2 5\n1   7\n3 4 6\n\nStep 278:\n8 2 5\n1 4 7\n3   6\n\nStep 279:\n8 2 5\n1 4 7\n3 6  \n\nStep 280:\n8 2 5\n1 4  \n3 6 7\n\nStep 281:\n8 2  \n1 4 5\n3 6 7\n\nStep 282:\n8   2\n1 4 5\n3 6 7\n\nStep 283:\n8 4 2\n1   5\n3 6 7\n\nStep 284:\n8 4 2\n1 6 5\n3   7\n\nStep 285:\n8 4 2\n1 6 5\n3 7  \n\nStep 286:\n8 4 2\n1 6  \n3 7 5\n\nStep 287:\n8 4  \n1 6 2\n3 7 5\n\nStep 288:\n8   4\n1 6 2\n3 7 5\n\nStep 289:\n8 6 4\n1   2\n3 7 5\n\nStep 290:\n8 6 4\n1 7 2\n3   5\n\nStep 291:\n8 6 4\n1 7 2\n3 5  \n\nStep 292:\n8 6 4\n1 7  \n3 5 2\n\nStep 293:\n8 6  \n1 7 4\n3 5 2\n\nStep 294:\n8   6\n1 7 4\n3 5 2\n\nStep 295:\n8 7 6\n1   4\n3 5 2\n\nStep 296:\n8 7 6\n1 5 4\n3   2\n\nStep 297:\n8 7 6\n1 5 4\n3 2  \n\nStep 298:\n8 7 6\n1 5  \n3 2 4\n\nStep 299:\n8 7  \n1 5 6\n3 2 4\n\nStep 300:\n8   7\n1 5 6\n3 2 4\n\nStep 301:\n8 5 7\n1   6\n3 2 4\n\nStep 302:\n8 5 7\n1 2 6\n3   4\n\nStep 303:\n8 5 7\n1 2 6\n3 4  \n\nStep 304:\n8 5 7\n1 2  \n3 4 6\n\nStep 305:\n8 5 7\n1   2\n3 4 6\n\nStep 306:\n8 5 7\n1 4 2\n3   6\n\nStep 307:\n8 5 7\n1 4 2\n3 6  \n\nStep 308:\n8 5 7\n1 4  \n3 6 2\n\nStep 309:\n8 5  \n1 4 7\n3 6 2\n\nStep 310:\n8   5\n1 4 7\n3 6 2\n\nStep 311:\n8 4 5\n1   7\n3 6 2\n\nStep 312:\n8 4 5\n1 6 7\n3   2\n\nStep 313:\n8 4 5\n1 6 7\n3 2  \n\nStep 314:\n8 4 5\n1 6  \n3 2 7\n\nStep 315:\n8 4  \n1 6 5\n3 2 7\n\nStep 316:\n8   4\n1 6 5\n3 2 7\n\nStep 317:\n8 6 4\n1   5\n3 2 7\n\nStep 318:\n8 6 4\n1 2 5\n3   7\n\nStep 319:\n8 6 4\n1 2 5\n  3 7\n\nStep 320:\n8 6 4\n  2 5\n1 3 7\n\nStep 321:\n8 6 4\n2   5\n1 3 7\n\nStep 322:\n8 6 4\n2 3 5\n1   7\n\nStep 323:\n8 6 4\n2 3 5\n1 7  \n\nStep 324:\n8 6 4\n2 3  \n1 7 5\n\nStep 325:\n8 6  \n2 3 4\n1 7 5\n\nStep 326:\n8   6\n2 3 4\n1 7 5\n\nStep 327:\n8 3 6\n2   4\n1 7 5\n\nStep 328:\n8 3 6\n2 7 4\n1   5\n\nStep 329:\n8 3 6\n2 7 4\n1 5  \n\nStep 330:\n8 3 6\n2 7  \n1 5 4\n\nStep 331:\n8 3  \n2 7 6\n1 5 4\n\nStep 332:\n8   3\n2 7 6\n1 5 4\n\nStep 333:\n8 7 3\n2   6\n1 5 4\n\nStep 334:\n8 7 3\n2 5 6\n1   4\n\nStep 335:\n8 7 3\n2 5 6\n1 4  \n\nStep 336:\n8 7 3\n2 5  \n1 4 6\n\nStep 337:\n8 7  \n2 5 3\n1 4 6\n\nStep 338:\n8   7\n2 5 3\n1 4 6\n\nStep 339:\n8 5 7\n2   3\n1 4 6\n\nStep 340:\n8 5 7\n2 4 3\n1   6\n\nStep 341:\n8 5 7\n2 4 3\n1 6  \n\nStep 342:\n8 5 7\n2 4  \n1 6 3\n\nStep 343:\n8 5  \n2 4 7\n1 6 3\n\nStep 344:\n8   5\n2 4 7\n1 6 3\n\nStep 345:\n8 4 5\n2   7\n1 6 3\n\nStep 346:\n8 4 5\n2 6 7\n1   3\n\nStep 347:\n8 4 5\n2 6 7\n1 3  \n\nStep 348:\n8 4 5\n2 6  \n1 3 7\n\nStep 349:\n8 4 5\n2   6\n1 3 7\n\nStep 350:\n8 4 5\n2 3 6\n1   7\n\nStep 351:\n8 4 5\n2 3 6\n1 7  \n\nStep 352:\n8 4 5\n2 3  \n1 7 6\n\nStep 353:\n8 4  \n2 3 5\n1 7 6\n\nStep 354:\n8   4\n2 3 5\n1 7 6\n\nStep 355:\n8 3 4\n2   5\n1 7 6\n\nStep 356:\n8 3 4\n2 7 5\n1   6\n\nStep 357:\n8 3 4\n2 7 5\n1 6  \n\nStep 358:\n8 3 4\n2 7  \n1 6 5\n\nStep 359:\n8 3  \n2 7 4\n1 6 5\n\nStep 360:\n8   3\n2 7 4\n1 6 5\n\nStep 361:\n8 7 3\n2   4\n1 6 5\n\nStep 362:\n8 7 3\n2 6 4\n1   5\n\nStep 363:\n8 7 3\n2 6 4\n  1 5\n\nStep 364:\n8 7 3\n  6 4\n2 1 5\n\nStep 365:\n  7 3\n8 6 4\n2 1 5\n\nStep 366:\n7   3\n8 6 4\n2 1 5\n\nStep 367:\n7 6 3\n8   4\n2 1 5\n\nStep 368:\n7 6 3\n8 1 4\n2   5\n\nStep 369:\n7 6 3\n8 1 4\n2 5  \n\nStep 370:\n7 6 3\n8 1  \n2 5 4\n\nStep 371:\n7 6  \n8 1 3\n2 5 4\n\nStep 372:\n7   6\n8 1 3\n2 5 4\n\nStep 373:\n7 1 6\n8   3\n2 5 4\n\nStep 374:\n7 1 6\n8 5 3\n2   4\n\nStep 375:\n7 1 6\n8 5 3\n2 4  \n\nStep 376:\n7 1 6\n8 5  \n2 4 3\n\nStep 377:\n7 1  \n8 5 6\n2 4 3\n\nStep 378:\n7   1\n8 5 6\n2 4 3\n\nStep 379:\n7 5 1\n8   6\n2 4 3\n\nStep 380:\n7 5 1\n8 4 6\n2   3\n\nStep 381:\n7 5 1\n8 4 6\n2 3  \n\nStep 382:\n7 5 1\n8 4  \n2 3 6\n\nStep 383:\n7 5  \n8 4 1\n2 3 6\n\nStep 384:\n7   5\n8 4 1\n2 3 6\n\nStep 385:\n7 4 5\n8   1\n2 3 6\n\nStep 386:\n7 4 5\n8 3 1\n2   6\n\nStep 387:\n7 4 5\n8 3 1\n2 6  \n\nStep 388:\n7 4 5\n8 3  \n2 6 1\n\nStep 389:\n7 4  \n8 3 5\n2 6 1\n\nStep 390:\n7   4\n8 3 5\n2 6 1\n\nStep 391:\n7 3 4\n8   5\n2 6 1\n\nStep 392:\n7 3 4\n8 6 5\n2   1\n\nStep 393:\n7 3 4\n8 6 5\n2 1  \n\nStep 394:\n7 3 4\n8 6  \n2 1 5\n\nStep 395:\n7 3 4\n8   6\n2 1 5\n\nStep 396:\n7 3 4\n8 1 6\n2   5\n\nStep 397:\n7 3 4\n8 1 6\n2 5  \n\nStep 398:\n7 3 4\n8 1  \n2 5 6\n\nStep 399:\n7 3  \n8 1 4\n2 5 6\n\nStep 400:\n7   3\n8 1 4\n2 5 6\n\nStep 401:\n7 1 3\n8   4\n2 5 6\n\nStep 402:\n7 1 3\n8 5 4\n2   6\n\nStep 403:\n7 1 3\n8 5 4\n2 6  \n\nStep 404:\n7 1 3\n8 5  \n2 6 4\n\nStep 405:\n7 1  \n8 5 3\n2 6 4\n\nStep 406:\n7   1\n8 5 3\n2 6 4\n\nStep 407:\n7 5 1\n8   3\n2 6 4\n\nStep 408:\n7 5 1\n8 3  \n2 6 4\n\nStep 409:\n7 5 1\n8 3 4\n2 6  \n\nStep 410:\n7 5 1\n8 3 4\n2   6\n\nStep 411:\n7 5 1\n8 3 4\n  2 6\n\nStep 412:\n7 5 1\n  3 4\n8 2 6\n\nStep 413:\n  5 1\n7 3 4\n8 2 6\n\nStep 414:\n5   1\n7 3 4\n8 2 6\n\nStep 415:\n5 3 1\n7   4\n8 2 6\n\nStep 416:\n5 3 1\n7 2 4\n8   6\n\nStep 417:\n5 3 1\n7 2 4\n8 6  \n\nStep 418:\n5 3 1\n7 2  \n8 6 4\n\nStep 419:\n5 3  \n7 2 1\n8 6 4\n\nStep 420:\n5   3\n7 2 1\n8 6 4\n\nStep 421:\n5 2 3\n7   1\n8 6 4\n\nStep 422:\n5 2 3\n7 6 1\n8   4\n\nStep 423:\n5 2 3\n7 6 1\n8 4  \n\nStep 424:\n5 2 3\n7 6  \n8 4 1\n\nStep 425:\n5 2  \n7 6 3\n8 4 1\n\nStep 426:\n5   2\n7 6 3\n8 4 1\n\nStep 427:\n5 6 2\n7   3\n8 4 1\n\nStep 428:\n5 6 2\n7 4 3\n8   1\n\nStep 429:\n5 6 2\n7 4 3\n8 1  \n\nStep 430:\n5 6 2\n7 4  \n8 1 3\n\nStep 431:\n5 6  \n7 4 2\n8 1 3\n\nStep 432:\n5   6\n7 4 2\n8 1 3\n\nStep 433:\n5 4 6\n7   2\n8 1 3\n\nStep 434:\n5 4 6\n7 1 2\n8   3\n\nStep 435:\n5 4 6\n7 1 2\n8 3  \n\nStep 436:\n5 4 6\n7 1  \n8 3 2\n\nStep 437:\n5 4  \n7 1 6\n8 3 2\n\nStep 438:\n5   4\n7 1 6\n8 3 2\n\nStep 439:\n5 1 4\n7   6\n8 3 2\n\nStep 440:\n5 1 4\n7 3 6\n8   2\n\nStep 441:\n5 1 4\n7 3 6\n8 2  \n\nStep 442:\n5 1 4\n7 3  \n8 2 6\n\nStep 443:\n5 1 4\n7   3\n8 2 6\n\nStep 444:\n5 1 4\n7 2 3\n8   6\n\nStep 445:\n5 1 4\n7 2 3\n8 6  \n\nStep 446:\n5 1 4\n7 2  \n8 6 3\n\nStep 447:\n5 1  \n7 2 4\n8 6 3\n\nStep 448:\n5   1\n7 2 4\n8 6 3\n\nStep 449:\n5 2 1\n7   4\n8 6 3\n\nStep 450:\n5 2 1\n7 6 4\n8   3\n\nStep 451:\n5 2 1\n7 6 4\n8 3  \n\nStep 452:\n5 2 1\n7 6  \n8 3 4\n\nStep 453:\n5 2  \n7 6 1\n8 3 4\n\nStep 454:\n5   2\n7 6 1\n8 3 4\n\nStep 455:\n5 6 2\n7   1\n8 3 4\n\nStep 456:\n5 6 2\n7 3 1\n8   4\n\nStep 457:\n5 6 2\n7 3 1\n  8 4\n\nStep 458:\n5 6 2\n  3 1\n7 8 4\n\nStep 459:\n  6 2\n5 3 1\n7 8 4\n\nStep 460:\n6   2\n5 3 1\n7 8 4\n\nStep 461:\n6 3 2\n5   1\n7 8 4\n\nStep 462:\n6 3 2\n5 8 1\n7   4\n\nStep 463:\n6 3 2\n5 8 1\n7 4  \n\nStep 464:\n6 3 2\n5 8  \n7 4 1\n\nStep 465:\n6 3  \n5 8 2\n7 4 1\n\nStep 466:\n6   3\n5 8 2\n7 4 1\n\nStep 467:\n6 8 3\n5   2\n7 4 1\n\nStep 468:\n6 8 3\n5 4 2\n7   1\n\nStep 469:\n6 8 3\n5 4 2\n7 1  \n\nStep 470:\n6 8 3\n5 4  \n7 1 2\n\nStep 471:\n6 8  \n5 4 3\n7 1 2\n\nStep 472:\n6   8\n5 4 3\n7 1 2\n\nStep 473:\n6 4 8\n5   3\n7 1 2\n\nStep 474:\n6 4 8\n5 1 3\n7   2\n\nStep 475:\n6 4 8\n5 1 3\n7 2  \n\nStep 476:\n6 4 8\n5 1  \n7 2 3\n\nStep 477:\n6 4  \n5 1 8\n7 2 3\n\nStep 478:\n6   4\n5 1 8\n7 2 3\n\nStep 479:\n6 1 4\n5   8\n7 2 3\n\nStep 480:\n6 1 4\n5 2 8\n7   3\n\nStep 481:\n6 1 4\n5 2 8\n7 3  \n\nStep 482:\n6 1 4\n5 2  \n7 3 8\n\nStep 483:\n6 1  \n5 2 4\n7 3 8\n\nStep 484:\n6   1\n5 2 4\n7 3 8\n\nStep 485:\n6 2 1\n5   4\n7 3 8\n\nStep 486:\n6 2 1\n5 3 4\n7   8\n\nStep 487:\n6 2 1\n5 3 4\n7 8  \n\nStep 488:\n6 2 1\n5 3  \n7 8 4\n\nStep 489:\n6 2 1\n5   3\n7 8 4\n\nStep 490:\n6 2 1\n5 8 3\n7   4\n\nStep 491:\n6 2 1\n5 8 3\n7 4  \n\nStep 492:\n6 2 1\n5 8  \n7 4 3\n\nStep 493:\n6 2  \n5 8 1\n7 4 3\n\nStep 494:\n6   2\n5 8 1\n7 4 3\n\nStep 495:\n6 8 2\n5   1\n7 4 3\n\nStep 496:\n6 8 2\n5 4 1\n7   3\n\nStep 497:\n6 8 2\n5 4 1\n7 3  \n\nStep 498:\n6 8 2\n5 4  \n7 3 1\n\nStep 499:\n6 8  \n5 4 2\n7 3 1\n\nStep 500:\n6   8\n5 4 2\n7 3 1\n\nStep 501:\n6 4 8\n5   2\n7 3 1\n\nStep 502:\n6 4 8\n5 3 2\n7   1\n\nStep 503:\n6 4 8\n5 3 2\n  7 1\n\nStep 504:\n6 4 8\n  3 2\n5 7 1\n\nStep 505:\n  4 8\n6 3 2\n5 7 1\n\nStep 506:\n4   8\n6 3 2\n5 7 1\n\nStep 507:\n4 3 8\n6   2\n5 7 1\n\nStep 508:\n4 3 8\n6 7 2\n5   1\n\nStep 509:\n4 3 8\n6 7 2\n5 1  \n\nStep 510:\n4 3 8\n6 7  \n5 1 2\n\nStep 511:\n4 3  \n6 7 8\n5 1 2\n\nStep 512:\n4   3\n6 7 8\n5 1 2\n\nStep 513:\n4 7 3\n6   8\n5 1 2\n\nStep 514:\n4 7 3\n6 1 8\n5   2\n\nStep 515:\n4 7 3\n6 1 8\n5 2  \n\nStep 516:\n4 7 3\n6 1  \n5 2 8\n\nStep 517:\n4 7  \n6 1 3\n5 2 8\n\nStep 518:\n4   7\n6 1 3\n5 2 8\n\nStep 519:\n4 1 7\n6   3\n5 2 8\n\nStep 520:\n4 1 7\n6 2 3\n5   8\n\nStep 521:\n4 1 7\n6 2 3\n5 8  \n\nStep 522:\n4 1 7\n6 2  \n5 8 3\n\nStep 523:\n4 1  \n6 2 7\n5 8 3\n\nStep 524:\n4   1\n6 2 7\n5 8 3\n\nStep 525:\n4 2 1\n6   7\n5 8 3\n\nStep 526:\n4 2 1\n6 8 7\n5   3\n\nStep 527:\n4 2 1\n6 8 7\n5 3  \n\nStep 528:\n4 2 1\n6 8  \n5 3 7\n\nStep 529:\n4 2  \n6 8 1\n5 3 7\n\nStep 530:\n4   2\n6 8 1\n5 3 7\n\nStep 531:\n4 8 2\n6   1\n5 3 7\n\nStep 532:\n4 8 2\n6 3 1\n5   7\n\nStep 533:\n4 8 2\n6 3 1\n5 7  \n\nStep 534:\n4 8 2\n6 3  \n5 7 1\n\nStep 535:\n4 8 2\n6   3\n5 7 1\n\nStep 536:\n4 8 2\n6 7 3\n5   1\n\nStep 537:\n4 8 2\n6 7 3\n5 1  \n\nStep 538:\n4 8 2\n6 7  \n5 1 3\n\nStep 539:\n4 8  \n6 7 2\n5 1 3\n\nStep 540:\n4   8\n6 7 2\n5 1 3\n\nStep 541:\n4 7 8\n6   2\n5 1 3\n\nStep 542:\n4 7 8\n6 1 2\n5   3\n\nStep 543:\n4 7 8\n6 1 2\n5 3  \n\nStep 544:\n4 7 8\n6 1  \n5 3 2\n\nStep 545:\n4 7  \n6 1 8\n5 3 2\n\nStep 546:\n4   7\n6 1 8\n5 3 2\n\nStep 547:\n4 1 7\n6   8\n5 3 2\n\nStep 548:\n4 1 7\n6 3 8\n5   2\n\nStep 549:\n4 1 7\n6 3 8\n  5 2\n\nStep 550:\n4 1 7\n  3 8\n6 5 2\n\nStep 551:\n  1 7\n4 3 8\n6 5 2\n\nStep 552:\n1   7\n4 3 8\n6 5 2\n\nStep 553:\n1 3 7\n4   8\n6 5 2\n\nStep 554:\n1 3 7\n4 5 8\n6   2\n\nStep 555:\n1 3 7\n4 5 8\n6 2  \n\nStep 556:\n1 3 7\n4 5  \n6 2 8\n\nStep 557:\n1 3  \n4 5 7\n6 2 8\n\nStep 558:\n1   3\n4 5 7\n6 2 8\n\nStep 559:\n1 5 3\n4   7\n6 2 8\n\nStep 560:\n1 5 3\n4 2 7\n6   8\n\nStep 561:\n1 5 3\n4 2 7\n6 8  \n\nStep 562:\n1 5 3\n4 2  \n6 8 7\n\nStep 563:\n1 5  \n4 2 3\n6 8 7\n\nStep 564:\n1   5\n4 2 3\n6 8 7\n\nStep 565:\n1 2 5\n4   3\n6 8 7\n\nStep 566:\n1 2 5\n4 8 3\n6   7\n\nStep 567:\n1 2 5\n4 8 3\n6 7  \n\nStep 568:\n1 2 5\n4 8  \n6 7 3\n\nStep 569:\n1 2  \n4 8 5\n6 7 3\n\nStep 570:\n1   2\n4 8 5\n6 7 3\n\nStep 571:\n1 8 2\n4   5\n6 7 3\n\nStep 572:\n1 8 2\n4 7 5\n6   3\n\nStep 573:\n1 8 2\n4 7 5\n6 3  \n\nStep 574:\n1 8 2\n4 7  \n6 3 5\n\nStep 575:\n1 8  \n4 7 2\n6 3 5\n\nStep 576:\n1   8\n4 7 2\n6 3 5\n\nStep 577:\n1 7 8\n4   2\n6 3 5\n\nStep 578:\n1 7 8\n4 3 2\n6   5\n\nStep 579:\n1 7 8\n4 3 2\n6 5  \n\nStep 580:\n1 7 8\n4 3  \n6 5 2\n\nStep 581:\n1 7 8\n4   3\n6 5 2\n\nStep 582:\n1 7 8\n4 5 3\n6   2\n\nStep 583:\n1 7 8\n4 5 3\n6 2  \n\nStep 584:\n1 7 8\n4 5  \n6 2 3\n\nStep 585:\n1 7  \n4 5 8\n6 2 3\n\nStep 586:\n1   7\n4 5 8\n6 2 3\n\nStep 587:\n1 5 7\n4   8\n6 2 3\n\nStep 588:\n1 5 7\n4 2 8\n6   3\n\nStep 589:\n1 5 7\n4 2 8\n6 3  \n\nStep 590:\n1 5 7\n4 2  \n6 3 8\n\nStep 591:\n1 5  \n4 2 7\n6 3 8\n\nStep 592:\n1   5\n4 2 7\n6 3 8\n\nStep 593:\n1 2 5\n4   7\n6 3 8\n\nStep 594:\n1 2 5\n4 3 7\n6   8\n\nStep 595:\n1 2 5\n4 3 7\n  6 8\n\nStep 596:\n1 2 5\n  3 7\n4 6 8\n\nStep 597:\n  2 5\n1 3 7\n4 6 8\n\nStep 598:\n2   5\n1 3 7\n4 6 8\n\nStep 599:\n2 3 5\n1   7\n4 6 8\n\nStep 600:\n2 3 5\n1 6 7\n4   8\n\nStep 601:\n2 3 5\n1 6 7\n4 8  \n\nStep 602:\n2 3 5\n1 6  \n4 8 7\n\nStep 603:\n2 3  \n1 6 5\n4 8 7\n\nStep 604:\n2   3\n1 6 5\n4 8 7\n\nStep 605:\n2 6 3\n1   5\n4 8 7\n\nStep 606:\n2 6 3\n1 8 5\n4   7\n\nStep 607:\n2 6 3\n1 8 5\n4 7  \n\nStep 608:\n2 6 3\n1 8  \n4 7 5\n\nStep 609:\n2 6  \n1 8 3\n4 7 5\n\nStep 610:\n2   6\n1 8 3\n4 7 5\n\nStep 611:\n2 8 6\n1   3\n4 7 5\n\nStep 612:\n2 8 6\n1 7 3\n4   5\n\nStep 613:\n2 8 6\n1 7 3\n4 5  \n\nStep 614:\n2 8 6\n1 7  \n4 5 3\n\nStep 615:\n2 8  \n1 7 6\n4 5 3\n\nStep 616:\n2   8\n1 7 6\n4 5 3\n\nStep 617:\n2 7 8\n1   6\n4 5 3\n\nStep 618:\n2 7 8\n1 5 6\n4   3\n\nStep 619:\n2 7 8\n1 5 6\n4 3  \n\nStep 620:\n2 7 8\n1 5  \n4 3 6\n\nStep 621:\n2 7  \n1 5 8\n4 3 6\n\nStep 622:\n2   7\n1 5 8\n4 3 6\n\nStep 623:\n2 5 7\n1   8\n4 3 6\n\nStep 624:\n2 5 7\n1 3 8\n4   6\n\nStep 625:\n2 5 7\n1 3 8\n4 6  \n\nStep 626:\n2 5 7\n1 3  \n4 6 8\n\nStep 627:\n2 5 7\n1   3\n4 6 8\n\nStep 628:\n2 5 7\n1 6 3\n4   8\n\nStep 629:\n2 5 7\n1 6 3\n4 8  \n\nStep 630:\n2 5 7\n1 6  \n4 8 3\n\nStep 631:\n2 5  \n1 6 7\n4 8 3\n\nStep 632:\n2   5\n1 6 7\n4 8 3\n\nStep 633:\n2 6 5\n1   7\n4 8 3\n\nStep 634:\n2 6 5\n1 8 7\n4   3\n\nStep 635:\n2 6 5\n1 8 7\n4 3  \n\nStep 636:\n2 6 5\n1 8  \n4 3 7\n\nStep 637:\n2 6  \n1 8 5\n4 3 7\n\nStep 638:\n2   6\n1 8 5\n4 3 7\n\nStep 639:\n2 8 6\n1   5\n4 3 7\n\nStep 640:\n2 8 6\n1 3 5\n4   7\n\nStep 641:\n2 8 6\n1 3 5\n  4 7\n\nStep 642:\n2 8 6\n  3 5\n1 4 7\n\nStep 643:\n  8 6\n2 3 5\n1 4 7\n\nStep 644:\n8   6\n2 3 5\n1 4 7\n\nStep 645:\n8 3 6\n2   5\n1 4 7\n\nStep 646:\n8 3 6\n2 4 5\n1   7\n\nStep 647:\n8 3 6\n2 4 5\n  1 7\n\nStep 648:\n8 3 6\n  4 5\n2 1 7\n\nStep 649:\n  3 6\n8 4 5\n2 1 7\n\nStep 650:\n3   6\n8 4 5\n2 1 7\n\nStep 651:\n3 4 6\n8   5\n2 1 7\n\nStep 652:\n3 4 6\n8 1 5\n2   7\n\nStep 653:\n3 4 6\n8 1 5\n2 7  \n\nStep 654:\n3 4 6\n8 1  \n2 7 5\n\nStep 655:\n3 4  \n8 1 6\n2 7 5\n\nStep 656:\n3   4\n8 1 6\n2 7 5\n\nStep 657:\n3 1 4\n8   6\n2 7 5\n\nStep 658:\n3 1 4\n8 7 6\n2   5\n\nStep 659:\n3 1 4\n8 7 6\n2 5  \n\nStep 660:\n3 1 4\n8 7  \n2 5 6\n\nStep 661:\n3 1  \n8 7 4\n2 5 6\n\nStep 662:\n3   1\n8 7 4\n2 5 6\n\nStep 663:\n3 7 1\n8   4\n2 5 6\n\nStep 664:\n3 7 1\n8 5 4\n2   6\n\nStep 665:\n3 7 1\n8 5 4\n2 6  \n\nStep 666:\n3 7 1\n8 5  \n2 6 4\n\nStep 667:\n3 7  \n8 5 1\n2 6 4\n\nStep 668:\n3   7\n8 5 1\n2 6 4\n\nStep 669:\n3 5 7\n8   1\n2 6 4\n\nStep 670:\n3 5 7\n8 6 1\n2   4\n\nStep 671:\n3 5 7\n8 6 1\n2 4  \n\nStep 672:\n3 5 7\n8 6  \n2 4 1\n\nStep 673:\n3 5  \n8 6 7\n2 4 1\n\nStep 674:\n3   5\n8 6 7\n2 4 1\n\nStep 675:\n3 6 5\n8   7\n2 4 1\n\nStep 676:\n3 6 5\n8 4 7\n2   1\n\nStep 677:\n3 6 5\n8 4 7\n2 1  \n\nStep 678:\n3 6 5\n8 4  \n2 1 7\n\nStep 679:\n3 6 5\n8   4\n2 1 7\n\nStep 680:\n3 6 5\n8 1 4\n2   7\n\nStep 681:\n3 6 5\n8 1 4\n2 7  \n\nStep 682:\n3 6 5\n8 1  \n2 7 4\n\nStep 683:\n3 6  \n8 1 5\n2 7 4\n\nStep 684:\n3   6\n8 1 5\n2 7 4\n\nStep 685:\n3 1 6\n8   5\n2 7 4\n\nStep 686:\n3 1 6\n8 7 5\n2   4\n\nStep 687:\n3 1 6\n8 7 5\n2 4  \n\nStep 688:\n3 1 6\n8 7  \n2 4 5\n\nStep 689:\n3 1  \n8 7 6\n2 4 5\n\nStep 690:\n3   1\n8 7 6\n2 4 5\n\nStep 691:\n3 7 1\n8   6\n2 4 5\n\nStep 692:\n3 7 1\n8 4 6\n2   5\n\nStep 693:\n3 7 1\n8 4 6\n  2 5\n\nStep 694:\n3 7 1\n  4 6\n8 2 5\n\nStep 695:\n  7 1\n3 4 6\n8 2 5\n\nStep 696:\n7   1\n3 4 6\n8 2 5\n\nStep 697:\n7 4 1\n3   6\n8 2 5\n\nStep 698:\n7 4 1\n3 2 6\n8   5\n\nStep 699:\n7 4 1\n3 2 6\n8 5  \n\nStep 700:\n7 4 1\n3 2  \n8 5 6\n\nStep 701:\n7 4  \n3 2 1\n8 5 6\n\nStep 702:\n7   4\n3 2 1\n8 5 6\n\nStep 703:\n7 2 4\n3   1\n8 5 6\n\nStep 704:\n7 2 4\n3 5 1\n8   6\n\nStep 705:\n7 2 4\n3 5 1\n8 6  \n\nStep 706:\n7 2 4\n3 5  \n8 6 1\n\nStep 707:\n7 2  \n3 5 4\n8 6 1\n\nStep 708:\n7   2\n3 5 4\n8 6 1\n\nStep 709:\n7 5 2\n3   4\n8 6 1\n\nStep 710:\n7 5 2\n3 6 4\n8   1\n\nStep 711:\n7 5 2\n3 6 4\n8 1  \n\nStep 712:\n7 5 2\n3 6  \n8 1 4\n\nStep 713:\n7 5  \n3 6 2\n8 1 4\n\nStep 714:\n7   5\n3 6 2\n8 1 4\n\nStep 715:\n7 6 5\n3   2\n8 1 4\n\nStep 716:\n7 6 5\n3 1 2\n8   4\n\nStep 717:\n7 6 5\n3 1 2\n8 4  \n\nStep 718:\n7 6 5\n3 1  \n8 4 2\n\nStep 719:\n7 6  \n3 1 5\n8 4 2\n\nStep 720:\n7   6\n3 1 5\n8 4 2\n\nStep 721:\n7 1 6\n3   5\n8 4 2\n\nStep 722:\n7 1 6\n3 4 5\n8   2\n\nStep 723:\n7 1 6\n3 4 5\n8 2  \n\nStep 724:\n7 1 6\n3 4  \n8 2 5\n\nStep 725:\n7 1 6\n3   4\n8 2 5\n\nStep 726:\n7 1 6\n3 2 4\n8   5\n\nStep 727:\n7 1 6\n3 2 4\n8 5  \n\nStep 728:\n7 1 6\n3 2  \n8 5 4\n\nStep 729:\n7 1  \n3 2 6\n8 5 4\n\nStep 730:\n7   1\n3 2 6\n8 5 4\n\nStep 731:\n7 2 1\n3   6\n8 5 4\n\nStep 732:\n7 2 1\n3 5 6\n8   4\n\nStep 733:\n7 2 1\n3 5 6\n8 4  \n\nStep 734:\n7 2 1\n3 5  \n8 4 6\n\nStep 735:\n7 2  \n3 5 1\n8 4 6\n\nStep 736:\n7   2\n3 5 1\n8 4 6\n\nStep 737:\n7 5 2\n3   1\n8 4 6\n\nStep 738:\n7 5 2\n3 4 1\n8   6\n\nStep 739:\n7 5 2\n3 4 1\n  8 6\n\nStep 740:\n7 5 2\n  4 1\n3 8 6\n\nStep 741:\n  5 2\n7 4 1\n3 8 6\n\nStep 742:\n5   2\n7 4 1\n3 8 6\n\nStep 743:\n5 4 2\n7   1\n3 8 6\n\nStep 744:\n5 4 2\n7 8 1\n3   6\n\nStep 745:\n5 4 2\n7 8 1\n3 6  \n\nStep 746:\n5 4 2\n7 8  \n3 6 1\n\nStep 747:\n5 4  \n7 8 2\n3 6 1\n\nStep 748:\n5   4\n7 8 2\n3 6 1\n\nStep 749:\n5 8 4\n7   2\n3 6 1\n\nStep 750:\n5 8 4\n7 6 2\n3   1\n\nStep 751:\n5 8 4\n7 6 2\n3 1  \n\nStep 752:\n5 8 4\n7 6  \n3 1 2\n\nStep 753:\n5 8  \n7 6 4\n3 1 2\n\nStep 754:\n5   8\n7 6 4\n3 1 2\n\nStep 755:\n5 6 8\n7   4\n3 1 2\n\nStep 756:\n5 6 8\n7 1 4\n3   2\n\nStep 757:\n5 6 8\n7 1 4\n3 2  \n\nStep 758:\n5 6 8\n7 1  \n3 2 4\n\nStep 759:\n5 6  \n7 1 8\n3 2 4\n\nStep 760:\n5   6\n7 1 8\n3 2 4\n\nStep 761:\n5 1 6\n7   8\n3 2 4\n\nStep 762:\n5 1 6\n7 2 8\n3   4\n\nStep 763:\n5 1 6\n7 2 8\n3 4  \n\nStep 764:\n5 1 6\n7 2  \n3 4 8\n\nStep 765:\n5 1  \n7 2 6\n3 4 8\n\nStep 766:\n5   1\n7 2 6\n3 4 8\n\nStep 767:\n5 2 1\n7   6\n3 4 8\n\nStep 768:\n5 2 1\n7 4 6\n3   8\n\nStep 769:\n5 2 1\n7 4 6\n3 8  \n\nStep 770:\n5 2 1\n7 4  \n3 8 6\n\nStep 771:\n5 2 1\n7   4\n3 8 6\n\nStep 772:\n5 2 1\n7 8 4\n3   6\n\nStep 773:\n5 2 1\n7 8 4\n3 6  \n\nStep 774:\n5 2 1\n7 8  \n3 6 4\n\nStep 775:\n5 2  \n7 8 1\n3 6 4\n\nStep 776:\n5   2\n7 8 1\n3 6 4\n\nStep 777:\n5 8 2\n7   1\n3 6 4\n\nStep 778:\n5 8 2\n7 6 1\n3   4\n\nStep 779:\n5 8 2\n7 6 1\n3 4  \n\nStep 780:\n5 8 2\n7 6  \n3 4 1\n\nStep 781:\n5 8  \n7 6 2\n3 4 1\n\nStep 782:\n5   8\n7 6 2\n3 4 1\n\nStep 783:\n5 6 8\n7   2\n3 4 1\n\nStep 784:\n5 6 8\n7 4 2\n3   1\n\nStep 785:\n5 6 8\n7 4 2\n  3 1\n\nStep 786:\n5 6 8\n  4 2\n7 3 1\n\nStep 787:\n5 6 8\n4   2\n7 3 1\n\nStep 788:\n5 6 8\n4 3 2\n7   1\n\nStep 789:\n5 6 8\n4 3 2\n7 1  \n\nStep 790:\n5 6 8\n4 3  \n7 1 2\n\nStep 791:\n5 6  \n4 3 8\n7 1 2\n\nStep 792:\n5   6\n4 3 8\n7 1 2\n\nStep 793:\n5 3 6\n4   8\n7 1 2\n\nStep 794:\n5 3 6\n4 1 8\n7   2\n\nStep 795:\n5 3 6\n4 1 8\n7 2  \n\nStep 796:\n5 3 6\n4 1  \n7 2 8\n\nStep 797:\n5 3  \n4 1 6\n7 2 8\n\nStep 798:\n5   3\n4 1 6\n7 2 8\n\nStep 799:\n5 1 3\n4   6\n7 2 8\n\nStep 800:\n5 1 3\n4 2 6\n7   8\n\nStep 801:\n5 1 3\n4 2 6\n7 8  \n\nStep 802:\n5 1 3\n4 2  \n7 8 6\n\nStep 803:\n5 1  \n4 2 3\n7 8 6\n\nStep 804:\n5   1\n4 2 3\n7 8 6\n\nStep 805:\n5 2 1\n4   3\n7 8 6\n\nStep 806:\n5 2 1\n4 8 3\n7   6\n\nStep 807:\n5 2 1\n4 8 3\n7 6  \n\nStep 808:\n5 2 1\n4 8  \n7 6 3\n\nStep 809:\n5 2  \n4 8 1\n7 6 3\n\nStep 810:\n5   2\n4 8 1\n7 6 3\n\nStep 811:\n5 8 2\n4   1\n7 6 3\n\nStep 812:\n5 8 2\n4 6 1\n7   3\n\nStep 813:\n5 8 2\n4 6 1\n7 3  \n\nStep 814:\n5 8 2\n4 6  \n7 3 1\n\nStep 815:\n5 8 2\n4   6\n7 3 1\n\nStep 816:\n5 8 2\n4 3 6\n7   1\n\nStep 817:\n5 8 2\n4 3 6\n7 1  \n\nStep 818:\n5 8 2\n4 3  \n7 1 6\n\nStep 819:\n5 8  \n4 3 2\n7 1 6\n\nStep 820:\n5   8\n4 3 2\n7 1 6\n\nStep 821:\n5 3 8\n4   2\n7 1 6\n\nStep 822:\n5 3 8\n4 1 2\n7   6\n\nStep 823:\n5 3 8\n4 1 2\n7 6  \n\nStep 824:\n5 3 8\n4 1  \n7 6 2\n\nStep 825:\n5 3  \n4 1 8\n7 6 2\n\nStep 826:\n5   3\n4 1 8\n7 6 2\n\nStep 827:\n5 1 3\n4   8\n7 6 2\n\nStep 828:\n5 1 3\n4 6 8\n7   2\n\nStep 829:\n5 1 3\n4 6 8\n  7 2\n\nStep 830:\n5 1 3\n  6 8\n4 7 2\n\nStep 831:\n  1 3\n5 6 8\n4 7 2\n\nStep 832:\n1   3\n5 6 8\n4 7 2\n\nStep 833:\n1 6 3\n5   8\n4 7 2\n\nStep 834:\n1 6 3\n5 7 8\n4   2\n\nStep 835:\n1 6 3\n5 7 8\n4 2  \n\nStep 836:\n1 6 3\n5 7  \n4 2 8\n\nStep 837:\n1 6  \n5 7 3\n4 2 8\n\nStep 838:\n1   6\n5 7 3\n4 2 8\n\nStep 839:\n1 7 6\n5   3\n4 2 8\n\nStep 840:\n1 7 6\n5 2 3\n4   8\n\nStep 841:\n1 7 6\n5 2 3\n4 8  \n\nStep 842:\n1 7 6\n5 2  \n4 8 3\n\nStep 843:\n1 7  \n5 2 6\n4 8 3\n\nStep 844:\n1   7\n5 2 6\n4 8 3\n\nStep 845:\n1 2 7\n5   6\n4 8 3\n\nStep 846:\n1 2 7\n5 8 6\n4   3\n\nStep 847:\n1 2 7\n5 8 6\n4 3  \n\nStep 848:\n1 2 7\n5 8  \n4 3 6\n\nStep 849:\n1 2  \n5 8 7\n4 3 6\n\nStep 850:\n1   2\n5 8 7\n4 3 6\n\nStep 851:\n1 8 2\n5   7\n4 3 6\n\nStep 852:\n1 8 2\n5 3 7\n4   6\n\nStep 853:\n1 8 2\n5 3 7\n4 6  \n\nStep 854:\n1 8 2\n5 3  \n4 6 7\n\nStep 855:\n1 8  \n5 3 2\n4 6 7\n\nStep 856:\n1   8\n5 3 2\n4 6 7\n\nStep 857:\n1 3 8\n5   2\n4 6 7\n\nStep 858:\n1 3 8\n5 6 2\n4   7\n\nStep 859:\n1 3 8\n5 6 2\n4 7  \n\nStep 860:\n1 3 8\n5 6  \n4 7 2\n\nStep 861:\n1 3 8\n5   6\n4 7 2\n\nStep 862:\n1 3 8\n5 7 6\n4   2\n\nStep 863:\n1 3 8\n5 7 6\n4 2  \n\nStep 864:\n1 3 8\n5 7  \n4 2 6\n\nStep 865:\n1 3  \n5 7 8\n4 2 6\n\nStep 866:\n1   3\n5 7 8\n4 2 6\n\nStep 867:\n1 7 3\n5   8\n4 2 6\n\nStep 868:\n1 7 3\n5 2 8\n4   6\n\nStep 869:\n1 7 3\n5 2 8\n4 6  \n\nStep 870:\n1 7 3\n5 2  \n4 6 8\n\nStep 871:\n1 7  \n5 2 3\n4 6 8\n\nStep 872:\n1   7\n5 2 3\n4 6 8\n\nStep 873:\n1 2 7\n5   3\n4 6 8\n\nStep 874:\n1 2 7\n5 6 3\n4   8\n\nStep 875:\n1 2 7\n5 6 3\n  4 8\n\nStep 876:\n1 2 7\n  6 3\n5 4 8\n\nStep 877:\n  2 7\n1 6 3\n5 4 8\n\nStep 878:\n2   7\n1 6 3\n5 4 8\n\nStep 879:\n2 6 7\n1   3\n5 4 8\n\nStep 880:\n2 6 7\n1 4 3\n5   8\n\nStep 881:\n2 6 7\n1 4 3\n5 8  \n\nStep 882:\n2 6 7\n1 4  \n5 8 3\n\nStep 883:\n2 6  \n1 4 7\n5 8 3\n\nStep 884:\n2   6\n1 4 7\n5 8 3\n\nStep 885:\n2 4 6\n1   7\n5 8 3\n\nStep 886:\n2 4 6\n1 8 7\n5   3\n\nStep 887:\n2 4 6\n1 8 7\n5 3  \n\nStep 888:\n2 4 6\n1 8  \n5 3 7\n\nStep 889:\n2 4  \n1 8 6\n5 3 7\n\nStep 890:\n2   4\n1 8 6\n5 3 7\n\nStep 891:\n2 8 4\n1   6\n5 3 7\n\nStep 892:\n2 8 4\n1 3 6\n5   7\n\nStep 893:\n2 8 4\n1 3 6\n5 7  \n\nStep 894:\n2 8 4\n1 3  \n5 7 6\n\nStep 895:\n2 8  \n1 3 4\n5 7 6\n\nStep 896:\n2   8\n1 3 4\n5 7 6\n\nStep 897:\n2 3 8\n1   4\n5 7 6\n\nStep 898:\n2 3 8\n1 7 4\n5   6\n\nStep 899:\n2 3 8\n1 7 4\n5 6  \n\nStep 900:\n2 3 8\n1 7  \n5 6 4\n\nStep 901:\n2 3  \n1 7 8\n5 6 4\n\nStep 902:\n2   3\n1 7 8\n5 6 4\n\nStep 903:\n2 7 3\n1   8\n5 6 4\n\nStep 904:\n2 7 3\n1 6 8\n5   4\n\nStep 905:\n2 7 3\n1 6 8\n5 4  \n\nStep 906:\n2 7 3\n1 6  \n5 4 8\n\nStep 907:\n2 7 3\n1   6\n5 4 8\n\nStep 908:\n2 7 3\n1 4 6\n5   8\n\nStep 909:\n2 7 3\n1 4 6\n5 8  \n\nStep 910:\n2 7 3\n1 4  \n5 8 6\n\nStep 911:\n2 7  \n1 4 3\n5 8 6\n\nStep 912:\n2   7\n1 4 3\n5 8 6\n\nStep 913:\n2 4 7\n1   3\n5 8 6\n\nStep 914:\n2 4 7\n1 8 3\n5   6\n\nStep 915:\n2 4 7\n1 8 3\n5 6  \n\nStep 916:\n2 4 7\n1 8  \n5 6 3\n\nStep 917:\n2 4  \n1 8 7\n5 6 3\n\nStep 918:\n2   4\n1 8 7\n5 6 3\n\nStep 919:\n2 8 4\n1   7\n5 6 3\n\nStep 920:\n2 8 4\n1 6 7\n5   3\n\nStep 921:\n2 8 4\n1 6 7\n  5 3\n\nStep 922:\n2 8 4\n  6 7\n1 5 3\n\nStep 923:\n  8 4\n2 6 7\n1 5 3\n\nStep 924:\n8   4\n2 6 7\n1 5 3\n\nStep 925:\n8 6 4\n2   7\n1 5 3\n\nStep 926:\n8 6 4\n2 5 7\n1   3\n\nStep 927:\n8 6 4\n2 5 7\n  1 3\n\nStep 928:\n8 6 4\n  5 7\n2 1 3\n\nStep 929:\n  6 4\n8 5 7\n2 1 3\n\nStep 930:\n6   4\n8 5 7\n2 1 3\n\nStep 931:\n6 5 4\n8   7\n2 1 3\n\nStep 932:\n6 5 4\n8 1 7\n2   3\n\nStep 933:\n6 5 4\n8 1 7\n2 3  \n\nStep 934:\n6 5 4\n8 1  \n2 3 7\n\nStep 935:\n6 5  \n8 1 4\n2 3 7\n\nStep 936:\n6   5\n8 1 4\n2 3 7\n\nStep 937:\n6 1 5\n8   4\n2 3 7\n\nStep 938:\n6 1 5\n8 3 4\n2   7\n\nStep 939:\n6 1 5\n8 3 4\n2 7  \n\nStep 940:\n6 1 5\n8 3  \n2 7 4\n\nStep 941:\n6 1  \n8 3 5\n2 7 4\n\nStep 942:\n6   1\n8 3 5\n2 7 4\n\nStep 943:\n6 3 1\n8   5\n2 7 4\n\nStep 944:\n6 3 1\n8 7 5\n2   4\n\nStep 945:\n6 3 1\n8 7 5\n2 4  \n\nStep 946:\n6 3 1\n8 7  \n2 4 5\n\nStep 947:\n6 3  \n8 7 1\n2 4 5\n\nStep 948:\n6   3\n8 7 1\n2 4 5\n\nStep 949:\n6 7 3\n8   1\n2 4 5\n\nStep 950:\n6 7 3\n8 4 1\n2   5\n\nStep 951:\n6 7 3\n8 4 1\n2 5  \n\nStep 952:\n6 7 3\n8 4  \n2 5 1\n\nStep 953:\n6 7  \n8 4 3\n2 5 1\n\nStep 954:\n6   7\n8 4 3\n2 5 1\n\nStep 955:\n6 4 7\n8   3\n2 5 1\n\nStep 956:\n6 4 7\n8 5 3\n2   1\n\nStep 957:\n6 4 7\n8 5 3\n2 1  \n\nStep 958:\n6 4 7\n8 5  \n2 1 3\n\nStep 959:\n6 4 7\n8   5\n2 1 3\n\nStep 960:\n6 4 7\n8 1 5\n2   3\n\nStep 961:\n6 4 7\n8 1 5\n2 3  \n\nStep 962:\n6 4 7\n8 1  \n2 3 5\n\nStep 963:\n6 4  \n8 1 7\n2 3 5\n\nStep 964:\n6   4\n8 1 7\n2 3 5\n\nStep 965:\n6 1 4\n8   7\n2 3 5\n\nStep 966:\n6 1 4\n8 3 7\n2   5\n\nStep 967:\n6 1 4\n8 3 7\n2 5  \n\nStep 968:\n6 1 4\n8 3  \n2 5 7\n\nStep 969:\n6 1  \n8 3 4\n2 5 7\n\nStep 970:\n6   1\n8 3 4\n2 5 7\n\nStep 971:\n6 3 1\n8   4\n2 5 7\n\nStep 972:\n6 3 1\n8 5 4\n2   7\n\nStep 973:\n6 3 1\n8 5 4\n  2 7\n\nStep 974:\n6 3 1\n  5 4\n8 2 7\n\nStep 975:\n  3 1\n6 5 4\n8 2 7\n\nStep 976:\n3   1\n6 5 4\n8 2 7\n\nStep 977:\n3 5 1\n6   4\n8 2 7\n\nStep 978:\n3 5 1\n6 2 4\n8   7\n\nStep 979:\n3 5 1\n6 2 4\n8 7  \n\nStep 980:\n3 5 1\n6 2  \n8 7 4\n\nStep 981:\n3 5  \n6 2 1\n8 7 4\n\nStep 982:\n3   5\n6 2 1\n8 7 4\n\nStep 983:\n3 2 5\n6   1\n8 7 4\n\nStep 984:\n3 2 5\n6 7 1\n8   4\n\nStep 985:\n3 2 5\n6 7 1\n8 4  \n\nStep 986:\n3 2 5\n6 7  \n8 4 1\n\nStep 987:\n3 2  \n6 7 5\n8 4 1\n\nStep 988:\n3   2\n6 7 5\n8 4 1\n\nStep 989:\n3 7 2\n6   5\n8 4 1\n\nStep 990:\n3 7 2\n6 4 5\n8   1\n\nStep 991:\n3 7 2\n6 4 5\n8 1  \n\nStep 992:\n3 7 2\n6 4  \n8 1 5\n\nStep 993:\n3 7  \n6 4 2\n8 1 5\n\nStep 994:\n3   7\n6 4 2\n8 1 5\n\nStep 995:\n3 4 7\n6   2\n8 1 5\n\nStep 996:\n3 4 7\n6 1 2\n8   5\n\nStep 997:\n3 4 7\n6 1 2\n8 5  \n\nStep 998:\n3 4 7\n6 1  \n8 5 2\n\nStep 999:\n3 4  \n6 1 7\n8 5 2\n\nStep 1000:\n3   4\n6 1 7\n8 5 2\n\nStep 1001:\n3 1 4\n6   7\n8 5 2\n\nStep 1002:\n3 1 4\n6 5 7\n8   2\n\nStep 1003:\n3 1 4\n6 5 7\n8 2  \n\nStep 1004:\n3 1 4\n6 5  \n8 2 7\n\nStep 1005:\n3 1 4\n6   5\n8 2 7\n\nStep 1006:\n3 1 4\n6 2 5\n8   7\n\nStep 1007:\n3 1 4\n6 2 5\n8 7  \n\nStep 1008:\n3 1 4\n6 2  \n8 7 5\n\nStep 1009:\n3 1  \n6 2 4\n8 7 5\n\nStep 1010:\n3   1\n6 2 4\n8 7 5\n\nStep 1011:\n3 2 1\n6   4\n8 7 5\n\nStep 1012:\n3 2 1\n6 7 4\n8   5\n\nStep 1013:\n3 2 1\n6 7 4\n8 5  \n\nStep 1014:\n3 2 1\n6 7  \n8 5 4\n\nStep 1015:\n3 2  \n6 7 1\n8 5 4\n\nStep 1016:\n3   2\n6 7 1\n8 5 4\n\nStep 1017:\n3 7 2\n6   1\n8 5 4\n\nStep 1018:\n3 7 2\n6 5 1\n8   4\n\nStep 1019:\n3 7 2\n6 5 1\n  8 4\n\nStep 1020:\n3 7 2\n  5 1\n6 8 4\n\nStep 1021:\n  7 2\n3 5 1\n6 8 4\n\nStep 1022:\n7   2\n3 5 1\n6 8 4\n\nStep 1023:\n7 5 2\n3   1\n6 8 4\n\nStep 1024:\n7 5 2\n3 8 1\n6   4\n\nStep 1025:\n7 5 2\n3 8 1\n6 4  \n\nStep 1026:\n7 5 2\n3 8  \n6 4 1\n\nStep 1027:\n7 5  \n3 8 2\n6 4 1\n\nStep 1028:\n7   5\n3 8 2\n6 4 1\n\nStep 1029:\n7 8 5\n3   2\n6 4 1\n\nStep 1030:\n7 8 5\n3 4 2\n6   1\n\nStep 1031:\n7 8 5\n3 4 2\n6 1  \n\nStep 1032:\n7 8 5\n3 4  \n6 1 2\n\nStep 1033:\n7 8  \n3 4 5\n6 1 2\n\nStep 1034:\n7   8\n3 4 5\n6 1 2\n\nStep 1035:\n7 4 8\n3   5\n6 1 2\n\nStep 1036:\n7 4 8\n3 1 5\n6   2\n\nStep 1037:\n7 4 8\n3 1 5\n6 2  \n\nStep 1038:\n7 4 8\n3 1  \n6 2 5\n\nStep 1039:\n7 4  \n3 1 8\n6 2 5\n\nStep 1040:\n7   4\n3 1 8\n6 2 5\n\nStep 1041:\n7 1 4\n3   8\n6 2 5\n\nStep 1042:\n7 1 4\n3 2 8\n6   5\n\nStep 1043:\n7 1 4\n3 2 8\n6 5  \n\nStep 1044:\n7 1 4\n3 2  \n6 5 8\n\nStep 1045:\n7 1  \n3 2 4\n6 5 8\n\nStep 1046:\n7   1\n3 2 4\n6 5 8\n\nStep 1047:\n7 2 1\n3   4\n6 5 8\n\nStep 1048:\n7 2 1\n3 5 4\n6   8\n\nStep 1049:\n7 2 1\n3 5 4\n6 8  \n\nStep 1050:\n7 2 1\n3 5  \n6 8 4\n\nStep 1051:\n7 2 1\n3   5\n6 8 4\n\nStep 1052:\n7 2 1\n3 8 5\n6   4\n\nStep 1053:\n7 2 1\n3 8 5\n6 4  \n\nStep 1054:\n7 2 1\n3 8  \n6 4 5\n\nStep 1055:\n7 2  \n3 8 1\n6 4 5\n\nStep 1056:\n7   2\n3 8 1\n6 4 5\n\nStep 1057:\n7 8 2\n3   1\n6 4 5\n\nStep 1058:\n7 8 2\n3 4 1\n6   5\n\nStep 1059:\n7 8 2\n3 4 1\n6 5  \n\nStep 1060:\n7 8 2\n3 4  \n6 5 1\n\nStep 1061:\n7 8  \n3 4 2\n6 5 1\n\nStep 1062:\n7   8\n3 4 2\n6 5 1\n\nStep 1063:\n7 4 8\n3   2\n6 5 1\n\nStep 1064:\n7 4 8\n3 5 2\n6   1\n\nStep 1065:\n7 4 8\n3 5 2\n  6 1\n\nStep 1066:\n7 4 8\n  5 2\n3 6 1\n\nStep 1067:\n  4 8\n7 5 2\n3 6 1\n\nStep 1068:\n4   8\n7 5 2\n3 6 1\n\nStep 1069:\n4 5 8\n7   2\n3 6 1\n\nStep 1070:\n4 5 8\n7 6 2\n3   1\n\nStep 1071:\n4 5 8\n7 6 2\n3 1  \n\nStep 1072:\n4 5 8\n7 6  \n3 1 2\n\nStep 1073:\n4 5  \n7 6 8\n3 1 2\n\nStep 1074:\n4   5\n7 6 8\n3 1 2\n\nStep 1075:\n4 6 5\n7   8\n3 1 2\n\nStep 1076:\n4 6 5\n7 1 8\n3   2\n\nStep 1077:\n4 6 5\n7 1 8\n3 2  \n\nStep 1078:\n4 6 5\n7 1  \n3 2 8\n\nStep 1079:\n4 6  \n7 1 5\n3 2 8\n\nStep 1080:\n4   6\n7 1 5\n3 2 8\n\nStep 1081:\n4 1 6\n7   5\n3 2 8\n\nStep 1082:\n4 1 6\n7 2 5\n3   8\n\nStep 1083:\n4 1 6\n7 2 5\n3 8  \n\nStep 1084:\n4 1 6\n7 2  \n3 8 5\n\nStep 1085:\n4 1  \n7 2 6\n3 8 5\n\nStep 1086:\n4   1\n7 2 6\n3 8 5\n\nStep 1087:\n4 2 1\n7   6\n3 8 5\n\nStep 1088:\n4 2 1\n7 8 6\n3   5\n\nStep 1089:\n4 2 1\n7 8 6\n3 5  \n\nStep 1090:\n4 2 1\n7 8  \n3 5 6\n\nStep 1091:\n4 2  \n7 8 1\n3 5 6\n\nStep 1092:\n4   2\n7 8 1\n3 5 6\n\nStep 1093:\n4 8 2\n7   1\n3 5 6\n\nStep 1094:\n4 8 2\n7 5 1\n3   6\n\nStep 1095:\n4 8 2\n7 5 1\n3 6  \n\nStep 1096:\n4 8 2\n7 5  \n3 6 1\n\nStep 1097:\n4 8 2\n7   5\n3 6 1\n\nStep 1098:\n4 8 2\n7 6 5\n3   1\n\nStep 1099:\n4 8 2\n7 6 5\n3 1  \n\nStep 1100:\n4 8 2\n7 6  \n3 1 5\n\nStep 1101:\n4 8  \n7 6 2\n3 1 5\n\nStep 1102:\n4   8\n7 6 2\n3 1 5\n\nStep 1103:\n4 6 8\n7   2\n3 1 5\n\nStep 1104:\n4 6 8\n7 1 2\n3   5\n\nStep 1105:\n4 6 8\n7 1 2\n3 5  \n\nStep 1106:\n4 6 8\n7 1  \n3 5 2\n\nStep 1107:\n4 6  \n7 1 8\n3 5 2\n\nStep 1108:\n4   6\n7 1 8\n3 5 2\n\nStep 1109:\n4 1 6\n7   8\n3 5 2\n\nStep 1110:\n4 1 6\n7 5 8\n3   2\n\nStep 1111:\n4 1 6\n7 5 8\n  3 2\n\nStep 1112:\n4 1 6\n  5 8\n7 3 2\n\nStep 1113:\n  1 6\n4 5 8\n7 3 2\n\nStep 1114:\n1   6\n4 5 8\n7 3 2\n\nStep 1115:\n1 5 6\n4   8\n7 3 2\n\nStep 1116:\n1 5 6\n4 3 8\n7   2\n\nStep 1117:\n1 5 6\n4 3 8\n7 2  \n\nStep 1118:\n1 5 6\n4 3  \n7 2 8\n\nStep 1119:\n1 5  \n4 3 6\n7 2 8\n\nStep 1120:\n1   5\n4 3 6\n7 2 8\n\nStep 1121:\n1 3 5\n4   6\n7 2 8\n\nStep 1122:\n1 3 5\n4 2 6\n7   8\n\nStep 1123:\n1 3 5\n4 2 6\n7 8  \n\nStep 1124:\n1 3 5\n4 2  \n7 8 6\n\nStep 1125:\n1 3  \n4 2 5\n7 8 6\n\nStep 1126:\n1   3\n4 2 5\n7 8 6\n\nStep 1127:\n1 2 3\n4   5\n7 8 6\n\nStep 1128:\n1 2 3\n4 8 5\n7   6\n\nStep 1129:\n1 2 3\n4 8 5\n7 6  \n\nStep 1130:\n1 2 3\n4 8  \n7 6 5\n\nStep 1131:\n1 2  \n4 8 3\n7 6 5\n\nStep 1132:\n1   2\n4 8 3\n7 6 5\n\nStep 1133:\n1 8 2\n4   3\n7 6 5\n\nStep 1134:\n1 8 2\n4 6 3\n7   5\n\nStep 1135:\n1 8 2\n4 6 3\n7 5  \n\nStep 1136:\n1 8 2\n4 6  \n7 5 3\n\nStep 1137:\n1 8  \n4 6 2\n7 5 3\n\nStep 1138:\n1   8\n4 6 2\n7 5 3\n\nStep 1139:\n1 6 8\n4   2\n7 5 3\n\nStep 1140:\n1 6 8\n4 5 2\n7   3\n\nStep 1141:\n1 6 8\n4 5 2\n7 3  \n\nStep 1142:\n1 6 8\n4 5  \n7 3 2\n\nStep 1143:\n1 6 8\n4   5\n7 3 2\n\nStep 1144:\n1 6 8\n4 3 5\n7   2\n\nStep 1145:\n1 6 8\n4 3 5\n7 2  \n\nStep 1146:\n1 6 8\n4 3  \n7 2 5\n\nStep 1147:\n1 6  \n4 3 8\n7 2 5\n\nStep 1148:\n1   6\n4 3 8\n7 2 5\n\nStep 1149:\n1 3 6\n4   8\n7 2 5\n\nStep 1150:\n1 3 6\n4 2 8\n7   5\n\nStep 1151:\n1 3 6\n4 2 8\n7 5  \n\nStep 1152:\n1 3 6\n4 2  \n7 5 8\n\nStep 1153:\n1 3  \n4 2 6\n7 5 8\n\nStep 1154:\n1   3\n4 2 6\n7 5 8\n\nStep 1155:\n1 2 3\n4   6\n7 5 8\n\nStep 1156:\n1 2 3\n4 5 6\n7   8\n\nStep 1157:\n1 2 3\n4 5 6\n7 8"
  },
  {
    "objectID": "lectures/15/slides.html#remarks",
    "href": "lectures/15/slides.html#remarks",
    "title": "Introduction to Search",
    "section": "Remarks",
    "text": "Remarks\n\nBreadth-first search (BFS) identifies the optimal solution, 25 moves, in 145,605 iterations.\nDepth-first search (DFS) discovers a solution involving 1,157 moves in 1,187 iterations.\n\n\n\nWill Depth-First Search (DFS) invariably yield sub-optimal solutions?\nNo, if the optimal solution lies along the path traversed by depth-first search (DFS) within the search tree, then DFS will indeed identify the optimal solution.\nIs it possible for DFS to discover solutions superior to the optimal solution?\nCertainly not; such solutions would either be invalid (involving impossible moves) or indicate an error in your estimation.\nDoes this imply that depth-first search (DFS) has no practical applications?\nWhen is it appropriate to use DFS?\nBreadth-first search (BFS) expands its frontier systematically in all directions, leading to rapid growth in memory requirements.\nIn contrast, the memory usage of DFS is constrained by the number of moves needed to reach its backtracking points or the path length of the first solution found. In all scenarios, DFS continues expanding the frontier in one direction.\nIn certain applications where all possible solutions must be explored, the entire search space must be traversed. Using BFS in these cases would be prohibitively expensive in terms of memory. However, DFS can explore the entire space with minimal memory usage.\nThe programming language Prolog includes a built-in backtracking algorithm that enumerates all possible solutions. Backtracking is a memory-efficient variant of DFS.\nDepth-limited and iterative deepening search would be alternative uninformed search algorithms.\nFinding solutions more efficiently requires domain knowledge.\n\n\nHow can solutions be discovered more efficiently?"
  },
  {
    "objectID": "lectures/15/slides.html#summary",
    "href": "lectures/15/slides.html#summary",
    "title": "Introduction to Search",
    "section": "Summary",
    "text": "Summary\n\nJustification for Studying Search\nKey Terminology and Concepts\nUninformed Search Algorithms\n\nBreadth-First Search (BFS)\nDepth-First Search (DFS)\n\nImplementations\n\n\n\nJustification for Studying Search:\n\nEmphasized the shift from solely focusing on machine learning to incorporating search algorithms.\nHighlighted the role of search in advanced AI systems like AlphaGo, AlphaZero, and MuZero.\nNoted that search algorithms are crucial for planning, reasoning, and will be increasingly significant.\n\nHistorical Timeline of Search Algorithms:\n\nPresented a biased timeline from 1968’s A* algorithm to recent developments like MuZero and Agent57.\nShowed the evolution from heuristic-based search to integrating deep learning with search methods.\n\nApplications of Search:\n\nPathfinding and Navigation: Finding optimal paths in robotics and games.\nPuzzle Solving: Solving problems like the 8-puzzle and Sudoku.\nNetwork Analysis: Analyzing connectivity and shortest paths in networks.\nGame Playing: Evaluating moves in games like chess or Go.\nScheduling and Resource Allocation: Planning tasks and allocating resources efficiently.\nConfiguration Problems: Assembling components to meet specific requirements.\nDecision Making under Uncertainty: Making decisions in dynamic and uncertain environments.\nStorytelling: Guiding language models with plans from automated planners.\n\nKey Terminology and Concepts:\n\nAgent: An entity that performs actions to achieve goals.\nEnvironment Characteristics: Fully observable, single-agent, deterministic, static, and discrete environments were focused on.\nSearch Problem Definition:\n\nState Space: All possible states.\nInitial State: Where the agent starts.\nGoal State(s): Desired outcome(s).\nActions: Possible moves from a state.\nTransition Model: Rules determining state changes.\nAction Cost Function: Cost associated with actions.\n\n\nUninformed Search Algorithms:\n\nBreadth-First Search (BFS):\n\nExplores the search space level by level.\nGuarantees the shortest path but can be memory-intensive.\nImplemented using a queue.\n\nDepth-First Search (DFS):\n\nExplores as deep as possible along each branch before backtracking.\nLess memory usage but may not find the shortest path.\nImplemented using a stack.\n\n\nImplementing Uninformed Search:\n\nUsed the 8-Puzzle as an example problem.\nRepresented states as lists of numbers, with 0 as the blank tile.\nDemonstrated BFS and DFS implementations in Python.\nShowed that BFS found the optimal solution in more iterations, while DFS found a suboptimal solution faster.\n\nLimitations of Uninformed Search:\n\nInefficient for large or complex problems due to exhaustive nature.\nLack of domain knowledge leads to unnecessary exploration."
  },
  {
    "objectID": "lectures/15/slides.html#next-lecture",
    "href": "lectures/15/slides.html#next-lecture",
    "title": "Introduction to Search",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will further explore heuristic functions and examine additional search algorithms."
  },
  {
    "objectID": "lectures/15/slides.html#references",
    "href": "lectures/15/slides.html#references",
    "title": "Introduction to Search",
    "section": "References",
    "text": "References\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nSchrittwieser, Julian, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, et al. 2020. “Mastering Atari, Go, chess and shogi by planning with a learned model.” Nature 588 (7839): 604–9. https://doi.org/10.1038/s41586-020-03051-4.\n\n\nSilver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, et al. 2016. “Mastering the game of Go with deep neural networks and tree search.” Nature 529 (7587): 484–89. https://doi.org/10.1038/nature16961.\n\n\nSimon, Nisha, and Christian Muise. 2024. “Want To Choose Your Own Adventure? Then First Make a Plan.” Proceedings of the Canadian Conference on Artificial Intelligence."
  },
  {
    "objectID": "lectures/15/index.html",
    "href": "lectures/15/index.html",
    "title": "Lecture 15",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 3 must be submitted no later than November 10, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/15/index.html#prepare",
    "href": "lectures/15/index.html#prepare",
    "title": "Lecture 15",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 63–85"
  },
  {
    "objectID": "lectures/15/index.html#participate",
    "href": "lectures/15/index.html#participate",
    "title": "Lecture 15",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/16/slides.html#quote-of-the-day",
    "href": "lectures/16/slides.html#quote-of-the-day",
    "title": "Heuristic Search",
    "section": "Quote of the Day",
    "text": "Quote of the Day"
  },
  {
    "objectID": "lectures/16/slides.html#learning-objectives",
    "href": "lectures/16/slides.html#learning-objectives",
    "title": "Heuristic Search",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nComprehend informed search strategies and heuristic functions’ role in search efficiency.\nImplement and compare BFS, DFS, and Best-First Search using the 8-Puzzle problem.\nAnalyze performance and optimality of various search algorithms."
  },
  {
    "objectID": "lectures/16/slides.html#search-problem-definition",
    "href": "lectures/16/slides.html#search-problem-definition",
    "title": "Heuristic Search",
    "section": "Search Problem Definition",
    "text": "Search Problem Definition\n\nA collection of states, referred to as the state space.\nAn initial state where the agent begins.\nOne or more goal states that define successful outcomes.\nA set of actions available in a given state \\(s\\).\nA transition model that determines the next state based on the current state and selected action.\nAn action cost function that specifies the cost of performing action \\(a\\) in state \\(s\\) to reach state \\(s'\\)."
  },
  {
    "objectID": "lectures/16/slides.html#definitions",
    "href": "lectures/16/slides.html#definitions",
    "title": "Heuristic Search",
    "section": "Definitions",
    "text": "Definitions\n\nA path is defined as a sequence of actions.\nA solution is a path that connects the initial state to the goal state.\nAn optimal solution is the path with the lowest cost among all possible solutions.\n\n\n\nIn certain problems, multiple optimal solutions may exist. However, it is typically sufficient to identify and report a single optimal solution. Providing all optimal solutions can significantly increase time and space complexity for some problems.\n\n\nWe assume that the path cost is the sum of the individual action costs, and all costs are positive. The state space can be conceptualized as a graph, where the nodes represent the states and the edges correspond to the actions."
  },
  {
    "objectID": "lectures/16/slides.html#example-8-puzzle",
    "href": "lectures/16/slides.html#example-8-puzzle",
    "title": "Heuristic Search",
    "section": "Example: 8-Puzzle",
    "text": "Example: 8-Puzzle"
  },
  {
    "objectID": "lectures/16/slides.html#search-tree",
    "href": "lectures/16/slides.html#search-tree",
    "title": "Heuristic Search",
    "section": "Search Tree",
    "text": "Search Tree\n\n\n\n\n\n\n\nThe search algorithms we examine today construct a search tree, where each node represents a state within the state space and each edge represents an action.\nIt is important to distinguish between the search tree and the state space, which can be depicted as a graph. The structure of the search tree varies depending on the algorithm employed to address the search problem.\n\n\nA search tree is a conceptual tree structure where nodes represent states in a state space, and edges represent possible actions, facilitating systematic exploration to find a path from an initial state to a goal state."
  },
  {
    "objectID": "lectures/16/slides.html#search-tree-1",
    "href": "lectures/16/slides.html#search-tree-1",
    "title": "Heuristic Search",
    "section": "Search Tree",
    "text": "Search Tree\n\n\n\n\n\n\n\nAn example of a search tree for the 8-Puzzle. The solution here is incomplete."
  },
  {
    "objectID": "lectures/16/slides.html#frontier",
    "href": "lectures/16/slides.html#frontier",
    "title": "Heuristic Search",
    "section": "Frontier",
    "text": "Frontier\n\n\n\n\n\n\n\nAny state corresponding to a node in the search tree is considered reached. Frontier nodes are those that have been reached but have not yet been expanded. Above, there are 10 expanded nodes and 11 frontier nodes, resulting in a total of 21 nodes that have been reached."
  },
  {
    "objectID": "lectures/16/slides.html#frontier-1",
    "href": "lectures/16/slides.html#frontier-1",
    "title": "Heuristic Search",
    "section": "Frontier",
    "text": "Frontier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe diagrams correspond to the search tree presented on the previous page. For example, the initial state can be expanded using three actions: slide left, right, and up. Node (2, 3) can only be expanded by sliding down, while node (3, 3) can be expanded by sliding left and down.\n\n\nIn the 8-Puzzle, four actions are possible: slide left, right, up, or down. The search can be visualized on a grid: purple nodes: expanded states, green nodes: frontier states (reached but not expanded)."
  },
  {
    "objectID": "lectures/16/slides.html#frontier-2",
    "href": "lectures/16/slides.html#frontier-2",
    "title": "Heuristic Search",
    "section": "Frontier",
    "text": "Frontier"
  },
  {
    "objectID": "lectures/16/slides.html#is_empty",
    "href": "lectures/16/slides.html#is_empty",
    "title": "Heuristic Search",
    "section": "is_empty",
    "text": "is_empty\n\ndef is_empty(frontier):\n    \"\"\"Checks if the frontier is empty.\"\"\"\n    return len(frontier) == 0"
  },
  {
    "objectID": "lectures/16/slides.html#is_goal",
    "href": "lectures/16/slides.html#is_goal",
    "title": "Heuristic Search",
    "section": "is_goal",
    "text": "is_goal\n\ndef is_goal(state, goal_state):\n    \"\"\"Determines if a given state matches the goal state.\"\"\"\n    return state == goal_state\n\n\n\nAuxilliary method."
  },
  {
    "objectID": "lectures/16/slides.html#expand",
    "href": "lectures/16/slides.html#expand",
    "title": "Heuristic Search",
    "section": "expand",
    "text": "expand\n\ndef expand(state):\n    \"\"\"Generates successor states by moving the blank tile in all possible directions.\"\"\"\n    size = int(len(state) ** 0.5)  # Determine puzzle size (3 for 8-puzzle, 4 for 15-puzzle)\n    idx = state.index(0)  # Find the index of the blank tile represented by 0\n    x, y = idx % size, idx // size  # Convert index to (x, y) coordinates\n    neighbors = []\n\n    # Define possible moves: Left, Right, Up, Down\n    moves = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n    for dx, dy in moves:\n        nx, ny = x + dx, y + dy\n        # Check if the new position is within the puzzle boundaries\n        if 0 &lt;= nx &lt; size and 0 &lt;= ny &lt; size:\n            n_idx = ny * size + nx\n            new_state = state.copy()\n            # Swap the blank tile with the adjacent tile\n            new_state[idx], new_state[n_idx] = new_state[n_idx], new_state[idx]\n            neighbors.append(new_state)\n    return neighbors"
  },
  {
    "objectID": "lectures/16/slides.html#print_solution",
    "href": "lectures/16/slides.html#print_solution",
    "title": "Heuristic Search",
    "section": "print_solution",
    "text": "print_solution\n\ndef print_solution(solution):\n    \"\"\"Prints the sequence of steps from the initial to the goal state.\"\"\"\n    size = int(len(solution[0]) ** 0.5)\n    for step, state in enumerate(solution):\n        print(f\"Step {step}:\")\n        for i in range(size):\n            row = state[i*size:(i+1)*size]\n            print(' '.join(str(n) if n != 0 else ' ' for n in row))\n        print()"
  },
  {
    "objectID": "lectures/16/slides.html#breadth-first-search",
    "href": "lectures/16/slides.html#breadth-first-search",
    "title": "Heuristic Search",
    "section": "Breadth-first search",
    "text": "Breadth-first search\n\nfrom collections import deque\n\nBreadth-first search (BFS) employs a queue to manage the frontier nodes, which are also known as the open list."
  },
  {
    "objectID": "lectures/16/slides.html#breadth-first-search-1",
    "href": "lectures/16/slides.html#breadth-first-search-1",
    "title": "Heuristic Search",
    "section": "Breadth-first search",
    "text": "Breadth-first search\n\ndef bfs(initial_state, goal_state):\n\n    frontier = deque()  # Initialize the queue for BFS\n    frontier.append((initial_state, []))  # Each element is a tuple: (state, path)\n\n    explored = set()\n    explored.add(tuple(initial_state))\n\n    iterations = 0 # simply used to compare algorithms\n\n    while not is_empty(frontier):\n        current_state, path = frontier.popleft()\n\n        if is_goal(current_state, goal_state):\n            print(f\"Number of iterations: {iterations}\")\n            return path + [current_state]  # Return the successful path\n\n        iterations = iterations + 1\n\n        for neighbor in expand(current_state):\n            neighbor_tuple = tuple(neighbor)\n            if neighbor_tuple not in explored:\n                explored.add(neighbor_tuple)\n                frontier.append((neighbor, path + [current_state]))\n\n    return None  # No solution found\n\n\n\nUsing tuple makes states immutable and hashable, enabling storage in a set."
  },
  {
    "objectID": "lectures/16/slides.html#depth-first-search",
    "href": "lectures/16/slides.html#depth-first-search",
    "title": "Heuristic Search",
    "section": "Depth-First Search",
    "text": "Depth-First Search\n\ndef dfs(initial_state, goal_state):\n\n    frontier = [(initial_state, [])]  # Each element is a tuple: (state, path)\n\n    explored = set()\n    explored.add(tuple(initial_state))\n\n    iterations = 0\n\n    while not is_empty(frontier):\n        current_state, path = frontier.pop()\n\n        if is_goal(current_state, goal_state):\n            print(f\"Number of iterations: {iterations}\")\n            return path + [current_state]  # Return the successful path\n\n        iterations = iterations + 1\n\n        for neighbor in expand(current_state):\n            neighbor_tuple = tuple(neighbor)\n            if neighbor_tuple not in explored:\n                explored.add(neighbor_tuple)\n                frontier.append((neighbor, path + [current_state]))\n\n    return None  # No solution found"
  },
  {
    "objectID": "lectures/16/slides.html#remarks",
    "href": "lectures/16/slides.html#remarks",
    "title": "Heuristic Search",
    "section": "Remarks",
    "text": "Remarks\n\nBreadth-first search (BFS) identifies the optimal solution, 25 moves, in 145,605 iterations.\nDepth-first search (DFS) discovers a solution involving 1,157 moves in 1,187 iterations.\n\n\n\nWill Depth-First Search (DFS) invariably yield sub-optimal solutions?\nNo, if the optimal solution lies along the path traversed by depth-first search (DFS) within the search tree, then DFS will indeed identify the optimal solution.\nIs it possible for DFS to discover solutions superior to the optimal solution?\nCertainly not; such solutions would either be invalid (involving impossible moves) or indicate an error in your estimation.\nDoes this imply that depth-first search (DFS) has no practical applications?\nWhen is it appropriate to use DFS?\nBreadth-first search (BFS) expands its frontier systematically in all directions, leading to rapid growth in memory requirements.\nIn contrast, the memory usage of DFS is constrained by the number of moves needed to reach its backtracking points or the path length of the first solution found. In all scenarios, DFS continues expanding the frontier in one direction.\nIn certain applications where all possible solutions must be explored, the entire search space must be traversed. Using BFS in these cases would be prohibitively expensive in terms of memory. However, DFS can explore the entire space with minimal memory usage.\nThe programming language Prolog includes a built-in backtracking algorithm that enumerates all possible solutions. Backtracking is a memory-efficient variant of DFS.\nDepth-limited and iterative deepening search would be alternative uninformed search algorithms.\nFinding solutions more efficiently requires domain knowledge.\n\n\nHow can solutions be discovered more efficiently?"
  },
  {
    "objectID": "lectures/16/slides.html#heuristic-search",
    "href": "lectures/16/slides.html#heuristic-search",
    "title": "Heuristic Search",
    "section": "Heuristic Search",
    "text": "Heuristic Search\nInformed search algorithms utilize domain-specific knowledge regarding the goal state’s location."
  },
  {
    "objectID": "lectures/16/slides.html#heuristic-search-1",
    "href": "lectures/16/slides.html#heuristic-search-1",
    "title": "Heuristic Search",
    "section": "Heuristic Search",
    "text": "Heuristic Search\nLet \\(f(n)\\) be a heuristic function that estimates the cost of the cheapest path from the current state or node \\(n\\) to the goal.\n\n\nThis approach is termed best-first search."
  },
  {
    "objectID": "lectures/16/slides.html#heuristic-search-2",
    "href": "lectures/16/slides.html#heuristic-search-2",
    "title": "Heuristic Search",
    "section": "Heuristic Search",
    "text": "Heuristic Search\nIn route-finding problems, one might employ the straight-line distance from the current node to the destination as a heuristic. Although an actual path may not exist along that straight line, the algorithm will prioritize expanding the node closest to the destination (goal) based on this straight-line measurement."
  },
  {
    "objectID": "lectures/16/slides.html#implementation",
    "href": "lectures/16/slides.html#implementation",
    "title": "Heuristic Search",
    "section": "Implementation",
    "text": "Implementation\n\nHow can the existing breadth-first and depth-first search algorithms be modified to implement best-first search?\n\nThis can be achieved by employing a priority queue, which is sorted according to the values of the heuristic function \\(h(n)\\).\n\n\n\n\nimport heapq"
  },
  {
    "objectID": "lectures/16/slides.html#remark",
    "href": "lectures/16/slides.html#remark",
    "title": "Heuristic Search",
    "section": "Remark",
    "text": "Remark\nBreadth-first search can be interpreted as a form of best-first search, where the heuristic function \\(f(n)\\) is defined as the depth of the node within the search tree, corresponding to the path length.\n\nIs this solution viable? The answer is nuanced. It is useful for examining the properties of the algorithm, but using a queue will likely provide a more efficient implementation.\nCan you think of a way to implement depth-first-search as a best-first-search?"
  },
  {
    "objectID": "lectures/16/slides.html#astar",
    "href": "lectures/16/slides.html#astar",
    "title": "Heuristic Search",
    "section": "\\(A^\\star\\)",
    "text": "\\(A^\\star\\)\n\\(A^\\star\\) (a-star) is the most common informed search.\n\\[\n    f(n) = g(n) + h(n)\n\\]\nwhere\n\n\\(g(n)\\) is the path cost from the initial state to \\(n\\).\n\\(h(n)\\) is an estimate of the cost of the shortest path from \\(n\\) to the goal state.\n\n\n\nIt is clear that \\(g(n)\\) is a known value and not an estimate. Consequently, the accuracy of \\(f(n)\\) improves as the execution progresses.\n\n\nHart, Nilsson, and Raphael (1968)"
  },
  {
    "objectID": "lectures/16/slides.html#admissibility",
    "href": "lectures/16/slides.html#admissibility",
    "title": "Heuristic Search",
    "section": "Admissibility",
    "text": "Admissibility\nA heuristic is admissible if it never overestimates the true cost to reach the goal from any node in the search space.\nThis ensures that the \\(A^\\star\\) algorithm finds an optimal solution, as it guarantees that the estimated cost is always a lower bound on the actual cost."
  },
  {
    "objectID": "lectures/16/slides.html#admissibility-1",
    "href": "lectures/16/slides.html#admissibility-1",
    "title": "Heuristic Search",
    "section": "Admissibility",
    "text": "Admissibility\nFormally, a heuristic \\(h(n)\\) is admissible if: \\[\nh(n) \\leq h^*(n)\n\\] where:\n\n\\(h(n)\\) is the heuristic estimate of the cost from node \\(n\\) to the goal.\n\\(h^*(n)\\) is the actual cost of the optimal path from node \\(n\\) to the goal.\n\n\n\nWhat would happen if a heuristic were to overestimate the cost of the shortest path from \\(n\\) to the goal?"
  },
  {
    "objectID": "lectures/16/slides.html#cost-optimality",
    "href": "lectures/16/slides.html#cost-optimality",
    "title": "Heuristic Search",
    "section": "Cost Optimality",
    "text": "Cost Optimality\nCost optimality refers to an algorithm’s ability to find the least-cost solution among all possible solutions.\nIn the context of search algorithms like \\(A^\\star\\), cost optimality means that the algorithm will identify the path with the lowest total cost from the start to the goal, assuming an admissible heuristic is used."
  },
  {
    "objectID": "lectures/16/slides.html#proof-of-optimality",
    "href": "lectures/16/slides.html#proof-of-optimality",
    "title": "Heuristic Search",
    "section": "Proof of optimality",
    "text": "Proof of optimality\nTheorem: If \\(h(n)\\) is an admissible heuristic, then \\(A^\\star\\) using \\(h(n)\\) will always find an optimal solution if one exists.\nProof:\n\nAssumption for Contradiction: Suppose that \\(A^\\star\\) returns a suboptimal solution with cost \\(C &gt; C^\\star\\), where \\(C^\\star\\) is the cost of the optimal solution.\nState of Frontier: At the time \\(A^\\star\\) finds and returns the suboptimal solution, there must be no unexplored nodes \\(n\\) in the frontier (open list) such that \\(f(n) \\leq C^\\star\\). If there were such a node, \\(A^\\star\\) would have selected it for expansion before the node leading to the suboptimal solution due to its lower \\(f(n)\\) value.\nExistence of Optimal Path Nodes: However, along the optimal path to the goal, there must be nodes \\(n\\) such that \\(f(n) = g(n) + h(n) \\leq C^\\star\\), because:\n\n\\(g(n)\\) is the cost from the start to \\(n\\) along the optimal path, so \\(g(n) \\leq C^\\star\\).\n\\(h(n) \\leq h^*(n)\\) because \\(h(n)\\) is admissible.\n\\(h^*(n)\\) is the true cost from \\(n\\) to the goal along the optimal path, so \\(g(n) + h^*(n) = C^\\star\\).\nTherefore, \\(f(n) = g(n) + h(n) \\leq g(n) + h^*(n) = C^\\star\\).\n\nContradiction: This means there are nodes in the frontier with \\(f(n) \\leq C^\\star\\) that have not yet been explored, contradicting the assumption that no such nodes exist at the time the suboptimal solution is returned.\nConclusion: Therefore, \\(A^\\star\\) cannot return a suboptimal solution when using an admissible heuristic. It must find the optimal solution with cost \\(C^\\star\\). Q.E.D."
  },
  {
    "objectID": "lectures/16/slides.html#puzzle",
    "href": "lectures/16/slides.html#puzzle",
    "title": "Heuristic Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle\nCan you think of a heuristic function, \\(h(n)\\), for the 8-Puzzle?"
  },
  {
    "objectID": "lectures/16/slides.html#misplaced-tiles-distance",
    "href": "lectures/16/slides.html#misplaced-tiles-distance",
    "title": "Heuristic Search",
    "section": "Misplaced Tiles Distance",
    "text": "Misplaced Tiles Distance\n\ndef  misplaced_tiles_distance(state, goal_state):\n\n    # Count the number of misplaced tiles\n    misplaced_tiles = sum(1 for s, g in zip(state, goal_state) if s != g and s != 0)\n    \n    return misplaced_tiles\n\n\n\nIs this heuristic admissible?"
  },
  {
    "objectID": "lectures/16/slides.html#puzzle-1",
    "href": "lectures/16/slides.html#puzzle-1",
    "title": "Heuristic Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle"
  },
  {
    "objectID": "lectures/16/slides.html#best-first-search",
    "href": "lectures/16/slides.html#best-first-search",
    "title": "Heuristic Search",
    "section": "Best-First Search",
    "text": "Best-First Search\n\ndef best_first_search(initial_state, goal_state):\n\n    frontier = []  # Initialize the priority queue\n    initial_h = misplaced_tiles_distance(initial_state, goal_state)\n    # Push the initial state with its heuristic value onto the queue\n    heapq.heappush(frontier, (initial_h, 0, initial_state, []))  # (f(n), g(n), state, path)\n\n    explored = set()\n\n    iterations = 0\n\n    while not is_empty(frontier):\n        f, g, current_state, path = heapq.heappop(frontier)\n\n        if is_goal(current_state, goal_state):\n            print(f\"Number of iterations: {iterations}\")\n            return path + [current_state]  # Return the successful path\n\n        iterations = iterations + 1\n\n        explored.add(tuple(current_state))\n\n        for neighbor in expand(current_state):\n            if tuple(neighbor) not in explored:\n                new_g = g + 1  # Increment the path cost\n                h = misplaced_tiles_distance(neighbor, goal_state)\n                new_f = new_g + h  # Calculate the new total cost\n                # Push the neighbor state onto the priority queue\n                heapq.heappush(frontier, (new_f, new_g, neighbor, path + [current_state]))\n                explored.add(tuple(neighbor))  # Mark neighbor as explored\n\n    return None  # No solution found"
  },
  {
    "objectID": "lectures/16/slides.html#simple-case",
    "href": "lectures/16/slides.html#simple-case",
    "title": "Heuristic Search",
    "section": "Simple Case",
    "text": "Simple Case\n\n\nNumber of iterations: 2\n\n\n\n\n\n\n\n\n\n\ninitial_state_8 = [1, 2, 3,\n                   4, 0, 6,\n                   7, 5, 8]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nbest_first_search(initial_state_8, goal_state_8)\n\nNumber of iterations: 2\n\n\n[[1, 2, 3, 4, 0, 6, 7, 5, 8],\n [1, 2, 3, 4, 5, 6, 7, 0, 8],\n [1, 2, 3, 4, 5, 6, 7, 8, 0]]"
  },
  {
    "objectID": "lectures/16/slides.html#challenging-case",
    "href": "lectures/16/slides.html#challenging-case",
    "title": "Heuristic Search",
    "section": "Challenging Case",
    "text": "Challenging Case\n\ninitial_state_8 = [6, 4, 5,\n                   8, 2, 7,\n                   1, 0, 3]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nprint(\"Solving 8-puzzle with best_first_search...\")\n\nsolution_8_bfs = best_first_search(initial_state_8, goal_state_8)\n\nif solution_8_bfs:\n    print(f\"Best_first_search Solution found in {len(solution_8_bfs) - 1} moves:\")\n    print_solution(solution_8_bfs)\nelse:\n    print(\"No solution found for 8-puzzle using best_first_search.\")\n\nSolving 8-puzzle with best_first_search...\nNumber of iterations: 29005\nBest_first_search Solution found in 25 moves:\nStep 0:\n6 4 5\n8 2 7\n1   3\n\nStep 1:\n6 4 5\n8 2 7\n  1 3\n\nStep 2:\n6 4 5\n  2 7\n8 1 3\n\nStep 3:\n6 4 5\n2   7\n8 1 3\n\nStep 4:\n6   5\n2 4 7\n8 1 3\n\nStep 5:\n  6 5\n2 4 7\n8 1 3\n\nStep 6:\n2 6 5\n  4 7\n8 1 3\n\nStep 7:\n2 6 5\n4   7\n8 1 3\n\nStep 8:\n2 6 5\n4 1 7\n8   3\n\nStep 9:\n2 6 5\n4 1 7\n  8 3\n\nStep 10:\n2 6 5\n  1 7\n4 8 3\n\nStep 11:\n2 6 5\n1   7\n4 8 3\n\nStep 12:\n2 6 5\n1 7  \n4 8 3\n\nStep 13:\n2 6 5\n1 7 3\n4 8  \n\nStep 14:\n2 6 5\n1 7 3\n4   8\n\nStep 15:\n2 6 5\n1   3\n4 7 8\n\nStep 16:\n2   5\n1 6 3\n4 7 8\n\nStep 17:\n2 5  \n1 6 3\n4 7 8\n\nStep 18:\n2 5 3\n1 6  \n4 7 8\n\nStep 19:\n2 5 3\n1   6\n4 7 8\n\nStep 20:\n2   3\n1 5 6\n4 7 8\n\nStep 21:\n  2 3\n1 5 6\n4 7 8\n\nStep 22:\n1 2 3\n  5 6\n4 7 8\n\nStep 23:\n1 2 3\n4 5 6\n  7 8\n\nStep 24:\n1 2 3\n4 5 6\n7   8\n\nStep 25:\n1 2 3\n4 5 6\n7 8"
  },
  {
    "objectID": "lectures/16/slides.html#puzzle-2",
    "href": "lectures/16/slides.html#puzzle-2",
    "title": "Heuristic Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle\n\ndef manhattan_distance(state, goal_state):\n    distance = 0\n    size = int(len(state) ** 0.5)\n    for num in range(1, len(state)):\n        idx1 = state.index(num)\n        idx2 = goal_state.index(num)\n        x1, y1 = idx1 % size, idx1 // size\n        x2, y2 = idx2 % size, idx2 // size\n        distance += abs(x1 - x2) + abs(y1 - y2)\n    return distance\n\n\n\nCalculates the Manhattan distance heuristic for a given state. Is this heuristic admissible?"
  },
  {
    "objectID": "lectures/16/slides.html#puzzle-3",
    "href": "lectures/16/slides.html#puzzle-3",
    "title": "Heuristic Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle"
  },
  {
    "objectID": "lectures/16/slides.html#puzzle-4",
    "href": "lectures/16/slides.html#puzzle-4",
    "title": "Heuristic Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle\n\nCompare Manhattan vs. Misplaced Tiles heuristics.\nWhich is more effective?\nSignificant run time differences?"
  },
  {
    "objectID": "lectures/16/slides.html#puzzle-5",
    "href": "lectures/16/slides.html#puzzle-5",
    "title": "Heuristic Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle\n\n\n\n\n\n\n\n\n\nwhere\n\na = misplaced tiles distance\nb = Manathan distance"
  },
  {
    "objectID": "lectures/16/slides.html#puzzle-6",
    "href": "lectures/16/slides.html#puzzle-6",
    "title": "Heuristic Search",
    "section": "8-Puzzle",
    "text": "8-Puzzle\n\n\n\n\n\n\n\n\n\nwhere\n\na = misplaced tiles distance\nb = Manathan distance\n\n\nmisplaced_tiles_distance does not take into account how far a tile is from its expected final location, whereas manhattan_distance does.\nThus, one can expect the algorithm using the Manhattan distance to select the next node to explore more wisely."
  },
  {
    "objectID": "lectures/16/slides.html#best-first-search-1",
    "href": "lectures/16/slides.html#best-first-search-1",
    "title": "Heuristic Search",
    "section": "Best-First Search",
    "text": "Best-First Search\n\ndef best_first_search_revised(initial_state, goal_state):\n\n    frontier = []  # Initialize the priority queue\n    initial_h = manhattan_distance(initial_state, goal_state)\n    # Push the initial state with its heuristic value onto the queue\n    heapq.heappush(frontier, (initial_h, 0, initial_state, []))  # (f(n), g(n), state, path)\n\n    explored = set()\n\n    iterations = 0\n\n    while not is_empty(frontier):\n        f, g, current_state, path = heapq.heappop(frontier)\n\n        if is_goal(current_state, goal_state):\n            print(f\"Number of iterations: {iterations}\")\n            return path + [current_state]  # Return the successful path\n\n        iterations = iterations + 1\n\n        explored.add(tuple(current_state))\n\n        for neighbor in expand(current_state):\n            if tuple(neighbor) not in explored:\n                new_g = g + 1  # Increment the path cost\n                h = manhattan_distance(neighbor, goal_state)\n                new_f = new_g + h  # Calculate the new total cost\n                # Push the neighbor state onto the priority queue\n                heapq.heappush(frontier, (new_f, new_g, neighbor, path + [current_state]))\n                explored.add(tuple(neighbor))  # Mark neighbor as explored\n\n    return None  # No solution found\n\n\nWhen expanding a node in the search tree, it is crucial to note that we do not immediately evaluate its descendant nodes to determine if they are goal nodes. Instead, these descendants are added to the frontier, which is a priority queue. This allows their \\(f(n)\\) values to be compared with those of other nodes in the frontier, ensuring that the most promising nodes are considered first based on their estimated total cost.\nConsequently, it is possible for the frontier to include nodes that are goal nodes. However, their \\(f(n)\\) values may be higher than those of other nodes deemed more promising, as these other nodes might lead to a shorter path to the goal."
  },
  {
    "objectID": "lectures/16/slides.html#simple-case-1",
    "href": "lectures/16/slides.html#simple-case-1",
    "title": "Heuristic Search",
    "section": "Simple Case",
    "text": "Simple Case\n\n\nNumber of iterations: 2\n\n\n\n\n\n\n\n\n\n\ninitial_state_8 = [1, 2, 3,\n                    4, 0, 6,\n                    7, 5, 8]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nbest_first_search_revised(initial_state_8, goal_state_8)\n\nNumber of iterations: 2\n\n\n[[1, 2, 3, 4, 0, 6, 7, 5, 8],\n [1, 2, 3, 4, 5, 6, 7, 0, 8],\n [1, 2, 3, 4, 5, 6, 7, 8, 0]]"
  },
  {
    "objectID": "lectures/16/slides.html#challenging-case-1",
    "href": "lectures/16/slides.html#challenging-case-1",
    "title": "Heuristic Search",
    "section": "Challenging Case",
    "text": "Challenging Case\n\ninitial_state_8 = [6, 4, 5,\n                   8, 2, 7,\n                   1, 0, 3]\ngoal_state_8 = [1, 2, 3,\n                4, 5, 6,\n                7, 8, 0]\n\nprint(\"Solving 8-puzzle with best_first_search...\")\n\nsolution_8_bfs = best_first_search_revised(initial_state_8, goal_state_8)\n\nif solution_8_bfs:\n    print(f\"Best_first_search Solution found in {len(solution_8_bfs) - 1} moves:\")\n    print_solution(solution_8_bfs)\nelse:\n    print(\"No solution found for 8-puzzle using best_first_search.\")\n\nSolving 8-puzzle with best_first_search...\nNumber of iterations: 2255\nBest_first_search Solution found in 25 moves:\nStep 0:\n6 4 5\n8 2 7\n1   3\n\nStep 1:\n6 4 5\n8 2 7\n  1 3\n\nStep 2:\n6 4 5\n  2 7\n8 1 3\n\nStep 3:\n6 4 5\n2   7\n8 1 3\n\nStep 4:\n6   5\n2 4 7\n8 1 3\n\nStep 5:\n  6 5\n2 4 7\n8 1 3\n\nStep 6:\n2 6 5\n  4 7\n8 1 3\n\nStep 7:\n2 6 5\n4   7\n8 1 3\n\nStep 8:\n2 6 5\n4 1 7\n8   3\n\nStep 9:\n2 6 5\n4 1 7\n  8 3\n\nStep 10:\n2 6 5\n  1 7\n4 8 3\n\nStep 11:\n2 6 5\n1   7\n4 8 3\n\nStep 12:\n2 6 5\n1 7  \n4 8 3\n\nStep 13:\n2 6 5\n1 7 3\n4 8  \n\nStep 14:\n2 6 5\n1 7 3\n4   8\n\nStep 15:\n2 6 5\n1   3\n4 7 8\n\nStep 16:\n2   5\n1 6 3\n4 7 8\n\nStep 17:\n2 5  \n1 6 3\n4 7 8\n\nStep 18:\n2 5 3\n1 6  \n4 7 8\n\nStep 19:\n2 5 3\n1   6\n4 7 8\n\nStep 20:\n2   3\n1 5 6\n4 7 8\n\nStep 21:\n  2 3\n1 5 6\n4 7 8\n\nStep 22:\n1 2 3\n  5 6\n4 7 8\n\nStep 23:\n1 2 3\n4 5 6\n  7 8\n\nStep 24:\n1 2 3\n4 5 6\n7   8\n\nStep 25:\n1 2 3\n4 5 6\n7 8"
  },
  {
    "objectID": "lectures/16/slides.html#experiments",
    "href": "lectures/16/slides.html#experiments",
    "title": "Heuristic Search",
    "section": "1000 Experiments",
    "text": "1000 Experiments"
  },
  {
    "objectID": "lectures/16/slides.html#scatter-plot-manathan",
    "href": "lectures/16/slides.html#scatter-plot-manathan",
    "title": "Heuristic Search",
    "section": "Scatter Plot (Manathan)",
    "text": "Scatter Plot (Manathan)"
  },
  {
    "objectID": "lectures/16/slides.html#exploration",
    "href": "lectures/16/slides.html#exploration",
    "title": "Heuristic Search",
    "section": "Exploration",
    "text": "Exploration\nBreadth-first search (BFS) is guaranteed to find the shortest path, or lowest-cost solution, assuming all actions have unit cost.\nDevelop a program that performs the following tasks:\n\nGenerate a random configuration of the 8-Puzzle.\nDetermine the shortest path using breadth-first search.\nIdentify the optimal solution using the \\(A^\\star\\) algorithm.\nCompare the costs of the solutions obtained in steps 2 and 3. There should be no discrepancy if \\(A^\\star\\) identifies cost-optimal solutions.\nRepeat the process."
  },
  {
    "objectID": "lectures/16/slides.html#exploration-1",
    "href": "lectures/16/slides.html#exploration-1",
    "title": "Heuristic Search",
    "section": "Exploration",
    "text": "Exploration\nThe heuristic \\(h(n) = 0\\) is considered admissible, yet it typically results in inefficient exploration of the search space. Develop a program to investigate this concept. Demonstrate that when all actions are assumed to have unit cost, both \\(A^\\star\\) and breadth-first search (BFS) explore the search space similarly. Specifically, they examine all paths of length one, followed by paths of length two, and so forth."
  },
  {
    "objectID": "lectures/16/slides.html#remarks-1",
    "href": "lectures/16/slides.html#remarks-1",
    "title": "Heuristic Search",
    "section": "Remarks",
    "text": "Remarks\n\nBreadth-first search (BFS) identifies the optimal solution, 25 moves, in 145,605 iterations.\nDepth-first search (DFS) discovers a solution involving 1,157 moves in 1,187 iterations.\nBest-First Search  using the Manathan distance identifies the optimal solution, 25 moves, in 2,255 iterations."
  },
  {
    "objectID": "lectures/16/slides.html#measuring-performance",
    "href": "lectures/16/slides.html#measuring-performance",
    "title": "Heuristic Search",
    "section": "Measuring Performance",
    "text": "Measuring Performance\n\nCompleteness: Does the algorithm ensure that a solution will be found if one exists, and accurately indicate failure when no solution exists?\nCost Optimality: Does the algorithm identify the (a) solution with the lowest path cost among all possible solutions?\n\n\n\nAre all three algorithms complete? What are the necessary conditions?\nDo all three algorithms guarantee cost optimality?"
  },
  {
    "objectID": "lectures/16/slides.html#measuring-performance-1",
    "href": "lectures/16/slides.html#measuring-performance-1",
    "title": "Heuristic Search",
    "section": "Measuring Performance",
    "text": "Measuring Performance\n\nTime Complexity: How does the time required by the algorithm scale with respect to the number of states and actions?\nSpace Complexity: How does the space required by the algorithm scale with respect to the number of states and actions?\n\n\n\n\nWhat is the time and space complexity of breadth-first-search? \\(\\mathcal{O}(b^d)\\)\n\n\n\nAlternatively, complexity can be evaluated based on the depth (\\(d\\)) and branching factor (\\(b\\)) of the search tree, instead of the number of states (nodes) and actions (edges) in the state space."
  },
  {
    "objectID": "lectures/16/slides.html#videos-by-sebastian-lague",
    "href": "lectures/16/slides.html#videos-by-sebastian-lague",
    "title": "Heuristic Search",
    "section": "Videos by Sebastian Lague",
    "text": "Videos by Sebastian Lague\n\nA* Pathfinding (E01: algorithm explanation) posted on 2014-12-16.\nA* Pathfinding (E02: node grid) posted on 2014-12-18.\nA* Pathfinding (E03: algorithm implementation) posted on 2014-12-19.\nA* Pathfinding (E04: heap optimization) posted on 2014-12-24.\nA* Pathfinding (E05: units) posted on 2015-01-06.\nA* Pathfinding (E06: weights) posted on 2015-01-11.\nA* Pathfinding (E07: smooth weights) posted on 2016-12-30.\nA* Pathfinding (E08: path smoothing 1/2) posted on 2017-01-31.\nA* Pathfinding (E09: path smoothing 2/2) posted on 2017-01-31.\nA* Pathfinding (E10: threading) posted on 2017-02-03.\nA* Pathfinding Tutorial (Unity) (play list)"
  },
  {
    "objectID": "lectures/16/slides.html#a-resource-dedicated-to-astar",
    "href": "lectures/16/slides.html#a-resource-dedicated-to-astar",
    "title": "Heuristic Search",
    "section": "A resource dedicated to \\(A^\\star\\)",
    "text": "A resource dedicated to \\(A^\\star\\)\n\nAmit’s A* Pages"
  },
  {
    "objectID": "lectures/16/slides.html#summary-1",
    "href": "lectures/16/slides.html#summary-1",
    "title": "Heuristic Search",
    "section": "Summary",
    "text": "Summary\n\nInformed Search and Heuristics\n\nBest-First Search\n\nImplementations\n\n\n\nInformed Search and Heuristics:\n\nIntroduced the concept of heuristic functions (h(n)) to estimate costs.\nBest-First Search:\n\nUses heuristics to prioritize nodes that seem closer to the goal.\nImplemented with a priority queue sorted by estimated cost.\n\nManhattan Distance Heuristic:\n\nCalculates the sum of the distances of tiles from their goal positions.\nUsed in the 8-Puzzle to guide the search more efficiently.\n\n\nComparative Analysis:\n\nBFS: Optimal solution in 145,605 iterations (25 moves).\nDFS: Suboptimal solution in 1,187 iterations (1,157 moves).\nBest-First Search: Optimal solution in 2,255 iterations (25 moves).\nDemonstrated that informed search algorithms can find optimal solutions more efficiently."
  },
  {
    "objectID": "lectures/16/slides.html#next-lecture",
    "href": "lectures/16/slides.html#next-lecture",
    "title": "Heuristic Search",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will examine additional search algorithms."
  },
  {
    "objectID": "lectures/16/slides.html#references",
    "href": "lectures/16/slides.html#references",
    "title": "Heuristic Search",
    "section": "References",
    "text": "References\n\n\nHart, Peter E., Nils J. Nilsson, and Bertram Raphael. 1968. “A Formal Basis for the Heuristic Determination of Minimum Cost Paths.” IEEE Transactions on Systems Science and Cybernetics 4 (2): 100–107. https://doi.org/10.1109/tssc.1968.300136.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/16/index.html",
    "href": "lectures/16/index.html",
    "title": "Heuristic Search",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 3 must be submitted no later than November 10, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/16/index.html#prepare",
    "href": "lectures/16/index.html#prepare",
    "title": "Heuristic Search",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 85–92"
  },
  {
    "objectID": "lectures/16/index.html#participate",
    "href": "lectures/16/index.html#participate",
    "title": "Heuristic Search",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/17/slides.html#quote-of-the-day",
    "href": "lectures/17/slides.html#quote-of-the-day",
    "title": "Local Search",
    "section": "Quote of the Day",
    "text": "Quote of the Day"
  },
  {
    "objectID": "lectures/17/slides.html#learning-objectives",
    "href": "lectures/17/slides.html#learning-objectives",
    "title": "Local Search",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the concept and application of local search algorithms in optimization problems.\nImplement and analyze the hill-climbing algorithm, recognizing its limitations such as local maxima and plateaus.\nApply effective state representation strategies in problems like the 8-Queens to enhance search efficiency.\nExplain how simulated annealing overcomes local optima by allowing probabilistic acceptance of worse states.\nAnalyze the influence of temperature and energy difference on the acceptance probability in simulated annealing.\nRecognize the application of simulated annealing in solving complex optimization problems like the Travelling Salesman Problem (TSP)."
  },
  {
    "objectID": "lectures/17/slides.html#context",
    "href": "lectures/17/slides.html#context",
    "title": "Local Search",
    "section": "Context",
    "text": "Context\n\nFocus has been on finding paths in state space.\nSome problems prioritize the goal state over the path.\n\nIntegrated-circuit design\nJob shop scheduling\nAutomatic programming\n\n\n\nThe importance of the path versus the goal state hinges on the problem’s nature. For instance, in a routing problem, the path is the critical piece of information sought."
  },
  {
    "objectID": "lectures/17/slides.html#queens-problem",
    "href": "lectures/17/slides.html#queens-problem",
    "title": "Local Search",
    "section": "8-Queens Problem",
    "text": "8-Queens Problem\n\n\n\n\n\n\n\n\n\n\n\nFor an \\(8 \\times 8\\) chessboard, there exist precisely 92 distinct solutions. Eliminating symmetry, one finds 12 fondamental solutions. In the more general scenario of an \\(n \\times n\\) chessboard, the exact number of solutions has been determined for all \\(n\\) values up to and including 27.\n\n\nThe 8-Queens problem involves placing eight queens on an \\(8 \\times 8\\) chessboard such that no two queens threaten each other, meaning no two queens share the same row, column, or diagonal."
  },
  {
    "objectID": "lectures/17/slides.html#definition",
    "href": "lectures/17/slides.html#definition",
    "title": "Local Search",
    "section": "Definition",
    "text": "Definition\n\n\n\n (Russell and Norvig 2020, 110)\n\n\nLocal search algorithms operate by searching from a start state to neighboring states, without keeping track of the paths, nor the set of states that have been reached.\n\n\n\n\n\nThis algorithm lacks a systematic approach and does not ensure the discovery of an optimal solution.\n\n\nOptimizes memory utilization while effectively solving problems in extensive or infinite state spaces."
  },
  {
    "objectID": "lectures/17/slides.html#problem-definition",
    "href": "lectures/17/slides.html#problem-definition",
    "title": "Local Search",
    "section": "Problem Definition",
    "text": "Problem Definition\nFind the “best” state according to an objective function, thereby locating the global maximum.\n\n\nThis optimization problem is commonly referred to as hill climbing."
  },
  {
    "objectID": "lectures/17/slides.html#hill-climbing-1",
    "href": "lectures/17/slides.html#hill-climbing-1",
    "title": "Local Search",
    "section": "Hill-Climbing",
    "text": "Hill-Climbing"
  },
  {
    "objectID": "lectures/17/slides.html#hill-climbing-2",
    "href": "lectures/17/slides.html#hill-climbing-2",
    "title": "Local Search",
    "section": "Hill-Climbing",
    "text": "Hill-Climbing\nGiven as in input a problem\n\ncurrent is the initial state of problem\nwhile not done do\n\nnighbour is the highest-valued successor state of current\nif value(neighbour) \\(\\le\\) value(current) the return current\nset current to neighbour\n\n\n\nHill climbing neither records previously visited states nor anticipates beyond its immediate neighbors. It keeps track of one current state moves in the direction of the steepest ascent.\nNotably, by inverting the sign of the objective function, the algorithm can be adapted to seek a local minimum instead."
  },
  {
    "objectID": "lectures/17/slides.html#queens",
    "href": "lectures/17/slides.html#queens",
    "title": "Local Search",
    "section": "8-Queens",
    "text": "8-Queens\nHow would you represent the current state?\n\nWhy is using a grid to represent the current state suboptimal?\n\n\nA grid representation permits the illegal placement of two queens in the same column.\n\n\nInstead, we can represent the state as a list (\\(\\mathrm{state}\\)), where each element corresponds to the row position of the queen in its respective column.\nIn other words, \\(\\mathrm{state}[i]\\) is the row of the queen is column \\(i\\)."
  },
  {
    "objectID": "lectures/17/slides.html#state-representation",
    "href": "lectures/17/slides.html#state-representation",
    "title": "Local Search",
    "section": "State Representation",
    "text": "State Representation\n\n\n\n\n\n\n\n\n\n\n\n\nstate = [0, 4, 7, 5, 2, 6, 1, 3]"
  },
  {
    "objectID": "lectures/17/slides.html#create_initial_state",
    "href": "lectures/17/slides.html#create_initial_state",
    "title": "Local Search",
    "section": "create_initial_state",
    "text": "create_initial_state\n\nimport random\nrandom.seed(7)\n\ndef create_initial_state(n):\n\n    \"\"\"Generates a random initial state with one queen per column.\"\"\"\n\n    return [random.randint(0, n - 1) for _ in range(n)]\n\n\n\nWhat do you think?"
  },
  {
    "objectID": "lectures/17/slides.html#create_initial_state-1",
    "href": "lectures/17/slides.html#create_initial_state-1",
    "title": "Local Search",
    "section": "create_initial_state",
    "text": "create_initial_state\n\n\n\n\n\n\n\n\n\n\nstate \n\n[5, 2, 6, 0, 1, 1, 5, 0]\n\n\n\nPermits two queens in the same row? How can this be resolved?"
  },
  {
    "objectID": "lectures/17/slides.html#representation-of-8-queens",
    "href": "lectures/17/slides.html#representation-of-8-queens",
    "title": "Local Search",
    "section": "Representation of 8-Queens",
    "text": "Representation of 8-Queens\n\\(8 \\times 8\\) chessboard.\n\nUnconstrained Placement: \\(\\binom{64}{8} = 4,426,165,368\\) possible configurations, representing the selection of 8 squares from 64.\nColumn Constraint: Use a list of length 8, with each entry indicating the row of a queen in its respective column, resulting in \\(8^8 = 16,777,216\\) configurations.\nRow and Column Constraints: Model board states as permutations of the 8 row indices, reducing configurations to \\(8! = 40,320\\).\n\n\n\nThis underscores the significance of selecting a good representation."
  },
  {
    "objectID": "lectures/17/slides.html#create_initial_state-2",
    "href": "lectures/17/slides.html#create_initial_state-2",
    "title": "Local Search",
    "section": "create_initial_state",
    "text": "create_initial_state\n\nimport random\nrandom.seed(7)\n\ndef create_initial_state(n):\n\n    \"\"\"Generates a permutation of numbers from 0 to n-1 as the initial state.\"\"\"\n\n    state = list(range(n))\n    random.shuffle(state)\n\n    return state"
  },
  {
    "objectID": "lectures/17/slides.html#create_initial_state-3",
    "href": "lectures/17/slides.html#create_initial_state-3",
    "title": "Local Search",
    "section": "create_initial_state",
    "text": "create_initial_state\n\n\n\n\n\n\n\n\n\n\nstate \n\n[6, 7, 2, 4, 0, 3, 1, 5]"
  },
  {
    "objectID": "lectures/17/slides.html#calculate_conflicts",
    "href": "lectures/17/slides.html#calculate_conflicts",
    "title": "Local Search",
    "section": "calculate_conflicts",
    "text": "calculate_conflicts\n\ndef calculate_conflicts(state):\n\n    n = len(state)\n    conflicts = 0\n\n    for col_i in range(n):\n        for col_j in range(col_i + 1, n):\n            row_i = state[col_i]\n            row_j = state[col_j]\n            if row_i == row_j:                 # same row\n                conflicts += 1\n            if col_i - row_i == col_j - row_j: # same diagonal\n                conflicts += 1\n            if col_i + row_i == col_j + row_j: # same anti-diagonal\n                conflicts += 1\n\n    return conflicts"
  },
  {
    "objectID": "lectures/17/slides.html#calculate_conflicts-1",
    "href": "lectures/17/slides.html#calculate_conflicts-1",
    "title": "Local Search",
    "section": "calculate_conflicts",
    "text": "calculate_conflicts\n\n\n\n\n\n\n\n\n\n\n\n\n\n5"
  },
  {
    "objectID": "lectures/17/slides.html#get_neighbors_rn",
    "href": "lectures/17/slides.html#get_neighbors_rn",
    "title": "Local Search",
    "section": "get_neighbors_rn",
    "text": "get_neighbors_rn\n\ndef get_neighbors_rn(state):\n\n    \"\"\"Generates neighboring states by moving on queen at a time to a new row.\"\"\"\n\n    neighbors = []\n    n = len(state)\n\n    for col in range(n):\n        for row in range(n):\n            if (state[col] != row):\n              new_state = state[:] # create a copy of the state\n              new_state[col] = row\n              neighbors.append(new_state)\n\n    return neighbors\n\n\n\nRussell and Norvig (2020), \\(8 \\times 7 = 56\\) neighbours"
  },
  {
    "objectID": "lectures/17/slides.html#get_neighbors_rn-1",
    "href": "lectures/17/slides.html#get_neighbors_rn-1",
    "title": "Local Search",
    "section": "get_neighbors_rn",
    "text": "get_neighbors_rn\n\ninitial_state_8 = create_initial_state(8)\nprint(initial_state_8)\nfor s in get_neighbors_rn(initial_state_8):\n  print(f\"{s} -&gt; # of conflicts = {calculate_conflicts(s)}\")\n\n[3, 2, 7, 1, 6, 0, 4, 5]\n[0, 2, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[1, 2, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[2, 2, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[4, 2, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[5, 2, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 7\n[6, 2, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[7, 2, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 0, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 1, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 3, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 4, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 5, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 6, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 7, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 0, 1, 6, 0, 4, 5] -&gt; # of conflicts = 9\n[3, 2, 1, 1, 6, 0, 4, 5] -&gt; # of conflicts = 8\n[3, 2, 2, 1, 6, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 2, 3, 1, 6, 0, 4, 5] -&gt; # of conflicts = 8\n[3, 2, 4, 1, 6, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 2, 5, 1, 6, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 2, 6, 1, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 0, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 2, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 7, 3, 6, 0, 4, 5] -&gt; # of conflicts = 4\n[3, 2, 7, 4, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 7, 5, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 7, 6, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 7, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 0, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 1, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 2, 0, 4, 5] -&gt; # of conflicts = 8\n[3, 2, 7, 1, 3, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 7, 1, 4, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 7, 1, 5, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 2, 7, 1, 7, 0, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 6, 1, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 6, 2, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 6, 3, 4, 5] -&gt; # of conflicts = 9\n[3, 2, 7, 1, 6, 4, 4, 5] -&gt; # of conflicts = 7\n[3, 2, 7, 1, 6, 5, 4, 5] -&gt; # of conflicts = 8\n[3, 2, 7, 1, 6, 6, 4, 5] -&gt; # of conflicts = 7\n[3, 2, 7, 1, 6, 7, 4, 5] -&gt; # of conflicts = 8\n[3, 2, 7, 1, 6, 0, 0, 5] -&gt; # of conflicts = 3\n[3, 2, 7, 1, 6, 0, 1, 5] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 2, 5] -&gt; # of conflicts = 3\n[3, 2, 7, 1, 6, 0, 3, 5] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 5, 5] -&gt; # of conflicts = 3\n[3, 2, 7, 1, 6, 0, 6, 5] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 7, 5] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 4, 0] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 4, 1] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 4, 2] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 6, 0, 4, 3] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 6, 0, 4, 4] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 4, 6] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 0, 4, 7] -&gt; # of conflicts = 4"
  },
  {
    "objectID": "lectures/17/slides.html#get_neighbors",
    "href": "lectures/17/slides.html#get_neighbors",
    "title": "Local Search",
    "section": "get_neighbors",
    "text": "get_neighbors\n\ndef get_neighbors(state):\n\n    \"\"\"Generates neighboring states by swapping two rows.\"\"\"\n\n    neighbors = []\n    n = len(state)\n\n    for i in range(n):\n        for j in range(i + 1, n):\n            new_state = state[:]\n            new_state[i], new_state[j] = new_state[j], new_state[i]\n            neighbors.append(new_state)\n\n    return neighbors\n\n\n\n\\(\\frac{8 \\times 7}{2} = 28\\) neighbours"
  },
  {
    "objectID": "lectures/17/slides.html#get_neighbors-1",
    "href": "lectures/17/slides.html#get_neighbors-1",
    "title": "Local Search",
    "section": "get_neighbors",
    "text": "get_neighbors\n\nprint(initial_state_8)\nfor s in get_neighbors(initial_state_8):\n  print(f\"{s} -&gt; # of conflicts = {calculate_conflicts(s)}\")\n\n[3, 2, 7, 1, 6, 0, 4, 5]\n[2, 3, 7, 1, 6, 0, 4, 5] -&gt; # of conflicts = 8\n[7, 2, 3, 1, 6, 0, 4, 5] -&gt; # of conflicts = 6\n[1, 2, 7, 3, 6, 0, 4, 5] -&gt; # of conflicts = 3\n[6, 2, 7, 1, 3, 0, 4, 5] -&gt; # of conflicts = 3\n[0, 2, 7, 1, 6, 3, 4, 5] -&gt; # of conflicts = 7\n[4, 2, 7, 1, 6, 0, 3, 5] -&gt; # of conflicts = 3\n[5, 2, 7, 1, 6, 0, 4, 3] -&gt; # of conflicts = 6\n[3, 7, 2, 1, 6, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 1, 7, 2, 6, 0, 4, 5] -&gt; # of conflicts = 3\n[3, 6, 7, 1, 2, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 0, 7, 1, 6, 2, 4, 5] -&gt; # of conflicts = 4\n[3, 4, 7, 1, 6, 0, 2, 5] -&gt; # of conflicts = 3\n[3, 5, 7, 1, 6, 0, 4, 2] -&gt; # of conflicts = 4\n[3, 2, 1, 7, 6, 0, 4, 5] -&gt; # of conflicts = 7\n[3, 2, 6, 1, 7, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 0, 1, 6, 7, 4, 5] -&gt; # of conflicts = 10\n[3, 2, 4, 1, 6, 0, 7, 5] -&gt; # of conflicts = 4\n[3, 2, 5, 1, 6, 0, 4, 7] -&gt; # of conflicts = 4\n[3, 2, 7, 6, 1, 0, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 7, 0, 6, 1, 4, 5] -&gt; # of conflicts = 5\n[3, 2, 7, 4, 6, 0, 1, 5] -&gt; # of conflicts = 4\n[3, 2, 7, 5, 6, 0, 4, 1] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 0, 6, 4, 5] -&gt; # of conflicts = 6\n[3, 2, 7, 1, 4, 0, 6, 5] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 5, 0, 4, 6] -&gt; # of conflicts = 4\n[3, 2, 7, 1, 6, 4, 0, 5] -&gt; # of conflicts = 3\n[3, 2, 7, 1, 6, 5, 4, 0] -&gt; # of conflicts = 5\n[3, 2, 7, 1, 6, 0, 5, 4] -&gt; # of conflicts = 2"
  },
  {
    "objectID": "lectures/17/slides.html#hill_climbing",
    "href": "lectures/17/slides.html#hill_climbing",
    "title": "Local Search",
    "section": "hill_climbing",
    "text": "hill_climbing\n\ndef hill_climbing(current_state):\n\n    current_conflicts = calculate_conflicts(current_state)\n\n    while True:\n\n        if current_conflicts == 0:\n          return curent_state\n\n        neighbors = get_neighbors(current_state)\n\n        conflicts = [calculate_conflicts(neighbor) for neighbor in neighbors]\n\n        if (min(conflicts)) &gt; current_conflicts:\n          return None # No improvement found, stuck at local minimum\n\n        arg_best = np.argmin(conflicts)\n        curent_state = neighbors[arg_best]\n        current_conflicts = conflicts[arg_best]\n\n\nThe program above presents a major issue. What exactly is it?\nIt is important to note that, in this particular context, the problem is defined such that the sought solution is free of any conflict. However, in some optimization problems, the minimum value of the objective function is not predetermined.\nThe main issue is that the algorithm might enter an infinite loop if the condition min(conflicts == current_conflicts) is satisfied.\nTwo scenarios may arise: either the plateau is followed by an ascending slope, or it represents a local maximum. In the first case, the algorithm could potentially exit the plateau, although this is not guaranteed. To prevent infinite loops, it would be wise to implement an appropriate mechanism."
  },
  {
    "objectID": "lectures/17/slides.html#hill_climbing-take-2",
    "href": "lectures/17/slides.html#hill_climbing-take-2",
    "title": "Local Search",
    "section": "hill_climbing (take 2)",
    "text": "hill_climbing (take 2)\n\nMAX_SIDE_MOVES = 100\n\ndef hill_climbing(current_state):\n\n    conflicts_current_state = calculate_conflicts(current_state)\n    side_moves = 0\n\n    while True:\n\n        if conflicts_current_state == 0:\n          return current_state\n\n        neighbors = get_neighbors(current_state)\n\n        conflicts = [calculate_conflicts(voisin) for voisin in neighbors]\n\n        if (min(conflicts)) &gt; conflicts_current_state:\n          return None  # No improvement, local maxima\n\n        if (min(conflicts)) == conflicts_current_state:\n          side_moves += 1  # Plateau\n\n        if side_moves &gt; MAX_SIDE_MOVES:\n          return None\n\n        arg_best = np.argmin(conflicts)\n        current_state = neighbors[arg_best]\n        conflicts_current_state = conflicts[arg_best]"
  },
  {
    "objectID": "lectures/17/slides.html#solve",
    "href": "lectures/17/slides.html#solve",
    "title": "Local Search",
    "section": "Solve",
    "text": "Solve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10 runs, number of solutions = 9, 0 duplicate(s)"
  },
  {
    "objectID": "lectures/17/slides.html#solve-2",
    "href": "lectures/17/slides.html#solve-2",
    "title": "Local Search",
    "section": "Solve (2)",
    "text": "Solve (2)\n\n\n1000 runs, number of solutions = 704, 92 unique solutions"
  },
  {
    "objectID": "lectures/17/slides.html#solve-40-queens",
    "href": "lectures/17/slides.html#solve-40-queens",
    "title": "Local Search",
    "section": "Solve 40-Queens",
    "text": "Solve 40-Queens\n\\(40! = 8.1591528325 \\times 10^{47}\\)\n\n\n\n10 runs, number of solutions = 6, 6 unique solutions\n\n\n\n\n\n\n\n\n\nElapsed time: 30.8039 seconds"
  },
  {
    "objectID": "lectures/17/slides.html#iterations-and-side-moves",
    "href": "lectures/17/slides.html#iterations-and-side-moves",
    "title": "Local Search",
    "section": "Iterations and Side Moves",
    "text": "Iterations and Side Moves\n\n\n1000 runs, number of solutions = 704, 92 unique solutions"
  },
  {
    "objectID": "lectures/17/slides.html#queens-1",
    "href": "lectures/17/slides.html#queens-1",
    "title": "Local Search",
    "section": "20-Queens",
    "text": "20-Queens\n\n\n1000 runs, number of solutions = 566, 566 unique solutions"
  },
  {
    "objectID": "lectures/17/slides.html#russell-norvig",
    "href": "lectures/17/slides.html#russell-norvig",
    "title": "Local Search",
    "section": "Russell & Norvig",
    "text": "Russell & Norvig\n\nHill climbing gets stuck 86% of the time.\n\nSuccessful attempts average 4 steps to a solution.\n\nPermitting 100 lateral moves boosts success rate from 14% to 94%.\nThe problem space comprises \\(8^8 = 16,777,216\\) states.\n\nImplementation from Russell & Norvig\n\n\n\n\nIn the implementation I proposed, there do not appear to be any local minima. However, this requires further verification.\n\n\nHas many variants, including random-restart hill climbing."
  },
  {
    "objectID": "lectures/17/slides.html#escaping-a-local-optimum",
    "href": "lectures/17/slides.html#escaping-a-local-optimum",
    "title": "Local Search",
    "section": "Escaping a Local Optimum",
    "text": "Escaping a Local Optimum\nWhat mechanisms would enable the hill climbing algorithm to escape from a local optimum, whether it be a local minimum or maximum?\n\nIt needs to accept going downhill.\nA random walk approach, which disregards the value of the objective function, could theoretically locate the global maximum. However, this method is highly impractical due to its extreme inefficiency."
  },
  {
    "objectID": "lectures/17/slides.html#remark",
    "href": "lectures/17/slides.html#remark",
    "title": "Local Search",
    "section": "Remark",
    "text": "Remark\nAssume the optimization problem is a minimization task, where the goal is to find a solution with the minimum cost.\n\n\nDownhill, gradient descent."
  },
  {
    "objectID": "lectures/17/slides.html#definition-1",
    "href": "lectures/17/slides.html#definition-1",
    "title": "Local Search",
    "section": "Definition",
    "text": "Definition\nSimulated annealing is an optimization algorithm inspired by the annealing process in metallurgy. It probabilistically explores the solution space by allowing occasional uphill moves, which helps escape local optima. The algorithm gradually reduces the probability of accepting worse solutions by lowering a “temperature” parameter, ultimately converging towards an optimal or near-optimal solution."
  },
  {
    "objectID": "lectures/17/slides.html#annealing",
    "href": "lectures/17/slides.html#annealing",
    "title": "Local Search",
    "section": "Annealing",
    "text": "Annealing\n\n\n\n (Russell and Norvig 2020, 114)\n\n\nIn metallurgy, annealing is the process used to temper or harden metals and glass by heating them to a high temperature and then gradually cooling them, thus allowing the material to reach a low-energy crystalline state.\n\n\n\n\nThe solid is heated to its melting point, causing the particles to become randomly distributed.\nSubsequently, the material is gradually cooled, allowing the particles to reorganize into a low-energy state."
  },
  {
    "objectID": "lectures/17/slides.html#algorithm",
    "href": "lectures/17/slides.html#algorithm",
    "title": "Local Search",
    "section": "Algorithm",
    "text": "Algorithm\n\n\n\n\n\n\n\n\nThis algorithm resembles hill climbing but differs by randomly selecting the next state rather than choosing the optimal move.\nIf the move results in a lower objective function value, it is accepted unconditionally.\nOtherwise, acceptance is probabilistic, contingent on both \\(\\Delta E\\) and \\(T\\).\n\n\n\nAttribution: (Russell and Norvig 2020, 115)"
  },
  {
    "objectID": "lectures/17/slides.html#varying-delta-e",
    "href": "lectures/17/slides.html#varying-delta-e",
    "title": "Local Search",
    "section": "Varying \\(\\Delta E\\)",
    "text": "Varying \\(\\Delta E\\)\n\n\n\n\n\n\n\n\n\n\n\nMoves resulting in significant negative changes (worse) to the objective function are less likely to be accepted."
  },
  {
    "objectID": "lectures/17/slides.html#varying-the-temperature-t",
    "href": "lectures/17/slides.html#varying-the-temperature-t",
    "title": "Local Search",
    "section": "Varying the temperature, \\(T\\)",
    "text": "Varying the temperature, \\(T\\)\n\n\n\n\n\n\n\n\n\n\n\nFor a fixed \\(\\Delta E\\) (here \\(0.1\\)), changes are more likely to be accepted whe \\(T\\) is high, at the start of the algorithm."
  },
  {
    "objectID": "lectures/17/slides.html#varying-the-temperature-and-delta-e",
    "href": "lectures/17/slides.html#varying-the-temperature-and-delta-e",
    "title": "Local Search",
    "section": "Varying the temperature and \\(\\Delta E\\)",
    "text": "Varying the temperature and \\(\\Delta E\\)\n\n\n\n\n\n\n\n\n\n\nBad moves are more likely to be accepted at the start when \\(T\\) is high, and less likely as \\(T\\) decreases."
  },
  {
    "objectID": "lectures/17/slides.html#varying-the-temperature-and-delta-e-1",
    "href": "lectures/17/slides.html#varying-the-temperature-and-delta-e-1",
    "title": "Local Search",
    "section": "Varying the temperature and \\(\\Delta E\\)",
    "text": "Varying the temperature and \\(\\Delta E\\)\n\nimport { Inputs, Plot } from \"@observablehq/plot\"\n\nviewof deltaE = Inputs.range([0.01, 100], {step: 0.01, value: 0.1, label: \"ΔE\", width: 300})\n\nT_values = Array.from({length: 1000}, (_, i) =&gt; (i + 1) * 0.1)\n\nfunction computeData(deltaE) {\n  return T_values.map(T =&gt; ({\n    T: T,\n    value: Math.exp(-deltaE / T)\n  }))\n}\n\ndata = computeData(deltaE)\n\nPlot.plot({\n  marks: [\n    Plot.line(data, {\n      x: \"T\", \n      y: \"value\", \n      stroke: \"steelblue\", \n      strokeWidth: 2\n    }),\n    Plot.ruleX([0], {stroke: \"black\"}), // X-axis line\n    Plot.ruleY([0], {stroke: \"black\"})  // Y-axis line\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Observable JS."
  },
  {
    "objectID": "lectures/17/slides.html#theory",
    "href": "lectures/17/slides.html#theory",
    "title": "Local Search",
    "section": "Theory",
    "text": "Theory\n\n\n\n (Russell and Norvig 2020, 114)\n\n\nIf the schedule lowers \\(T\\) to 0 slowly enough, then a property of the Boltzmann (aka Gibbs) distribution, \\(e^{\\frac{\\Delta E}{T}}\\), is that all the probability is concentrated on the global maxima, which the algorithm will find with probability approaching 1."
  },
  {
    "objectID": "lectures/17/slides.html#definition-2",
    "href": "lectures/17/slides.html#definition-2",
    "title": "Local Search",
    "section": "Definition",
    "text": "Definition\nThe Travelling Salesman Problem (TSP) is a classic optimization problem that seeks the shortest possible route for a salesman to visit a set of cities, returning to the origin city, while visiting each city exactly once.\n\nThe challenge lies in determining the most efficient path, especially as the number of cities increases, due to the combinatorial explosion of possible routes."
  },
  {
    "objectID": "lectures/17/slides.html#how-to-represent-a-solution",
    "href": "lectures/17/slides.html#how-to-represent-a-solution",
    "title": "Local Search",
    "section": "How to Represent a Solution?",
    "text": "How to Represent a Solution?\n\nWe will use a list where each element represents the index of a city, and the order of elements indicates the sequence of city visits."
  },
  {
    "objectID": "lectures/17/slides.html#calculate-the-total-distance",
    "href": "lectures/17/slides.html#calculate-the-total-distance",
    "title": "Local Search",
    "section": "Calculate the Total Distance",
    "text": "Calculate the Total Distance\n\n# Function to calculate the total distance of a given route\n\ndef calculate_total_distance(route, distance_matrix):\n\n    total_distance = 0\n\n    for i in range(len(route) - 1):\n        total_distance += distance_matrix[route[i], route[i + 1]]\n\n    total_distance += distance_matrix[route[-1], route[0]]  # Back to start\n\n    return total_distance"
  },
  {
    "objectID": "lectures/17/slides.html#generating-a-neighboring-solution",
    "href": "lectures/17/slides.html#generating-a-neighboring-solution",
    "title": "Local Search",
    "section": "Generating a Neighboring Solution",
    "text": "Generating a Neighboring Solution\nHow to generate a neighboring solution?"
  },
  {
    "objectID": "lectures/17/slides.html#swap-two-cities",
    "href": "lectures/17/slides.html#swap-two-cities",
    "title": "Local Search",
    "section": "Swap Two Cities",
    "text": "Swap Two Cities\n\nDescription: Select two cities at random and swap their positions.\nPros: Simple and effective for exploring nearby solutions.\nCons: Change may be too small, potentially slowing down convergence."
  },
  {
    "objectID": "lectures/17/slides.html#reverse-segment",
    "href": "lectures/17/slides.html#reverse-segment",
    "title": "Local Search",
    "section": "Reverse Segment",
    "text": "Reverse Segment\n\nDescription: Select two indices and reverse the segment between them.\nPros: More effective at finding shorter paths compared to simple swaps.\nCons: Can still be computationally expensive as the number of cities increases."
  },
  {
    "objectID": "lectures/17/slides.html#remove-reconnect",
    "href": "lectures/17/slides.html#remove-reconnect",
    "title": "Local Search",
    "section": "Remove & Reconnect",
    "text": "Remove & Reconnect\n\nDescription: Removes three edges from the route and reconnects the segments in the best possible way. This can generate up to 7 different routes.\nPros: Provides more extensive changes and can escape local optima more effectively than 2-opt.\nCons: More complex and computationally expensive to implement."
  },
  {
    "objectID": "lectures/17/slides.html#insertion-move",
    "href": "lectures/17/slides.html#insertion-move",
    "title": "Local Search",
    "section": "Insertion Move",
    "text": "Insertion Move\n\nDescription: Select a city and move it to a different position in the route.\nPros: Offers a balance between small and large changes, making it useful for fine-tuning solutions.\nCons: May require more iterations to converge to an optimal solution."
  },
  {
    "objectID": "lectures/17/slides.html#shuffle-subset",
    "href": "lectures/17/slides.html#shuffle-subset",
    "title": "Local Search",
    "section": "Shuffle Subset",
    "text": "Shuffle Subset\n\nDescription: Select a subset of cities in the route and randomly shuffle their order.\nPros: Introduces larger changes and can help escape local minima.\nCons: Can lead to less efficient routes if not handled carefully."
  },
  {
    "objectID": "lectures/17/slides.html#generating-a-neighboring-solution-1",
    "href": "lectures/17/slides.html#generating-a-neighboring-solution-1",
    "title": "Local Search",
    "section": "Generating a Neighboring Solution",
    "text": "Generating a Neighboring Solution\n\n# Function to generate a random neighboring solution\n\ndef get_neighbor(route):\n\n    a, b = np.random.randint(0, len(route), size=2)\n\n    if a &gt; b:\n        a, b = b, a\n\n    new_route = route.copy()\n    new_route[a:b+1] = new_route[a:b+1][::-1]  # Reverse the segment between a and b\n    \n    return new_route"
  },
  {
    "objectID": "lectures/17/slides.html#simulated_annealing",
    "href": "lectures/17/slides.html#simulated_annealing",
    "title": "Local Search",
    "section": "simulated_annealing",
    "text": "simulated_annealing\n\ndef simulated_annealing(distance_matrix, initial_temp, cooling_rate, max_iterations):\n\n    num_cities = len(distance_matrix)\n    current_route = np.arange(num_cities)\n    np.random.shuffle(current_route)\n    current_cost = calculate_total_distance(current_route, distance_matrix)\n    \n    best_route = current_route.copy()\n    best_cost = current_cost\n\n    temperature = initial_temp\n\n    for iteration in range(max_iterations):\n\n        neighbor_route = get_neighbor(current_route)\n        neighbor_cost = calculate_total_distance(neighbor_route, distance_matrix)\n        \n        # Accept the neighbor if it is better, or with a probability if it is worse.\n\n        delta_E = neighbor_cost - current_cost\n\n        if neighbor_cost &lt; current_cost or np.random.rand() &lt; np.exp(-(delta_E)/temperature):\n            current_route = neighbor_route\n            current_cost = neighbor_cost\n\n            if current_cost &lt; best_cost:\n                best_route = current_route.copy()\n                best_cost = current_cost\n\n        # Cool down the temperature\n        temperature *= cooling_rate\n\n    return best_route, best_cost, temperatures, costs"
  },
  {
    "objectID": "lectures/17/slides.html#remarks",
    "href": "lectures/17/slides.html#remarks",
    "title": "Local Search",
    "section": "Remarks",
    "text": "Remarks\n\nAs \\(t \\to \\infty\\), the algorithm exhibits behavior characteristic of a random walk. During this phase, any neighboring state, regardless of whether it improves the objective function, is accepted. This facilitates exploration and occurs at the start of the algorithm’s execution."
  },
  {
    "objectID": "lectures/17/slides.html#remarks-1",
    "href": "lectures/17/slides.html#remarks-1",
    "title": "Local Search",
    "section": "Remarks",
    "text": "Remarks\n\nConversely, as \\(t \\to 0\\), the algorithm behaves like hill climbing. In this phase, only those states that enhance the objective function’s value are accepted, ensuring that the algorithm consistently moves towards optimal solutions—specifically, towards lower values in minimization problems. This phase emphasizes the exploitation of promising solutions and occurs towards the algorithm’s conclusion.\n\n\n\n\nExploration:\n\nExploration involves searching through a broad area of the search space to discover new possibilities, solutions, or information. The goal of exploration is to gather a diverse set of data points or solutions that could potentially lead to finding better global optima. It prevents the search process from getting trapped in local optima by encouraging the consideration of less-visited or unexplored regions of the search space.\nIn algorithms, exploration can be implemented by introducing randomness, trying new or less-promising paths, or using strategies like simulated annealing or genetic algorithms that encourage diversity.\n\nExploitation:\n\nExploitation focuses on leveraging known information to refine and improve existing solutions. It involves concentrating the search effort around areas believed to contain high-quality solutions based on prior knowledge or experience. The goal is to optimize and fine-tune these solutions to achieve the best possible outcome in those regions.\nIn algorithms, exploitation can be seen in strategies like hill climbing, gradient ascent/descent, or greedy algorithms, where the search is focused on local improvement and making incremental gains.\n\n\n\n\nSee also: Properties of Simulated Annealing - Georgia Tech - Machine Learning. Udacity video (4m 10s). Posted on 2015-02-23."
  },
  {
    "objectID": "lectures/17/slides.html#example",
    "href": "lectures/17/slides.html#example",
    "title": "Local Search",
    "section": "Example",
    "text": "Example\n\n# Ensuring reproducibility\n\nnp.random.seed(42)\n\n# Generate random coordinates for cities\n\nnum_cities = 20\ncoordinates = np.random.rand(num_cities, 2) * 100\n\n# Calculate distance matrix\n\ndistance_matrix = np.sqrt(((coordinates[:, np.newaxis] - coordinates[np.newaxis, :]) ** 2).sum(axis=2))\n\n# Run simulated annealing\n\ninitial_temp = 15\ncooling_rate = 0.995\nmax_iterations = 1000"
  },
  {
    "objectID": "lectures/17/slides.html#heldkarp-algorithm",
    "href": "lectures/17/slides.html#heldkarp-algorithm",
    "title": "Local Search",
    "section": "Held–Karp Algorithm",
    "text": "Held–Karp Algorithm\n\nIntroduced: 1962 by Held, Karp, and independently by Bellman.\nProblem: Solves the Traveling Salesman Problem (TSP) using dynamic programming.\nTime Complexity: \\(\\Theta(2^n n^2)\\).\nSpace Complexity: \\(\\Theta(2^n n)\\).\nEfficiency: Better than brute-force \\(\\Theta(n!)\\), yet still exponential.\n\n\n\nUsing Held–Karp to find the minimum cost of TSP tour: 386.43\n\n\n\n\nHeld and Karp (1962) and Bellman (1962)"
  },
  {
    "objectID": "lectures/17/slides.html#execution",
    "href": "lectures/17/slides.html#execution",
    "title": "Local Search",
    "section": "Execution",
    "text": "Execution\n\n\n\n\n\n\n\n\n\n\nWhen I initially published these slides, the selected initial temperature of 1000 was excessively high relative to the objective function’s cost. By adjusting the initial temperature to 15, we achieve a more effective balance between exploration and exploitation.\nDue to the snapshots being captured every 100 iterations, the increases in cost are not visible. This is illustrated on the “Temperature and Cost” slide."
  },
  {
    "objectID": "lectures/17/slides.html#best-route",
    "href": "lectures/17/slides.html#best-route",
    "title": "Local Search",
    "section": "Best Route",
    "text": "Best Route\n\n\n\n\n\n\n\n\n\n\n\nWe have found an optimal tour!"
  },
  {
    "objectID": "lectures/17/slides.html#temperature-and-cost",
    "href": "lectures/17/slides.html#temperature-and-cost",
    "title": "Local Search",
    "section": "Temperature and Cost",
    "text": "Temperature and Cost"
  },
  {
    "objectID": "lectures/17/slides.html#swapping-neighbors",
    "href": "lectures/17/slides.html#swapping-neighbors",
    "title": "Local Search",
    "section": "Swapping Neighbors",
    "text": "Swapping Neighbors\n\nDescription: Select two cities at random, swap their positions.\nPros: Simple and effective for exploring nearby solutions.\nCons: Change may be too small, potentially slowing down convergence.\n\n\ndef get_neighbor_swap(route):\n    a, b = np.random.randint(0, len(route), size=2)\n    new_route = route.copy()\n    new_route[a], new_route[b] = new_route[b], new_route[a]\n    return new_route"
  },
  {
    "objectID": "lectures/17/slides.html#execution-1",
    "href": "lectures/17/slides.html#execution-1",
    "title": "Local Search",
    "section": "Execution",
    "text": "Execution"
  },
  {
    "objectID": "lectures/17/slides.html#best-route-1",
    "href": "lectures/17/slides.html#best-route-1",
    "title": "Local Search",
    "section": "Best Route",
    "text": "Best Route\n\n\n\n\n\n\n\n\n\n\n\nIn this specific instance and for the given problem, reverse segment (cost = 386.43) was more effective compared to swapping neighbors (cost = 430.03)."
  },
  {
    "objectID": "lectures/17/slides.html#temperature-and-cost-1",
    "href": "lectures/17/slides.html#temperature-and-cost-1",
    "title": "Local Search",
    "section": "Temperature and Cost",
    "text": "Temperature and Cost"
  },
  {
    "objectID": "lectures/17/slides.html#selecting-a-neighborhood-strategy",
    "href": "lectures/17/slides.html#selecting-a-neighborhood-strategy",
    "title": "Local Search",
    "section": "Selecting a Neighborhood Strategy",
    "text": "Selecting a Neighborhood Strategy\n\nSimple Moves (Swap, Insertion): Effective for initial exploration; risk of local optima entrapment.\nComplex Moves: Enhance capability to escape local optima and accelerate convergence; entail higher computational expense.\nHybrid Approaches: Integrate diverse strategies for neighborhood generation. Employ simple moves initially, transitioning to complex ones as convergence progresses."
  },
  {
    "objectID": "lectures/17/slides.html#initial-temperature",
    "href": "lectures/17/slides.html#initial-temperature",
    "title": "Local Search",
    "section": "Initial Temperature",
    "text": "Initial Temperature\nInfluence: Since the probability of accepting a new state is given by \\(e^{-\\frac{\\Delta E}{T}}\\), the selection of the initial temperature is directly influenced by \\(\\Delta E\\) and consequently by the objective function value for a random state, \\(f(s)\\)."
  },
  {
    "objectID": "lectures/17/slides.html#initial-temperature-1",
    "href": "lectures/17/slides.html#initial-temperature-1",
    "title": "Local Search",
    "section": "Initial Temperature",
    "text": "Initial Temperature\n\nExample Problems: Consider two scenarios: problem \\(a\\) with \\(f(a) = 1,000\\) and problem \\(b\\) with \\(f(b) = 100\\).\nEnergy Difference: Accepting a state that is 10% worse results in energy differences \\(\\Delta E = 0.1 \\cdot f(a) = 100\\) for problem \\(a\\) and \\(\\Delta E = 0.1 \\cdot f(b) = 10\\) for problem \\(b\\).\nAcceptance Probability: To accept such state 60% of the time, set \\(e^{-\\frac{\\Delta E}{T}} = 0.6\\). Solving for \\(T\\) yields initial temperatures of approximately \\(T \\approx 195.8\\) for problem \\(a\\) and \\(T \\approx 19.58\\) for problem \\(b\\)."
  },
  {
    "objectID": "lectures/17/slides.html#initial-temperature-2",
    "href": "lectures/17/slides.html#initial-temperature-2",
    "title": "Local Search",
    "section": "Initial Temperature",
    "text": "Initial Temperature\nA popular approach is to set the initial temperature so that a significant portion of moves (often around 60-80%) are accepted.\nThis can be done by running a preliminary phase where the temperature is adjusted until the acceptance ratio stabilizes within this range.\n\n\nBen-Ameur (2004) suggests a more rigorous mathematical methodology."
  },
  {
    "objectID": "lectures/17/slides.html#cooling-strategies",
    "href": "lectures/17/slides.html#cooling-strategies",
    "title": "Local Search",
    "section": "Cooling Strategies",
    "text": "Cooling Strategies\nIn simulated annealing, cooling down is essential for managing algorithm convergence. The cooling schedule dictates the rate at which the temperature decreases, affecting the algorithm’s capacity to escape local optima and converge towards a near-optimal solution.\n\n\nNourani and Andresen (1998) and Alex, Simon, and Samuel (2017)"
  },
  {
    "objectID": "lectures/17/slides.html#linear-cooling",
    "href": "lectures/17/slides.html#linear-cooling",
    "title": "Local Search",
    "section": "Linear Cooling",
    "text": "Linear Cooling\n\nDescription: The temperature decreases linearly with each iteration.\nFormula: \\(T = T_0 - \\alpha \\cdot k\\)\n\n\\(T_0\\): Initial temperature\n\\(\\alpha\\): A constant decrement\n\\(k\\): Current iteration\n\nPros: Simple to implement and understand.\nCons: Often leads to premature convergence because the temperature decreases too quickly.\n\n\ntemperature = initial_temp - alpha * iteration"
  },
  {
    "objectID": "lectures/17/slides.html#geometric-exponential-cooling",
    "href": "lectures/17/slides.html#geometric-exponential-cooling",
    "title": "Local Search",
    "section": "Geometric (Exponential) Cooling",
    "text": "Geometric (Exponential) Cooling\n\nDescription: The temperature decreases exponentially with each iteration.\nFormula: \\(T = T_0 \\cdot \\alpha^k\\)\n\n\\(\\alpha\\): Cooling rate, typically between 0.8 and 0.99\n\\(k\\): Current iteration\n\nPros: Widely used due to its simplicity and effectiveness.\nCons: The choice of \\(\\alpha\\) is critical; if it’s too small, the temperature drops too fast, and if it’s too large, convergence can be slow.\n\n\ntemperature = initial_temp * (cooling_rate ** iteration)"
  },
  {
    "objectID": "lectures/17/slides.html#logarithmic-cooling",
    "href": "lectures/17/slides.html#logarithmic-cooling",
    "title": "Local Search",
    "section": "Logarithmic Cooling",
    "text": "Logarithmic Cooling\n\nDescription: The temperature decreases slowly following a logarithmic function.\nFormula: \\(T = \\frac{\\alpha \\cdot T_0}{\\log(1+k)}\\)\n\n\\(\\alpha\\): A scaling constant\n\\(k\\): Current iteration\n\nPros: Provides a slower cooling rate, which is useful for problems that require extensive exploration of the solution space.\nCons: Convergence can be very slow, requiring many iterations.\n\n\ntemperature = alpha * initial_temp / (np.log(1 + iteration))"
  },
  {
    "objectID": "lectures/17/slides.html#inverse-cooling",
    "href": "lectures/17/slides.html#inverse-cooling",
    "title": "Local Search",
    "section": "Inverse Cooling",
    "text": "Inverse Cooling\n\nDescription: The temperature decreases as an inverse function of the iteration number.\nFormula: \\(T = \\frac{T_0}{1+\\alpha \\cdot K}\\)\n\n\\(\\alpha\\): A scaling constant\n\\(k\\): Current iteration\n\nPros: Allows for a more controlled cooling process, balancing exploration and exploitation.\nCons: May require careful tuning of \\(\\alpha\\) to be effective.\n\n\ntemperature = initial_temp / (1 + alpha * iteration)"
  },
  {
    "objectID": "lectures/17/slides.html#adaptive-cooling",
    "href": "lectures/17/slides.html#adaptive-cooling",
    "title": "Local Search",
    "section": "Adaptive Cooling",
    "text": "Adaptive Cooling\n\nDescription: The cooling schedule is adjusted dynamically based on the performance of the algorithm.\nStrategy: If the algorithm is not making significant progress, the cooling rate may be slowed down. Conversely, if progress is steady, the cooling rate can be increased.\nPros: More flexible and can adapt to the characteristics of the problem.\nCons: More complex to implement and requires careful design to avoid instability.\n\n\nif no_significant_change_in_cost:\n    temperature *= 0.99  # Slow down cooling\nelse:\n    temperature *= 0.95  # Speed up cooling"
  },
  {
    "objectID": "lectures/17/slides.html#cooling-schedule---summary",
    "href": "lectures/17/slides.html#cooling-schedule---summary",
    "title": "Local Search",
    "section": "Cooling Schedule - Summary",
    "text": "Cooling Schedule - Summary\n\n\n\n\n\n\n\n\n\n\n\nSee also: Effective Simulated Annealing with Python by Nathan A. Rooy."
  },
  {
    "objectID": "lectures/17/slides.html#choosing-the-right-cooling-schedule",
    "href": "lectures/17/slides.html#choosing-the-right-cooling-schedule",
    "title": "Local Search",
    "section": "Choosing the Right Cooling Schedule",
    "text": "Choosing the Right Cooling Schedule\n\nProblem-Specific: The choice of cooling schedule often depends on the characteristics of the problem being solved. Some problems benefit from a slower cooling rate, while others may need faster convergence.\nExperimentation: It’s common to experiment with different strategies and parameters to find the best balance between exploration (searching broadly) and exploitation (refining the current best solutions)."
  },
  {
    "objectID": "lectures/17/slides.html#conclusion",
    "href": "lectures/17/slides.html#conclusion",
    "title": "Local Search",
    "section": "Conclusion",
    "text": "Conclusion\nAfter applying simulated annealing, a local search method such as hill climbing can be used to refine the solution.\n\nSimulated annealing is effective for exploring the solution space and avoiding local minima, while local search focuses on the exploration of neighboring solutions."
  },
  {
    "objectID": "lectures/17/slides.html#simulated-annealing-visualization",
    "href": "lectures/17/slides.html#simulated-annealing-visualization",
    "title": "Local Search",
    "section": "Simulated Annealing Visualization",
    "text": "Simulated Annealing Visualization\n\n\n\nAttribution: ComputationalScientist, Posted on 2018-01-06."
  },
  {
    "objectID": "lectures/17/slides.html#summary",
    "href": "lectures/17/slides.html#summary",
    "title": "Local Search",
    "section": "Summary",
    "text": "Summary\n\nLocal search algorithms focus on finding goal states by moving between neighboring states without tracking paths.\nThe hill-climbing algorithm seeks the highest-valued neighbor but can get stuck in local maxima or plateaus.\nEffective state representation, such as using permutations in the 8-Queens problem, avoids illegal placements and improves performance.\nSimulated annealing allows occasional uphill moves to escape local optima, controlled by a decreasing temperature parameter.\nThe acceptance probability in simulated annealing decreases as temperature lowers and energy difference increases.\nSimulated annealing effectively solves complex problems like the Travelling Salesman Problem by probabilistically exploring the solution space."
  },
  {
    "objectID": "lectures/17/slides.html#further-readings",
    "href": "lectures/17/slides.html#further-readings",
    "title": "Local Search",
    "section": "Further Readings",
    "text": "Further Readings\n\n\n\n\n\n\n\n\n“The overall SA [simulated annealing] methodology is then deployed in detail on a real-life application: a large-scale aircraft trajectory planning problem involving nearly 30,000 flights at the European continental scale.”\n(Gendreau and Potvin 2019, chap. 1)\n\n\n\nDid you know that you can freely access the entire collection of books from Springer? By using a device connected to a uOttawa IP address and visiting Springer Link, you have the ability to download books in either PDF or EPUB format.\nThe book is co-edited by Jean-Yves Potvin and Michel Gendreau. Jean-Yves Potvin serves as a professor at the Université de Montréal, while Michel Gendreau holds a professorship at École Polytechnique de Montréal.\n\n\nGendreau and Potvin (2019), access via Springer Link."
  },
  {
    "objectID": "lectures/17/slides.html#next-lecture",
    "href": "lectures/17/slides.html#next-lecture",
    "title": "Local Search",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will discuss population-based algorithms."
  },
  {
    "objectID": "lectures/17/slides.html#references",
    "href": "lectures/17/slides.html#references",
    "title": "Local Search",
    "section": "References",
    "text": "References\n\n\nAlex, Kwaku Peprah, Kojo Appiah Simon, and Kwame Amponsah Samuel. 2017. “An Optimal Cooling Schedule Using a Simulated Annealing Based Approach.” Applied Mathematics 08 (08): 1195–1210. https://doi.org/10.4236/am.2017.88090.\n\n\nBellman, Richard. 1962. “Dynamic Programming Treatment of the Travelling Salesman Problem.” Journal of the ACM (JACM) 9 (1): 61–63. https://doi.org/10.1145/321105.321111.\n\n\nBen-Ameur, Walid. 2004. “Computing the Initial Temperature of Simulated Annealing.” Computational Optimization and Applications 29 (3): 369–85. https://doi.org/10.1023/b:coap.0000044187.23143.bd.\n\n\nGendreau, M., and J. Y. Potvin. 2019. Handbook of Metaheuristics. International Series in Operations Research & Management Science. Springer International Publishing. https://books.google.com.ag/books?id=RbfFwQEACAAJ.\n\n\nHeld, Michael, and Richard M. Karp. 1962. “A Dynamic Programming Approach to Sequencing Problems.” Journal of the Society for Industrial and Applied Mathematics 10 (1): 196–210. https://doi.org/10.1137/0110015.\n\n\nNourani, Yaghout, and Bjarne Andresen. 1998. “A Comparison of Simulated Annealing Cooling Strategies.” Journal of Physics A: Mathematical and General 31 (41): 8373.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/17/index.html",
    "href": "lectures/17/index.html",
    "title": "Local Search",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Assignment 3 must be submitted no later than November 10, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/17/index.html#prepare",
    "href": "lectures/17/index.html#prepare",
    "title": "Local Search",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 110-115"
  },
  {
    "objectID": "lectures/17/index.html#participate",
    "href": "lectures/17/index.html#participate",
    "title": "Local Search",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/18/slides.html#quote-of-the-day",
    "href": "lectures/18/slides.html#quote-of-the-day",
    "title": "Population-Based Metaheuristics",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\nLeland McInnes is a data science researcher at the Tutte Institute for Mathematics and Computing (TIMC) in Ottawa. TIMC is a government research institute dedicated to fundamental mathematics and computer science. McInnes is renowned for developing UMAP, a leading dimensionality reduction technique, and HDBSCAN, a popular clustering algorithm integrated into scikit-learn.\nThis post highlights the application of these technologies in visualizing publications from arXiv."
  },
  {
    "objectID": "lectures/18/slides.html#learning-objectives",
    "href": "lectures/18/slides.html#learning-objectives",
    "title": "Population-Based Metaheuristics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the definition and purpose of metaheuristics in optimization problems.\nLearn the principles and components of genetic algorithms (GAs).\nComprehend the implementation details of GAs, including encoding, selection, crossover, mutation, and fitness evaluation.\nApply GAs to solve the 0/1 knapsack problem with practical Python examples.\nRecognize different encoding schemes and selection methods in GAs.\n\n\n\nSee also: companion Jupyter Notebook."
  },
  {
    "objectID": "lectures/18/slides.html#metaheuristics",
    "href": "lectures/18/slides.html#metaheuristics",
    "title": "Population-Based Metaheuristics",
    "section": "Metaheuristics",
    "text": "Metaheuristics\n\n\n\n\n\n\n\nSimulated annealing draws inspiration from principles in physics. In contrast, we now explore a biologically inspired strategy."
  },
  {
    "objectID": "lectures/18/slides.html#definition",
    "href": "lectures/18/slides.html#definition",
    "title": "Population-Based Metaheuristics",
    "section": "Definition",
    "text": "Definition\n\n\n\n (Gil-Rios et al. 2021)\n\n\nMetaheuristics are higher-level procedures or heuristics designed to guide the search for solutions in optimization problems with large solution spaces, aiming to find good solutions more efficiently than traditional methods.\n\n\n\nMeta heuristics balance exploitation and exploration to avoid local optima, often incorporating randomness, memory, or adaptive mechanisms.\n\n\nThey are adaptable to diverse optimization problems."
  },
  {
    "objectID": "lectures/18/slides.html#definition-1",
    "href": "lectures/18/slides.html#definition-1",
    "title": "Population-Based Metaheuristics",
    "section": "Definition",
    "text": "Definition\nA genetic algorithm is an evolutionary optimization technique that uses a population of candidate solutions, evolving them through selection, crossover, and mutation to iteratively improve towards an “optimal” solution."
  },
  {
    "objectID": "lectures/18/slides.html#trends-in-ai",
    "href": "lectures/18/slides.html#trends-in-ai",
    "title": "Population-Based Metaheuristics",
    "section": "Trends in AI",
    "text": "Trends in AI"
  },
  {
    "objectID": "lectures/18/slides.html#applications",
    "href": "lectures/18/slides.html#applications",
    "title": "Population-Based Metaheuristics",
    "section": "Applications",
    "text": "Applications\n\nOptimization: Solving complex engineering, logistics, and scheduling problems.\nMachine Learning: Feature selection, hyperparameter tuning, and evolving neural network architectures.\nRobotics: Path planning, sensor optimization, control strategy development, and robot designs1.\n\nThis approach has led to the development of unique, sometimes unexpected robot forms and control strategies that are well-suited to specific tasks or environments, often outperforming traditional, human-engineered designs in adaptability and robustness."
  },
  {
    "objectID": "lectures/18/slides.html#applications-continued",
    "href": "lectures/18/slides.html#applications-continued",
    "title": "Population-Based Metaheuristics",
    "section": "Applications (continued)",
    "text": "Applications (continued)\n\n\n\n\n\n\n\nOliva, Houssein, and Hinojosa (2021)\nSpringer Link\n\n\n\n\n\n\nEddaly, Jarboui, and Siarry (2023)\nSpringer Link\n\n\nDid you know that you can freely access the entire collection of books from Springer? By using a device connected to a uOttawa IP address and visiting Springer Link, you have the ability to download books in either PDF or EPUB format."
  },
  {
    "objectID": "lectures/18/slides.html#from-biology-to-genetic-algorithms",
    "href": "lectures/18/slides.html#from-biology-to-genetic-algorithms",
    "title": "Population-Based Metaheuristics",
    "section": "From Biology to Genetic Algorithms",
    "text": "From Biology to Genetic Algorithms\n\n\n\n (Mayr 1982, 481)\n\n\nThere is probably no more original, more complex, and bolder concept in the history of ideas than Darwin’s mechanistic explanation of adaptation.\n\n\n\n\n\n\n (Dennett 1995)\n\n\nIf I were to give an award for the single best idea anyone has ever had, I’d give it to Darwin, ahead of Newton & Einstein and everyone else."
  },
  {
    "objectID": "lectures/18/slides.html#definition-2",
    "href": "lectures/18/slides.html#definition-2",
    "title": "Population-Based Metaheuristics",
    "section": "Definition",
    "text": "Definition\n\n\n\n (Gregory 2009)\n\n\nNatural selection is a non-random difference in reproductive output among replicating entities, often due indirectly to differences in survival in a particular environment, leading to an increase in the proportion of beneficial, heritable characteristics within a population from one generation to the next.\n\n\n\n\n\nEvolution is an adaptive optimization process."
  },
  {
    "objectID": "lectures/18/slides.html#basic-ga",
    "href": "lectures/18/slides.html#basic-ga",
    "title": "Population-Based Metaheuristics",
    "section": "Basic GA",
    "text": "Basic GA\n\n\n\n\n\n\n\n\n\nInitialize population\nCompute the fitness\nSelect individuals (chromosomes)\nCrossover\nMutation\nIf not done, goto 2\n\n\n\n\nIn this context, the term population refers to a collection of candidate solutions or states."
  },
  {
    "objectID": "lectures/18/slides.html#choices",
    "href": "lectures/18/slides.html#choices",
    "title": "Population-Based Metaheuristics",
    "section": "Choices",
    "text": "Choices\n\nHow to encode a candidate solution or state?\nHow to select candidate solutions?\nHow to define the crossover operator?\nHow to define the mutation operator?\nHow to calculate the fitness?"
  },
  {
    "objectID": "lectures/18/slides.html#problem",
    "href": "lectures/18/slides.html#problem",
    "title": "Population-Based Metaheuristics",
    "section": "Problem",
    "text": "Problem\n\n\n0/1 knapsack problem: Given items with defined weights and values, the objective is to maximize total value by selecting items for a knapsack without surpassing a fixed capacity. Each item must be either fully included (1) or excluded (0).\n\n\n\n\n\nThis problem is NP-complete and often solved using dynamic programming for optimal solutions in feasible time.\nThe image displayed above was generated based on the following prompt: “Illustrate a cartoon girl scout wearing glasses, dressed in a scout uniform featuring brown shorts and hiking boots. She holds a ledger in one hand and a pencil in the other, with a large backpack secured to her back. In front of her, display a variety of items she might choose to pack into her backpack. These items should include a stack of books, a stuffed toy, a cup, assorted snacks, and a pair of binoculars. The scene should evoke a sense of decision-making and exploration.”\n\n\nAttribution: Generated by DALL-E, via ChatGPT (GPT-4), OpenAI, November 10, 2024."
  },
  {
    "objectID": "lectures/18/slides.html#problem-continued",
    "href": "lectures/18/slides.html#problem-continued",
    "title": "Population-Based Metaheuristics",
    "section": "Problem (continued)",
    "text": "Problem (continued)\n\\[\n\\begin{aligned}\n& \\text { maximize } \\sum_{i=1}^n x_i \\cdot v_i  \\\\\n& \\text { subject to } \\sum_{i=1}^n x_i \\cdot w_i  \\leq W \\text { and } x_i \\in\\{0,1\\} .\n\\end{aligned}\n\\]\nwhere \\(W\\) represents the fixed maximum weight, and \\(x_i\\) is a binary variable indicating whether item \\(i\\) is included (1) or excluded (0)."
  },
  {
    "objectID": "lectures/18/slides.html#applications-1",
    "href": "lectures/18/slides.html#applications-1",
    "title": "Population-Based Metaheuristics",
    "section": "Applications",
    "text": "Applications\n\nFinance and Investment: In portfolio optimization, where each asset has a risk (analogous to weight) and expected return (value), the knapsack framework helps select a set of assets that maximizes return without exceeding a risk threshold.\nResource Allocation: Common in project management, where resources (budget, personnel, time) need to be allocated across projects or tasks to maximize overall value, taking into account limited availability.\nSupply Chain and Logistics: Used to maximize the value of goods transported within vehicle weight or volume constraints. It can also be applied in warehouse storage, where space is limited, and high-value items are prioritized.\nAd Placement and Marketing: Used in digital advertising to select the most profitable combination of ads to display within limited space (e.g., website or app banner space), maximizing revenue under size or display constraints."
  },
  {
    "objectID": "lectures/18/slides.html#greedy-algorithms",
    "href": "lectures/18/slides.html#greedy-algorithms",
    "title": "Population-Based Metaheuristics",
    "section": "Greedy Algorithms",
    "text": "Greedy Algorithms\n\n\n\n (Skiena 2008, 192)\n\n\nGreedy algorithms make the decision of what to do next by selecting the best local option from all available choices without regard to the global structure."
  },
  {
    "objectID": "lectures/18/slides.html#data",
    "href": "lectures/18/slides.html#data",
    "title": "Population-Based Metaheuristics",
    "section": "Data",
    "text": "Data\n\nimport numpy as np\n\n# Sample data\n\nvalues = np.array([\n    360, 83, 59, 130, 431, 67, 230, 52, 93, 125, 670, 892, 600, 38, 48, 147,\n    78, 256, 63, 17, 120, 164, 432, 35, 92, 110, 22, 42, 50, 323, 514, 28,\n    87, 73, 78, 15, 26, 78, 210, 36, 85, 189, 274, 43, 33, 10, 19, 389, 276,\n    312])\n\nweights = np.array([\n    7, 0, 30, 22, 80, 94, 11, 81, 70, 64, 59, 18, 0, 36, 3, 8, 15, 42, 9, 0,\n    42, 47, 52, 32, 26, 48, 55, 6, 29, 84, 2, 4, 18, 56, 7, 29, 93, 44, 71,\n    3, 86, 66, 31, 65, 0, 79, 20, 65, 52, 13])\n\ncapacity = 850\n\n\n\nData from Google OR-Tools."
  },
  {
    "objectID": "lectures/18/slides.html#ascending-order-of-weight",
    "href": "lectures/18/slides.html#ascending-order-of-weight",
    "title": "Population-Based Metaheuristics",
    "section": "Ascending order of weight",
    "text": "Ascending order of weight\n\ndef greedy_knapsack_weight(weights, values, capacity):\n\n    num_items = len(weights)\n\n    # Create a list of items with their values and original indices\n    items = list(zip(weights, values, range(num_items)))\n\n    # Sort items by weight in increasing order\n    items.sort()\n    \n    total_weight, total_value = 0,0\n    solution = np.zeros(num_items, dtype=int)\n    \n    # Select items based on the sorted order\n    for w, v, idx in items:\n        if total_weight + w &lt;= capacity:\n            solution[idx] = 1\n            total_weight += w\n            total_value += v\n        else:\n            break  # Skip items that would exceed the capacity\n    \n    return solution, total_value, total_weight\n\n\n\n\nWhat is the time complexity of this method?\n\n\\(\\mathcal{O}(n \\log n)\\) due to sorting.\n\nIs this strategy relevant?\n\nIt overlooks value, the critical factor for optimization.\n\n\n\n\nIs this strategy relevant?"
  },
  {
    "objectID": "lectures/18/slides.html#greedy_knapsack_weight",
    "href": "lectures/18/slides.html#greedy_knapsack_weight",
    "title": "Population-Based Metaheuristics",
    "section": "greedy_knapsack_weight",
    "text": "greedy_knapsack_weight\n\nsolution, total_value, total_weight = greedy_knapsack_weight(weights, values, capacity)\n\nprint(f\"Solution: {solution}\")\nprint(f\"Value: {total_value}\")\nprint(f\"Weight: {total_weight}\")\n\nSolution: [1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n 1 0 1 0 0 1 0 1 0 1 0 1 1]\nValue: 5891\nWeight: 817"
  },
  {
    "objectID": "lectures/18/slides.html#descending-value-order",
    "href": "lectures/18/slides.html#descending-value-order",
    "title": "Population-Based Metaheuristics",
    "section": "Descending value order",
    "text": "Descending value order\n\ndef greedy_knapsack_value(weights, values, capacity):\n\n    num_items = len(weights)\n\n    # Create a list of items with their values and original indices\n    items = list(zip(values, weights, range(num_items)))\n\n    # Sort items by value in decreasing order\n    items.sort(reverse=True)\n    \n    total_weight = 0\n    total_value = 0\n    solution = np.zeros(num_items, dtype=int)\n    \n    # Select items based on the sorted order\n    for v, w, idx in items:\n        if total_weight + w &lt;= capacity:\n            solution[idx] = 1\n            total_weight += w\n            total_value += v\n    \n    return solution, total_value, total_weight\n\n\n\nWhat is the time complexity of this method?\n\n\\(\\mathcal{O}(n \\log n)\\) due to sorting.\n\nIs this strategy relevant?\n\nEmphasizes maximizing value but does not guarantee an optimal solution."
  },
  {
    "objectID": "lectures/18/slides.html#greedy_knapsack_value",
    "href": "lectures/18/slides.html#greedy_knapsack_value",
    "title": "Population-Based Metaheuristics",
    "section": "greedy_knapsack_value",
    "text": "greedy_knapsack_value\n\nsolution, total_value, total_weight = greedy_knapsack_value(weights, values, capacity)\n\nprint(f\"Solution: {solution}\")\nprint(f\"Value: {total_value}\")\nprint(f\"Weight: {total_weight}\")\n\nSolution: [1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7339\nWeight: 849"
  },
  {
    "objectID": "lectures/18/slides.html#encoding",
    "href": "lectures/18/slides.html#encoding",
    "title": "Population-Based Metaheuristics",
    "section": "Encoding",
    "text": "Encoding\n\n\n\n\n\n\n\nThe most straightforward representation for each chromosome (state) is an array of size \\(n\\), where \\(n\\) represents the number of items. Each element \\(i\\) in the array indicates whether item \\(i\\) is included (1) or excluded (0)."
  },
  {
    "objectID": "lectures/18/slides.html#population",
    "href": "lectures/18/slides.html#population",
    "title": "Population-Based Metaheuristics",
    "section": "Population",
    "text": "Population\n\ndef initialize_population(pop_size, num_items):\n\n    \"\"\"\n    Initialize the population with random binary strings.\n\n    Args:\n        pop_size (int): Number of individuals in the population.\n        num_items (int): Number of items in the knapsack problem.\n\n    Returns:\n        np.ndarray: Initialized population.\n    \"\"\"\n\n    return np.random.randint(2, size=(pop_size, num_items))\n\n\n\nProblem specificity: Adjust the population size based on the complexity of the problem. More complex problems may require a larger population to effectively explore the solution space.\nAvailable resources: Consider the available computing resources, as a larger population size increases memory and computational time requirements.\nBalance between diversity and convergence: A larger population can maintain higher genetic diversity, which helps avoid local optima, but may also slow convergence. Find a balance suitable for your problem.\nGuidelines: For many problems, an empirical rule is to start with a population size between 50 and 100, then adjust based on observed performance.\nAdaptive approaches: Consider using adaptive methods that dynamically adjust the population size based on the algorithm’s progress.\n\n\nHow to choose the population size (number of individuals/chromosomes)?"
  },
  {
    "objectID": "lectures/18/slides.html#population-1",
    "href": "lectures/18/slides.html#population-1",
    "title": "Population-Based Metaheuristics",
    "section": "Population",
    "text": "Population\nThe proposed method for initializing the population presents a problem.\n\n\nThe initial population is generated entirely at random without considering feasibility.\nThis can result in most individuals being infeasible (exceeding capacity), especially for larger problems, slowing down convergence.\nSuggestion: Introduce a feasibility check during initialization or generate initial solutions that are more likely to be feasible.\n\n\nCan you identify what it is?"
  },
  {
    "objectID": "lectures/18/slides.html#fitness",
    "href": "lectures/18/slides.html#fitness",
    "title": "Population-Based Metaheuristics",
    "section": "Fitness",
    "text": "Fitness\n\ndef evaluate_fitness(population, weights, values, capacity, penalty_factor=10):\n\n    total_weights = np.dot(population, weights)\n\n    total_values = np.dot(population, values)\n\n    penalties = penalty_factor * np.maximum(0, total_weights - capacity)\n\n    fitness = total_values - penalties\n\n    return fitness\n\n\n\nFirst, notice the extensive use of numpy. The total weight for each chromosome of our population is calculated with a single expression. Likewise for total values.\nThe fitness function employs a smoother penalization strategy by deducting a penalty proportional to the excess weight, thereby distinguishing between solutions that exceed the weight limit.\nAlternatively, one could assign a fitness value of zero to any solution that exceeds the knapsack’s capacity. However, this stringent penalization could result in a significant portion, or even all, of the population having zero fitness, particularly in the initial generations. This scenario poses challenges for selection mechanisms, such as roulette wheel selection, which rely on non-zero fitness values to calculate selection probabilities, potentially leading to division by zero errors.\nThe proposed strategy, which applies penalties to overweight solutions, may lead the genetic algorithm to generate infeasible solutions. Such instances require external handling by restarting the genetic algorithm whenever an infeasible solution is encountered.\n\n\nCan you identify a possible issue with this fitness function?"
  },
  {
    "objectID": "lectures/18/slides.html#roulette-wheel-selection",
    "href": "lectures/18/slides.html#roulette-wheel-selection",
    "title": "Population-Based Metaheuristics",
    "section": "Roulette Wheel Selection",
    "text": "Roulette Wheel Selection\n\n\nRoulette wheel selection is a stochastic selection method where the probability of selecting an individual is proportional to its fitness relative to the rest of the population.\n\n\n\n\n\n\n\n\n\nWhat is the fundamental objective of this selection method? Why not simply choose the individuals with the highest fitness?\nThe fundamental objective is to maintain a diverse population.\nAdvantages\n\nFitness Proportionality\n\nSimple Implementation: The method is straightforward to implement, requiring the calculation of cumulative probabilities based on fitness values.\nAll Individuals Have a Chance: Even individuals with lower fitness have a non-zero probability of being selected, maintaining genetic diversity.\n\nSelection Pressure Adjusted by Fitness\n\nDynamic Pressure: Selection pressure naturally adjusts based on the fitness distribution of the population.\nEncourages High-Fitness Individuals: Individuals with higher fitness are more likely to be selected, promoting the propagation of advantageous traits.\n\n\nDisadvantages\n\nSensitivity to Fitness Scaling\n\nNegative Fitness Values: If fitness values are negative or zero (which can happen when penalties are applied), the method becomes problematic as probabilities cannot be negative or zero.\nScaling Issues: When fitness values are very close together or have a small range, the selection probabilities become nearly uniform, reducing selection pressure.\n\nPremature Convergence Risk\n\nDominance of High-Fitness Individuals: If a few individuals have significantly higher fitness, they may dominate the selection process, leading to reduced diversity and premature convergence to suboptimal solutions.\n\nComputational Overhead\n\nNormalization Required: Fitness values need to be normalized to probabilities, which adds computational steps, especially if adjustments are needed for negative fitness values.\n\n\n\n\nAttribution: Santos Amorim et al. (2012)"
  },
  {
    "objectID": "lectures/18/slides.html#roulette_selection",
    "href": "lectures/18/slides.html#roulette_selection",
    "title": "Population-Based Metaheuristics",
    "section": "roulette_selection",
    "text": "roulette_selection\n\ndef roulette_selection(population, fitness):\n\n    # Adjust fitness to be non-negative\n    min_fitness = np.min(fitness)\n    adjusted_fitness = fitness - min_fitness + 1e-6  # small epsilon to avoid zero division\n\n    total_fitness = np.sum(adjusted_fitness)\n    probabilities = adjusted_fitness / total_fitness\n\n    pop_size = population.shape[0]\n    selected_indices = np.random.choice(pop_size, size=pop_size, p=probabilities)\n\n    return population[selected_indices]\n\n\n\nA small value is added to the adjusted fitness values to avoid dividing by 0.\nReturns a population of the same size. The fittest individuals should now be more represented.\n\n\nIn your own words, what does roulette_selection do?"
  },
  {
    "objectID": "lectures/18/slides.html#crossover",
    "href": "lectures/18/slides.html#crossover",
    "title": "Population-Based Metaheuristics",
    "section": "Crossover",
    "text": "Crossover\n\n\n\n\n\n\n\nIn the single crossover method, a crossover point is randomly selected. The resulting child 1 is formed by combining the prefix of parent 1 with the suffix of parent 2, while child 2 is created by joining the suffix of parent 1 with the prefix of parent 2."
  },
  {
    "objectID": "lectures/18/slides.html#crossover-1",
    "href": "lectures/18/slides.html#crossover-1",
    "title": "Population-Based Metaheuristics",
    "section": "Crossover",
    "text": "Crossover\n\n\n\nParents\n\n\nOffspring\n\n\n\nTwo parent individuals produce two offspring."
  },
  {
    "objectID": "lectures/18/slides.html#crossover-2",
    "href": "lectures/18/slides.html#crossover-2",
    "title": "Population-Based Metaheuristics",
    "section": "Crossover",
    "text": "Crossover\n\ndef single_point_crossover(parents, crossover_rate):\n\n    num_parents, num_genes = parents.shape\n    np.random.shuffle(parents)\n    offspring = []\n\n    for i in range(0, num_parents, 2):\n\n        parent1 = parents[i]\n        parent2 = parents[i+1 if i+1 &lt; num_parents else 0]\n\n        child1 = parent1.copy()\n        child2 = parent2.copy()\n\n        if np.random.rand() &lt; crossover_rate:\n            point = np.random.randint(1, num_genes)  # Crossover point\n            child1[:point], child2[:point] = parent2[:point], parent1[:point]\n\n        offspring.append(child1)\n        offspring.append(child2)\n\n    return np.array(offspring)\n\n\n\nControlled by a user-specified parameter, crossover_rate, typical value 0.8."
  },
  {
    "objectID": "lectures/18/slides.html#mutation",
    "href": "lectures/18/slides.html#mutation",
    "title": "Population-Based Metaheuristics",
    "section": "Mutation",
    "text": "Mutation\n\n\n\n\n\n\n\nIn this basic scenario, a mutation involves “flipping” a bit."
  },
  {
    "objectID": "lectures/18/slides.html#mutate",
    "href": "lectures/18/slides.html#mutate",
    "title": "Population-Based Metaheuristics",
    "section": "Mutate",
    "text": "Mutate\n\ndef mutation(offspring, mutation_rate):\n\n    num_offspring, num_genes = offspring.shape\n\n    mutation_matrix = np.random.rand(num_offspring, num_genes) &lt; mutation_rate\n\n    offspring[mutation_matrix] = 1 - offspring[mutation_matrix]\n\n    return offspring\n\n\n\nA user-defined mutation rate determines whether a position undergoes “mutation.”"
  },
  {
    "objectID": "lectures/18/slides.html#clarification",
    "href": "lectures/18/slides.html#clarification",
    "title": "Population-Based Metaheuristics",
    "section": "Clarification",
    "text": "Clarification\n\nnp.random.seed(42)\n\noffspring = initialize_population(4, 10)\n\nnum_offspring, num_genes = offspring.shape\n\nprint(\"Offspring:\")\nprint(offspring)\n\nOffspring:\n[[0 1 0 0 0 1 0 0 0 1]\n [0 0 0 0 1 0 1 1 1 0]\n [1 0 1 1 1 1 1 1 1 1]\n [0 0 1 1 1 0 1 0 0 0]]\n\n\n\nmutation_rate = 0.05\nmutation_matrix = np.random.rand(num_offspring, num_genes) &lt; mutation_rate\n\nprint(\"Mutation matrix:\")\nprint(mutation_matrix)\n\nMutation matrix:\n[[False False False False False False False False False  True]\n [False False False False False False False False False False]\n [False False  True False False False False False False False]\n [False False False False False False False False  True False]]\n\n\n\nprint(\"offspring[mutation_matrix]:\")\nprint(offspring[mutation_matrix])\n\noffspring[mutation_matrix]:\n[1 1 0]\n\n\n\nprint(\"1 - offspring[mutation_matrix]:\")\nprint(1 - offspring[mutation_matrix])\n\n1 - offspring[mutation_matrix]:\n[0 0 1]\n\n\n\noffspring[mutation_matrix] = 1 - offspring[mutation_matrix]\n\nprint(\"Mutated offstring:\")\nprint(offspring)\n\nMutated offstring:\n[[0 1 0 0 0 1 0 0 0 0]\n [0 0 0 0 1 0 1 1 1 0]\n [1 0 0 1 1 1 1 1 1 1]\n [0 0 1 1 1 0 1 0 1 0]]\n\n\n\nThis implementation makes extensive use of Numpy."
  },
  {
    "objectID": "lectures/18/slides.html#elitism",
    "href": "lectures/18/slides.html#elitism",
    "title": "Population-Based Metaheuristics",
    "section": "Elitism",
    "text": "Elitism\nElitism in genetic algorithms is a strategy where a subset of the fittest individuals from the current generation is directly carried over to the next generation.\nThis approach ensures that the best solutions are preserved throughout the evolutionary process, enhancing convergence speed and maintaining high-quality solutions within the population."
  },
  {
    "objectID": "lectures/18/slides.html#elitism-1",
    "href": "lectures/18/slides.html#elitism-1",
    "title": "Population-Based Metaheuristics",
    "section": "Elitism",
    "text": "Elitism\n\ndef elitism(population, fitness, elite_size):\n\n    elite_indices = np.argsort(fitness)[-elite_size:]  # Get indices of top individuals\n\n    elites = population[elite_indices]\n\n    return elites"
  },
  {
    "objectID": "lectures/18/slides.html#genetic-algorithm-version-1",
    "href": "lectures/18/slides.html#genetic-algorithm-version-1",
    "title": "Population-Based Metaheuristics",
    "section": "Genetic Algorithm (Version 1)",
    "text": "Genetic Algorithm (Version 1)\n\ndef genetic_algorithm(weights, values, capacity, pop_size=100, \n                      num_generations=100, crossover_rate=0.8,\n                      mutation_rate=0.05, elite_percent=0.02):\n\n    num_items = len(weights)\n    elite_size = max(1, int(pop_size * elite_percent))\n    population = initialize_population(pop_size, num_items)\n\n    for generation in range(num_generations):\n\n        fitness = evaluate_fitness(population, weights, values, capacity)\n\n        # Elitism\n        elites = elitism(population, fitness, elite_size)\n\n        # Selection\n        parents = roulette_selection(population, fitness)\n\n        # Crossover\n        offspring = single_point_crossover(parents, crossover_rate)\n\n        # Mutation\n        offspring = mutation(offspring, mutation_rate)\n\n        # Create new population\n        population = np.vstack((elites, offspring))\n\n        # Ensure population size\n        if population.shape[0] &gt; pop_size:\n            population = population[:pop_size]\n        elif population.shape[0] &lt; pop_size:\n            # Add random individuals to fill population\n            num_new_individuals = pop_size - population.shape[0]\n            new_individuals = initialize_population(num_new_individuals, num_items)\n            population = np.vstack((population, new_individuals))\n\n    # After all generations, return the best solution\n    fitness = evaluate_fitness(population, weights, values, capacity)\n    best_index = np.argmax(fitness)\n    best_solution = population[best_index]\n    best_value = np.dot(best_solution, values)\n    best_weight = np.dot(best_solution, weights)\n\n    return best_solution, best_value, best_weight"
  },
  {
    "objectID": "lectures/18/slides.html#run",
    "href": "lectures/18/slides.html#run",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nnp.random.seed(13)\n\nsolution, total_value, total_weight = genetic_algorithm(weights, values, capacity)\n\nprint(f\"Solution: {solution}\")\nprint(f\"Value: {total_value}\")\nprint(f\"Weight: {total_weight}\")\n\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0\n 1 0 1 0 0 1 0 1 0 0 1 1 1]\nValue: 7357\nWeight: 848"
  },
  {
    "objectID": "lectures/18/slides.html#genetic-algorithm-version-1.1",
    "href": "lectures/18/slides.html#genetic-algorithm-version-1.1",
    "title": "Population-Based Metaheuristics",
    "section": "Genetic Algorithm (Version 1.1)",
    "text": "Genetic Algorithm (Version 1.1)\n\ndef genetic_algorithm(weights, values, capacity, pop_size=100, \n                      num_generations=100, crossover_rate=0.8, \n                      mutation_rate=0.05, elite_percent=0.02):\n\n    num_items = len(weights)\n    elite_size = max(1, int(pop_size * elite_percent))\n    population = initialize_population(pop_size, num_items)\n\n    average_fitness_history = []\n    best_fitness_history = []\n\n    for generation in range(num_generations):\n\n        fitness = evaluate_fitness(population, weights, values, capacity)\n\n        # Track average and best fitness\n        average_fitness = np.mean(fitness)\n        best_fitness = np.max(fitness)\n        average_fitness_history.append(average_fitness)\n        best_fitness_history.append(best_fitness)\n\n        # Elitism\n        elites = elitism(population, fitness, elite_size)\n\n        # Selection\n        parents = roulette_selection(population, fitness)\n\n        # Crossover\n        offspring = single_point_crossover(parents, crossover_rate)\n\n        # Mutation\n        offspring = mutation(offspring, mutation_rate)\n\n        # Create new population\n        population = np.vstack((elites, offspring))\n\n        # Ensure population size\n        if population.shape[0] &gt; pop_size:\n            population = population[:pop_size]\n        elif population.shape[0] &lt; pop_size:\n            # Add random individuals to fill population\n            num_new_individuals = pop_size - population.shape[0]\n            new_individuals = initialize_population(num_new_individuals, num_items)\n            population = np.vstack((population, new_individuals))\n\n    # After all generations, return the best solution\n    fitness = evaluate_fitness(population, weights, values, capacity)\n    best_index = np.argmax(fitness)\n    best_solution = population[best_index]\n    best_value = np.dot(best_solution, values)\n    best_weight = np.dot(best_solution, weights)\n\n    return best_solution, best_value, best_weight, average_fitness_history, best_fitness_history"
  },
  {
    "objectID": "lectures/18/slides.html#plot",
    "href": "lectures/18/slides.html#plot",
    "title": "Population-Based Metaheuristics",
    "section": "Plot",
    "text": "Plot\n\nimport matplotlib.pyplot as plt\n\ndef plot_fitness_over_generations(avg_fitness_history, best_fitness_history):\n\n  generations = range(1, len(avg_fitness_history) + 1)\n\n  plt.figure(figsize=(6, 6))\n\n  plt.plot(generations, avg_fitness_history, label='Average Fitness')\n  plt.plot(generations, best_fitness_history, label='Best Fitness')\n  plt.xlabel('Generation')\n  plt.ylabel('Fitness')\n  plt.title('Fitness over Generations')\n  plt.legend()"
  },
  {
    "objectID": "lectures/18/slides.html#run-1",
    "href": "lectures/18/slides.html#run-1",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nnp.random.seed(13)\n\nsolution, total_value, total_weight, avg_fitness_history, best_fitness_history = genetic_algorithm(weights, values, capacity)\n\nprint(f\"Solution: {solution}\")\nprint(f\"Value: {total_value}\")\nprint(f\"Weight: {total_weight}\")\n\nplot_fitness_over_generations(avg_fitness_history, best_fitness_history)"
  },
  {
    "objectID": "lectures/18/slides.html#run-1-output",
    "href": "lectures/18/slides.html#run-1-output",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0\n 1 0 1 0 0 1 0 1 0 0 1 1 1]\nValue: 7357\nWeight: 848"
  },
  {
    "objectID": "lectures/18/slides.html#run-2",
    "href": "lectures/18/slides.html#run-2",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nnp.random.seed(42)\n\nbest_value = -1\nbest_weight = -1\nbest_solution, best_averages, best_bests = None,  None, None\n\nfor i in range(100):\n\n  solution, total_value, total_weight, avg_fitness_history, best_fitness_history = genetic_algorithm(weights, values, capacity)\n\n  if total_value &gt; best_value and total_weight &lt;= capacity:\n    best_value = total_value\n    best_weight = total_weight\n    best_solution = solution\n    best_averages = avg_fitness_history\n    best_bests = best_fitness_history\n\n\nprint(f\"Solution: {best_solution}\")\nprint(f\"Value: {best_value}\")\nprint(f\"Weight: {best_weight}\")\n\nplot_fitness_over_generations(best_averages, best_bests)"
  },
  {
    "objectID": "lectures/18/slides.html#run-2-output",
    "href": "lectures/18/slides.html#run-2-output",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7506\nWeight: 846"
  },
  {
    "objectID": "lectures/18/slides.html#using-google-or-tools",
    "href": "lectures/18/slides.html#using-google-or-tools",
    "title": "Population-Based Metaheuristics",
    "section": "Using Google OR Tools",
    "text": "Using Google OR Tools\n\n# https://developers.google.com/optimization/pack/knapsack\n\nfrom ortools.algorithms.python import knapsack_solver\n\ndef solve_using_ortools(values, weights, capacity):\n\n  weights = [weights]\n\n  # Create the solver\n  \n  solver = knapsack_solver.KnapsackSolver(\n      knapsack_solver.SolverType.KNAPSACK_MULTIDIMENSION_BRANCH_AND_BOUND_SOLVER,\n      \"KnapsackExample\",\n  )\n\n  solver.init(values, weights, [capacity])\n\n  computed_value = solver.solve()\n\n  packed_items = []\n  packed_weights = []\n  total_weight = 0\n  print(\"Total value =\", computed_value)\n  for i in range(len(values)):\n      if solver.best_solution_contains(i):\n          packed_items.append(i)\n          packed_weights.append(weights[0][i])\n          total_weight += weights[0][i]\n  print(\"Total weight:\", total_weight)\n  print(\"Packed items:\", packed_items)\n  print(\"Packed_weights:\", packed_weights)"
  },
  {
    "objectID": "lectures/18/slides.html#solve_using_ortools",
    "href": "lectures/18/slides.html#solve_using_ortools",
    "title": "Population-Based Metaheuristics",
    "section": "solve_using_ortools",
    "text": "solve_using_ortools\n\nsolve_using_ortools(values, weights, capacity)\n\nTotal value = 7534\nTotal weight: 850\nPacked items: [0, 1, 3, 4, 6, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 24, 27, 28, 29, 30, 31, 32, 34, 38, 39, 41, 42, 44, 47, 48, 49]\nPacked_weights: [np.int64(7), np.int64(0), np.int64(22), np.int64(80), np.int64(11), np.int64(59), np.int64(18), np.int64(0), np.int64(3), np.int64(8), np.int64(15), np.int64(42), np.int64(9), np.int64(0), np.int64(47), np.int64(52), np.int64(26), np.int64(6), np.int64(29), np.int64(84), np.int64(2), np.int64(4), np.int64(18), np.int64(7), np.int64(71), np.int64(3), np.int64(66), np.int64(31), np.int64(0), np.int64(65), np.int64(52), np.int64(13)]"
  },
  {
    "objectID": "lectures/18/slides.html#encoding-schemes",
    "href": "lectures/18/slides.html#encoding-schemes",
    "title": "Population-Based Metaheuristics",
    "section": "Encoding Schemes",
    "text": "Encoding Schemes\n\nBinary encoding is commonly used.\nPermutation encoding. Typically used with problems such as “Travelling Salesman Problem (TSP)” and N-Queens.\nValues encoding. In this encoding, integer, real, or character values are used. Example: learning the parameters of a polynomical in a regression problem."
  },
  {
    "objectID": "lectures/18/slides.html#selection",
    "href": "lectures/18/slides.html#selection",
    "title": "Population-Based Metaheuristics",
    "section": "Selection",
    "text": "Selection\nTournament selection involves randomly selecting a subset of individuals (a tournament) from the population and then selecting the best individual from this subset to be a parent. The process is repeated until the required number of parents is selected.\nThis method balances between exploration and exploitation. It allows for controlling selection pressure by varying the tournament size. Larger tournaments increase selection pressure, favoring the fittest individuals more strongly.\n\nAdvantages\n\nRobustness to Fitness Scaling\n\nHandles Negative Fitness Values: The method relies on relative ranking within the tournament rather than absolute fitness values, making it robust to negative or zero fitness values.\nLess Sensitive to Fitness Distribution: Since selection is based on comparison rather than proportion, it performs well even when fitness values are close together.\n\nAdjustable Selection Pressure\n\nControl via Tournament Size: The selection pressure can be easily adjusted by changing the tournament size:\n\nLarger Tournaments: Higher selection pressure, as there is a greater chance of selecting the best individuals.\nSmaller Tournaments: Lower selection pressure, promoting diversity.\n\nSimplicity: Easy to implement without the need for fitness normalization.\n\nMaintains Diversity\n\nAvoids Premature Convergence: By not solely focusing on high-fitness individuals, it maintains genetic diversity within the population.\n\n\nDisadvantages\n\nStochastic Nature\n\nRandomness in Selection: The selection process is more stochastic, and the best individual in the population might not be selected if not included in a tournament.\nPossible Slow Convergence: If the tournament size is too small, the algorithm may converge slowly due to low selection pressure.\n\nParameter Dependence\n\nRequires Tuning: The performance is sensitive to the choice of tournament size, which may require experimentation to optimize.\n\nComputational Considerations\n\nMultiple Comparisons: Requires random sampling and comparisons, which might be computationally more intensive for very large populations, though generally negligible."
  },
  {
    "objectID": "lectures/18/slides.html#tournament_selection",
    "href": "lectures/18/slides.html#tournament_selection",
    "title": "Population-Based Metaheuristics",
    "section": "tournament_selection",
    "text": "tournament_selection\n\ndef tournament_selection(population, fitness, tournament_size):\n\n    pop_size = population.shape[0]\n\n    selected_indices = []\n\n    for _ in range(pop_size):\n\n        participants = np.random.choice(pop_size, tournament_size, replace=False)\n\n        best = participants[np.argmax(fitness[participants])]\n\n        selected_indices.append(best)\n\n    return population[selected_indices]\n\n\n\nTypical values for tournament_size are 2, 3, 4, or 5."
  },
  {
    "objectID": "lectures/18/slides.html#discussion-1",
    "href": "lectures/18/slides.html#discussion-1",
    "title": "Population-Based Metaheuristics",
    "section": "Discussion",
    "text": "Discussion\n\nnp.random.seed(27)\n\npop_size, num_items = 100, 50\n\npopulation = initialize_population(pop_size, num_items)\n\nfitness = evaluate_fitness(population, weights, values, capacity)\n\nplt.figure(figsize=(4, 4))\nplt.hist(fitness, bins=10, edgecolor='black')\nplt.xlabel('Fitness Values')\nplt.ylabel('Frequency')\nplt.title('Histogram of Fitness Values')\nplt.show()\n\nfor tournament_size in [2, 4, 8, pop_size]:\n  participants = np.random.choice(pop_size, tournament_size, replace=False)\n  print(f\"tournament_size: {tournament_size}, fitness: {max(fitness[participants])}\")\n\n\n\n\nSmaller \\(k\\) (e.g., \\(k = 2\\)): Low selection pressure promotes diversity and exploration, useful in early generations.\nLarger \\(k\\) (e.g., \\(k = 5\\)): High selection pressure accelerates convergence, emphasizing exploitation, ideal in later generations."
  },
  {
    "objectID": "lectures/18/slides.html#discussion-1-output",
    "href": "lectures/18/slides.html#discussion-1-output",
    "title": "Population-Based Metaheuristics",
    "section": "Discussion",
    "text": "Discussion\n\n\n\n\n\n\n\n\ntournament_size: 2, fitness: 1985\ntournament_size: 4, fitness: 2933\ntournament_size: 8, fitness: 3966\ntournament_size: 100, fitness: 5478"
  },
  {
    "objectID": "lectures/18/slides.html#genetic-algorithm-version-2",
    "href": "lectures/18/slides.html#genetic-algorithm-version-2",
    "title": "Population-Based Metaheuristics",
    "section": "Genetic Algorithm (Version 2)",
    "text": "Genetic Algorithm (Version 2)\n\ndef genetic_algorithm(weights, values, capacity, pop_size=100, \n                      num_generations=100, crossover_rate=0.8,\n                      mutation_rate=0.05, elite_percent=0.02, \n                      selection_type='tournament', tournament_size=3):\n\n    num_items = len(weights)\n    elite_size = max(1, int(pop_size * elite_percent))\n    population = initialize_population(pop_size, num_items)\n\n    average_fitness_history = []\n    best_fitness_history = []\n\n    for generation in range(num_generations):\n\n        fitness = evaluate_fitness(population, weights, values, capacity)\n\n        # Track average and best fitness\n        average_fitness = np.mean(fitness)\n        best_fitness = np.max(fitness)\n        average_fitness_history.append(average_fitness)\n        best_fitness_history.append(best_fitness)\n\n        # Elitism\n        elites = elitism(population, fitness, elite_size)\n\n        # Selection\n        if selection_type == 'tournament':\n            parents = tournament_selection(population, fitness, tournament_size)\n        elif selection_type == 'roulette':\n            parents = roulette_selection(population, fitness)\n        else:\n            raise ValueError(\"Invalid selection type\")\n\n        # Crossover\n        offspring = single_point_crossover(parents, crossover_rate)\n\n        # Mutation\n        offspring = mutation(offspring, mutation_rate)\n\n        # Create new population\n        population = np.vstack((elites, offspring))\n\n        # Ensure population size\n        if population.shape[0] &gt; pop_size:\n            population = population[:pop_size]\n        elif population.shape[0] &lt; pop_size:\n            # Add random individuals to fill population\n            num_new_individuals = pop_size - population.shape[0]\n            new_individuals = initialize_population(num_new_individuals, num_items)\n            population = np.vstack((population, new_individuals))\n\n    # After all generations, return the best solution\n    fitness = evaluate_fitness(population, weights, values, capacity)\n    best_index = np.argmax(fitness)\n    best_solution = population[best_index]\n    best_value = np.dot(best_solution, values)\n    best_weight = np.dot(best_solution, weights)\n\n    return best_solution, best_value, best_weight, average_fitness_history, best_fitness_history"
  },
  {
    "objectID": "lectures/18/slides.html#run-3",
    "href": "lectures/18/slides.html#run-3",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nnp.random.seed(42)\n\nbest_value, best_weight = -1, -1\nbest_solution, best_averages, best_bests = None,  None, None\n\nfor i in range(100):\n\n  solution, total_value, total_weight, avg_fitness_history, best_fitness_history = genetic_algorithm(weights, values, capacity)\n\n  if total_value &gt; best_value and total_weight &lt;= capacity:\n    best_value = total_value\n    best_weight = total_weight\n    best_solution = solution\n    best_averages = avg_fitness_history\n    best_bests = best_fitness_history\n\n\nprint(f\"Solution: {best_solution}\")\nprint(f\"Value: {best_value}\")\nprint(f\"Weight: {best_weight}\")\n\nplot_fitness_over_generations(best_averages, best_bests)"
  },
  {
    "objectID": "lectures/18/slides.html#run-3-output",
    "href": "lectures/18/slides.html#run-3-output",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7534\nWeight: 850"
  },
  {
    "objectID": "lectures/18/slides.html#tournament_size2-4-8",
    "href": "lectures/18/slides.html#tournament_size2-4-8",
    "title": "Population-Based Metaheuristics",
    "section": "tournament_size=2, 4, 8",
    "text": "tournament_size=2, 4, 8\n\nnp.random.seed(42)\n\nfor tournament_size in (2, 4, 8):\n\n  best_value, best_weight = -1, -1\n  best_solution, best_averages, best_bests = None,  None, None\n\n  for i in range(100):\n\n      solution, total_value, total_weight, avg_fitness_history, best_fitness_history = genetic_algorithm(\n        weights, values, capacity, tournament_size=tournament_size\n      )\n\n      if total_value &gt; best_value and total_weight &lt;= capacity:\n        best_value = total_value\n        best_weight = total_weight\n        best_solution = solution\n        best_averages = avg_fitness_history\n        best_bests = best_fitness_history\n\n  print(f\"Solution: {best_solution}\")\n  print(f\"Value: {best_value}\")\n  print(f\"Weight: {best_weight}\")\n\n  plot_fitness_over_generations(best_averages, best_bests)\n\n\n\nAs one increases the tournament size increases, average and best fitness get closer. Faster convergence."
  },
  {
    "objectID": "lectures/18/slides.html#tournament_size2-4-8-output",
    "href": "lectures/18/slides.html#tournament_size2-4-8-output",
    "title": "Population-Based Metaheuristics",
    "section": "tournament_size=2, 4, 8",
    "text": "tournament_size=2, 4, 8\n\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7534\nWeight: 850\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7534\nWeight: 850\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7534\nWeight: 850"
  },
  {
    "objectID": "lectures/18/slides.html#crossover-3",
    "href": "lectures/18/slides.html#crossover-3",
    "title": "Population-Based Metaheuristics",
    "section": "Crossover",
    "text": "Crossover\n\nSingle or k-point cross-over.\n\n\nK-point crossover is a genetic algorithm technique used for combining two parent solutions to generate offspring. It involves selecting \\(k\\) crossover points and swapping segments of the parents between these points. Here are some scenarios where k-point crossover might be particularly useful:\n\nComplex Solution Spaces: When the problem domain involves complex interdependencies between variables, k-point crossover can help explore the solution space more thoroughly by allowing multiple segments to be exchanged between parents.\nDiverse Genetic Material: By increasing \\(k\\), more genetic material from both parents is mixed, which can introduce greater diversity into the offspring. This can be beneficial in avoiding premature convergence on suboptimal solutions.\nBalancing Exploration and Exploitation: K-point crossover provides a balance between exploration (by introducing new combinations of genetic material) and exploitation (by maintaining some continuity with the parent solutions). This can be advantageous in maintaining a healthy diversity in the population.\nTuning Genetic Algorithm Performance: Adjusting the number of crossover points (\\(k\\)) allows for fine-tuning the genetic algorithm’s performance. A higher \\(k\\) can be used to increase diversity, while a lower \\(k\\) can focus on exploiting known good solutions.\nLarge Solution Representations: In problems with large solution representations, such as long binary strings or large arrays, k-point crossover allows for more nuanced mixing of genetic material, potentially leading to more effective search and optimization.\nEmpirical Testing: Sometimes, k-point crossover is chosen based on empirical results, where experimentation shows that it performs better for a specific problem or dataset compared to other crossover methods.\n\nK-point crossover is versatile and can be adapted to the needs of different problems by adjusting the number of crossover points, making it a useful tool in the genetic algorithm toolkit."
  },
  {
    "objectID": "lectures/18/slides.html#uniform-crossover",
    "href": "lectures/18/slides.html#uniform-crossover",
    "title": "Population-Based Metaheuristics",
    "section": "Uniform crossover",
    "text": "Uniform crossover\nUniform crossover in genetic algorithms is a recombination technique where each gene in the offspring is independently chosen from one of the two parent genomes with equal probability. This approach allows for a more varied combination of parental traits compared to traditional crossover methods, promoting greater genetic diversity in the resulting population."
  },
  {
    "objectID": "lectures/18/slides.html#uniform_crossover",
    "href": "lectures/18/slides.html#uniform_crossover",
    "title": "Population-Based Metaheuristics",
    "section": "uniform_crossover",
    "text": "uniform_crossover\n\ndef uniform_crossover(parents, crossover_rate):\n\n    num_parents, num_genes = parents.shape\n    np.random.shuffle(parents)\n\n    offspring = []\n\n    for i in range(0, num_parents, 2):\n\n        parent1 = parents[i]\n        parent2 = parents[i+1 if i+1 &lt; num_parents else 0]\n\n        child1 = parent1.copy()\n        child2 = parent2.copy()\n\n        if np.random.rand() &lt; crossover_rate:\n\n            mask = np.random.randint(0, 2, size=num_genes).astype(bool)\n\n            child1[mask], child2[mask] = parent2[mask], parent1[mask]\n\n        offspring.append(child1)\n        offspring.append(child2)\n\n    return np.array(offspring)"
  },
  {
    "objectID": "lectures/18/slides.html#genetic-algorithm-version-3",
    "href": "lectures/18/slides.html#genetic-algorithm-version-3",
    "title": "Population-Based Metaheuristics",
    "section": "Genetic Algorithm (Version 3)",
    "text": "Genetic Algorithm (Version 3)\n\ndef genetic_algorithm(weights, values, capacity, pop_size=100, \n                      num_generations=200, crossover_rate=0.8,\n                      mutation_rate=0.05, elite_percent=0.02, \n                      selection_type='tournament', tournament_size=3,\n                      crossover_type='single_point'):\n\n    num_items = len(weights)\n    elite_size = max(1, int(pop_size * elite_percent))\n    population = initialize_population(pop_size, num_items)\n\n    average_fitness_history = []\n    best_fitness_history = []\n\n    for generation in range(num_generations):\n\n        fitness = evaluate_fitness(population, weights, values, capacity)\n\n        # Track average and best fitness\n        average_fitness = np.mean(fitness)\n        best_fitness = np.max(fitness)\n        average_fitness_history.append(average_fitness)\n        best_fitness_history.append(best_fitness)\n\n        # Elitism\n        elites = elitism(population, fitness, elite_size)\n\n        # Selection\n        if selection_type == 'tournament':\n            parents = tournament_selection(population, fitness, tournament_size)\n        elif selection_type == 'roulette':\n            parents = roulette_selection(population, fitness)\n        else:\n            raise ValueError(\"Invalid selection type\")\n\n        # Crossover\n        if crossover_type == 'single_point':\n            offspring = single_point_crossover(parents, crossover_rate)\n        elif crossover_type == 'uniform':\n            offspring = uniform_crossover(parents, crossover_rate)\n        else:\n            raise ValueError(\"Invalid crossover type\")\n\n        # Mutation\n        offspring = mutation(offspring, mutation_rate)\n\n        # Create new population\n        population = np.vstack((elites, offspring))\n\n        # Ensure population size\n        if population.shape[0] &gt; pop_size:\n            population = population[:pop_size]\n        elif population.shape[0] &lt; pop_size:\n            # Add random individuals to fill population\n            num_new_individuals = pop_size - population.shape[0]\n            new_individuals = initialize_population(num_new_individuals, num_items)\n            population = np.vstack((population, new_individuals))\n\n    # After all generations, return the best solution\n    fitness = evaluate_fitness(population, weights, values, capacity)\n    best_index = np.argmax(fitness)\n    best_solution = population[best_index]\n    best_value = np.dot(best_solution, values)\n    best_weight = np.dot(best_solution, weights)\n\n    return best_solution, best_value, best_weight, average_fitness_history, best_fitness_history"
  },
  {
    "objectID": "lectures/18/slides.html#run-4",
    "href": "lectures/18/slides.html#run-4",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nnp.random.seed(42)\n\nbest_value, best_weight = -1, -1\nbest_solution, best_averages, best_bests = None,  None, None\n\nfor i in range(100):\n\n  solution, total_value, total_weight, avg_fitness_history, best_fitness_history = genetic_algorithm(\n    weights, values, capacity, crossover_type='uniform'\n  )\n\n  if total_value &gt; best_value and total_weight &lt;= capacity:\n    best_value = total_value\n    best_weight = total_weight\n    best_solution = solution\n    best_averages = avg_fitness_history\n    best_bests = best_fitness_history\n\n\nprint(f\"Solution: {best_solution}\")\nprint(f\"Value: {best_value}\")\nprint(f\"Weight: {best_weight}\")\n\nplot_fitness_over_generations(best_averages, best_bests)"
  },
  {
    "objectID": "lectures/18/slides.html#run-4-output",
    "href": "lectures/18/slides.html#run-4-output",
    "title": "Population-Based Metaheuristics",
    "section": "Run",
    "text": "Run\n\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7534\nWeight: 850"
  },
  {
    "objectID": "lectures/18/slides.html#crossover-4",
    "href": "lectures/18/slides.html#crossover-4",
    "title": "Population-Based Metaheuristics",
    "section": "Crossover",
    "text": "Crossover\nSingle-Point Crossover is advantageous when building blocks (contiguous gene sequences) are meaningful and beneficial to preserve. However, in the 0/1 Knapsack Problem, the position of items in the chromosome is typically arbitrary, and preserving contiguous sections may not correspond to better solutions.\nUniform Crossover offers better exploration by independently mixing genes, which aligns well with the nature of the knapsack problem where each item’s inclusion is an independent decision. It reduces positional bias and increases the likelihood of discovering optimal combinations of items."
  },
  {
    "objectID": "lectures/18/slides.html#crossover-5",
    "href": "lectures/18/slides.html#crossover-5",
    "title": "Population-Based Metaheuristics",
    "section": "Crossover",
    "text": "Crossover\nOrder preserving. For each offspring, retain the sequence of elements from one parent while filling in the remaining positions with elements from the other parent, preserving their order as they appear in the second parent.\n\n\nSee (Cattolico and Cicirello 2006) for variants."
  },
  {
    "objectID": "lectures/18/slides.html#order-1-crossover-ox",
    "href": "lectures/18/slides.html#order-1-crossover-ox",
    "title": "Population-Based Metaheuristics",
    "section": "Order 1 crossover (OX)",
    "text": "Order 1 crossover (OX)\n\n\n\n\n\n\n\nOX is designed to preserve the relative order of elements from one parent while filling gaps with elements from the other parent.\n\n\nAttribution: (Bye et al. 2021)"
  },
  {
    "objectID": "lectures/18/slides.html#partially-mapped-crossover-pmx",
    "href": "lectures/18/slides.html#partially-mapped-crossover-pmx",
    "title": "Population-Based Metaheuristics",
    "section": "Partially Mapped Crossover (PMX)",
    "text": "Partially Mapped Crossover (PMX)\n\n\n\n\n\n\n\nPMX ensures positional consistency by maintaining the relative ordering of elements between parent chromosomes.\n\n\nAttribution: (Bye et al. 2021)"
  },
  {
    "objectID": "lectures/18/slides.html#comparison",
    "href": "lectures/18/slides.html#comparison",
    "title": "Population-Based Metaheuristics",
    "section": "Comparison",
    "text": "Comparison\n\n\n\n\n\n\n\n\nFeature\nPMX\nOX\n\n\n\n\nPreservation of Position\nHigh\nLow\n\n\nPreservation of Order\nPartial\nHigh\n\n\nExploration vs. Exploitation\nExploitation-focused\nExploration-focused\n\n\nImplementation Complexity\nHigher\nLower\n\n\nApplication Suitability\nProblems with positional dependencies\nProblems with order dependencies"
  },
  {
    "objectID": "lectures/18/slides.html#mutation-1",
    "href": "lectures/18/slides.html#mutation-1",
    "title": "Population-Based Metaheuristics",
    "section": "Mutation",
    "text": "Mutation\n\nBit Flip Mutation: This involves flipping the value of a bit at a selected position within the chromosome.\n\nMutation Rate: A typical mutation rate is \\(1/n\\), where \\(n\\) represents the length of the chromosome."
  },
  {
    "objectID": "lectures/18/slides.html#mutation-2",
    "href": "lectures/18/slides.html#mutation-2",
    "title": "Population-Based Metaheuristics",
    "section": "Mutation",
    "text": "Mutation\n\nReplacement or Random Resetting: For integer and real-valued chromosomes, employ a random selection from the uniform distribution \\(U(a, b)\\) to choose a new value within the interval \\([a, b]\\). Similar to the bit flip operator, determine for each position whether a mutation should occur, then apply the replacement if necessary."
  },
  {
    "objectID": "lectures/18/slides.html#mutation-3",
    "href": "lectures/18/slides.html#mutation-3",
    "title": "Population-Based Metaheuristics",
    "section": "Mutation",
    "text": "Mutation\n\nSwap Mutation: This operator randomly selects two genes within a permutation and exchanges their positions. Such mutations facilitate the exploration of various permutations, potentially yielding improved solutions.\n\n\n\nMutation operators should be crafted to preserve valid permutations while introducing population diversity, thereby mitigating premature convergence to suboptimal solutions."
  },
  {
    "objectID": "lectures/18/slides.html#remarks",
    "href": "lectures/18/slides.html#remarks",
    "title": "Population-Based Metaheuristics",
    "section": "Remarks",
    "text": "Remarks\nWhen designing operators, it is critical to ensure they can explore the entire state space exhaustively.\nMutation operators should remain unbiased to maintain the integrity of the exploration process."
  },
  {
    "objectID": "lectures/18/slides.html#comprehensive-example-1",
    "href": "lectures/18/slides.html#comprehensive-example-1",
    "title": "Population-Based Metaheuristics",
    "section": "Comprehensive Example (1)",
    "text": "Comprehensive Example (1)\nA Jupyter Notebook containing all lecture code has been created.\nIt includes tests on 25 problem instances.\nIn this context, the genetic algorithm consistently outperformed the greedy algorithms, matching the best greedy results in 8 cases and surpassing them in 17 cases, with improvements up to 6%."
  },
  {
    "objectID": "lectures/18/slides.html#comprehensive-example-2",
    "href": "lectures/18/slides.html#comprehensive-example-2",
    "title": "Population-Based Metaheuristics",
    "section": "Comprehensive Example (2)",
    "text": "Comprehensive Example (2)\nFredj Kharroubi conducted an empirical study on the knapsack problem, comparing the performance of several algorithms: generate-and-test, greedy search, simulated annealing, and a genetic algorithm.\nJupyter Notebook"
  },
  {
    "objectID": "lectures/18/slides.html#discussions-on-hyperparameters",
    "href": "lectures/18/slides.html#discussions-on-hyperparameters",
    "title": "Population-Based Metaheuristics",
    "section": "Discussions on Hyperparameters",
    "text": "Discussions on Hyperparameters\nPopulation Size\n\nA larger size improves genetic diversity but increases computational cost.\nA smaller size speeds up execution but risks premature convergence."
  },
  {
    "objectID": "lectures/18/slides.html#discussions-on-hyperparameters-1",
    "href": "lectures/18/slides.html#discussions-on-hyperparameters-1",
    "title": "Population-Based Metaheuristics",
    "section": "Discussions on Hyperparameters",
    "text": "Discussions on Hyperparameters\nMutation and Crossover Rates\n\nHigh rates promote exploration but risk disrupting viable solutions.\nLow rates favor exploitation but risk getting stuck in local optima."
  },
  {
    "objectID": "lectures/18/slides.html#discussions-on-hyperparameters-2",
    "href": "lectures/18/slides.html#discussions-on-hyperparameters-2",
    "title": "Population-Based Metaheuristics",
    "section": "Discussions on Hyperparameters",
    "text": "Discussions on Hyperparameters\nSelection and Tournament Size\n\nTournament selection is robust against uneven fitness distributions.\nA medium tournament size (3-5) balances exploration and exploitation well."
  },
  {
    "objectID": "lectures/18/slides.html#parameters",
    "href": "lectures/18/slides.html#parameters",
    "title": "Population-Based Metaheuristics",
    "section": "Parameters",
    "text": "Parameters\nGenetic algorithms, like many machine learning and search algorithms, require hyperparameter tuning to optimize their performance.\nKey hyperparameters in genetic algorithms include population size, mutation rate, crossover rate, selection method, and the number of generations."
  },
  {
    "objectID": "lectures/18/slides.html#discussion-2",
    "href": "lectures/18/slides.html#discussion-2",
    "title": "Population-Based Metaheuristics",
    "section": "Discussion",
    "text": "Discussion\nLike other metaheuristic approaches, genetic algorithms can become trapped in local optima. A common solution, akin to the random restart technique used in hill climbing, is to periodically reinitialize the algorithm to explore different regions of the solution space.\nDoubling the population size with each restart enhances the likelihood of exploring diverse regions of the state space."
  },
  {
    "objectID": "lectures/18/slides.html#skepticism-toward-ga",
    "href": "lectures/18/slides.html#skepticism-toward-ga",
    "title": "Population-Based Metaheuristics",
    "section": "Skepticism toward GA",
    "text": "Skepticism toward GA\n\n\n\n (Skiena 2008, 267)\n\n\n[I]t is quite unnatural to model applications in terms of genetic operators like mutation and crossover on bit strings. The pseudobiology adds another level of complexity between you and your problem. Second, genetic algorithms take a very long time on nontrivial problems. [\\(\\ldots\\)] [T]he analogy with evolution – where significant progress require [sic] millions of years – can be quite appropriate. […]\nI have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me. Stick to simulated annealing for your heuristic search voodoo needs.\n\n\n\n\n\nIt seems that individuals tend to either appreciate or dislike genetic algorithms.\n\n\nThe bold formatting has been applied by me."
  },
  {
    "objectID": "lectures/18/slides.html#greedy-value-to-weight-ratio",
    "href": "lectures/18/slides.html#greedy-value-to-weight-ratio",
    "title": "Population-Based Metaheuristics",
    "section": "Greedy: value-to-weight ratio",
    "text": "Greedy: value-to-weight ratio\n\ndef greedy_knapsack_ratio(weights, values, capacity):\n\n    num_items = len(weights)\n\n    # Calculate value-to-weight ratio for each item\n    ratio = values / (weights + 1e-6)\n\n    # Create a list of items with their ratios and original indices\n    items = list(zip(ratio, values, weights, range(num_items)))\n\n    # Sort items by ratio in decreasing order\n    items.sort(reverse=True)\n    \n    total_weight = 0\n    total_value = 0\n    solution = np.zeros(num_items, dtype=int)\n    \n    # Select items based on the sorted order\n    for r, v, w, idx in items:\n        if total_weight + w &lt;= capacity:\n            solution[idx] = 1\n            total_weight += w\n            total_value += v\n     \n    return solution, total_value, total_weight\n\n\nWhy adding 1e-6) to the denominator ratio = values / (weights + 1e-6)?"
  },
  {
    "objectID": "lectures/18/slides.html#greedy_knapsack_ratio",
    "href": "lectures/18/slides.html#greedy_knapsack_ratio",
    "title": "Population-Based Metaheuristics",
    "section": "greedy_knapsack_ratio",
    "text": "greedy_knapsack_ratio\n\nsolution, total_value, total_weight = greedy_knapsack_ratio(weights, values, capacity)\n\nprint(f\"Solution: {solution}\")\nprint(f\"Value: {total_value}\")\nprint(f\"Weight: {total_weight}\")\n\nSolution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0\n 0 1 1 0 1 1 0 1 0 0 1 1 1]\nValue: 7534\nWeight: 850\n\n\n\n\nFor this particular instance, greedy_knapsack_ratio finds the optimal solution!"
  },
  {
    "objectID": "lectures/18/slides.html#frameworks",
    "href": "lectures/18/slides.html#frameworks",
    "title": "Population-Based Metaheuristics",
    "section": "Frameworks",
    "text": "Frameworks\n\nDEAP,\n\nDEAP is an evolutionary computation framework designed for rapid prototyping and testing of ideas. It aims to make algorithms explicit and data structures transparent. The framework seamlessly integrates with parallelization mechanisms, including multiprocessing and SCOOP.\nIt has been developed at Université Laval since 2012.\n\nPyGAD, 5 PyGAD applications"
  },
  {
    "objectID": "lectures/18/slides.html#definition-3",
    "href": "lectures/18/slides.html#definition-3",
    "title": "Population-Based Metaheuristics",
    "section": "Definition",
    "text": "Definition\nGenetic programming is an evolutionary algorithm-based methodology that evolves computer programs to solve problems by mimicking natural selection processes.\nIt automatically discovers optimal or near-optimal solutions by iteratively modifying a population of candidate programs, guided by a fitness function.\n\n\nCan be seen as a form of machine learning or automatic programming."
  },
  {
    "objectID": "lectures/18/slides.html#genetic-programming-1",
    "href": "lectures/18/slides.html#genetic-programming-1",
    "title": "Population-Based Metaheuristics",
    "section": "Genetic Programming",
    "text": "Genetic Programming\n\n\n\n\n\n\n\nAttribution: U-ichi, CC BY-SA 3.0, via Wikimedia Commons"
  },
  {
    "objectID": "lectures/18/slides.html#genetic-programming-2",
    "href": "lectures/18/slides.html#genetic-programming-2",
    "title": "Population-Based Metaheuristics",
    "section": "Genetic Programming",
    "text": "Genetic Programming"
  },
  {
    "objectID": "lectures/18/slides.html#conclusion",
    "href": "lectures/18/slides.html#conclusion",
    "title": "Population-Based Metaheuristics",
    "section": "Conclusion",
    "text": "Conclusion\n\nRather than exploring a single solution at a time, GA explore several solutions in parallel."
  },
  {
    "objectID": "lectures/18/slides.html#comparison-of-sa-and-ga",
    "href": "lectures/18/slides.html#comparison-of-sa-and-ga",
    "title": "Population-Based Metaheuristics",
    "section": "Comparison of SA and GA",
    "text": "Comparison of SA and GA\n\n\n\n\n\n\n\n\nAspect\nSimulated Annealing (SA)\nGenetic Algorithms (GA)\n\n\n\n\nSolution Representation\nSingle solution iteratively improved\nPopulation of solutions evolved over generations\n\n\nExploration Mechanism\nRandom moves to neighboring solutions; acceptance based on temperature\nCrossover and mutation generate new solutions from existing ones\n\n\nExploitation Mechanism\nGradual reduction in temperature focuses search around current best solution\nSelection and elitism favor fitter individuals in the population\n\n\nControl Parameters\nTemperature, cooling schedule\nPopulation size, crossover rate, mutation rate, selection method\n\n\nSearch Strategy\nExplores by accepting worse solutions at higher temperatures\nExplores by combining and mutating existing solutions\n\n\nBalance of Exploration and Exploitation\nControlled by temperature schedule\nControlled by genetic operator rates and selection pressure\n\n\nEscape from Local Optima\nPossible due to probabilistic acceptance of worse solutions\nPossible due to diversity in population and genetic variations\n\n\nConvergence\nDepends on cooling schedule; may be slow for large problems\nCan converge prematurely without sufficient diversity"
  },
  {
    "objectID": "lectures/18/slides.html#summary",
    "href": "lectures/18/slides.html#summary",
    "title": "Population-Based Metaheuristics",
    "section": "Summary",
    "text": "Summary\n\nMetaheuristics Overview\nGenetic Algorithms (GAs)\nApplications of GAs\nComponents of GAs:\n\nEncoding: Representation of candidate solutions (e.g., binary strings for the knapsack problem).\nPopulation: A set of candidate solutions initialized randomly or by some heuristic.\nSelection: Methods like roulette wheel and tournament selection choose fitter individuals for reproduction.\nCrossover: Combines parts of two parents to create offspring (e.g., single-point crossover).\nMutation: Randomly alters genes in a chromosome to maintain genetic diversity.\nFitness Function: Evaluates how close a candidate solution is to the optimum.\n\nKnapsack Problem Example:\n\nDemonstrated how to apply GAs to the 0/1 knapsack problem.\nProvided Python code snippets implementing GA components for the problem.\nShowed how to generate an initial population, perform crossover and mutation, and select the next generation.\nCompared GA solutions with optimal solutions obtained using Google’s OR-Tools.\n\n\n\n\nMetaheuristics Overview:\n\nMetaheuristics are high-level strategies guiding other heuristics to explore large solution spaces.\nThey balance exploitation and exploration to avoid local optima.\nGenetic algorithms (GAs) are a type of metaheuristic inspired by biological evolution.\n\nGenetic Algorithms (GAs):\n\nGAs use a population of candidate solutions (chromosomes) that evolve over generations.\nKey operations in GAs include selection, crossover (recombination), and mutation.\nThe goal is to optimize a fitness function that measures the quality of solutions.\n\nApplications of GAs:\n\nWidely used in optimization, machine learning (e.g., feature selection, hyperparameter tuning), robotics, finance, resource allocation, supply chain, and more.\nGAs can solve complex problems that are difficult for traditional methods.\n\nComponents of GAs:\n\nEncoding: Representation of candidate solutions (e.g., binary strings for the knapsack problem).\nPopulation: A set of candidate solutions initialized randomly or by some heuristic.\nSelection: Methods like roulette wheel and tournament selection choose fitter individuals for reproduction.\nCrossover: Combines parts of two parents to create offspring (e.g., single-point crossover).\nMutation: Randomly alters genes in a chromosome to maintain genetic diversity.\nFitness Function: Evaluates how close a candidate solution is to the optimum.\n\nKnapsack Problem Example:\n\nDemonstrated how to apply GAs to the 0/1 knapsack problem.\nProvided Python code snippets implementing GA components for the problem.\nShowed how to generate an initial population, perform crossover and mutation, and select the next generation.\nCompared GA solutions with optimal solutions obtained using Google’s OR-Tools.\n\nChoices in GAs:\n\nEncoding Schemes: Binary encoding, permutation encoding (for problems like TSP), and value encoding.\nSelection Methods: Roulette wheel selection and tournament selection.\nCrossover Techniques: Single-point, k-point, and order-preserving crossovers.\nMutation Rates: Balancing exploration and exploitation.\n\nSkepticism Toward GAs:\n\nPresented a critical view from Steven Skiena, emphasizing the unnatural modeling and long computation times.\nHighlighted that some experts prefer other methods like simulated annealing.\n\nGenetic Programming:\n\nAn extension of GAs where the solutions are computer programs.\nPrograms evolve over time to solve problems, guided by a fitness function.\nApplications include automated programming and machine learning tasks.\n\nFrameworks and Resources:\n\nMentioned frameworks like DEAP and PyGAD for implementing GAs.\nProvided resources for further reading and exploration.\nEncouraged accessing materials through university resources like Springer Link.\n\nConclusion:\n\nGAs explore multiple solutions in parallel, offering a different approach from single-solution methods.\nRecognized the importance of parameter tuning in GAs for optimal performance.\nAcknowledged the ongoing debates about the efficacy of GAs in various applications.\n\nNext Steps:\n\nEncouraged further exploration of metaheuristics and their applications.\nSuggested delving into genetic programming for advanced problem-solving techniques."
  },
  {
    "objectID": "lectures/18/slides.html#further-readings",
    "href": "lectures/18/slides.html#further-readings",
    "title": "Population-Based Metaheuristics",
    "section": "Further Readings",
    "text": "Further Readings\n\n\n\n\n\n\n\nDid you know that you can freely access the entire collection of books from Springer? By using a device connected to a uOttawa IP address and visiting Springer Link, you have the ability to download books in either PDF or EPUB format.\n\n\nKramer (2017), access via Springer Link."
  },
  {
    "objectID": "lectures/18/slides.html#resources",
    "href": "lectures/18/slides.html#resources",
    "title": "Population-Based Metaheuristics",
    "section": "Resources",
    "text": "Resources\n\nHands on genetic algorithms with Python\nSee Direct Evolutionary Optimization of Variational Autoencoders With Binary Latents for a recent application in machine learning.\nAI Improves at Improving Itself Using an Evolutionary Trick: Researchers use evolutionary algorithms to enhance AI coding skills by Matthew Mutson, in IEEE Spectrum, 26 june 2025 (5 minutes read)"
  },
  {
    "objectID": "lectures/18/slides.html#next-lecture",
    "href": "lectures/18/slides.html#next-lecture",
    "title": "Population-Based Metaheuristics",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will look at the Monte Carlo Tree Search (MCTS) algorithm"
  },
  {
    "objectID": "lectures/18/slides.html#references",
    "href": "lectures/18/slides.html#references",
    "title": "Population-Based Metaheuristics",
    "section": "References",
    "text": "References\n\n\nBye, Robin T., Magnus Gribbestad, Ramesh Chandra, and Ottar L. Osen. 2021. “A Comparison of GA Crossover and Mutation Methods for the Traveling Salesman Problem.” In Innovations in Computational Intelligence and Computer Vision, edited by Manoj Kumar Sharma, Vijaypal Singh Dhaka, Thinagaran Perumal, Nilanjan Dey, and João Manuel R. S. Tavares, 529–42. Singapore: Springer Singapore.\n\n\nCattolico, Mike, and Vincent A Cicirello. 2006. “Non-wrapping order crossover: an order preserving crossover operator that respects absolute position.” Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation, 1125–32. https://doi.org/10.1145/1143997.1144177.\n\n\nDennett, Daniel C. 1995. “Darwin’s Dangerous Idea.” The Sciences 35 (3): 34–40.\n\n\nEddaly, M., B. Jarboui, and P. Siarry. 2023. Metaheuristics for Machine Learning: New Advances and Tools. Computational Intelligence Methods and Applications. Springer Nature Singapore. https://books.google.ca/books?id=yXMtzwEACAAJ.\n\n\nGil-Rios, Miguel-Angel, Ivan Cruz-Aceves, Fernando Cervantes-Sanchez, Igor Guryev, and Juan-Manuel López-Hernández. 2021. “Automatic Enhancement of Coronary Arteries Using Convolutional Gray-Level Templates and Path-Based Metaheuristics.” In Recent Trends in Computational Intelligence Enabled Research, edited by Siddhartha Bhattacharyya, Paramartha Dutta, Debabrata Samanta, Anirban Mukherjee, and Indrajit Pan, 129–53. Academic Press.\n\n\nGregory, T. Ryan. 2009. “Understanding Natural Selection: Essential Concepts and Common Misconceptions.” Evolution: Education and Outreach 2 (2): 156–75. https://doi.org/10.1007/s12052-009-0128-1.\n\n\nHolland, John H. 1973. “Genetic Algorithms and the Optimal Allocation of Trials.” SIAM Journal on Computing 2 (2): 88–105. https://doi.org/10.1137/0202009.\n\n\n———. 1992. “Genetic Algorithms.” Scientific American 267: 66–73. https://www.jstor.org/stable/10.2307/24939139.\n\n\nKramer, Oliver. 2017. Genetic Algorithm Essentials. Studies in Computational Intelligence ; 679. Cham, Switzerland: Springer.\n\n\nMayr, Ernst. 1982. The Growth of Biological Thought: Diversity, Evolution, and Inheritance. Harvard University Press.\n\n\nMitchell, Melanie. 1998. An Introduction to Genetic Algorithms. Cambridge, MA, USA: MIT Press.\n\n\nOliva, D., E. H. Houssein, and S. Hinojosa. 2021. Metaheuristics in Machine Learning: Theory and Applications. Studies in Computational Intelligence. Springer International Publishing. https://books.google.ca/books?id=Zlw4EAAAQBAJ.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nSantos Amorim, Elisa Portes dos, Carolina Ribeiro Xavier, Ricardo Silva Campos, and Rodrigo Weber dos Santos. 2012. “Comparison Between Genetic Algorithms and Differential Evolution for Solving the History Matching Problem.” In Computational Science and Its Applications - ICCSA 2012 - 12th International Conference, Salvador de Bahia, Brazil, June 18-21, 2012, Proceedings, Part I, edited by Beniamino Murgante, Osvaldo Gervasi, Sanjay Misra, Nadia Nedjah, Ana Maria A. C. Rocha, David Taniar, and Bernady O. Apduhan, 7333:635–48. Lecture Notes in Computer Science. Springer. https://doi.org/10.1007/978-3-642-31125-3\\_48.\n\n\nSkiena, Steven S. 2008. The Algorithm Design Manual. London: Springer. https://doi.org/10.1007/978-1-84800-070-4."
  },
  {
    "objectID": "lectures/18/knapsack.html",
    "href": "lectures/18/knapsack.html",
    "title": "Lecture 16",
    "section": "",
    "text": "0/1 knapsack problem: Given items with defined weights and values, the objective is to maximize total value by selecting items for a knapsack without surpassing a fixed capacity. Each item must be either fully included (1) or excluded (0).\n\n\n\n\n\n\nAttribution: Generated by DALL-E, via ChatGPT (GPT-4), OpenAI, November 10, 2024."
  },
  {
    "objectID": "lectures/18/knapsack.html#problem",
    "href": "lectures/18/knapsack.html#problem",
    "title": "Lecture 16",
    "section": "",
    "text": "0/1 knapsack problem: Given items with defined weights and values, the objective is to maximize total value by selecting items for a knapsack without surpassing a fixed capacity. Each item must be either fully included (1) or excluded (0).\n\n\n\n\n\n\nAttribution: Generated by DALL-E, via ChatGPT (GPT-4), OpenAI, November 10, 2024."
  },
  {
    "objectID": "lectures/18/knapsack.html#utilities",
    "href": "lectures/18/knapsack.html#utilities",
    "title": "Lecture 16",
    "section": "Utilities",
    "text": "Utilities\n\nimport requests\n\ndef read_knapsack_data(url):\n\n    \"\"\"\n    Reads and processes knapsack problem data from a given URL.\n    \n    Args:\n        url (str): The URL pointing to the data file.\n        \n    Returns:\n        values, weights, capacity\n        \n    Raises:\n        Exception: If there is an issue with fetching the data or parsing the content.\n    \"\"\"\n\n    try:\n        # Fetch data from the URL\n        response = requests.get(url)\n        \n        # Raise an error if the request was unsuccessful\n        response.raise_for_status()\n        \n        # Split the data into lines\n        lines = response.text.strip().split('\\n')\n        \n        # Parse the number of items\n        num_items = int(lines[0].strip())\n        \n        # Parse the values and weights lists\n        values = list(map(int, lines[1].strip().split()))\n        weights = list(map(int, lines[2].strip().split()))\n        \n        # Parse the capacity\n        capacity = int(lines[3].strip())\n        \n        # Validate that the number of items matches the length of values and weights\n        if len(values) != num_items or len(weights) != num_items:\n            raise ValueError(\"The number of items does not match the length of values or weights list.\")\n        \n        # Return the values, weights, and capacity\n        return np.array(values), np.array(weights), capacity\n    \n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching data from URL: {e}\")\n        raise\n    except ValueError as e:\n        print(f\"Error processing data: {e}\")\n        raise\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n        raise"
  },
  {
    "objectID": "lectures/18/knapsack.html#greedy-algorithms",
    "href": "lectures/18/knapsack.html#greedy-algorithms",
    "title": "Lecture 16",
    "section": "Greedy Algorithms",
    "text": "Greedy Algorithms\n\n\n\n\n\n\n [@Skiena:2008aa, page 192]\n\n\n\nGreedy algorithms make the decision of what to do next by selecting the best local option from all available choices without regard to the global structure.\n\n\n\nGreedy by weight\nA possible greedy strategy involves selecting items in increasing order of weight until the total exceeds the capacity.\n\ndef greedy_knapsack_weight(weights, values, capacity):\n\n    \"\"\"\n    Greedy algorithm for the 0/1 Knapsack Problem based on weigth.\n\n    Args:\n        weights (np.ndarray): Weights of the items.\n        values (np.ndarray): Values of the items.\n        capacity (int): Capacity of the knapsack.\n\n    Returns:\n        tuple: Selected items (binary array), total value, total weight.\n    \"\"\"\n\n    num_items = len(weights)\n\n    # Create a list of items with their values and original indices\n    items = list(zip(weights, values, range(num_items)))\n\n    # Sort items by weight in increasing order\n    items.sort()\n    \n    total_weight = 0\n    total_value = 0\n    solution = np.zeros(num_items, dtype=int)\n    \n    # Select items based on the sorted order\n    for w, v, idx in items:\n        if total_weight + w &lt;= capacity:\n            solution[idx] = 1\n            total_weight += w\n            total_value += v\n        else:\n            continue  # Skip items that would exceed the capacity\n    \n    return solution, total_value, total_weight\n\n\n\nGreedy by value\nAnother greedy strategy involves selecting items in descending order of value until the total exceeds the capacity.\n\nimport numpy as np\n\ndef greedy_knapsack_value(weights, values, capacity):\n\n    \"\"\"\n    Greedy algorithm for the 0/1 Knapsack Problem based on value.\n\n    Args:\n        weights (np.ndarray): Weights of the items.\n        values (np.ndarray): Values of the items.\n        capacity (int): Capacity of the knapsack.\n\n    Returns:\n        tuple: Selected items (binary array), total value, total weight.\n    \"\"\"\n\n    num_items = len(weights)\n\n    # Create a list of items with their values and original indices\n    items = list(zip(values, weights, range(num_items)))\n\n    # Sort items by value in decreasing order\n    items.sort(reverse=True)\n    \n    total_weight = 0\n    total_value = 0\n    solution = np.zeros(num_items, dtype=int)\n    \n    # Select items based on the sorted order\n    for v, w, idx in items:\n        if total_weight + w &lt;= capacity:\n            solution[idx] = 1\n            total_weight += w\n            total_value += v\n        else:\n            continue  # Skip items that would exceed the capacity\n    \n    return solution, total_value, total_weight\n\n\n\nGreedy by ratio\nBased on value-to-weight ratio.\n\ndef greedy_knapsack_ratio(weights, values, capacity):\n\n    \"\"\"\n    Greedy algorithm for the 0/1 Knapsack Problem based on value-to-weight ratio.\n\n    Args:\n        weights (np.ndarray): Weights of the items.\n        values (np.ndarray): Values of the items.\n        capacity (int): Capacity of the knapsack.\n\n    Returns:\n        tuple: Selected items (binary array), total value, total weight.\n    \"\"\"\n\n    num_items = len(weights)\n\n    # Calculate value-to-weight ratio for each item\n    ratio = values / weights\n\n    # Create a list of items with their ratios and original indices\n    items = list(zip(ratio, values, weights, range(num_items)))\n\n    # Sort items by ratio in decreasing order\n    items.sort(reverse=True)\n    \n    total_weight = 0\n    total_value = 0\n    solution = np.zeros(num_items, dtype=int)\n    \n    # Select items based on the sorted order\n    for r, v, w, idx in items:\n        if total_weight + w &lt;= capacity:\n            solution[idx] = 1\n            total_weight += w\n            total_value += v\n        else:\n            continue  # Skip items that would exceed the capacity\n    \n    return solution, total_value, total_weight"
  },
  {
    "objectID": "lectures/18/knapsack.html#genetic-algorithm",
    "href": "lectures/18/knapsack.html#genetic-algorithm",
    "title": "Lecture 16",
    "section": "Genetic Algorithm",
    "text": "Genetic Algorithm\nSee lecture notes for details.\n\nimport random\n\ndef initialize_population(pop_size, num_items):\n    \"\"\"\n    Initialize the population with random binary strings.\n\n    Args:\n        pop_size (int): Number of individuals in the population.\n        num_items (int): Number of items in the knapsack problem.\n\n    Returns:\n        np.ndarray: Initialized population.\n    \"\"\"\n    return np.random.randint(2, size=(pop_size, num_items))\n\n\ndef evaluate_fitness(population, weights, values, capacity, penalty_factor=10):\n    \"\"\"\n    Evaluate the fitness of each individual in the population.\n\n    Args:\n        population (np.ndarray): Current population.\n        weights (np.ndarray): Weights of the items.\n        values (np.ndarray): Values of the items.\n        capacity (int): Capacity of the knapsack.\n        penalty_factor (float): Penalty factor for exceeding capacity.\n\n    Returns:\n        np.ndarray: Fitness values for the population.\n    \"\"\"\n    total_weights = np.dot(population, weights)\n    total_values = np.dot(population, values)\n    penalties = penalty_factor * np.maximum(0, total_weights - capacity)\n    fitness = total_values - penalties\n    return fitness\n\n\ndef tournament_selection(population, fitness, tournament_size):\n    \"\"\"\n    Select individuals from the population using tournament selection.\n\n    Args:\n        population (np.ndarray): Current population.\n        fitness (np.ndarray): Fitness values of the population.\n        tournament_size (int): Number of individuals in each tournament.\n\n    Returns:\n        np.ndarray: Selected parents.\n    \"\"\"\n    pop_size = population.shape[0]\n    selected_indices = []\n    for _ in range(pop_size):\n        participants = np.random.choice(pop_size, tournament_size, replace=False)\n        best = participants[np.argmax(fitness[participants])]\n        selected_indices.append(best)\n    return population[selected_indices]\n\n\ndef roulette_selection(population, fitness):\n    \"\"\"\n    Select individuals from the population using roulette wheel selection.\n\n    Args:\n        population (np.ndarray): Current population.\n        fitness (np.ndarray): Fitness values of the population.\n\n    Returns:\n        np.ndarray: Selected parents.\n    \"\"\"\n    # Adjust fitness to be non-negative\n    min_fitness = np.min(fitness)\n    adjusted_fitness = fitness - min_fitness + 1e-6  # small epsilon to avoid zero division\n    total_fitness = np.sum(adjusted_fitness)\n    probabilities = adjusted_fitness / total_fitness\n    pop_size = population.shape[0]\n    selected_indices = np.random.choice(pop_size, size=pop_size, p=probabilities)\n    return population[selected_indices]\n\n\ndef single_point_crossover(parents, crossover_rate):\n    \"\"\"\n    Perform single-point crossover on the parents.\n\n    Args:\n        parents (np.ndarray): Selected parents.\n        crossover_rate (float): Probability of crossover.\n\n    Returns:\n        np.ndarray: Offspring after crossover.\n    \"\"\"\n    num_parents, num_genes = parents.shape\n    np.random.shuffle(parents)\n    offspring = []\n    for i in range(0, num_parents, 2):\n        parent1 = parents[i]\n        parent2 = parents[i+1 if i+1 &lt; num_parents else 0]\n        child1 = parent1.copy()\n        child2 = parent2.copy()\n        if np.random.rand() &lt; crossover_rate:\n            point = np.random.randint(1, num_genes)  # Crossover point\n            child1[:point], child2[:point] = parent2[:point], parent1[:point]\n        offspring.append(child1)\n        offspring.append(child2)\n    return np.array(offspring)\n\n\ndef uniform_crossover(parents, crossover_rate):\n    \"\"\"\n    Perform uniform crossover on the parents.\n\n    Args:\n        parents (np.ndarray): Selected parents.\n        crossover_rate (float): Probability of crossover.\n\n    Returns:\n        np.ndarray: Offspring after crossover.\n    \"\"\"\n    num_parents, num_genes = parents.shape\n    np.random.shuffle(parents)\n    offspring = []\n    for i in range(0, num_parents, 2):\n        parent1 = parents[i]\n        parent2 = parents[i+1 if i+1 &lt; num_parents else 0]\n        child1 = parent1.copy()\n        child2 = parent2.copy()\n        if np.random.rand() &lt; crossover_rate:\n            mask = np.random.randint(0, 2, size=num_genes).astype(bool)\n            child1[mask], child2[mask] = parent2[mask], parent1[mask]\n        offspring.append(child1)\n        offspring.append(child2)\n    return np.array(offspring)\n\n\ndef mutation(offspring, mutation_rate):\n    \"\"\"\n    Apply bit-flip mutation to the offspring.\n\n    Args:\n        offspring (np.ndarray): Offspring after crossover.\n        mutation_rate (float): Probability of mutation for each bit.\n\n    Returns:\n        np.ndarray: Offspring after mutation.\n    \"\"\"\n    num_offspring, num_genes = offspring.shape\n    mutation_matrix = np.random.rand(num_offspring, num_genes) &lt; mutation_rate\n    offspring[mutation_matrix] = 1 - offspring[mutation_matrix]\n    return offspring\n\n\ndef elitism(population, fitness, elite_size):\n    \"\"\"\n    Preserve the top-performing individuals in the population.\n\n    Args:\n        population (np.ndarray): Current population.\n        fitness (np.ndarray): Fitness values of the population.\n        elite_size (int): Number of top individuals to preserve.\n\n    Returns:\n        np.ndarray: Elite individuals.\n    \"\"\"\n    elite_indices = np.argsort(fitness)[-elite_size:]  # Get indices of top individuals\n    elites = population[elite_indices]\n    return elites\n\n\ndef genetic_algorithm(weights, values, capacity, pop_size=100, num_generations=200, crossover_rate=0.8,\n                      mutation_rate=0.05, elite_percent=0.02, selection_type='tournament', tournament_size=3,\n                      crossover_type='single_point'):\n    \"\"\"\n    Main function to run the genetic algorithm for the 0/1 knapsack problem.\n\n    Args:\n        weights (np.ndarray): Weights of the items.\n        values (np.ndarray): Values of the items.\n        capacity (int): Capacity of the knapsack.\n        pop_size (int): Population size.\n        num_generations (int): Number of generations.\n        crossover_rate (float): Probability of crossover.\n        mutation_rate (float): Probability of mutation.\n        elite_percent (float): Percentage of elites to preserve.\n        selection_type (str): 'tournament' or 'roulette'.\n        tournament_size (int): Number of individuals in tournament selection.\n        crossover_type (str): 'single_point' or 'uniform'.\n\n    Returns:\n        tuple: Best solution, best value, and best weight found.\n    \"\"\"\n\n    num_items = len(weights)\n    elite_size = max(1, int(pop_size * elite_percent))\n    population = initialize_population(pop_size, num_items)\n\n    average_fitness_history = []\n    best_fitness_history = []\n\n    for generation in range(num_generations):\n        fitness = evaluate_fitness(population, weights, values, capacity)\n\n        # Track average and best fitness\n        average_fitness = np.mean(fitness)\n        best_fitness = np.max(fitness)\n        average_fitness_history.append(average_fitness)\n        best_fitness_history.append(best_fitness)\n\n        # Elitism\n        elites = elitism(population, fitness, elite_size)\n\n        # Selection\n        if selection_type == 'tournament':\n            parents = tournament_selection(population, fitness, tournament_size)\n        elif selection_type == 'roulette':\n            parents = roulette_selection(population, fitness)\n        else:\n            raise ValueError(\"Invalid selection type\")\n\n        # Crossover\n        if crossover_type == 'single_point':\n            offspring = single_point_crossover(parents, crossover_rate)\n        elif crossover_type == 'uniform':\n            offspring = uniform_crossover(parents, crossover_rate)\n        else:\n            raise ValueError(\"Invalid crossover type\")\n\n        # Mutation\n        offspring = mutation(offspring, mutation_rate)\n\n        # Create new population\n        population = np.vstack((elites, offspring))\n\n        # Ensure population size\n        if population.shape[0] &gt; pop_size:\n            population = population[:pop_size]\n        elif population.shape[0] &lt; pop_size:\n            # Add random individuals to fill population\n            num_new_individuals = pop_size - population.shape[0]\n            new_individuals = initialize_population(num_new_individuals, num_items)\n            population = np.vstack((population, new_individuals))\n\n    # After all generations, return the best solution\n    fitness = evaluate_fitness(population, weights, values, capacity)\n    best_index = np.argmax(fitness)\n    best_solution = population[best_index]\n    best_value = np.dot(best_solution, values)\n    best_weight = np.dot(best_solution, weights)\n\n    return best_solution, best_value, best_weight, average_fitness_history, best_fitness_history\n\n\ndef genetic_algorithm_do_n(weights, values, capacity, pop_size=100, num_generations=200, crossover_rate=0.8,\n      mutation_rate=0.05, elite_percent=0.02, selection_type='tournament', tournament_size=3, crossover_type='single_point', repeats=100):\n\n    best_solution = None\n    best_value = -1\n    best_weight = -1\n\n    best_averages = []\n    best_bests = []\n\n    for i in range(repeats):\n\n        solution, value, weight, average_history, best_history = genetic_algorithm(weights, values, capacity, pop_size, num_generations, crossover_rate,\n            mutation_rate, elite_percent, selection_type, tournament_size, crossover_type)\n\n        if value &gt; best_value and weight &lt;= capacity:\n            best_solution = solution\n            best_value = value\n            best_weight = weight\n            best_averages = average_history\n            best_bests = best_history\n\n    return best_solution, best_value, best_weight, best_averages, best_bests"
  },
  {
    "objectID": "lectures/18/knapsack.html#tests",
    "href": "lectures/18/knapsack.html#tests",
    "title": "Lecture 16",
    "section": "Tests",
    "text": "Tests\nTesting our genetic algorithm on data from Google OR-Tools.\n\nimport matplotlib.pyplot as plt\n\ndef test_genetic_algorithm():\n    # Sample data\n\n    values = np.array([\n        360, 83, 59, 130, 431, 67, 230, 52, 93, 125, 670, 892, 600, 38, 48, 147,\n        78, 256, 63, 17, 120, 164, 432, 35, 92, 110, 22, 42, 50, 323, 514, 28,\n        87, 73, 78, 15, 26, 78, 210, 36, 85, 189, 274, 43, 33, 10, 19, 389, 276,\n        312])\n\n    weights = np.array([\n        7, 0, 30, 22, 80, 94, 11, 81, 70, 64, 59, 18, 0, 36, 3, 8, 15, 42, 9, 0,\n        42, 47, 52, 32, 26, 48, 55, 6, 29, 84, 2, 4, 18, 56, 7, 29, 93, 44, 71,\n        3, 86, 66, 31, 65, 0, 79, 20, 65, 52, 13])\n\n    capacity = 850\n\n    # Run genetic algorithm\n    best_solution, best_value, best_weight, avg_fitness, best_fitness = genetic_algorithm_do_n(\n        weights, values, capacity, pop_size=50, num_generations=100,\n        crossover_rate=0.8, mutation_rate=0.05, elite_percent=0.02,\n        selection_type='tournament', tournament_size=3)\n\n    print(\"Best Solution:\", best_solution)\n    print(\"Best Value:\", best_value)\n    print(\"Best Weight:\", best_weight)\n\n    # Plot the fitness over generations\n    generations = range(1, len(avg_fitness) + 1)\n    plt.plot(generations, avg_fitness, label='Average Fitness')\n    plt.plot(generations, best_fitness, label='Best Fitness')\n    plt.xlabel('Generation')\n    plt.ylabel('Fitness')\n    plt.title('Fitness Over Generations')\n    plt.legend()\n    plt.show()\n\ntest_genetic_algorithm()\n\nBest Solution: [1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0\n 0 1 1 0 0 1 0 1 0 0 1 1 1]\nBest Value: 7525\nBest Weight: 845\n\n\n\n\n\n\n\n\n\nTesting all the algorithms on data from pages.mtu.edu/~kreher/cages/data/knapsack/.\n\nimport pandas as pd\n\nBASE_URL = 'https://pages.mtu.edu/~kreher/cages/data/knapsack/'\n\ndatasets = [\n    'ks_8a.dat','ks_8b.dat','ks_8c.dat','ks_8d.dat','ks_8e.dat','ks_12a.dat',\n    'ks_12b.dat','ks_12c.dat','ks_12d.dat','ks_12e.dat','ks_16a.dat','ks_16b.dat',\n    'ks_16c.dat','ks_16d.dat','ks_16e.dat','ks_20a.dat','ks_20b.dat','ks_20c.dat',\n    'ks_20d.dat','ks_20e.dat','ks_24a.dat','ks_24b.dat','ks_24c.dat','ks_24d.dat',\n    'ks_24e.dat'\n]\n\ncolumns = [\n    'file_path', 'capacity', \n    'gw_value', 'gw_weight', \n    'gv_value', 'gw_weight', \n    'gr_value', 'gr_weight', \n    'ga_value', 'ga_weight'\n]\n\ndf = pd.DataFrame(columns=columns)\n\nfor idx, file_path in enumerate(datasets):\n\n  values, weights, capacity = read_knapsack_data(BASE_URL + file_path)\n\n  solution, total_value, total_weight = greedy_knapsack_weight(weights, values, capacity)\n\n  gw_value = total_value\n  gw_weight = total_weight\n\n  solution, total_value, total_weight = greedy_knapsack_value(weights, values, capacity)\n\n  gv_value = total_value\n  gv_weight = total_weight\n\n  solution, total_value, total_weight = greedy_knapsack_ratio(weights, values, capacity)\n\n  gr_value = total_value\n  gr_weight = total_weight\n\n  solution, total_value, total_weight, avg_fitness, best_fitness = genetic_algorithm_do_n(\n        weights, values, capacity, pop_size=50, num_generations=100,\n        crossover_rate=0.8, mutation_rate=0.05, elite_percent=0.02,\n        selection_type='tournament', tournament_size=3, crossover_type='single_point')\n\n  ga_value = total_value\n  ga_weight = total_weight\n\n  df.loc[idx] = [\n    file_path, capacity, \n    gw_value, gw_weight, \n    gv_value, gw_weight, \n    gr_value, gr_weight, \n    ga_value, ga_weight\n  ]\n\ndf.to_csv(\"knapsack.csv\", index=False)\n\nprint(df)\n\n     file_path  capacity  gw_value  gw_weight  gv_value  gw_weight  gr_value  \\\n0    ks_8a.dat   1863633    874414    1803989    925369    1803989    925369   \n1    ks_8b.dat   1822718    724029    1421763    836649    1421763    724029   \n2    ks_8c.dat   1609419    771637    1609296    756847    1609296    713452   \n3    ks_8d.dat   2112292    749458    1558340   1006793    1558340    881823   \n4    ks_8e.dat   2493250   1224805    2386238   1300939    2386238   1300939   \n5   ks_12a.dat   2805213   1180238    2323972   1409053    2323972   1381444   \n6   ks_12b.dat   3259036   1334963    2639964   1681436    2639964   1602435   \n7   ks_12c.dat   2489815    926226    1808471   1152681    1808471   1303224   \n8   ks_12d.dat   3453702   1679959    3406646   1724265    3406646   1858992   \n9   ks_12e.dat   2520392   1277814    2429214   1216398    2429214   1309915   \n10  ks_16a.dat   3780355   1654432    3150713   1886539    3150713   2018230   \n11  ks_16b.dat   4426945   1838356    3601726   2182562    3601726   2170190   \n12  ks_16c.dat   4323280   1741661    3539978   2125245    3539978   2176322   \n13  ks_16d.dat   4450938   2051218    4155271   2189910    4155271   2207441   \n14  ks_16e.dat   3760429   1735397    3442535   1954173    3442535   1967510   \n15  ks_20a.dat   5169647   2558243    5101533   2658865    5101533   2721946   \n16  ks_20b.dat   4681373   2230065    4543967   2419141    4543967   2383424   \n17  ks_20c.dat   5063791   2128763    4361690   2410432    4361690   2723135   \n18  ks_20d.dat   4286641   1870486    3557405   2158431    3557405   2276327   \n19  ks_20e.dat   4476000   2115412    4173744   2159969    4173744   2294511   \n20  ks_24a.dat   6404180   2886589    5845661   3174264    5845661   3393387   \n21  ks_24b.dat   5971071   2961351    5941814   3019080    5941814   3164151   \n22  ks_24c.dat   5870470   2505304    5008038   2830470    5008038   3045772   \n23  ks_24d.dat   5762284   2711513    5247821   3047367    5247821   3135427   \n24  ks_24e.dat   6654569   3278044    6634696   3296337    6634696   3401688   \n\n    gr_weight  ga_value  ga_weight  \n0     1714834    925369    1714834  \n1     1421763        -1         -1  \n2     1422422    771637    1609296  \n3     1682688   1084704    2059405  \n4     2377405   1300939    2377405  \n5     2672179   1468476    2804581  \n6     2953017   1753926    3254705  \n7     2406387   1329478    2458307  \n8     3412958   1858992    3412958  \n9     2477116   1309915    2477116  \n10    3768480   2018230    3768480  \n11    4071350   2311731    4392978  \n12    4054333   2282303    4315302  \n13    4245406   2298302    4422372  \n14    3616049   2030691    3755734  \n15    5054489   2788040    5161352  \n16    4471059   2471511    4676284  \n17    5029940   2723135    5029940  \n18    4273053   2280911    4275282  \n19    4353690   2350457    4471547  \n20    6379172   3393387    6379172  \n21    5911388   3194906    5970122  \n22    5820857   3066886    5848030  \n23    5734259   3150365    5754023  \n24    6435390   3501861    6649161  \n\n\nIn the context of the 25 instances of the 0/1 knapsack problem, the genetic algorithm consistently outperformed the greedy algorithms. Specifically, it achieved solutions that were equivalent to the best greedy algorithm results in 8 cases and surpassed them in 17 cases, with up to 6% improvement."
  },
  {
    "objectID": "lectures/18/knapsack.html#resources",
    "href": "lectures/18/knapsack.html#resources",
    "title": "Lecture 16",
    "section": "Resources",
    "text": "Resources\n\nDEAP is an evolutionary computation framework designed for rapid prototyping and testing of ideas. This environment has been developed at Université Laval since (at least) 2012.\n\nSolving the knapsack problem using DEAP, complete example."
  },
  {
    "objectID": "lectures/18/index.html",
    "href": "lectures/18/index.html",
    "title": "Population-Based Metaheuristics",
    "section": "",
    "text": "Important\n\n\n\nDeadline: Quiz 2 is scheduled for this Wednesday, November 12, 2025, during class. Additional details are available in the FAQ.\nDeadline: Assignment 4 must be submitted no later than December 1, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/18/index.html#prepare",
    "href": "lectures/18/index.html#prepare",
    "title": "Population-Based Metaheuristics",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 115-119"
  },
  {
    "objectID": "lectures/18/index.html#participate",
    "href": "lectures/18/index.html#participate",
    "title": "Population-Based Metaheuristics",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/18/index.html#practice",
    "href": "lectures/18/index.html#practice",
    "title": "Population-Based Metaheuristics",
    "section": "Practice",
    "text": "Practice\n\nGreedy and genetic algorithms for the 0/1 knapsack problem"
  },
  {
    "objectID": "lectures/19/index.html",
    "href": "lectures/19/index.html",
    "title": "Quiz 2",
    "section": "",
    "text": "Important\n\n\n\nDue dates: Quiz 2, today, November 12, 2025."
  },
  {
    "objectID": "lectures/19/index.html#prepare",
    "href": "lectures/19/index.html#prepare",
    "title": "Quiz 2",
    "section": "Prepare",
    "text": "Prepare\n\nFormat: Closed book. Multiple-choice and true/false questions.\nScope: Lectures 10 to 18.\n\nThe numbering corresponds to that used in the URLs, for example, turcotte.xyz/teaching/csi-4506/lectures/07/slides.html is Lecture 7. Consequently, the quiz covers the lectures from October 6 to November 10 inclusively.\n\nContent: Emphasis on conceptual questions rather than intricate technical details (e.g., reshaping a numpy array).\nQuestion Types: Includes code excerpts or diagrams requiring identification of the correct statements.\nNumber of Questions: Expect 25 to 35 questions.\nIn class: You will take the quiz in class on a paper questionnaire, but we will also use Scantron sheets (both). Please arrive on time so that we can start as early as possible (the total time available depends on your arrival time). We must collect all copies 10 minutes before the end of the class to allow the next class to begin on time.\nPencil: Please bring pencils, as we will be using Scantron sheets to facilitate the grading process.\nStudent ID Card: Bring your student ID card.\nProcess: The teaching assistants will assist with proctoring, and we will have multiple attendance sheets to ensure efficiency."
  },
  {
    "objectID": "lectures/20/slides.html#quote-of-the-day",
    "href": "lectures/20/slides.html#quote-of-the-day",
    "title": "Adversarial Search",
    "section": "Quote of the Day",
    "text": "Quote of the Day"
  },
  {
    "objectID": "lectures/20/slides.html#adversarial-search",
    "href": "lectures/20/slides.html#adversarial-search",
    "title": "Adversarial Search",
    "section": "Adversarial Search",
    "text": "Adversarial Search\nThis lecture examines competitive environments where multiple agents have conflicting objectives, resulting in adversarial search problems."
  },
  {
    "objectID": "lectures/20/slides.html#learning-objectives",
    "href": "lectures/20/slides.html#learning-objectives",
    "title": "Adversarial Search",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nExplain zero-sum game concepts\nFormulate never-lose strategies in Tic-Tac-Toe regardless of opponent moves\nUtilize the minimax algorithm to determine optimal moves in adversarial settings\nArticulate how alpha-beta pruning reduces the number of nodes evaluated without affecting outcomes"
  },
  {
    "objectID": "lectures/20/slides.html#search",
    "href": "lectures/20/slides.html#search",
    "title": "Adversarial Search",
    "section": "Search",
    "text": "Search"
  },
  {
    "objectID": "lectures/20/slides.html#types-of-games",
    "href": "lectures/20/slides.html#types-of-games",
    "title": "Adversarial Search",
    "section": "Types of Games",
    "text": "Types of Games\n\nDeterministic or stochastic\nOne, two, or more players\nZero-sum or not\nPerfect information or not"
  },
  {
    "objectID": "lectures/20/slides.html#definition",
    "href": "lectures/20/slides.html#definition",
    "title": "Adversarial Search",
    "section": "Definition",
    "text": "Definition\nZero-sum games are competitive scenarios where one player’s gain is exactly balanced by another player’s loss, resulting in a net change of zero in total wealth or benefit.\n\n\nTic-tac-toe is a zero-sum game."
  },
  {
    "objectID": "lectures/20/slides.html#deterministic-games",
    "href": "lectures/20/slides.html#deterministic-games",
    "title": "Adversarial Search",
    "section": "Deterministic Games",
    "text": "Deterministic Games\n\nStates: \\(S\\) (\\(S_0\\) to \\(S_k\\))\nPlayers: \\(P = {1, N}\\)\nActions: \\(A\\) (depends on \\(P\\) and \\(S\\))\nTransition function: \\(S \\times A \\rightarrow S\\)\nA final state: \\(S_\\mathrm{final}\\)\nReward or utility: \\(S_\\mathrm{final}, p\\)\n\nDevelop a policy \\(S_0 \\rightarrow S_\\mathrm{final}\\)."
  },
  {
    "objectID": "lectures/20/slides.html#what-do-think",
    "href": "lectures/20/slides.html#what-do-think",
    "title": "Adversarial Search",
    "section": "What do think?",
    "text": "What do think?\n\nConsider playing tic-tac-toe.\nCan you ensure a never-lose strategy, irrespective of your opponent’s moves?\nExtend this analysis to games like chess or Go.\n\n\nDoes it matter if you play first or second?\nAnyone who has played tic-tac-toe understands that the first player can adopt a strategy that ensures they never lose.\nIn itself this statement is rather surprising. Why?\nHow many board configurations are there?\n\nEach square can be occupied by X or O or be empty. This leads to \\(3^9= 19,683\\) board configurations.\nAre all these configurations possible in a valid game?\n\nGame progression.\n\nNot all of these configurations are valid game states because they may contain impossible numbers of Xs and Os or may not follow the rules of the game.\nA tic-tac-toe game can end in a win for either player or a draw. The longest game without a winner involves 9 moves (a full board).\nValid games account for the rules that players alternate turns, starting with X.\nHow many valid sequences of moves are there?"
  },
  {
    "objectID": "lectures/20/slides.html#tic-tac-toe",
    "href": "lectures/20/slides.html#tic-tac-toe",
    "title": "Adversarial Search",
    "section": "Tic-Tac-Toe",
    "text": "Tic-Tac-Toe\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s represent the state of a tic-tac-toe game with a numpy array:\n\ncurrent_state = np.full((3, 3), ' ')"
  },
  {
    "objectID": "lectures/20/slides.html#get_valid_moves",
    "href": "lectures/20/slides.html#get_valid_moves",
    "title": "Adversarial Search",
    "section": "get_valid_moves",
    "text": "get_valid_moves\n\ndef get_valid_moves(state):\n\n    size = state.shape[0]\n\n    # Returns a list of available positions\n    moves = []\n    for i in range(size):\n        for j in range(size):\n            if state[i][j] == ' ':\n                moves.append((i, j))\n\n    return moves"
  },
  {
    "objectID": "lectures/20/slides.html#make_move",
    "href": "lectures/20/slides.html#make_move",
    "title": "Adversarial Search",
    "section": "make_move",
    "text": "make_move\n\ndef make_move(state, move, player):\n\n    # Returns a new state after making the move\n    new_state = state.copy()\n    new_state[move] = player\n\n    return new_state"
  },
  {
    "objectID": "lectures/20/slides.html#is_terminal",
    "href": "lectures/20/slides.html#is_terminal",
    "title": "Adversarial Search",
    "section": "is_terminal",
    "text": "is_terminal\n\ndef is_terminal(state):\n\n    # Check rows, columns, and diagonals for a win\n    lines = []\n    lines.extend(state)  # Rows\n    lines.extend(state.T)  # Columns\n    lines.append(np.diagonal(state))  # Main diagonal\n    lines.append(np.diagonal(np.fliplr(state)))  # Anti-diagonal\n\n    for line in lines:\n        if np.all(line == 'X') or np.all(line == 'O'):\n            return True\n\n    # Check for a draw (no empty spaces)\n    if ' ' not in state:\n        return True\n\n    return False"
  },
  {
    "objectID": "lectures/20/slides.html#get_opponent",
    "href": "lectures/20/slides.html#get_opponent",
    "title": "Adversarial Search",
    "section": "get_opponent",
    "text": "get_opponent\n\ndef get_opponent(player):\n    return 'O' if player == 'X' else 'X'"
  },
  {
    "objectID": "lectures/20/slides.html#count_valid_sequences",
    "href": "lectures/20/slides.html#count_valid_sequences",
    "title": "Adversarial Search",
    "section": "count_valid_sequences",
    "text": "count_valid_sequences\n\ndef count_valid_sequences(state, player):\n\n    if is_terminal(state):\n      return 1\n\n    valid_moves = get_valid_moves(state)\n\n    total = 0\n    for move in valid_moves:\n        new_state = make_move(state, move, player)\n        total += count_valid_sequences(new_state, get_opponent(player))\n\n    return total\n\n\n\nThe total number of valid sequences is: 255,168\n\n\n\n\nConsidering the number of valid sequences, it is unsurprising that the first player can adopt a strategy to avoid losing?"
  },
  {
    "objectID": "lectures/20/slides.html#symmetry-digression",
    "href": "lectures/20/slides.html#symmetry-digression",
    "title": "Adversarial Search",
    "section": "Symmetry (digression)",
    "text": "Symmetry (digression)\n\nTic-tac-toe has 8 symmetrical transformations (4 rotations and 4 reflections).\nBy considering these, many game sequences that are different in raw move order become equivalent.\nThe number of unique sequences of moves is 26,830, whereas the number of unique board positions is 765.\n\n\n\nExercise: write a Python program the confirm the above."
  },
  {
    "objectID": "lectures/20/slides.html#search-tree",
    "href": "lectures/20/slides.html#search-tree",
    "title": "Adversarial Search",
    "section": "Search Tree",
    "text": "Search Tree\nThe search tree size for the tic-tac-toe game is relatively small, making it suitable for use as a running example in later discussions.\nHow does this compare to the search trees for chess and Go?"
  },
  {
    "objectID": "lectures/20/slides.html#search-tree-1",
    "href": "lectures/20/slides.html#search-tree-1",
    "title": "Adversarial Search",
    "section": "Search Tree",
    "text": "Search Tree\n\nChess: \\(35^{80} \\sim 10^{123}\\)\nGo: \\(361! \\sim 10^{768}\\)\n\n\n\nChess:\nChess has a relatively small board (\\(8 \\times 8\\)) but a variety of pieces with different movement capabilities.\nOn average, each position has about 35 legal moves.\nConsidering an average game length of 80 ply (a ply is a half-move, so 40 moves per player), the total games are estimated using the formula: \\(35^{80} \\sim 10^{123}\\), adjusted down to account for illegal and redundant positions.\nGo:\nGo is played on a \\(19 \\times 19\\) board, providing 361 points where stones can be placed. Accordingly, the total number of games is \\(361! \\sim 10^{768}\\).\n\n\nThe estimated number of atoms in the observable universe is around \\(10^{78}\\) to \\(10^{82}\\)."
  },
  {
    "objectID": "lectures/20/slides.html#definition-1",
    "href": "lectures/20/slides.html#definition-1",
    "title": "Adversarial Search",
    "section": "Definition",
    "text": "Definition\nOptimal play involves executing the best possible move at each step to maximize winning chances or outcomes.\nIn perfect information games like tic-tac-toe or chess, it requires anticipating the opponent’s moves and choosing actions that enhance one’s position or minimize losses.\n\nWhen both players employ optimal strategies, the outcome—win, loss, or draw—is dictated by the game’s inherent mechanics and initial conditions.\nPerfect information refers to a feature of certain games or decision-making scenarios where all players have complete and accurate knowledge of the entire game state at all times. This includes full visibility of all actions taken previously and no hidden elements or randomness affecting the game’s progression. In games with perfect information, such as chess or tic-tac-toe, players can make fully informed decisions based on the entire history and current status of the game, allowing for strategies that can be planned several moves ahead."
  },
  {
    "objectID": "lectures/20/slides.html#two-move-game",
    "href": "lectures/20/slides.html#two-move-game",
    "title": "Adversarial Search",
    "section": "Two-Move Game",
    "text": "Two-Move Game\n\n\n\n\n\n\nTwo-Move is a hypothetical game involving two players, designed to facilitate discussions on the minimax algorithm."
  },
  {
    "objectID": "lectures/20/slides.html#game-setup",
    "href": "lectures/20/slides.html#game-setup",
    "title": "Adversarial Search",
    "section": "Game Setup",
    "text": "Game Setup\n\nThe game starts with a single decision point for Player 1, who has two possible moves: \\(A\\) and \\(B\\).\nEach of these moves leads to a decision point for Player 2, who also has two possible responses: \\(C\\) and \\(D\\).\nThe game ends after Player 2’s move, resulting in a terminal state with predefined scores."
  },
  {
    "objectID": "lectures/20/slides.html#search-tree-2",
    "href": "lectures/20/slides.html#search-tree-2",
    "title": "Adversarial Search",
    "section": "Search Tree",
    "text": "Search Tree\n\nRoot Node: Represents the initial state before Player 1’s move.\nPly 1: Player 1 chooses between moves \\(A\\) and \\(B\\).\nPly 2: For each of Player 1’s moves, Player 2 chooses between moves \\(C\\) and \\(D\\).\nLeaf Nodes: Each branch’s endpoint is a terminal state with an associated score."
  },
  {
    "objectID": "lectures/20/slides.html#scores",
    "href": "lectures/20/slides.html#scores",
    "title": "Adversarial Search",
    "section": "Scores",
    "text": "Scores\n\n\\((A, C)\\) results in a score of 3.\n\\((A, D)\\) results in a score of 5.\n\\((B, C)\\) results in a score of 2.\n\\((B, D)\\) results in a score of 1.\n\n\n\nPlayer 1 wants to maximize its score."
  },
  {
    "objectID": "lectures/20/slides.html#strategy",
    "href": "lectures/20/slides.html#strategy",
    "title": "Adversarial Search",
    "section": "Strategy",
    "text": "Strategy\n\n\n\n\n\n\n\n\nWhat should be player 2’s strategy and why?"
  },
  {
    "objectID": "lectures/20/slides.html#strategy-1",
    "href": "lectures/20/slides.html#strategy-1",
    "title": "Adversarial Search",
    "section": "Strategy",
    "text": "Strategy\n\n\n\n\n\n\n\n\n\nFor move \\(A\\):\n\nPlayer 2 can choose \\(C\\) (score = 3) or \\(D\\) (score = 5); they choose \\(C\\) (minimizing to 3).\n\nFor move \\(B\\):\n\nPlayer 2 can choose \\(C\\) (score = 2) or \\(D\\) (score = 1); they choose \\(D\\) (minimizing to 1)."
  },
  {
    "objectID": "lectures/20/slides.html#strategy-2",
    "href": "lectures/20/slides.html#strategy-2",
    "title": "Adversarial Search",
    "section": "Strategy",
    "text": "Strategy\n\n\n\n\n\n\n\n\nWhat should now be the strategy for Player 1?"
  },
  {
    "objectID": "lectures/20/slides.html#strategy-3",
    "href": "lectures/20/slides.html#strategy-3",
    "title": "Adversarial Search",
    "section": "Strategy",
    "text": "Strategy\n\n\n\n\n\n\n\n\nPlayer 1, being the maximizer, will choose move \\(A\\), as it leads to the higher score of 3 after Player 2 minimizes."
  },
  {
    "objectID": "lectures/20/slides.html#minimax",
    "href": "lectures/20/slides.html#minimax",
    "title": "Adversarial Search",
    "section": "Minimax",
    "text": "Minimax\n\nPlayer 1 is the maximizing player, seeking the highest score.\nPlayer 2 is the minimizing player, seeking the lowest score.\n\nEvaluation:\n\nPlayer 2 evaluates the potential outcomes for each of their moves and chooses the least favorable outcome for Player 1.\nPlayer 1 then evaluates these outcomes, choosing the move that maximizes their minimum guaranteed score."
  },
  {
    "objectID": "lectures/20/slides.html#minimax-search",
    "href": "lectures/20/slides.html#minimax-search",
    "title": "Adversarial Search",
    "section": "Minimax Search",
    "text": "Minimax Search"
  },
  {
    "objectID": "lectures/20/slides.html#minimax-search-1",
    "href": "lectures/20/slides.html#minimax-search-1",
    "title": "Adversarial Search",
    "section": "Minimax Search",
    "text": "Minimax Search\nThe minimax algorithm operates by exploring all possible moves in a game tree, evaluating the outcomes to minimize the possible loss for a worst-case scenario. At each node:\n\nMaximizing Player’s Turn: Choose the move with the highest possible value.\nMinimizing Player’s Turn: Choose the move with the lowest possible value.\n\nBy backtracking from the terminal nodes to the root, the algorithm selects the move that maximizes the player’s minimum gain, effectively anticipating and countering the opponent’s best strategies."
  },
  {
    "objectID": "lectures/20/slides.html#minimax-search-2",
    "href": "lectures/20/slides.html#minimax-search-2",
    "title": "Adversarial Search",
    "section": "Minimax Search",
    "text": "Minimax Search\n\n\n\n\n\n\n\nAttribution: (Russell and Norvig 2020, fig. 5.3)"
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-first-4-minutes",
    "href": "lectures/20/slides.html#walkthrough-first-4-minutes",
    "title": "Adversarial Search",
    "section": "Walkthrough (first 4 minutes)",
    "text": "Walkthrough (first 4 minutes)\n\n\n\nWatch the first 5m 20s of the video.\nThe video introduces a variant of the minimax algorithm that includes a maximum depth parameter, enabling the algorithm to terminate at a user-specified depth. This approach is essential for games with extensive search spaces, such as chess and Go. However, it necessitates a reliable method for evaluating the current state, referred to as static evaluation in the video.\n\n\nAttribution: Sebastian Lague"
  },
  {
    "objectID": "lectures/20/slides.html#base",
    "href": "lectures/20/slides.html#base",
    "title": "Adversarial Search",
    "section": "Base",
    "text": "Base\n\n# Base class for the game\nclass Game:\n    def __init__(self):\n        pass\n\n    def get_valid_moves(self, state):\n        pass\n\n    def make_move(self, state, move, player):\n        pass\n\n    def is_terminal(self, state):\n        pass\n\n    def evaluate(self, state):\n        pass\n\n    def display(self, state):\n        pass\n\n    def get_opponent(self, player):\n        pass"
  },
  {
    "objectID": "lectures/20/slides.html#tic-tac-toe-1",
    "href": "lectures/20/slides.html#tic-tac-toe-1",
    "title": "Adversarial Search",
    "section": "Tic-Tac-Toe",
    "text": "Tic-Tac-Toe\n\n# Tic-Tac-Toe game class\nclass TicTacToe(Game):\n\n    def __init__(self):\n        self.size = 3\n        self.board = np.full((self.size, self.size), ' ')\n\n    def get_valid_moves(self, state):\n        # Returns a list of available positions\n        moves = []\n        for i in range(self.size):\n            for j in range(self.size):\n                if state[i][j] == ' ':\n                    moves.append((i, j))\n        return moves\n\n    def make_move(self, state, move, player):\n        # Returns a new state after making the move\n        new_state = state.copy()\n        new_state[move] = player\n        return new_state\n\n    def is_terminal(self, state):\n\n        # Check rows, columns, and diagonals for a win\n        lines = []\n        lines.extend(state)  # Rows\n        lines.extend(state.T)  # Columns\n        lines.append(np.diagonal(state))  # Main diagonal\n        lines.append(np.diagonal(np.fliplr(state)))  # Anti-diagonal\n\n        for line in lines:\n            if np.all(line == 'X') or np.all(line == 'O'):\n                return True\n\n        # Check for a draw (no empty spaces)\n        if ' ' not in state:\n            return True\n\n        return False\n\n    def evaluate(self, state):\n\n        # Simple evaluation function\n        lines = []\n        lines.extend(state)  # Rows\n        lines.extend(state.T)  # Columns\n        lines.append(np.diagonal(state))  # Main diagonal\n        lines.append(np.diagonal(np.fliplr(state)))  # Anti-diagonal\n\n        for line in lines:\n            if np.all(line == 'X'):\n                return 1  # X wins\n            if np.all(line == 'O'):\n                return -1  # O wins\n\n        return 0  # Draw or ongoing\n\n    def display(self, state):\n\n        display_tic_tac_toe(state, title=None)\n\n    def get_opponent(self, player):\n        return 'O' if player == 'X' else 'X'"
  },
  {
    "objectID": "lectures/20/slides.html#minimax-1",
    "href": "lectures/20/slides.html#minimax-1",
    "title": "Adversarial Search",
    "section": "Minimax",
    "text": "Minimax\n\nimport math\n\ndef minimax(game, state, depth, player, maximizing_player):\n\n    if game.is_terminal(state) or depth == 0:\n        return game.evaluate(state), None\n\n    valid_moves = game.get_valid_moves(state)\n    best_move = None\n\n    if maximizing_player:\n        max_eval = -math.inf\n        for move in valid_moves:\n            new_state = game.make_move(state, move, player)\n            eval_score, _ = minimax(game, new_state, depth - 1, game.get_opponent(player), False)\n            if eval_score &gt; max_eval:\n                max_eval = eval_score\n                best_move = move\n        return max_eval, best_move\n    else:\n        min_eval = math.inf\n        for move in valid_moves:\n            new_state = game.make_move(state, move, player)\n            eval_score, _ = minimax(game, new_state, depth - 1, game.get_opponent(player), True)\n            if eval_score &lt; min_eval:\n                min_eval = eval_score\n                best_move = move\n        return min_eval, best_move"
  },
  {
    "objectID": "lectures/20/slides.html#run",
    "href": "lectures/20/slides.html#run",
    "title": "Adversarial Search",
    "section": "Run",
    "text": "Run\n\ndef test_tic_tac_toe():\n\n    game = TicTacToe()\n    current_state = game.board.copy()\n    player = 'X'\n    maximizing_player=True\n\n    # Simulate a game\n    while not game.is_terminal(current_state):\n\n        game.display(current_state)\n\n        _, move = minimax(game, current_state, depth=9, player=player, maximizing_player=maximizing_player)\n\n        if move is None:\n            print(\"Game Over!\")\n            break\n\n        current_state = game.make_move(current_state, move, player)\n\n        player = game.get_opponent(player)\n        maximizing_player = not maximizing_player\n\n    game.display(current_state)\n    result = game.evaluate(current_state)\n    if result == 1:\n        print(\"X wins!\")\n    elif result == -1:\n        print(\"O wins!\")\n    else:\n        print(\"It's a draw!\")"
  },
  {
    "objectID": "lectures/20/slides.html#run-12",
    "href": "lectures/20/slides.html#run-12",
    "title": "Adversarial Search",
    "section": "Run (1/2)",
    "text": "Run (1/2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt's a draw!\nElapsed time: 22.929095 seconds"
  },
  {
    "objectID": "lectures/20/slides.html#faster-execution-digression",
    "href": "lectures/20/slides.html#faster-execution-digression",
    "title": "Adversarial Search",
    "section": "Faster Execution (digression)",
    "text": "Faster Execution (digression)\n\nIs test_tic_tac_toe slower than expected?\nDo you see an area for improvement?"
  },
  {
    "objectID": "lectures/20/slides.html#caching",
    "href": "lectures/20/slides.html#caching",
    "title": "Adversarial Search",
    "section": "Caching",
    "text": "Caching\n\ndef memoize_minimax(f):\n\n    cache = {}\n\n    def wrapper(game, state, depth, player, maximizing_player):\n\n        state_key = tuple(map(tuple, state)) # hashable state\n        key = (state_key, depth, player, maximizing_player)\n\n        if key in cache:\n            return cache[key]\n\n        result = f(game, state, depth, player, maximizing_player)\n        cache[key] = result\n\n        return result\n\n    return wrapper"
  },
  {
    "objectID": "lectures/20/slides.html#caching-1",
    "href": "lectures/20/slides.html#caching-1",
    "title": "Adversarial Search",
    "section": "Caching",
    "text": "Caching\n\n@memoize_minimax\ndef minimax(game, state, depth, player, maximizing_player):\n\n    # The minimax code remains the same, without any cache handling\n    if game.is_terminal(state) or depth == 0:\n        return game.evaluate(state), None\n\n    valid_moves = game.get_valid_moves(state)\n    best_move = None\n\n    if maximizing_player:\n        max_eval = -math.inf\n        for move in valid_moves:\n            new_state = game.make_move(state, move, player)\n            eval_score, _ = minimax(game, new_state, depth - 1, game.get_opponent(player), False)\n            if eval_score &gt; max_eval:\n                max_eval = eval_score\n                best_move = move\n        return max_eval, best_move\n    else:\n        min_eval = math.inf\n        for move in valid_moves:\n            new_state = game.make_move(state, move, player)\n            eval_score, _ = minimax(game, new_state, depth - 1, game.get_opponent(player), True)\n            if eval_score &lt; min_eval:\n                min_eval = eval_score\n                best_move = move\n        return min_eval, best_move"
  },
  {
    "objectID": "lectures/20/slides.html#run-22",
    "href": "lectures/20/slides.html#run-22",
    "title": "Adversarial Search",
    "section": "Run (2/2)",
    "text": "Run (2/2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt's a draw!\nElapsed time: 0.576714 seconds"
  },
  {
    "objectID": "lectures/20/slides.html#lower-predictability-digression",
    "href": "lectures/20/slides.html#lower-predictability-digression",
    "title": "Adversarial Search",
    "section": "Lower Predictability (digression)",
    "text": "Lower Predictability (digression)\n\nimport random\n\nclass TicTacToe(Game):\n\n    def get_valid_moves(self, state):\n        # Returns a list of available positions\n        moves = []\n        for i in range(self.size):\n            for j in range(self.size):\n                if state[i][j] == ' ':\n                    moves.append((i, j))\n\n        return random.shuffle(moves)\n\n    # All the other methods stay the same\n\n\n\nWe are randomizing the order of moves prior to returning them. However, the optimal move for a given configuration will remain fixed, if solutions are cached.\n\n\nGames can become monotonous if you quickly discern patterns in your opponent’s strategy, such as consistently choosing moves in a specific sequence."
  },
  {
    "objectID": "lectures/20/slides.html#exploration",
    "href": "lectures/20/slides.html#exploration",
    "title": "Adversarial Search",
    "section": "Exploration",
    "text": "Exploration\n\nCompare the reduction in execution time achieved through symmetry considerations versus caching techniques. Evaluate the combined effect of both approaches.\nDevelop a Connect Four game implementation employing a minimax search algorithm.\nConnect Four is symmetric across its vertical axis. Develop a new implementation that leverages this symmetry.\n\n\n\nSee also: Connect 4: Principles and Techniques"
  },
  {
    "objectID": "lectures/20/slides.html#remark",
    "href": "lectures/20/slides.html#remark",
    "title": "Adversarial Search",
    "section": "Remark",
    "text": "Remark\nThe number of valid sequences of actions grows factorially, with particularly large growth observed in games like chess and Go."
  },
  {
    "objectID": "lectures/20/slides.html#pruning",
    "href": "lectures/20/slides.html#pruning",
    "title": "Adversarial Search",
    "section": "Pruning",
    "text": "Pruning\nTo enhance the efficiency of the minimax algorithm, one could possibly prune certain parts of the search tree, thereby avoiding the exploration of descendant nodes."
  },
  {
    "objectID": "lectures/20/slides.html#pruning-1",
    "href": "lectures/20/slides.html#pruning-1",
    "title": "Adversarial Search",
    "section": "Pruning",
    "text": "Pruning\nHow would you implement this modification? What factors would you take into account?"
  },
  {
    "objectID": "lectures/20/slides.html#pruning-2",
    "href": "lectures/20/slides.html#pruning-2",
    "title": "Adversarial Search",
    "section": "Pruning",
    "text": "Pruning\nTree pruning should be performed only when it can be demonstrated that those subtrees cannot yield better solutions.\n\n\nBut how?"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning",
    "href": "lectures/20/slides.html#criteria-for-pruning",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nBased on Algorithms Explained – minimax and alpha-beta pruning by Sebastian Lague."
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-1",
    "href": "lectures/20/slides.html#criteria-for-pruning-1",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-2",
    "href": "lectures/20/slides.html#criteria-for-pruning-2",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-3",
    "href": "lectures/20/slides.html#criteria-for-pruning-3",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-4",
    "href": "lectures/20/slides.html#criteria-for-pruning-4",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-5",
    "href": "lectures/20/slides.html#criteria-for-pruning-5",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\nWe know that the value of node c is at least 5, since c is a maximizing node.\nNode a is minimizing node and has to choose between 3 (node b) and at least 5 (node c). No matter what we find in node d does not matter, node a will choose 3."
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-6",
    "href": "lectures/20/slides.html#criteria-for-pruning-6",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nLet us continue briefly."
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-7",
    "href": "lectures/20/slides.html#criteria-for-pruning-7",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nLet us continue briefly."
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-8",
    "href": "lectures/20/slides.html#criteria-for-pruning-8",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nThis is a maximizing node; therefore, we will assign it the value of -4.\n\n\nWhat value should be assigned to the node indicated by the arrow?"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-9",
    "href": "lectures/20/slides.html#criteria-for-pruning-9",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-10",
    "href": "lectures/20/slides.html#criteria-for-pruning-10",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nThe node marked by an arrow presents an interesting scenario.\nCan you work out its value?"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-11",
    "href": "lectures/20/slides.html#criteria-for-pruning-11",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nWhat do we know?"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-12",
    "href": "lectures/20/slides.html#criteria-for-pruning-12",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nSuppose the right child of node c contains the value 5. Would you assign 5 to node c? Certainly not. As a minimizing node, node c will have a value no greater than -4.\n\n\nCan I say that the maximum value for node c is -4?"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-13",
    "href": "lectures/20/slides.html#criteria-for-pruning-13",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nExploring the right child of node c might reveal a value lower than -4. Does this matter?"
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-14",
    "href": "lectures/20/slides.html#criteria-for-pruning-14",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\nNode a is a maximizing node. From node b, it ascertains a minimum achievable value of 3.\nNode c is a minimizing node. From node d, it determines that the maximum value it can return is -4.\nConsequently, node a will always select node b, regardless of the value stored in node c, since the value of c will not exceed -4.\nEven if node c, as a minimizing node, discovers an extremely low value (e.g., -100) by exploring its right child, node a, being a maximizing node, will still opt for node b."
  },
  {
    "objectID": "lectures/20/slides.html#criteria-for-pruning-15",
    "href": "lectures/20/slides.html#criteria-for-pruning-15",
    "title": "Adversarial Search",
    "section": "Criteria for Pruning",
    "text": "Criteria for Pruning\n\n\n\n\n\n\n\nThe decisions made by players 1 and 2 remain unchanged with or without pruning. However, pruning reduces the number of nodes visited."
  },
  {
    "objectID": "lectures/20/slides.html#alph-beta-pruning",
    "href": "lectures/20/slides.html#alph-beta-pruning",
    "title": "Adversarial Search",
    "section": "Alph-Beta Pruning",
    "text": "Alph-Beta Pruning\nAlpha-beta pruning is an optimization technique for the minimax algorithm that reduces the number of nodes evaluated in the search tree."
  },
  {
    "objectID": "lectures/20/slides.html#alph-beta-pruning-1",
    "href": "lectures/20/slides.html#alph-beta-pruning-1",
    "title": "Adversarial Search",
    "section": "Alph-Beta Pruning",
    "text": "Alph-Beta Pruning\nIt achieves this by eliminating branches that cannot possibly influence the final decision, using two parameters:\n\nalpha, the maximum score that the maximizing player is assured, and\nbeta, the minimum score that the minimizing player is assured."
  },
  {
    "objectID": "lectures/20/slides.html#maximizing-players-perspective",
    "href": "lectures/20/slides.html#maximizing-players-perspective",
    "title": "Adversarial Search",
    "section": "Maximizing Player’s Perspective",
    "text": "Maximizing Player’s Perspective\nAt a maximizing node:\n\nThe maximizer aims to maximize the score.\nAlpha (\\(\\alpha\\)) is updated to the highest value found so far among child nodes.\nProcess:\n\nInitialize \\(\\alpha = -\\infty\\).\nFor each child node:\n\nCompute the evaluation score.\nUpdate \\(\\alpha = \\max(\\alpha, \\mathrm{child\\_score})\\)."
  },
  {
    "objectID": "lectures/20/slides.html#minimizing-players-perspective",
    "href": "lectures/20/slides.html#minimizing-players-perspective",
    "title": "Adversarial Search",
    "section": "Minimizing Player’s Perspective",
    "text": "Minimizing Player’s Perspective\nAt a minimizing node:\n\nThe minimizer aims to minimize the score.\nBeta (\\(\\beta\\)) is updated to the lowest value found so far among child nodes.\nProcess:\n\nInitialize \\(\\beta = \\infty\\).\nFor each child node:\n\nCompute the evaluation score.\nUpdate \\(\\beta = \\min(\\beta, \\mathrm{child\\_score})\\)."
  },
  {
    "objectID": "lectures/20/slides.html#alph-beta-pruning-2",
    "href": "lectures/20/slides.html#alph-beta-pruning-2",
    "title": "Adversarial Search",
    "section": "Alph-Beta Pruning",
    "text": "Alph-Beta Pruning\nWhen a node’s evaluation proves it cannot improve on the current alpha or beta, further exploration of that branch is halted, thereby enhancing computational efficiency without affecting the outcome."
  },
  {
    "objectID": "lectures/20/slides.html#role-of-alpha-and-beta-in-pruning",
    "href": "lectures/20/slides.html#role-of-alpha-and-beta-in-pruning",
    "title": "Adversarial Search",
    "section": "Role of Alpha and Beta in Pruning",
    "text": "Role of Alpha and Beta in Pruning\nPruning Condition:\n\nIf \\(\\beta \\leq \\alpha\\), further exploration of the current node’s siblings is unnecessary.\nRationale:\n\nThe maximizer has a guaranteed score of at least \\(\\alpha\\).\nThe minimizer can ensure that the maximizer cannot get a better score than \\(\\beta\\).\nIf \\(\\beta \\leq \\alpha\\), the maximizer won’t find a better option in this branch."
  },
  {
    "objectID": "lectures/20/slides.html#alpha-beta-search",
    "href": "lectures/20/slides.html#alpha-beta-search",
    "title": "Adversarial Search",
    "section": "Alpha-Beta Search",
    "text": "Alpha-Beta Search\n\n\n\n\n\n\n\nAttribution: (Russell and Norvig 2020, fig. 5.7)"
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-621-to-810",
    "href": "lectures/20/slides.html#walkthrough-621-to-810",
    "title": "Adversarial Search",
    "section": "Walkthrough (6:21 to 8:10)",
    "text": "Walkthrough (6:21 to 8:10)\n\n\n\nAttribution: Sebastian Lague. Start watching at 6m 21s."
  },
  {
    "objectID": "lectures/20/slides.html#node-order",
    "href": "lectures/20/slides.html#node-order",
    "title": "Adversarial Search",
    "section": "Node Order",
    "text": "Node Order\n\nThe effectiveness of pruning is influenced by the order in which nodes are evaluated.\nGreater pruning is achieved if nodes are ordered from most to least promising.\n\n\n\nRefer to: Shannon (1959) for a discussion within the context of chess."
  },
  {
    "objectID": "lectures/20/slides.html#alpha-beta-search-1",
    "href": "lectures/20/slides.html#alpha-beta-search-1",
    "title": "Adversarial Search",
    "section": "Alpha-Beta Search",
    "text": "Alpha-Beta Search\n\n# Minimax algorithm with Alpha-Beta Pruning\n\ndef alpha_beta_search(game, state, depth, player, alpha, beta, maximizing_player):\n\n    \"\"\"\n    Minimax algorithm with alpha-beta pruning.\n\n    :param game: The game instance.\n    :param state: The current game state.\n    :param depth: The maximum depth to search.\n    :param player: The current player ('X' or 'O').\n    :param alpha: The best value that the maximizer currently can guarantee at that level or above.\n    :param beta: The best value that the minimizer currently can guarantee at that level or above.\n    :param maximizing_player: True if the current move is for the maximizer.\n    :return: A tuple of (evaluation score, best move).\n    \"\"\""
  },
  {
    "objectID": "lectures/20/slides.html#alpha-beta-search-2",
    "href": "lectures/20/slides.html#alpha-beta-search-2",
    "title": "Adversarial Search",
    "section": "Alpha-Beta Search",
    "text": "Alpha-Beta Search\n\n    # Base case: check for terminal state or maximum depth\n\n    if game.is_terminal(state) or depth == 0:\n        score = game.evaluate(state)\n        return score, None  # Return the evaluation score and no move\n\n    valid_moves = game.get_valid_moves(state)\n    best_move = None  # Initialize the best move\n\n\n\nThe base case is identical to that of the minimax algorithm."
  },
  {
    "objectID": "lectures/20/slides.html#alpha-beta-search-3",
    "href": "lectures/20/slides.html#alpha-beta-search-3",
    "title": "Adversarial Search",
    "section": "Alpha-Beta Search",
    "text": "Alpha-Beta Search\n\n    if maximizing_player:\n\n        max_eval = -math.inf  # Initialize maximum evaluation\n\n        for move in valid_moves:\n\n            # Simulate the move\n            new_state = game.make_move(state, move, player)\n\n            # Recursive call to alpha_beta_search for the minimizing player\n            eval_score, _ = alpha_beta_search(game, new_state, depth - 1, game.get_opponent(player), alpha, beta, False)\n\n            if eval_score &gt; max_eval:\n                max_eval = eval_score  # Update maximum evaluation\n                best_move = move       # Update best move\n\n            alpha = max(alpha, eval_score)  # Update alpha\n\n            if beta &lt;= alpha:\n                break  # Beta cut-off (prune the remaining branches)\n\n        return max_eval, best_move"
  },
  {
    "objectID": "lectures/20/slides.html#alpha-beta-search-4",
    "href": "lectures/20/slides.html#alpha-beta-search-4",
    "title": "Adversarial Search",
    "section": "Alpha-Beta Search",
    "text": "Alpha-Beta Search\n\n    else:\n\n        min_eval = math.inf  # Initialize minimum evaluation\n\n        for move in valid_moves:\n\n            # Simulate the move\n            new_state = game.make_move(state, move, player)\n\n            # Recursive call to alpha_beta_search for the maximizing player\n            eval_score, _ = alpha_beta_search(game, new_state, depth - 1, game.get_opponent(player), alpha, beta, True)\n\n            if eval_score &lt; min_eval:\n                min_eval = eval_score  # Update minimum evaluation\n                best_move = move       # Update best move\n\n            beta = min(beta, eval_score)  # Update beta\n\n            if beta &lt;= alpha:\n                break  # Alpha cut-off (prune the remaining branches)\n\n        return min_eval, best_move"
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough",
    "href": "lectures/20/slides.html#walkthrough",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nMaximizing nodes update the alpha values, while minimizing nodes update the beta values."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-1",
    "href": "lectures/20/slides.html#walkthrough-1",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nThe values of \\(\\alpha\\) and \\(\\beta\\) are initially set to \\(-\\infty\\) and \\(\\infty\\), respectively. The recursive calls continue traversing the tree until the leftmost node is reached."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-2",
    "href": "lectures/20/slides.html#walkthrough-2",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nThe value of \\(\\alpha\\) is updated to -1."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-3",
    "href": "lectures/20/slides.html#walkthrough-3",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nUpdating \\(\\alpha\\) to 3."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-4",
    "href": "lectures/20/slides.html#walkthrough-4",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nUpdating \\(\\beta\\) from \\(\\infty\\) to 3. Passing those values to the right child."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-5",
    "href": "lectures/20/slides.html#walkthrough-5",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nUpdating \\(\\alpha\\) from \\(-\\infty\\) to 5. We now have \\(\\beta \\le \\alpha\\)."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-6",
    "href": "lectures/20/slides.html#walkthrough-6",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nThe right child is not visited. The parent (a minimizer) has a better option (\\(\\beta\\)) than \\(\\alpha\\)."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-7",
    "href": "lectures/20/slides.html#walkthrough-7",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nReturning from the recursive calls, the root node receives a value of 3 from its left child and updates its \\(\\alpha\\) to 3, which exceeds its initial value of \\(-\\infty\\)."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-8",
    "href": "lectures/20/slides.html#walkthrough-8",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nNow traversing the right subtree from the root. Upon reaching left-most maximizing node of the right subtree, \\(\\alpha\\) is not updated since -6 and -4 are less than 3."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-9",
    "href": "lectures/20/slides.html#walkthrough-9",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\n\\(\\beta\\) is now updated to -4. We now have that \\(\\beta \\le \\alpha\\)."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-10",
    "href": "lectures/20/slides.html#walkthrough-10",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nThe right child is pruned."
  },
  {
    "objectID": "lectures/20/slides.html#walkthrough-11",
    "href": "lectures/20/slides.html#walkthrough-11",
    "title": "Adversarial Search",
    "section": "Walkthrough",
    "text": "Walkthrough\n\n\n\n\n\n\n\nThe maximizing player knows that its best move has a value of 3 (going left)."
  },
  {
    "objectID": "lectures/20/slides.html#summmary",
    "href": "lectures/20/slides.html#summmary",
    "title": "Adversarial Search",
    "section": "Summmary",
    "text": "Summmary\n\n\n\n\n\n\nAlpha Cutoff: Occurs at minimizer nodes when \\(\\beta \\le \\alpha\\).\nBeta Cutoff: Occurs at maximizer nodes when \\(\\alpha \\ge \\beta\\).\n\n\n\nPruning at Both Node Types:\n\nPruning can occur during both the minimization and maximization phases. This means that both minimizer and maximizer nodes can be pruned if certain conditions are met.\n\nUpdating Alpha and Beta:\n\nAt maximizer nodes, the algorithm updates the alpha value to the maximum of its current value and the value of the child nodes evaluated so far.\nAt minimizer nodes, the algorithm updates the beta value to the minimum of its current value and the value of the child nodes evaluated so far.\n\nPruning Conditions:\n\nAt Maximizer Nodes:\n\nIf alpha becomes greater than or equal to beta (\\(\\alpha \\ge \\beta\\)), further exploration of the current node’s descendants can be stopped. This is because the minimizer (opponent) can force the outcome to be no better than beta, so the maximizer cannot improve the result beyond this point.\nThis is often referred to as a beta cutoff because the value of beta is causing the pruning at a maximizer node.\n\nAt Minimizer Nodes:\n\nIf beta becomes less than or equal to alpha (\\(\\beta \\le \\alpha\\)), the algorithm can prune the remaining child nodes of the minimizer node. This is because the maximizer can force a result of at least alpha, so the minimizer cannot find a better (lower) outcome.\nThis is known as an alpha cutoff because the value of alpha is causing the pruning at a minimizer node.\n\n\nProcess of Pruning:\n\nThe pruning occurs not when alpha or beta are updated, but when the pruning condition (\\(\\alpha \\ge \\beta\\) at maximizer nodes or \\(\\beta \\le \\alpha\\) at minimizer nodes) is met.\nOnce these conditions are satisfied, the algorithm knows that further exploration will not yield a better outcome, and thus it can safely prune those branches.\n\n\nSummary:\n\nAlpha Cutoff: Occurs at minimizer nodes when \\(\\beta \\le \\alpha\\).\nBeta Cutoff: Occurs at maximizer nodes when \\(\\alpha \\ge \\beta\\).\nWhy Pruning Occurs:\n\nIn both cases, the pruning occurs because further exploration cannot influence the final decision. The opponent can force the game into a situation that’s no better than the current evaluation.\n\nImpact on Algorithm Efficiency:\n\nBy implementing these cutoffs, the alpha-beta pruning algorithm reduces the number of nodes that need to be evaluated compared to the standard minimax algorithm, thus improving efficiency without affecting the outcome."
  },
  {
    "objectID": "lectures/20/slides.html#minimax-vs.-alpha-beta-pruning",
    "href": "lectures/20/slides.html#minimax-vs.-alpha-beta-pruning",
    "title": "Adversarial Search",
    "section": "Minimax vs. Alpha-Beta Pruning",
    "text": "Minimax vs. Alpha-Beta Pruning\n\nGrasping why alpha-beta pruning boosts minimax efficiency without altering outcomes requires careful thought.\nThe algorithm changes are minimal.\nIs the enhancement justified?"
  },
  {
    "objectID": "lectures/20/slides.html#minimax-vs.-alpha-beta-pruning-1",
    "href": "lectures/20/slides.html#minimax-vs.-alpha-beta-pruning-1",
    "title": "Adversarial Search",
    "section": "Minimax vs. Alpha-Beta Pruning",
    "text": "Minimax vs. Alpha-Beta Pruning\n\n\nNumber of sequences explored by the Minimax Search algorithm: 255,168\n\nNumber of sequences explored by the Alpha-Beta Search algorithm: 7,330\n\nA 97.13% reduction in the number of the sequences visited!"
  },
  {
    "objectID": "lectures/20/slides.html#exploration-1",
    "href": "lectures/20/slides.html#exploration-1",
    "title": "Adversarial Search",
    "section": "Exploration",
    "text": "Exploration\nImplement a Connect Four game using the Alpha-Beta Search algorithm. Conduct a comparative analysis between the Minimax and Alpha-Beta Search implementations."
  },
  {
    "objectID": "lectures/20/slides.html#further-exploration",
    "href": "lectures/20/slides.html#further-exploration",
    "title": "Adversarial Search",
    "section": "Further exploration",
    "text": "Further exploration\n\nExpetimax search: handling players that are not perfect;\nExpectiminimax: handling chance in games such as backgammon."
  },
  {
    "objectID": "lectures/20/slides.html#summary",
    "href": "lectures/20/slides.html#summary",
    "title": "Adversarial Search",
    "section": "Summary",
    "text": "Summary\n\nIntroduction to adversarial search\nZero-sum games\nIntroduction to the minimax search method\nRole of alpha and beta pruning in minimax search\n\n\n\nIntroduction to Adversarial Search:\n\nExploration of competitive environments with conflicting objectives.\n\nClassification of Games:\n\nTypes based on determinism (deterministic vs. stochastic).\nNumber of players (one, two, or more).\nNature of competition (zero-sum vs. non-zero-sum).\nAvailability of information (perfect vs. imperfect information).\n\nZero-Sum Games:\n\nDefinition and characteristics.\nExample: Tic-Tac-Toe as a zero-sum game.\n\nDeterministic Games Framework:\n\nComponents: states, players, actions, transition functions, final states, rewards.\nDevelopment of policies from initial to final states.\n\nGame Strategies and Complexity:\n\nAnalysis of never-lose strategies in Tic-Tac-Toe.\nDiscussion on the impact of move order (first or second player).\nExploration of game complexity in Tic-Tac-Toe, Chess, and Go.\n\nOptimal Play and Perfect Information:\n\nConcepts of optimal strategies and their implications.\nImportance of perfect information in game theory.\n\nMinimax Algorithm:\n\nIntroduction to the minimax search method.\nApplication in determining optimal moves in adversarial games.\nImplementation details with a Python example for Tic-Tac-Toe.\n\nEfficiency Improvements:\n\nUse of caching (memoization) to enhance algorithm performance.\nReduction of computational overhead in game search trees.\n\nPruning Techniques:\n\nIntroduction to pruning in search trees to avoid unnecessary computations.\nDetailed explanation of Alpha-Beta pruning.\nCriteria for pruning and walkthrough examples illustrating the process.\n\nAlpha-Beta Pruning:\n\nIntegration with the minimax algorithm.\nRole of alpha and beta parameters in optimizing search.\nImpact on the number of nodes evaluated.\n\nPerformance Comparison:\n\nAnalysis of node exploration between minimax and alpha-beta pruning.\nQuantitative demonstration of efficiency gains.\n\nNode Ordering and Pruning Effectiveness:\n\nDiscussion on how node evaluation order affects pruning success.\nStrategies for ordering nodes to maximize pruning potential."
  },
  {
    "objectID": "lectures/20/slides.html#next-lecture",
    "href": "lectures/20/slides.html#next-lecture",
    "title": "Adversarial Search",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will look at the Monte Carlo Tree Search (MCTS) algorithm"
  },
  {
    "objectID": "lectures/20/slides.html#references",
    "href": "lectures/20/slides.html#references",
    "title": "Adversarial Search",
    "section": "References",
    "text": "References\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nShannon, Claude E. 1959. “Programming a Computer Playing Chess.” Philosophical Magazine Ser.7, 41 (312)."
  },
  {
    "objectID": "lectures/20/index.html",
    "href": "lectures/20/index.html",
    "title": "Adversarial Search",
    "section": "",
    "text": "Important\n\n\n\nFor detailed information regarding the evaluation of CSI 4106, please refer to the course evaluation webpage. The evaluation period for the Fall 2024 term is scheduled from November 17 to November 28.\nDeadline: Assignment 4 must be submitted no later than December 1, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/20/index.html#prepare",
    "href": "lectures/20/index.html#prepare",
    "title": "Adversarial Search",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 146-156"
  },
  {
    "objectID": "lectures/20/index.html#participate",
    "href": "lectures/20/index.html#participate",
    "title": "Adversarial Search",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/21/slides.html#quote-of-the-day",
    "href": "lectures/21/slides.html#quote-of-the-day",
    "title": "Monte Carlo Tree Search",
    "section": "Quote of the Day",
    "text": "Quote of the Day\n\n\n\n\n\n\n\nAlibaba has recently introduced a large-scale reasoning model named Marco-o1. This model employs Monte Carlo Tree Search (MCTS) to expand the solution space and devise innovative reasoning strategies.\n\n\nhuggingface.co/AIDC-AI/Marco-o1 or ollama.com/library/marco-o1"
  },
  {
    "objectID": "lectures/21/slides.html#learning-objectives",
    "href": "lectures/21/slides.html#learning-objectives",
    "title": "Monte Carlo Tree Search",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nExplain the concept and key steps of Monte Carlo Tree Search (MCTS).\nCompare MCTS with other search algorithms like BFS, DFS, A*, Simulated Annealing, and Genetic Algorithms.\nAnalyze how MCTS balances exploration and exploitation using the UCB1 formula.\nImplement MCTS in practical applications such as Tic-Tac-Toe."
  },
  {
    "objectID": "lectures/21/slides.html#monte-carlo-tree-search-mcts",
    "href": "lectures/21/slides.html#monte-carlo-tree-search-mcts",
    "title": "Monte Carlo Tree Search",
    "section": "Monte Carlo Tree Search (MCTS)",
    "text": "Monte Carlo Tree Search (MCTS)\nIn the introductory lecture on state space search, I used Monte Carlo Tree Search (MCTS), a key component of AlphaGo, to exemplify the role of search algorithms in reasoning.\nToday, we conclude this series by examining the implementation details of this algorithm."
  },
  {
    "objectID": "lectures/21/slides.html#applications",
    "href": "lectures/21/slides.html#applications",
    "title": "Monte Carlo Tree Search",
    "section": "Applications",
    "text": "Applications\n\nDe novo drug design\nElectronic circuit routing\nLoad monitoring in smart grids\nLane keeping and overtaking tasks\nMotion planning in autonomous driving\nEven solving the travelling salesman problem\n\n\n\nThe paper by Kemmerling and colleagues (Kemmerling, Lütticke, and Schmitt 2024) illustrates the wide range of applications for MCTS when combined with deep neural networks.\n\n\nSee: Kemmerling, Lütticke, and Schmitt (2024)"
  },
  {
    "objectID": "lectures/21/slides.html#historical-notes",
    "href": "lectures/21/slides.html#historical-notes",
    "title": "Monte Carlo Tree Search",
    "section": "Historical Notes",
    "text": "Historical Notes\n\n2008: the algorithm is introduced in the context of AI game (Chaslot et al. 2008)\n2016: the algorithm is combined with deep neural networks to create AlphaGo (Silver et al. 2016)"
  },
  {
    "objectID": "lectures/21/slides.html#definition",
    "href": "lectures/21/slides.html#definition",
    "title": "Monte Carlo Tree Search",
    "section": "Definition",
    "text": "Definition\nA Monte Carlo algorithm is a computational method that uses random sampling to obtain numerical results, often used for optimization, numerical integration, and probability distribution estimation.\nIt is characterized by its ability to handle complex problems with probabilistic solutions, trading exactness for efficiency and scalability."
  },
  {
    "objectID": "lectures/21/slides.html#algorithm",
    "href": "lectures/21/slides.html#algorithm",
    "title": "Monte Carlo Tree Search",
    "section": "Algorithm",
    "text": "Algorithm\n\nSelection (tree traversal)\nNode expansion\nRollout (simulation)\nBack-propagation"
  },
  {
    "objectID": "lectures/21/slides.html#algorithm-1",
    "href": "lectures/21/slides.html#algorithm-1",
    "title": "Monte Carlo Tree Search",
    "section": "Algorithm",
    "text": "Algorithm\n\n\n\n\n\n\n\nAttribution: Russell and Norvig (2020), Figure 5.11"
  },
  {
    "objectID": "lectures/21/slides.html#discussion",
    "href": "lectures/21/slides.html#discussion",
    "title": "Monte Carlo Tree Search",
    "section": "Discussion",
    "text": "Discussion\nLike other algorithms previously discussed, such as BFS, DFS, and \\(A^\\star\\), Monte Carlo Tree Search (MCTS) maintains a frontier of unexpanded nodes.\n\nExamining the relationship between MCTS and previous search algorithms offers valuable insights into their similarities and differences, providing an excellent opportunity to synthesize key concepts."
  },
  {
    "objectID": "lectures/21/slides.html#discussion-1",
    "href": "lectures/21/slides.html#discussion-1",
    "title": "Monte Carlo Tree Search",
    "section": "Discussion",
    "text": "Discussion\nSimilar to \\(A^\\star\\), Monte Carlo Tree Search (MCTS) employs a heuristic, referred to as a policy, to determine the optimal node for expansion.\nHowever, in \\(A^\\star\\), the heuristic is typically a static function estimating cost to a goal, whereas in MCTS, the “policy” involves dynamic evaluation.\n\nBy “static evaluation,” we mean a function that yields the same result for a given state, irrespective of the moment the function is called within the program’s execution."
  },
  {
    "objectID": "lectures/21/slides.html#discussion-2",
    "href": "lectures/21/slides.html#discussion-2",
    "title": "Monte Carlo Tree Search",
    "section": "Discussion",
    "text": "Discussion\nSimilar to Simulated Annealing and Genetic Algorithms, Monte Carlo Tree Search (MCTS) incorporates a mechanism to balance exploration and exploitation."
  },
  {
    "objectID": "lectures/21/slides.html#discussion-3",
    "href": "lectures/21/slides.html#discussion-3",
    "title": "Monte Carlo Tree Search",
    "section": "Discussion",
    "text": "Discussion\n\nMCTS leverages all visited nodes in its decision-making process, unlike \\(A^\\star\\), which primarily focuses on the current frontier.\nAdditionally, MCTS iteratively updates the value of its nodes based on simulations, whereas \\(A^\\star\\) typically uses a static heuristic.\n\n\n\nThe effectiveness of MCTS in selecting promising nodes increases with longer execution time."
  },
  {
    "objectID": "lectures/21/slides.html#discussion-4",
    "href": "lectures/21/slides.html#discussion-4",
    "title": "Monte Carlo Tree Search",
    "section": "Discussion",
    "text": "Discussion\nIn contrast to previous algorithms with implicit search trees, MCTS constructs an explicit tree structure during execution.\n\n\nWhile previous algorithms often imply a search tree structure without explicitly constructing it, MCTS explicitly builds and maintains a tree structure during execution.\nThis explicit tree is used to record the outcomes of simulations and guide decision-making.\nThe explicit tree tracks visited states and their evaluations, while the implicit aspect refers to the expansion of the tree during simulations.\n\n\nAs we will explore, MCTS maintains both explicit and implicit representations of the search tree."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through",
    "href": "lectures/21/slides.html#walk-through",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nAdapted from: Monte Carlo Tree Search by John Levine posted on YouTube on 2017-03-06."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-1",
    "href": "lectures/21/slides.html#walk-through-1",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nEach node keeps track of the number of visits (\\(n\\)) and a total score (\\(t\\)).\n\\(S_0\\) is the initial state."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-2",
    "href": "lectures/21/slides.html#walk-through-2",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nAdding the available actions, \\(a_1\\) and \\(a_2\\), as well as the corresponding states, \\(S_1\\) and \\(S_2\\)."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-3",
    "href": "lectures/21/slides.html#walk-through-3",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n1.1 Start of the first iteration: Selection Step."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-4",
    "href": "lectures/21/slides.html#walk-through-4",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n1.1 The UCB1 score of \\(S_1\\) and \\(S_2\\) are both \\(\\infty\\) since \\(n_1 = n_2 = 0\\).\nWe can select the either node."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-5",
    "href": "lectures/21/slides.html#walk-through-5",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n1.1 We reached a leaf node, \\(S_1\\)."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-6",
    "href": "lectures/21/slides.html#walk-through-6",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n1.2 Node expansion. This node has not been visited yet. Therefore, no expansion."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-7",
    "href": "lectures/21/slides.html#walk-through-7",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n1.3 A rollout (simulation) is simply randomly selecting actions until a terminal node is found."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-8",
    "href": "lectures/21/slides.html#walk-through-8",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n1.4 Back-propagation."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-9",
    "href": "lectures/21/slides.html#walk-through-9",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nEnd of iteration 1."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-10",
    "href": "lectures/21/slides.html#walk-through-10",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n2.1 Selection. Computing the UCB1 value of \\(S_1 = 20 + 2 \\sqrt{\\frac{\\ln(1)}{1}}\\) and \\(S_2  = \\infty\\).\nWe select \\(S_2\\)."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-11",
    "href": "lectures/21/slides.html#walk-through-11",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n2.2 Expansion. This node has not been visited yet. Therefore, no expansion."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-12",
    "href": "lectures/21/slides.html#walk-through-12",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n2.3 Rollout."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-13",
    "href": "lectures/21/slides.html#walk-through-13",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n2.4 Back-propagation."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-14",
    "href": "lectures/21/slides.html#walk-through-14",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nEnd of iteration 2."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-15",
    "href": "lectures/21/slides.html#walk-through-15",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n3.1 Selection. Calculating UCB1 values."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-16",
    "href": "lectures/21/slides.html#walk-through-16",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n3.1 Selection.\nComputing the UCB1 value of \\(S_1 = 20 + 2 \\sqrt{\\frac{\\ln(2)}{1}} = 21.67\\) and \\(S_2  = 10 + 2 \\sqrt{\\frac{\\ln(2)}{1}} = 11.67\\).\nSelecting \\(S_1\\)"
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-17",
    "href": "lectures/21/slides.html#walk-through-17",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n3.2 Node expansion."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-18",
    "href": "lectures/21/slides.html#walk-through-18",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n3.2 Node expansion. Since \\(n_1 \\gt 0\\), the node is expanded."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-19",
    "href": "lectures/21/slides.html#walk-through-19",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n3.3 Rollout."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-20",
    "href": "lectures/21/slides.html#walk-through-20",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n3.4 Back-propagation."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-21",
    "href": "lectures/21/slides.html#walk-through-21",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nEnd of iteration 3."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-22",
    "href": "lectures/21/slides.html#walk-through-22",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n4.1 Selection. Calculating UCB1 values."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-23",
    "href": "lectures/21/slides.html#walk-through-23",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nComputing the UCB1 value of \\(S_1 = \\frac{20}{2} + 2 \\sqrt{\\frac{\\ln(3)}{2}} = 10 + 2 \\sqrt{\\frac{\\ln(3)}{2}} = 11.48\\) and \\(S_2  == 10 + 2 \\sqrt{\\frac{\\ln(3)}{1}} = 12.10\\).\nSelecting \\(S_2\\)"
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-24",
    "href": "lectures/21/slides.html#walk-through-24",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n4.2 Expansion."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-25",
    "href": "lectures/21/slides.html#walk-through-25",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n4.2 Expansion. Both nodes have the same USCB1 value, \\(\\infty\\).\nSelecting \\(S_6\\)."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-26",
    "href": "lectures/21/slides.html#walk-through-26",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n4.3 Rollout."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-27",
    "href": "lectures/21/slides.html#walk-through-27",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\n4.4 Back-propagation."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-28",
    "href": "lectures/21/slides.html#walk-through-28",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nEnd of iteration 4."
  },
  {
    "objectID": "lectures/21/slides.html#walk-through-29",
    "href": "lectures/21/slides.html#walk-through-29",
    "title": "Monte Carlo Tree Search",
    "section": "Walk-through",
    "text": "Walk-through\n\n\n\n\n\n\n\nIn applications such as chess, Go, or Atari games, MCTS conducts 1000 to 2000 simulations per move. This seemingly low count is attributed to the use of deep learning algorithms, which direct the search through tree and default policies.\nEach set of iterations, for instance, 1000, is utilized solely to determine the subsequent optimal move.\nDuring the initial iterations, MCTS operates with limited information for selecting the next best move. As iterations increase, the estimates become more refined.\nThe number of nodes in a search tree after 1000 iterations of MCTS depends on several factors, including the branching factor at each node and the specific policy used for node expansion. Generally, each iteration of MCTS consists of four main steps: selection, expansion, simulation, and backpropagation. During the expansion phase, a new node is added to the tree.\nIn a typical MCTS setup:\n\nSelection: Traverse the existing tree from the root to a leaf node using a tree policy, often based on Upper Confidence Bounds for Trees (UCT).\nExpansion: Add one or more child nodes to the selected node if it is not fully expanded.\nSimulation: Perform a simulation from the new node to a terminal state.\nBackpropagation: Update the value estimates of the traversed nodes based on the simulation result.\n\nAssuming that each iteration expands exactly one new node, the search tree will have approximately 1000 additional nodes after 1000 iterations. However, the actual number can vary if multiple nodes are expanded per iteration or due to the tree’s initial setup and other variations in the algorithm’s implementation.\n\n\nIf the algorithm halts at this stage, it will recommend \\(a_2\\) as the optimal move, given that \\(S_2\\) possesses the highest average score."
  },
  {
    "objectID": "lectures/21/slides.html#russell-and-norvig",
    "href": "lectures/21/slides.html#russell-and-norvig",
    "title": "Monte Carlo Tree Search",
    "section": "Russell and Norvig",
    "text": "Russell and Norvig\n\n\n\n\n\n\n\nThis example includes a significantly larger number of nodes, which may aid in comprehending the selection step more effectively.\nThe algorithm seeks to navigate toward the most promising area of the tree, characterized by the highest average score, and subsequently expands this section of the search tree.\nObserve that the backpropagation step updates all nodes along the path from the selected node to the root. This update can influence the path chosen in the subsequent iteration.\n\n\nAttribution: Russell and Norvig (2020), Figure 5.10"
  },
  {
    "objectID": "lectures/21/slides.html#summary-1",
    "href": "lectures/21/slides.html#summary-1",
    "title": "Monte Carlo Tree Search",
    "section": "Summary (1)",
    "text": "Summary (1)\nInitially, the tree has one node, it is \\(S_0\\).\nWe add its descendants and we are ready to start.\nThe Monte Carlo Tree Search slowly builds its search tree."
  },
  {
    "objectID": "lectures/21/slides.html#summary-2",
    "href": "lectures/21/slides.html#summary-2",
    "title": "Monte Carlo Tree Search",
    "section": "Summary (2)",
    "text": "Summary (2)\nWith each iteration, the following steps occur:\n\nSelection: Identify the optimal node by traversing a single path in the tree, guided by UCB1.\nExpansion: Expand the node if it is a leaf in the MCTS Tree and \\(n \\gt 0\\).\nRollout: Simulate a game from the current state to a terminal state by randomly selecting actions.\nBackpropagation: Use the obtained information to update the current node and all parent nodes up to the root."
  },
  {
    "objectID": "lectures/21/slides.html#summary-3",
    "href": "lectures/21/slides.html#summary-3",
    "title": "Monte Carlo Tree Search",
    "section": "Summary (3)",
    "text": "Summary (3)\nEach node records its total score and visit count.\nThis information is used to calculate a value that guides tree traversal, balancing exploration and exploitation."
  },
  {
    "objectID": "lectures/21/slides.html#summary-4",
    "href": "lectures/21/slides.html#summary-4",
    "title": "Monte Carlo Tree Search",
    "section": "Summary (4)",
    "text": "Summary (4)\n\\[\n\\mathrm{UCB1}(S_i) = \\overline{V_i} + C \\sqrt{\\frac{\\ln(N)}{n_i}}\n\\]\nThe usual value for \\(C\\) is \\(\\sqrt{2}\\).\nExploration essentially occurs when two nodes have approximately the same average score, then MCTS favours nodes with fewer visits (dividing by \\(n\\)).\nFor \\(n \\lt \\ln(N)\\), the value of the ratio is greater than 1, whereas for \\(n \\gt \\ln(N)\\), the ratio becomes less than 1.\nSo there is a small fraction of the time where exploration kicks in. But even then, the contribution of the ratio is quite tame, we’re taking the square root of that ratio, multiplied by \\(\\sqrt{2} \\sim 1.414213562\\)."
  },
  {
    "objectID": "lectures/21/slides.html#summary-5",
    "href": "lectures/21/slides.html#summary-5",
    "title": "Monte Carlo Tree Search",
    "section": "Summary (5)",
    "text": "Summary (5)\n\n\n\n\n\n\n\n\n\n[4.60517019 6.90775528 9.21034037]"
  },
  {
    "objectID": "lectures/21/slides.html#summary-5-1",
    "href": "lectures/21/slides.html#summary-5-1",
    "title": "Monte Carlo Tree Search",
    "section": "Summary (5)",
    "text": "Summary (5)\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnum_iterations = 10\n\n# Define the range for n and N\nn_values = np.arange(1, num_iterations + 1)\nN_values = np.arange(1, num_iterations + 1)\n\n# Prepare a meshgrid for n and N\nN, n = np.meshgrid(N_values, n_values)\n\n# Compute the expression for each pair (n, N)\nZ = np.sqrt(2) * np.sqrt(np.log(N) / n)\n\n# Plotting\nplt.figure(figsize=(8, 6))\nplt.contourf(N, n, Z, cmap='viridis')\nplt.colorbar(label=r'$\\sqrt{2} \\times \\sqrt{\\frac{\\log{N}}{n}}$')\nplt.xlabel('N')\nplt.ylabel('n')\nplt.title(r'Visualization of $\\sqrt{2} \\times \\sqrt{\\frac{\\log{N}}{n}}$ for $n, N = 1..\\mathrm{num\\_iterations}$')\nplt.show()"
  },
  {
    "objectID": "lectures/21/slides.html#summary-5-2",
    "href": "lectures/21/slides.html#summary-5-2",
    "title": "Monte Carlo Tree Search",
    "section": "Summary (5)",
    "text": "Summary (5)\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnum_iterations = 100\n\n# Define the range for n and N\nn_values = np.arange(1, num_iterations + 1)\nN_values = np.arange(1, num_iterations + 1)\n\n# Prepare a meshgrid for n and N\nN, n = np.meshgrid(N_values, n_values)\n\n# Compute the expression for each pair (n, N)\nZ = np.sqrt(2) * np.sqrt(np.log(N) / n)\n\n# Plotting\nplt.figure(figsize=(8, 6))\nplt.contourf(N, n, Z, cmap='viridis')\nplt.colorbar(label=r'$\\sqrt{2} \\times \\sqrt{\\frac{\\log{N}}{n}}$')\nplt.xlabel('N')\nplt.ylabel('n')\nplt.title(r'Visualization of $\\sqrt{2} \\times \\sqrt{\\frac{\\log{N}}{n}}$ for $n, N = 1..\\mathrm{num\\_iterations}$')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nOrigin of UCB1 in MCTS:\nThe Upper Confidence Bound 1 (UCB1) formula originates from the multi-armed bandit problem, a classic problem in reinforcement learning and decision theory. In this problem, a gambler must decide which arm of multiple slot machines to pull to maximize their total reward, balancing the exploration of less-known machines and the exploitation of machines known to provide high rewards.\nThe UCB1 algorithm was developed to address this exploration-exploitation dilemma by providing a statistical upper bound on the expected reward of each action (or arm). In the context of Monte Carlo Tree Search (MCTS), UCB1 is adapted to guide the selection of nodes during the Selection phase, helping the algorithm decide which node to explore next.\nUnderstanding the UCB1 Formula:\nThe UCB1 formula used in MCTS is:\n\\[\n\\text{UCB1}(i) = \\overline{X}_i + C \\sqrt{\\frac{\\ln N}{n_i}}\n\\]\n\n\\(\\overline{X}_i\\): The average reward (value) of node \\(i\\) (exploitation term).\n\\(C\\): A constant parameter that balances exploration and exploitation (commonly set to \\(\\sqrt{2}\\)).\n\\(N\\): The total number of simulations or visits to the parent node.\n\\(n_i\\): The number of times node \\(i\\) has been visited.\n\nComponents Explained:\n\nExploitation Term (\\(\\overline{X}_i\\)): Represents the average reward obtained from node \\(i\\), encouraging the selection of nodes with higher known rewards.\nExploration Term (\\(C \\sqrt{\\frac{\\ln N}{n_i}}\\)): Provides a bonus to nodes that have been visited less frequently, encouraging the exploration of less-visited nodes.\n\nBalancing Exploration and Exploitation:\n\nExploitation: Favors nodes with high average rewards.\nExploration: Favors nodes that have been visited less, to gather more information.\n\nThe exploration term decreases as \\(n_i\\) increases, meaning that as a node is visited more often, the incentive to explore it further diminishes. Conversely, nodes with fewer visits receive a higher exploration bonus.\nWhy Exploration Occurs When Average Scores Are Similar:\nHere’s why:\n\nSimilar Average Rewards (\\(\\overline{X}_i\\)): When nodes have comparable exploitation values, the exploration term becomes the deciding factor in the UCB1 value.\nInfluence of the Exploration Term:\n\nLess-Visited Nodes: Have a higher exploration term due to smaller \\(n_i\\), increasing their UCB1 value.\nWell-Visited Nodes: Have a lower exploration term, as \\(n_i\\) is larger.\n\nResult: The algorithm is more likely to select less-explored nodes when the average rewards are similar, promoting exploration to potentially discover better outcomes.\n\nMathematical Insight:\n\nWhen \\(\\overline{X}_i\\) values are equal, the UCB1 formula simplifies to comparing the exploration terms.\nThe node with the smaller \\(n_i\\) (less visited) will have a larger exploration term due to the \\(\\frac{1}{\\sqrt{n_i}}\\) relationship.\nAs \\(N\\) increases (more total simulations), the exploration bonus diminishes logarithmically, ensuring that the algorithm eventually favors exploitation.\n\nVisualizing the Exploration Term:\nTo further understand how exploration is encouraged:\n\nExploration Term Behavior:\n\nEarly Stages (\\(n_i\\) is small): Exploration term is significant, promoting the exploration of all nodes.\nLater Stages (\\(n_i\\) increases): Exploration term decreases, and nodes with higher average rewards are preferred.\n\nLogarithmic Growth:\n\nThe \\(\\ln N\\) term grows slowly, meaning that the exploration bonus reduces over time unless \\(n_i\\) remains low.\n\n\nConclusion:\nThe UCB1 formula in MCTS effectively balances exploration and exploitation by:\n\nUsing the average reward to exploit known good nodes.\nIncorporating the exploration term to ensure that less-visited nodes are explored, especially when their average rewards are similar to others.\nAdapting over time, so the algorithm initially explores widely but gradually focuses on the most promising nodes as more information is gathered.\n\nIn summary, the UCB1 formula originates from the need to solve the exploration-exploitation dilemma in the multi-armed bandit problem and is integral to MCTS’s ability to efficiently search large decision spaces. The exploration primarily occurs when nodes have similar average scores because the exploration term then plays a crucial role in differentiating between them, guiding the algorithm to potentially unexplored but promising areas of the search space.\nAdditional Resources:\n\nResearch Papers:\n\nAuer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time Analysis of the Multiarmed Bandit Problem. Machine Learning.\nKocsis, L., & Szepesvári, C. (2006). Bandit Based Monte-Carlo Planning. ECML.\n\nFurther Reading:\n\nMonte Carlo Tree Search Tutorial\nUnderstanding UCB1 and MCTS"
  },
  {
    "objectID": "lectures/21/slides.html#tic-tac-toe",
    "href": "lectures/21/slides.html#tic-tac-toe",
    "title": "Monte Carlo Tree Search",
    "section": "Tic-tac-toe",
    "text": "Tic-tac-toe\n\n# Game class for Tic-Tac-Toe\nclass TicTacToe:\n    def __init__(self):\n        # Initialize the 3x3 board with empty spaces\n        self.size = 3\n        self.board = np.full((self.size, self.size), ' ')\n\n    def get_valid_moves(self, state):\n        \"\"\"\n        Return a list of available positions on the board.\n        \"\"\"\n        moves = [(i, j) for i in range(self.size) for j in range(self.size) if state[i][j] == ' ']\n        return moves\n\n    def make_move(self, state, move, player):\n        \"\"\"\n        Place the player's symbol on the board at the specified move.\n        Return the new state.\n        \"\"\"\n        new_state = state.copy()\n        new_state[move[0], move[1]] = player\n        return new_state\n\n    def get_opponent(self, player):\n        \"\"\"\n        Return the opponent of the given player.\n        \"\"\"\n        return 'O' if player == 'X' else 'X'\n\n    def is_terminal(self, state):\n        \"\"\"\n        Check if the game has ended, either by win or draw.\n        \"\"\"\n        return self.evaluate(state) != 0 or ' ' not in state\n\n    def evaluate(self, state):\n        \"\"\"\n        Evaluate the board state.\n        Return:\n            1 if 'X' wins,\n            -1 if 'O' wins,\n            0 otherwise (draw or ongoing game).\n        \"\"\"\n        lines = []\n\n        # Rows and columns\n        for i in range(self.size):\n            lines.append(state[i, :])      # Row i\n            lines.append(state[:, i])      # Column i\n\n        # Diagonals\n        lines.append(np.diag(state))\n        lines.append(np.diag(np.fliplr(state)))\n\n        # Check for a winner\n        for line in lines:\n            if np.all(line == 'X'):\n                return 1\n            elif np.all(line == 'O'):\n                return -1\n\n        # No winner\n        return 0\n\n    def display(self, state):\n        \"\"\"\n        Print the board to the console.\n        \"\"\"\n        print(\"\\nCurrent board:\")\n        for i in range(self.size):\n            row = '|'.join(state[i])\n            print(row)\n            if i &lt; self.size - 1:\n                print('-' * (self.size * 2 - 1))"
  },
  {
    "objectID": "lectures/21/slides.html#node",
    "href": "lectures/21/slides.html#node",
    "title": "Monte Carlo Tree Search",
    "section": "Node",
    "text": "Node\n\n# Node class for MCTS\nclass Node:\n    def __init__(self, state, parent=None, move=None, player='X'):\n        self.state = state            # Game state at this node\n        self.parent = parent          # Parent node\n        self.children = []            # List of child nodes\n        self.visits = 0               # Number of times node has been visited\n        self.wins = 0                 # Number of wins from this node\n        self.move = move              # Move that led to this node\n        self.player = player          # Player who made the move\n\n    def is_fully_expanded(self, game):\n\n        \"\"\"\n        Check if all possible moves from this node have been explored.\n        \"\"\"\n\n        return len(self.children) == len(game.get_valid_moves(self.state))\n\n    def best_child(self, c_param=math.sqrt(2)):\n\n        \"\"\"\n        Select the child node with the highest UCB1 value.\n        \"\"\"\n\n        choices_weights = []\n        for child in self.children:\n            if child.visits == 0:\n                ucb1 = float('inf')\n            else:\n                win_rate = child.wins / child.visits\n                exploration = c_param * math.sqrt((2 * math.log(self.visits)) / child.visits)\n                ucb1 = win_rate + exploration\n            choices_weights.append(ucb1)\n\n        return self.children[np.argmax(choices_weights)]\n\n    def most_visited_child(self):\n\n        \"\"\"\n        Select the child node with the highest visit count.\n        \"\"\"\n\n        visits = [child.visits for child in self.children]\n        return self.children[np.argmax(visits)]"
  },
  {
    "objectID": "lectures/21/slides.html#mcts",
    "href": "lectures/21/slides.html#mcts",
    "title": "Monte Carlo Tree Search",
    "section": "mcts",
    "text": "mcts\n\n# MCTS Algorithm\ndef mcts(game, root, iterations):\n\n    for _ in range(iterations):\n        node = tree_policy(game, root)\n        reward = default_policy(game, node.state, node.player)\n        backup(node, reward)\n\n    return root.most_visited_child()\n\ndef tree_policy(game, node):\n\n    \"\"\"\n    Selection and Expansion phases.\n    \"\"\"\n\n    while not game.is_terminal(node.state):\n        if not node.is_fully_expanded(game):\n            return expand(game, node)\n        else:\n            node = node.best_child()\n\n    return node\n\ndef expand(game, node):\n\n    \"\"\"\n    Expand a child node from the current node.\n    \"\"\"\n\n    tried_moves = [child.move for child in node.children]\n    possible_moves = game.get_valid_moves(node.state)\n\n    for move in possible_moves:\n        if move not in tried_moves:\n            next_state = game.make_move(node.state, move, node.player)\n            child_node = Node(state=next_state, parent=node, move=move, player=game.get_opponent(node.player))\n            node.children.append(child_node)\n            return child_node\n\ndef default_policy(game, state, player):\n\n    \"\"\"\n    Simulation phase: play out the game randomly from the given state.\n    \"\"\"\n\n    current_state = state.copy()\n    current_player = player\n\n    while not game.is_terminal(current_state):\n        possible_moves = game.get_valid_moves(current_state)\n        move = random.choice(possible_moves)\n        current_state = game.make_move(current_state, move, current_player)\n        current_player = game.get_opponent(current_player)\n\n    result = game.evaluate(current_state)\n\n    return result\n\ndef backup(node, reward):\n\n    \"\"\"\n    Backpropagation phase: update the node statistics.\n    \"\"\"\n\n    while node is not None:\n        node.visits += 1\n        # Update wins. If the result is a win for the player who just played, add 1.\n        if (node.player == 'X' and reward == 1) or (node.player == 'O' and reward == -1):\n            node.wins += 1\n        elif reward == 0:\n            node.wins += 0.5  # Consider draw as half win\n        node = node.parent"
  },
  {
    "objectID": "lectures/21/slides.html#test_tic_tac_toe_mcts",
    "href": "lectures/21/slides.html#test_tic_tac_toe_mcts",
    "title": "Monte Carlo Tree Search",
    "section": "test_tic_tac_toe_mcts",
    "text": "test_tic_tac_toe_mcts\n\n# Main function to demonstrate the application\ndef test_tic_tac_toe_mcts():\n\n    game = TicTacToe()\n    current_state = game.board.copy()\n    current_player = 'X'\n    root_node = Node(state=current_state, player=current_player)\n\n    while not game.is_terminal(current_state):\n\n        game.display(current_state)\n        print(f\"Player {current_player}'s turn.\")\n\n        if current_player == 'X':\n            # AI's turn using MCTS\n            iterations = 1000  # Adjust as needed\n            best_child = mcts(game, root_node, iterations)\n            current_state = best_child.state\n            root_node = best_child\n        else:\n            # Human player's turn\n            possible_moves = game.get_valid_moves(current_state)\n            print(\"Possible moves:\", possible_moves)\n            move = None\n            while move not in possible_moves:\n                try:\n                    move_input = input(\"Enter your move as 'row,col': \")\n                    move = tuple(int(x.strip()) for x in move_input.split(','))\n                except:\n                    print(\"Invalid input. Please enter row and column numbers separated by a comma.\")\n            current_state = game.make_move(current_state, move, current_player)\n            # Update the tree: find or create the child node corresponding to the move\n            matching_child = None\n            for child in root_node.children:\n                if child.move == move:\n                    matching_child = child\n                    break\n            if matching_child:\n                root_node = matching_child\n            else:\n                root_node = Node(state=current_state, parent=None, move=move, player=game.get_opponent(current_player))\n        # Switch player\n        current_player = game.get_opponent(current_player)\n\n    # Game over\n    game.display(current_state)\n    result = game.evaluate(current_state)\n    if result == 1:\n        print(\"X wins!\")\n    elif result == -1:\n        print(\"O wins!\")\n    else:\n        print(\"It's a draw!\")\n\nif __name__ == \"__main__\":\n    test_tic_tac_toe_mcts()"
  },
  {
    "objectID": "lectures/21/slides.html#exploration",
    "href": "lectures/21/slides.html#exploration",
    "title": "Monte Carlo Tree Search",
    "section": "Exploration",
    "text": "Exploration\n\nImplement code to visualize the search tree, either as text or using Graphviz.\nIncorporate heuristics to detect when a winning move is achievable in a single step.\nExperiment with varying the number of iterations and the constant \\(C\\)."
  },
  {
    "objectID": "lectures/21/slides.html#summary",
    "href": "lectures/21/slides.html#summary",
    "title": "Monte Carlo Tree Search",
    "section": "Summary",
    "text": "Summary\n\nMonte Carlo Tree Search (MCTS) is a search algorithm used for decision-making in complex games.\nMCTS operates through four main steps: Selection, Expansion, Rollout (Simulation), and Backpropagation.\nIt balances exploration and exploitation using the UCB1 formula, which guides node selection based on visit counts and scores.\nMCTS maintains an explicit search tree, updating node values iteratively based on simulations.\nThe algorithm has wide-ranging applications, including AI gaming, drug design, circuit routing, and autonomous driving.\nIntroduced in 2008, MCTS gained prominence with its use in AlphaGo in 2016.\nUnlike traditional algorithms like \\(A^\\star\\), MCTS uses dynamic policies and leverages all visited nodes for decision-making.\nImplementing MCTS involves tracking node statistics and applying the UCB1 formula to guide search.\nA practical example of MCTS is demonstrated through implementing Tic-Tac-Toe.\nFurther exploration includes integrating MCTS with deep learning models like AlphaZero and MuZero."
  },
  {
    "objectID": "lectures/21/slides.html#further-exploration",
    "href": "lectures/21/slides.html#further-exploration",
    "title": "Monte Carlo Tree Search",
    "section": "Further exploration",
    "text": "Further exploration\n\nJAX-native environment for simulations\nAlphaZero\nMuZero\nGumbel\nMCTS Tic-Tac-Toe with Visualization"
  },
  {
    "objectID": "lectures/21/slides.html#the-end",
    "href": "lectures/21/slides.html#the-end",
    "title": "Monte Carlo Tree Search",
    "section": "The End",
    "text": "The End\n\nConsult the course website for information on the final examination."
  },
  {
    "objectID": "lectures/21/slides.html#references",
    "href": "lectures/21/slides.html#references",
    "title": "Monte Carlo Tree Search",
    "section": "References",
    "text": "References\n\n\nChaslot, Guillaume, Sander Bakkes, Istvan Szita, and Pieter Spronck. 2008. “Monte-Carlo Tree Search: a new framework for game AI.” In Proceedings of the Fourth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, 216–17. AIIDE’08. Stanford, California: AAAI Press.\n\n\nKemmerling, Marco, Daniel Lütticke, and Robert H. Schmitt. 2024. “Beyond Games: A Systematic Review of Neural Monte Carlo Tree Search Applications.” Applied Intelligence 54 (1): 1020–46. https://doi.org/10.1007/s10489-023-05240-w.\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/.\n\n\nSilver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, et al. 2016. “Mastering the game of Go with deep neural networks and tree search.” Nature 529 (7587): 484–89. https://doi.org/10.1038/nature16961."
  },
  {
    "objectID": "lectures/21/index.html",
    "href": "lectures/21/index.html",
    "title": "Monte Carlo Tree Search",
    "section": "",
    "text": "Important\n\n\n\nFor detailed information regarding the evaluation of CSI 4106, please refer to the course evaluation webpage. The evaluation period for the Fall 2024 term is scheduled from November 17 to November 28.\nDeadline: Assignment 4 must be submitted no later than December 1, 2025, at 11 PM. Please refer to the assignment description available on Brightspace. You must first register to a group in order to access the description."
  },
  {
    "objectID": "lectures/21/index.html#prepare",
    "href": "lectures/21/index.html#prepare",
    "title": "Monte Carlo Tree Search",
    "section": "Prepare",
    "text": "Prepare\n\nRussell and Norvig (2020), pages 161-164"
  },
  {
    "objectID": "lectures/21/index.html#participate",
    "href": "lectures/21/index.html#participate",
    "title": "Monte Carlo Tree Search",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/22/index.html",
    "href": "lectures/22/index.html",
    "title": "Formal Reasoning",
    "section": "",
    "text": "Important\n\n\n\nDue dates: TBA"
  },
  {
    "objectID": "lectures/22/index.html#prepare",
    "href": "lectures/22/index.html#prepare",
    "title": "Formal Reasoning",
    "section": "Prepare",
    "text": "Prepare\nSuggested readings will be inserted here."
  },
  {
    "objectID": "lectures/22/index.html#participate",
    "href": "lectures/22/index.html#participate",
    "title": "Formal Reasoning",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/22/index.html#practice",
    "href": "lectures/22/index.html#practice",
    "title": "Formal Reasoning",
    "section": "Practice",
    "text": "Practice\nSuggested exercises will be inserted here."
  },
  {
    "objectID": "lectures/22/index.html#perform",
    "href": "lectures/22/index.html#perform",
    "title": "Formal Reasoning",
    "section": "Perform",
    "text": "Perform\nReminders for assignments to be inserted here."
  },
  {
    "objectID": "lectures/22/slides.html#quote-of-the-day",
    "href": "lectures/22/slides.html#quote-of-the-day",
    "title": "Formal Reasoning",
    "section": "Quote of the Day",
    "text": "Quote of the Day"
  },
  {
    "objectID": "lectures/22/slides.html#learning-objectives",
    "href": "lectures/22/slides.html#learning-objectives",
    "title": "Formal Reasoning",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nClarify…\nSummarize…\nDiscuss.."
  },
  {
    "objectID": "lectures/22/slides.html#prologue",
    "href": "lectures/22/slides.html#prologue",
    "title": "Formal Reasoning",
    "section": "Prologue",
    "text": "Prologue\n\n\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/23/slides.html#quote-of-the-day",
    "href": "lectures/23/slides.html#quote-of-the-day",
    "title": "Neuro-Symbolic",
    "section": "Quote of the Day",
    "text": "Quote of the Day"
  },
  {
    "objectID": "lectures/23/slides.html#learning-objectives",
    "href": "lectures/23/slides.html#learning-objectives",
    "title": "Neuro-Symbolic",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nClarify…\nSummarize…\nDiscuss.."
  },
  {
    "objectID": "lectures/23/slides.html#prologue",
    "href": "lectures/23/slides.html#prologue",
    "title": "Neuro-Symbolic",
    "section": "Prologue",
    "text": "Prologue\n\n\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/23/index.html",
    "href": "lectures/23/index.html",
    "title": "Neuro-Symbolic",
    "section": "",
    "text": "Important\n\n\n\nDue dates: TBA"
  },
  {
    "objectID": "lectures/23/index.html#prepare",
    "href": "lectures/23/index.html#prepare",
    "title": "Neuro-Symbolic",
    "section": "Prepare",
    "text": "Prepare\nSuggested readings will be inserted here."
  },
  {
    "objectID": "lectures/23/index.html#participate",
    "href": "lectures/23/index.html#participate",
    "title": "Neuro-Symbolic",
    "section": "Participate",
    "text": "Participate\n\nslides as Jupyter Notebook"
  },
  {
    "objectID": "lectures/23/index.html#practice",
    "href": "lectures/23/index.html#practice",
    "title": "Neuro-Symbolic",
    "section": "Practice",
    "text": "Practice\nSuggested exercises will be inserted here."
  },
  {
    "objectID": "lectures/23/index.html#perform",
    "href": "lectures/23/index.html#perform",
    "title": "Neuro-Symbolic",
    "section": "Perform",
    "text": "Perform\nReminders for assignments to be inserted here."
  },
  {
    "objectID": "lectures/24/slides.html#quote-of-the-day",
    "href": "lectures/24/slides.html#quote-of-the-day",
    "title": "Review",
    "section": "Quote of the Day",
    "text": "Quote of the Day"
  },
  {
    "objectID": "lectures/24/slides.html#learning-objectives",
    "href": "lectures/24/slides.html#learning-objectives",
    "title": "Review",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nClarify…\nSummarize…\nDiscuss.."
  },
  {
    "objectID": "lectures/24/slides.html#prologue",
    "href": "lectures/24/slides.html#prologue",
    "title": "Review",
    "section": "Prologue",
    "text": "Prologue\n\n\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/tests/index.html",
    "href": "lectures/tests/index.html",
    "title": "Test page",
    "section": "",
    "text": "Important\n\n\n\nThis quiz has a duration of one (1) hour (60 minutes).\nThe copies are printed single-sided.\nSometimes, difficulties arise due to poor time management, where 80% of the time is dedicated to 20% of the questions. If you get stuck, an effective strategy is to annotate the problematic question, move on to the next one, and return to it later if time permits. Maximize the number of points earned.\nIf you need to go to the bathroom, please go now, as 60 minutes is a short period of time, and I don’t have teaching assistants to help me."
  },
  {
    "objectID": "lectures/tests/index.html#quiz",
    "href": "lectures/tests/index.html#quiz",
    "title": "Test page",
    "section": "Quiz",
    "text": "Quiz\nDo not open the quiz until I give the signal.\nWrite your name and student number, on both the questionnaire and the Scantron sheet.\nRead the instructions carefully.\nDuring the exam, we will circulate the attendance sheets.\nWrite all your answers (true or false and multiple choices in both the questionnaire and the Scantron sheet)"
  },
  {
    "objectID": "lectures/tests/index.html#after-the-quiz",
    "href": "lectures/tests/index.html#after-the-quiz",
    "title": "Test page",
    "section": "After the quiz",
    "text": "After the quiz\nIt is imperative not to leave the room with your exam copy, in accordance with the copyright mentioned at the bottom of the page.\nIf you finish before the allotted time and the situation is calm, stay seated, raise your hand and I will come to collect your copy, and you may then leave.\nHowever, if multiple people finish simultaneously, I will ask you to remain seated to avoid disturbing other students who are still writing.\nWe must ensure that all copies are collected 10 minutes before the start of the next class."
  },
  {
    "objectID": "lectures/17/test.html",
    "href": "lectures/17/test.html",
    "title": "Local Search",
    "section": "",
    "text": "import { Inputs, Plot } from \"@observablehq/plot\";\n\n// Alpha slider ranging from 0 to 0.999\nviewof alpha = Inputs.range([0, 0.999], {step: 0.001, value: 0.995, label: \"Alpha\", width: 300})\n\n// Constants\ninitial_temp = 100\n\n// Iterations from 0 to 1000\niterations = Array.from({length: 1001}, (_, i) =&gt; i)\n\n// Cooling strategies\nexponential_cooling = (initial_temp, alpha, iteration) =&gt;\n  initial_temp * Math.pow(alpha, iteration)\n\nlinear_cooling = (initial_temp, alpha, iteration) =&gt;\n  Math.max(0, initial_temp - alpha * iteration)\n\nlogarithmic_cooling = (initial_temp, alpha, iteration) =&gt;\n  Math.min(initial_temp, initial_temp * alpha / (Math.log(1 + iteration)))\n\ninverse_cooling = (initial_temp, alpha, iteration) =&gt;\n  initial_temp / (1 + alpha * iteration)\n\n// Calculate temperatures and prepare data for plotting\nfunction getCoolingData(alpha) {\n  return iterations.flatMap(i =&gt; [\n    {\n      iteration: i,\n      temp: exponential_cooling(initial_temp, alpha, i),\n      strategy: \"Exponential Cooling\"\n    },\n    {\n      iteration: i,\n      temp: linear_cooling(initial_temp, alpha, i),\n      strategy: \"Linear Cooling\"\n    },\n    {\n      iteration: i,\n      temp: logarithmic_cooling(initial_temp, alpha, i),\n      strategy: \"Logarithmic Cooling\"\n    },\n    {\n      iteration: i,\n      temp: inverse_cooling(initial_temp, alpha, i),\n      strategy: \"Inverse Cooling\"\n    }\n  ]);\n}\n\n// Make coolingData reactive to alpha changes\ncoolingData = getCoolingData(alpha)\n\n// Plotting using Observable Plot\nPlot.plot({\n  marks: [\n    Plot.line(coolingData, {x: \"iteration\", y: \"temp\", stroke: \"strategy\"})\n  ],\n  x: {\n    label: \"Iteration\",\n    grid: true\n  },\n  y: {\n    label: \"Temperature\",\n    grid: true\n  },\n  color: {\n    legend: true\n  },\n  caption: `Cooling Strategies (α = ${alpha})`\n})"
  },
  {
    "objectID": "lectures/17/test.html#section",
    "href": "lectures/17/test.html#section",
    "title": "Local Search",
    "section": "",
    "text": "import { Inputs, Plot } from \"@observablehq/plot\";\n\n// Alpha slider ranging from 0 to 0.999\nviewof alpha = Inputs.range([0, 0.999], {step: 0.001, value: 0.995, label: \"Alpha\", width: 300})\n\n// Constants\ninitial_temp = 100\n\n// Iterations from 0 to 1000\niterations = Array.from({length: 1001}, (_, i) =&gt; i)\n\n// Cooling strategies\nexponential_cooling = (initial_temp, alpha, iteration) =&gt;\n  initial_temp * Math.pow(alpha, iteration)\n\nlinear_cooling = (initial_temp, alpha, iteration) =&gt;\n  Math.max(0, initial_temp - alpha * iteration)\n\nlogarithmic_cooling = (initial_temp, alpha, iteration) =&gt;\n  Math.min(initial_temp, initial_temp * alpha / (Math.log(1 + iteration)))\n\ninverse_cooling = (initial_temp, alpha, iteration) =&gt;\n  initial_temp / (1 + alpha * iteration)\n\n// Calculate temperatures and prepare data for plotting\nfunction getCoolingData(alpha) {\n  return iterations.flatMap(i =&gt; [\n    {\n      iteration: i,\n      temp: exponential_cooling(initial_temp, alpha, i),\n      strategy: \"Exponential Cooling\"\n    },\n    {\n      iteration: i,\n      temp: linear_cooling(initial_temp, alpha, i),\n      strategy: \"Linear Cooling\"\n    },\n    {\n      iteration: i,\n      temp: logarithmic_cooling(initial_temp, alpha, i),\n      strategy: \"Logarithmic Cooling\"\n    },\n    {\n      iteration: i,\n      temp: inverse_cooling(initial_temp, alpha, i),\n      strategy: \"Inverse Cooling\"\n    }\n  ]);\n}\n\n// Make coolingData reactive to alpha changes\ncoolingData = getCoolingData(alpha)\n\n// Plotting using Observable Plot\nPlot.plot({\n  marks: [\n    Plot.line(coolingData, {x: \"iteration\", y: \"temp\", stroke: \"strategy\"})\n  ],\n  x: {\n    label: \"Iteration\",\n    grid: true\n  },\n  y: {\n    label: \"Temperature\",\n    grid: true\n  },\n  color: {\n    legend: true\n  },\n  caption: `Cooling Strategies (α = ${alpha})`\n})"
  },
  {
    "objectID": "lectures/tests/notebook.html",
    "href": "lectures/tests/notebook.html",
    "title": "Test",
    "section": "",
    "text": "Some text.\n\nprint(\"some code\")\n\nsome code"
  },
  {
    "objectID": "lectures/motd/slides.html#section",
    "href": "lectures/motd/slides.html#section",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-09",
    "text": "2024-09-09\n\n\n\n\nWe are assembling a lean, cracked team of the world’s best engineers and researchers dedicated to focusing on SSI (safe superintelligence) and nothing else.\n\n\n\nIlya Sutskever is a renowned computer scientist and a leading figure in the field of artificial intelligence. He co-founded OpenAI, where he serves as the Chief Scientist, and has been instrumental in the development of groundbreaking AI models. Sutskever completed his Ph.D. at the University of Toronto, where he worked under the supervision of Geoffrey Hinton. His contributions to deep learning, particularly in neural networks and natural language processing, have significantly advanced the capabilities of AI technologies.\n\n\nssi.inc"
  },
  {
    "objectID": "lectures/motd/slides.html#references",
    "href": "lectures/motd/slides.html#references",
    "title": "Message of the day (MOTD) - 2024",
    "section": "",
    "text": "Marcel Turcotte\nMarcel.Turcotte@uOttawa.ca\nSchool of Electrical Engineering and Computer Science (EECS)\nUniversity of Ottawa\n\n\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/motd/slides.html#section-1",
    "href": "lectures/motd/slides.html#section-1",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-11",
    "text": "2024-09-11\n\n\n\n\n\n\n\nTIME has recently published its list of the 100 most influential individuals in AI for 2024.\n\n\nThe 100 Most Influential People in AI 2024, TIME, September 5, 2024"
  },
  {
    "objectID": "lectures/motd/slides.html#continued",
    "href": "lectures/motd/slides.html#continued",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-11 (continued)",
    "text": "2024-09-11 (continued)\n\n\n\nYoshua Bengio\nUniversité de Montréal\n\n\nFrancois Chollet\nSoftware engineer, Google\n\n\nSasha Luccioni\nAI & Climate Lead, Hugging Face (Montréal)\n\n\nOnce again this year, Yoshua Bengio from Université de Montréal has been included in the list. Bengio, along with Geoffrey Hinton and Yann LeCun, received the ACM Turing Award in 2018 for their pioneering contributions to the field. The trio is often referred to as the “Fathers of Deep Learning.” Geoffrey Hinton is a professor at the University of Toronto.\n\nFathers of the Deep Learning Revolution Receive ACM A.M. Turing Award\n\nI mentioned François Chollet in the first lecture. In addition to creating Keras, a widely-used deep learning framework, François is the co-initiator of the $1 million ARC challenge, which aims to measure skill acquisition. More information about ARC can be found here: ARC.\n\nFinally, some of you are registered in this course to question the rationale behind building AI systems. You seek a deeper understanding of the technology to form an informed opinion. Some of you are concerned about the societal and ecological impacts of AI. Sasha Luccioni is the Climate and AI Lead at Hugging Face. She resides in Montréal with her family."
  },
  {
    "objectID": "lectures/motd/slides.html#continued-1",
    "href": "lectures/motd/slides.html#continued-1",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-11 (continued)",
    "text": "2024-09-11 (continued)\n\n\n\n\n\nIlya Sutskever\nCo-founder, Safe Superintelligence\n\n\nAndrej Karpathy\nFounder, Eureka Labs\n\n\n\n\nIlya Sutskever and Andrej Karpathy, whom I mentioned in the first lecture, are notable co-founders of OpenAI. Ilya Sutskever completed his undergraduate, master’s, and PhD studies at the University of Toronto, where he was supervised by Geoffrey Hinton. Hinton describes Ilya as a visionary.\nAndrej Karpathy earned his undergraduate degree at the University of Toronto, a master’s degree at the University of British Columbia, and a PhD at Stanford under the supervision of Fei-Fei Li. He served as the Senior Director of AI at Tesla and is renowned for his significant contributions to AI education. You will encounter more about Andrej Karpathy later in the course."
  },
  {
    "objectID": "lectures/01/slides.html#message-of-the-day-motd",
    "href": "lectures/01/slides.html#message-of-the-day-motd",
    "title": "Welcome to CSI 4106!",
    "section": "Message of the day (MOTD)",
    "text": "Message of the day (MOTD)\n\n\n\n\n\n2025-08 – Chief AI Officer, Cohere\n2023-03 – 2025-05 VP AI Research, Meta\n2017-05 – 2023-02 Director, Facebook Artificial Intelligence Research (FAIR), Montréal\n2004-08 – Professor, McGill University\n\n\n\nCohere raises US$500-million, hires former Meta AI expert Joelle Pineau, Joe Castaldo, The Globe and Mail, 2025-08-14.\n\n\nJoëlle_Pineau, a distinguished Canadian computer scientist, was born in Ottawa and has had an exemplary career in the field of artificial intelligence research. She previously held the position of Vice President of AI Research at Meta and served as the Director of Facebook Artificial Intelligence Research (FAIR) in Montréal. Currently, she is the Chief AI Officer at Cohere.\nCohere, a Canadian AI company, is dedicated to the development of advanced natural language processing (NLP) technologies aimed at equipping businesses with state-of-the-art language models. Two of its cofounders, Aidan Gomez and Nick Frosst, previously conducted research at Google Brain. They are also co-authors of the landmark paper “Attention is All You Need,” which introduced the transformer architecture, a key advancement in machine learning. The paper has 192,363 citations according to Google Scholar.\n\nFederal government taps Cohere to work on use of AI in public service, Anja Karadeglija, The Canadian Press, 2025-08-20."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-2",
    "href": "lectures/01/slides.html#symbolic-ai-2",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI",
    "text": "Symbolic AI\n\nWhat were the primary challenges associated with symbolic AI?"
  },
  {
    "objectID": "lectures/01/slides.html#perceptions-and-attitudes-toward-artificial-intelligence",
    "href": "lectures/01/slides.html#perceptions-and-attitudes-toward-artificial-intelligence",
    "title": "Welcome to CSI 4106!",
    "section": "Perceptions and Attitudes Toward Artificial Intelligence",
    "text": "Perceptions and Attitudes Toward Artificial Intelligence\nViewing the results."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-strips",
    "href": "lectures/01/slides.html#symbolic-ai-strips",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI (STRIPS)",
    "text": "Symbolic AI (STRIPS)\n\nProblemRulesStartGoalSolution\n\n\nThe Towers of Hanoi is a puzzle that consists of three pegs and a number of disks of different sizes. The puzzle starts with all the disks stacked in decreasing size on one peg, and the goal is to move the entire stack to another peg, following these rules:\n\nOnly one disk can be moved at a time.\nA disk can only be placed on top of a larger disk or on an empty peg.\n\n\n\nAction Move(X,Y,Z):\n    Preconditions = {Clear(X), On(X,Y), Clear(Z), Smaller(X,Z)};\n    Effects = {-On(X,Y), Clear(Y), On(X,Z), -Clear(Z)};\n\n\nD1, D2, D3, P1, P2, P3 are symbols, where D1, D2, and D3 are disks, and P1, P2, and P3 are pegs.\nOn(D1, D2), On(D2, D3), On(D3, P1),\nclear(D1), clear(P2), clear(P3),\nSmaller(D1, D2), Smaller(D1, D3), Smaller(D2, D3),\nSmaller(D1, P1), Smaller(D1, P2), Smaller(D1, P3),\nSmaller(D2, P1), Smaller(D2, P2), Smaller(D2, P3),\nSmaller(D3, P1), Smaller(D3, P2), Smaller(D3, P3).\n\n\nOn(D1, D2), On(D2, D3), On(D3, P3).\n\n\nMove(D1, P1, P3)\nMove(D2, P1, P2)\nMove(D1, P3, P2)\nMove(D3, P1, P3)\nMove(D1, P2, P1)\nMove(D2, P2, P3)\nMove(D1, P1, P3)\n\n\n\n\nSTRIPS (Stanford Research Institute Problem Solver, 1971) is a classical AI planning system that represents problems in terms of:\n\nStates: sets of logical predicates describing the world.\nOperators (Actions): defined by\n\nPreconditions: predicates that must be true to apply the action,\nAdd list: predicates made true after execution,\nDelete list: predicates made false after execution.\n\nGoal: a set of predicates to be achieved.\n\nA plan is found by applying actions to transform the initial state into a goal state, updating the world via the add/delete lists.\nThese methods will be examined in depth starting from Lecture 16, focused on search methods, and Lecture 22, which will cover formal reasoning."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-logic-programming",
    "href": "lectures/01/slides.html#symbolic-ai-logic-programming",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI (Logic Programming)",
    "text": "Symbolic AI (Logic Programming)\n\nProblemRulesFactsQuery\n\n\nGiven a few facts about who is parent of whom (symbols) and a handful of Horn-clause rules, infer new relations (e.g., ancestor, siblings, grandparent) by logical deduction.\n\n\nfather(F,C) :- male(F), parent(F,C).\nmother(M,C) :- female(M), parent(M,C).\n\nsibling(X,Y) :- parent(P,X), parent(P,Y), X \\= Y.\n\ngrandparent(G,C) :- parent(G,P), parent(P,C).\n\nancestor(A,D) :- parent(A,D).\nancestor(A,D) :- parent(A,X), ancestor(X,D).\n\n\n% facts/symbols\n\nmale(alan).  female(brenda).\nmale(chris). female(dina).\nmale(eli).   female(fiona).\n\nparent(alan, chris).\nparent(brenda, chris).\nparent(chris, dina).\nparent(dina, eli).\nparent(dina, fiona).\n\n\n?- grandparent(G, dina).\n% Expected: G = alan ; G = brenda.\n\n?- ancestor(A, fiona).\n% Expected chain: alan/brenda -&gt; chris -&gt; dina -&gt; fiona\n\n?- sibling(eli, fiona).\n% Expected: true."
  },
  {
    "objectID": "lectures/01/slides.html#survey",
    "href": "lectures/01/slides.html#survey",
    "title": "Welcome to CSI 4106!",
    "section": "Survey",
    "text": "Survey\nPerceptions and Attitudes Toward Artificial Intelligence.\n\n\nThe majority of students exhibit a generally positive disposition towards AI. If your perspective differs, please elaborate.\nThere is a wide range of opinions regarding the probability of catastrophic outcomes due to AI (P(doom)).\nA relatively small number of students express concern about AI replacing their jobs.\nFew students perceive current AI systems as genuinely intelligent.\nViews on Artificial General Intelligence (AGI) and Super-intelligence vary significantly.\nThe primary concerns surrounding AI include potential job displacement and misuse, with privacy issues also noted.\nMany students regard the medical and healthcare sectors as areas where AI could exert significant influence.\nA substantial portion of students believes that AI is excessively hyped.\nFewer than 20% of the students possess substantial experience in artificial intelligence."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-logic-programming-1",
    "href": "lectures/01/slides.html#symbolic-ai-logic-programming-1",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI (Logic Programming)",
    "text": "Symbolic AI (Logic Programming)\n\nProblemRulesCoursesStudentsQuery\n\n\nGiven course prerequisites and a student’s completed set, infer which courses they can take next. This shows symbolic constraint reasoning.\n\n\nall_prereqs_met(Student, Course) :-\n    \\+ (prereq(Course, P), \\+ completed(Student, P)).\n\ncan_take(Student, Course) :-\n    all_prereqs_met(Student, Course),\n    \\+ completed(Student, Course).\n\n\n% --- Course graph (facts, symbols) ---\n\nprereq(csi2501, csi2110).   % e.g., Data Structures -&gt; Algorithms\nprereq(csi4106, csi2501).   % AI requires Data Structures\nprereq(csi4506, csi2501).   % ML for Bioinformatics requires Data Structures\nprereq(csi4506, sta2371).   % ML for Bioinformatics also needs Statistics\n\n\n% --- Student record (facts, symbols) ---\n\ncompleted(alex, csi2110).\ncompleted(alex, sta2371).\n\n\n?- can_take(alex, csi4106).\n% true  (alex has csi2110 -&gt; can complete csi2501? If required, add completed(alex,csi2501).)\n\n?- can_take(alex, csi4506).\n% true  if alex has csi2501 and sta2371 completed; otherwise false until satisfied.\n\n?- all_prereqs_met(alex, csi4506)."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-planning",
    "href": "lectures/01/slides.html#symbolic-ai-planning",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI (Planning)",
    "text": "Symbolic AI (Planning)\n\nProblemRulesStartGoalSolution\n\n\nThe Towers of Hanoi is a puzzle that consists of three pegs and a number of disks of different sizes. The puzzle starts with all the disks stacked in decreasing size on one peg, and the goal is to move the entire stack to another peg, following these rules:\n\nOnly one disk can be moved at a time.\nA disk can only be placed on top of a larger disk or on an empty peg.\n\n\n\nAction Move(X,Y,Z):\n    Preconditions = {Clear(X), On(X,Y), Clear(Z), Smaller(X,Z)};\n    Effects = {-On(X,Y), Clear(Y), On(X,Z), -Clear(Z)};\n\n\nD1, D2, D3, P1, P2, P3 are symbols, where D1, D2, and D3 are disks, and P1, P2, and P3 are pegs.\nOn(D1, D2), On(D2, D3), On(D3, P1),\nclear(D1), clear(P2), clear(P3),\nSmaller(D1, D2), Smaller(D1, D3), Smaller(D2, D3),\nSmaller(D1, P1), Smaller(D1, P2), Smaller(D1, P3),\nSmaller(D2, P1), Smaller(D2, P2), Smaller(D2, P3),\nSmaller(D3, P1), Smaller(D3, P2), Smaller(D3, P3).\n\n\nOn(D1, D2), On(D2, D3), On(D3, P3).\n\n\nMove(D1, P1, P3)\nMove(D2, P1, P2)\nMove(D1, P3, P2)\nMove(D3, P1, P3)\nMove(D1, P2, P1)\nMove(D2, P2, P3)\nMove(D1, P1, P3)\n\n\n\n\nSTRIPS (Stanford Research Institute Problem Solver, 1971) is a classical AI planning system that represents problems in terms of:\n\nStates: sets of logical predicates describing the world.\nOperators (Actions): defined by\n\nPreconditions: predicates that must be true to apply the action,\nAdd list: predicates made true after execution,\nDelete list: predicates made false after execution.\n\nGoal: a set of predicates to be achieved.\n\nA plan is found by applying actions to transform the initial state into a goal state, updating the world via the add/delete lists.\nThese methods will be examined in depth starting from Lecture 16, focused on search methods, and Lecture 22, which will cover formal reasoning."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-kinship",
    "href": "lectures/01/slides.html#symbolic-ai-kinship",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI (Kinship)",
    "text": "Symbolic AI (Kinship)\n\nProblemRulesFactsQuery\n\n\nGiven a few facts about who is parent of whom (symbols) and a handful of Horn-clause rules, infer new relations (e.g., ancestor, siblings, grandparent) by logical deduction.\n\n\nfather(F,C) :- male(F), parent(F,C).\nmother(M,C) :- female(M), parent(M,C).\n\nsibling(X,Y) :- parent(P,X), parent(P,Y), X \\= Y.\n\ngrandparent(G,C) :- parent(G,P), parent(P,C).\n\nancestor(A,D) :- parent(A,D).\nancestor(A,D) :- parent(A,X), ancestor(X,D).\n\n\n% facts/symbols\n\nmale(alan).  female(brenda).\nmale(chris). female(dina).\nmale(eli).   female(fiona).\n\nparent(alan, chris).\nparent(brenda, chris).\nparent(chris, dina).\nparent(dina, eli).\nparent(dina, fiona).\n\n\n?- grandparent(G, dina).\n% Expected: G = alan ; G = brenda.\n\n?- ancestor(A, fiona).\n% Expected: A = dina ; A = alan ; A = brenda ; A = chris ;\n\n?- sibling(eli, fiona).\n% Expected: true.\n\n\n\n\nThe preceding example demonstrates the application of logic programming, specifically Prolog, to articulate relationships between entities.\n\nClear separation of knowledge (facts) and reasoning (rules).\nExplanations: Prolog’s proof trees make deductions inspectable.\nRecursion illustrates expressive power (e.g., ancestor/2)."
  },
  {
    "objectID": "lectures/01/slides.html#symbolic-ai-prerequisites",
    "href": "lectures/01/slides.html#symbolic-ai-prerequisites",
    "title": "Welcome to CSI 4106!",
    "section": "Symbolic AI (Prerequisites)",
    "text": "Symbolic AI (Prerequisites)\n\nProblemRulesCoursesStudentsQuery\n\n\nGiven course prerequisites and a student’s completed set, infer which courses they can take next. This shows symbolic constraint reasoning.\n\n\nall_prereqs_met(Student, Course) :-\n    \\+ (prereq(Course, P), \\+ completed(Student, P)).\n\ncan_take(Student, Course) :-\n    all_prereqs_met(Student, Course),\n    \\+ completed(Student, Course).\n\n\n% --- Course graph (facts, symbols) ---\n\nprereq(csi2120, csi2110).\nprereq(csi2110, iti1121).\nprereq(csi2110, mat1338).\nprereq(iti1121, iti1120).\n\n\n% --- Student record (facts, symbols) ---\n\ncompleted(alex, iti1121).\ncompleted(alex, iti1120).\ncompleted(alex, mat1338).\n\n\n?- can_take(alex, csi2110).\n% true\n\n?- can_take(alex, csi2120).\n% false\n\n?- can_take(alex, iti1121).\n% false\n\n?- all_prereqs_met(alex, csi2110).\n% true\n\n\n\n\nAnother example using logic programming (Prolog).\n\nShows constraint satisfaction and closed-world negation.\nEasy to extend with electives, co-requisites, or anti-requisites.\nProduces auditable recommendations (why/why not).\n\nNegation as failure, which is represented as \\+ (backslash-plus), Prolog.\n\n\\+ Goal succeeds if Goal cannot be proven.\nSemantics: closed-world assumption — if it’s not in the knowledge base, we assume it’s false.\n\nThe rule\nall_prereqs_met(Student, Course) :-\n    \\+ (prereq(Course, P), \\+ completed(Student, P)).\nreads as:\n\n“all_prereqs_met(Student, Course) holds if there does not exist a prerequisite P of Course such that Student has not completed P.”\n\nOr, more naturally:\n\n“A student has met all the prerequisites for a course when every course that is listed as a prerequisite has already been completed by that student.”"
  },
  {
    "objectID": "lectures/01/slides.html#how-do-you-define-intelligence",
    "href": "lectures/01/slides.html#how-do-you-define-intelligence",
    "title": "Welcome to CSI 4106!",
    "section": "How do you define intelligence?",
    "text": "How do you define intelligence?\n\nWhat are the characteristics you associate with intelligence?\n“Intelligence is a very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience.”\n\nOriginally published in the Wall Street Journal in 1994, the content was reprinted in 1997: (Gottfredson 1997)\n\n\n\nCan AI make mistakes?"
  },
  {
    "objectID": "lectures/01/slides.html#questions",
    "href": "lectures/01/slides.html#questions",
    "title": "Welcome to CSI 4106!",
    "section": "Questions",
    "text": "Questions\n\nCan the concept of intelligence be considered independently of the entities that express it? This is the problem of embodiment.\nCan a machine exhibit human-level intelligence?\nIs it possible to dissociate the following concepts from that of intelligence?\n\nAgency.\nSentience.\nConsciousness.\nEmotions.\nLanguage.\nMind.\n\nCan an AI suffer?\n\n\nFor me, an interesting definition of intelligence would be similar in nature to that of computation.\nUsing computation as an analogous concept can help clarify this question. Theoretically, computation is often considered in an abstract manner, independent of any physical implementation. The Church-Turing theorem, a fundamental principle in computer science, states that any computation that can be performed by a machine (specifically, a Turing machine) is universally applicable. This implies that the concept of computation can exist independently of its hardware or specific physical form.\nI must confess: until 2022, I was rather skeptical. I often drew a parallel between artificial intelligence and alchemy. Alchemists never succeeded in transmuting lead into gold because it is a physical process, but their approach led to the development of chemistry. Similarly, we may never be able to replicate human intelligence, but the impacts of AI are immense and often unexpected, like the garbage collector introduced by Lisp.\nThen, it struck me: I am a scientist, and I wondered what it would mean if we were not able to produce intelligence comparable to that of humans.\nRichard Feynman, who received the Nobel Prize in Physics in 1965, famously said, “What I cannot build. I do not understand.”\nWhy seek to dissociate intelligence from other concepts such as agency, consciousness, and emotions? A computer system devoid of these attributes seems, indeed, far less daunting."
  },
  {
    "objectID": "lectures/01/slides.html#approfondir-la-réflexion",
    "href": "lectures/01/slides.html#approfondir-la-réflexion",
    "title": "Welcome to CSI 4106!",
    "section": "Approfondir la réflexion",
    "text": "Approfondir la réflexion\n\n\nRouleau, N. & Levin, M. (2024). Discussions of machine versus living intelligence need more clarity. Nature Machine Intelligence, 6(12), 1424–1426. doi: 10.1038/s42256-024-00955-y"
  },
  {
    "objectID": "lectures/01/slides.html#deepen-the-reflection",
    "href": "lectures/01/slides.html#deepen-the-reflection",
    "title": "Welcome to CSI 4106!",
    "section": "Deepen the Reflection",
    "text": "Deepen the Reflection\n\n\n\n\n\n\nRouleau, N. & Levin, M. (2024). Discussions of machine versus living intelligence need more clarity. Nature Machine Intelligence, 6(12), 1424–1426."
  },
  {
    "objectID": "lectures/01/slides.html#question",
    "href": "lectures/01/slides.html#question",
    "title": "Welcome to CSI 4106!",
    "section": "Question",
    "text": "Question\nUser: The man and the goat want to enjoy a picnic near a river, but there’s a wolf. What to do with the zucchini?\n\n\nChatGPT 5: You’ve got the classic river‐crossing (wolf–goat–cabbage ⇒ here, zucchini).\nBoat carries you + one item. Unsafe pairings: wolf with goat; goat with zucchini.\nMinimal plan:\n\nTake goat over.\nReturn alone.\nTake wolf over.\nBring goat back.\nTake zucchini over.\nReturn alone.\nTake goat over.\n\nConclusion: keep the zucchini never alone with the goat; ferry it on step 5.\n\n\n\n\nAttribution: Andriy Burkov, published on LinkedIn 3 weeks ago."
  },
  {
    "objectID": "lectures/01/index.html#deepening",
    "href": "lectures/01/index.html#deepening",
    "title": "Administration, exploring various definitions of AI",
    "section": "Deepening",
    "text": "Deepening\n\n\nThe first 18 minutes of this 47-minute video provide a historical overview of artificial intelligence.\nTo fully understand the evolution of artificial intelligence (AI), it is important to look into its history, especially at a time when we are reaching a peak of speculative optimism. Indeed, it is often claimed that the advent of general artificial intelligence (AGI) is near. This video will reveal that such predictions have been regularly made since the 1950s.\n\nMelanie Mitchell is an influential voice in the current debates on artificial intelligence, particularly concerning the evaluation of software systems. For those interested in the nature of intelligence, I highly recommend her podcast series, which consists of six episodes, each lasting between 35 and 50 minutes.\n\nSanta Fe Institute, Complexity Podcast, The Nature of Intelligence"
  },
  {
    "objectID": "computing/01/slides.html#learning-objectives",
    "href": "computing/01/slides.html#learning-objectives",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nWrite and execute a Jupyter Notebook.\nExecute a Jupyter Notebook on Google Colab."
  },
  {
    "objectID": "computing/01/slides.html#requirements",
    "href": "computing/01/slides.html#requirements",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Requirements",
    "text": "Requirements\nProficiency in Python is expected.\n\nFor those needing a refresher, the official tutorial on Python.org is a good place to start.\n\n\nSimultaneously enhance your skills by creating a Jupyter Notebook that incorporates examples and notes from the tutorial.\n\n\nOther resources include:\n\nStanford CS231n Python Tutorial with Google Colab\nAdvanced Python Tutorial\n\n\nStanford CS231n Python Tutorial with Google Colab: This link directs you to a Python tutorial presented in a Jupyter Notebook format, which can be executed within the Google Colab environment. Additional details are provided below.\nFinally, here is an Advanced Python Tutorial provided by Google.\nCreating a Jupyter Notebook that incorporates examples and notes from the tutorial can be pretty handy. Later, when you want to look up a concept, you can also prototype your solution directly in the notebook."
  },
  {
    "objectID": "computing/01/slides.html#jupyter-notebooks",
    "href": "computing/01/slides.html#jupyter-notebooks",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\n\n\n\n What is a Notebook?\n\n\nA notebook is a shareable document that combines computer code, plain language descriptions, data, rich visualizations like 3D models, charts, graphs and figures, and interactive controls. A notebook, along with an editor (like JupyterLab), provides a fast interactive environment for prototyping and explaining code, exploring and visualizing data, and sharing ideas with others.\n\n\n\nQuick Start\n\n\n\nThis tutorial is designed for those who may not yet be acquainted with Jupyter Notebook and Google Colab. Both platforms are widely used in machine learning communities for interactive computational work.\nGoogle Colab provides a user-friendly interface for writing and executing notebooks without requiring any local software installation. Notably, it allows you to edit and run your code on various devices, including tablets and mobile phones.\nWhile anyone can view a shared notebook, you will need a Google account to execute it. For most educational purposes, the free version of Google Colab should suffice. However, there are paid options, such as Colab Pro and Pro Plus. These versions offer longer runtimes, priority access to more powerful GPUs and TPUs, increased memory and storage capacities, and fewer interruptions and timeouts.\nA notebook seamlessly integrates narrative text with source code and visualizations. As you explore the document, notice how it alternates between explanatory text, code snippets, and graphics.\nYour code is executed within an environment known as a kernel. In this tutorial, we are using a Python kernel. Other available kernels include Julia and R. For additional details, you can refer to the Jupyter Kernels documentation.\nYou may run the entire notebook by selecting Runtime → Run all. However, a more common practice is to execute cells individually. This approach allows you to follow the instructions closely and observe the results of each cell. It also facilitates code experimentation by enabling you to modify code and immediately see the effects of your changes.\nAll cells within a notebook share a common execution environment, which makes the sequence of cell execution crucial. A cell that depends on variables or functions defined in another cell must be executed subsequently. Therefore, ensure that any necessary libraries are loaded before running dependent cells.\nSee also: - The Jupyter Notebook\n\n\nJupyter Notebooks are widely utilized in the fields of data science and machine learning."
  },
  {
    "objectID": "computing/01/slides.html#running-jupyter-on-your-computer",
    "href": "computing/01/slides.html#running-jupyter-on-your-computer",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Running Jupyter on your computer",
    "text": "Running Jupyter on your computer\nAssuming the notebook is in the current directory, execute the following command from the terminal.\njupyter notebook 01_ottawa_river_temperature.ipynb\nSimilarly, to create a new notebook from scratch,\njupyter notebook\n\n\nThese commands launch a Jupyter server on your computer, listening on a local port and directing your browser to the specified local URL. The output will be something like this:\nJupyter Server 2.14.2 is running at:\n     http://localhost:8888/tree?token=94eca753b1887a460404d2b5eebb3b7a6211be0b839e9c34\n     http://127.0.0.1:8888/tree?token=94eca753b1887a460404d2b5eebb3b7a6211be0b839e9c34\nUse Control-C to stop this server and shut down all kernels (twice to skip confirmation).\nAs you can see, executing a notebook locally is similar to running it in Google Colab. However, it requires that Jupyter and all necessary libraries (such as NumPy, pandas, and scikit-learn) be installed on your local system.\nIn a new notebook:\n\nCreate an example showing how text and cells alternate.\nWrite an example showing how the order of execution matters.\n\nSee also:\n\nRunning the Notebook\n\n\n\nThe installation process for Jupyter and other environments will be covered later in this presentation."
  },
  {
    "objectID": "computing/01/slides.html#why",
    "href": "computing/01/slides.html#why",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Why?",
    "text": "Why?\n\nEase of Use: The interface is intuitive and conducive to exploratory analysis.\nVisualization: The capability to embed rich, interactive visualizations directly within the notebook enhances its utility for data analysis and presentation.\nReproducibility: Jupyter Notebooks have become the de facto standard in many domains for demonstrating code functionality and ensuring reproducibility."
  },
  {
    "objectID": "computing/01/slides.html#how",
    "href": "computing/01/slides.html#how",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "How?",
    "text": "How?\n\nGoogle Colab\nLocal installation\n\nIn your browser\n\nNotebook or JupyterLab\n\nVisual Studio Code\n\nMore options, including JupyterHub (a multi-user version)\n\n\nMastering new technology often requires time and patience. Recognize that your levels of experience may vary. Select the option that best aligns with your current expertise. Begin with simpler choices, knowing that you can revisit and adjust your decisions as you gain proficiency.\nFor those comfortable with technology, JupyterLab may be the preferable choice. As the next-generation web-based interface for Jupyter projects, it offers an integrated development environment (IDE)-like experience with support for multiple tabs. Conversely, if you prefer a more straightforward starting point, Jupyter Notebook might be a better option."
  },
  {
    "objectID": "computing/01/slides.html#version-control-github",
    "href": "computing/01/slides.html#version-control-github",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Version Control (GitHub)",
    "text": "Version Control (GitHub)\nBy default, Jupyter Notebooks store the outputs of code cells, including media objects.\n\nJupyter Notebooks are JSON documents, and images within them are encoded in PNG base64 format.\n\n\nThis encoding can lead to several issues when using version control systems, such as GitHub.\n\nLarge File Sizes: Jupyter Notebooks can become quite large due to embedded images and outputs, leading to prolonged upload times and potential storage constraints.\nIncompatibility with Text-Based Version Control: GitHub is optimized for text-based files, and the inclusion of binary data, such as images, complicates the process of tracking changes and resolving conflicts. Traditional diff and merge operations are not well-suited for handling these binary formats."
  },
  {
    "objectID": "computing/01/slides.html#version-control-github---solutions",
    "href": "computing/01/slides.html#version-control-github---solutions",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Version Control (GitHub) - solutions",
    "text": "Version Control (GitHub) - solutions\n\nIn JupyterLab or Notebook, Edit \\(\\rightarrow\\) Clear Outputs of All Cells, then save.\nOn the command line, use jupyter nbconvert --clear-output\n\njupyter nbconvert --clear-output --inplace 04_stock_price.ipynb\nor\njupyter nbconvert 04_stock_price.ipynb --to notebook --ClearOutputPreprocessor.enabled=True --output 04_stock_price_clear\n\nUse nbdime, specialized for Jupyter Notebooks.\n\n\n\nWhen copying source code from slides or notebooks, click on the ‘Copy to Clipboard’ icon to ensure that only the plain text is copied, excluding any HTML formatting.\n\n\nFor assignments, we will ask you to keep the outputs."
  },
  {
    "objectID": "computing/01/slides.html#installing-jupyter-12",
    "href": "computing/01/slides.html#installing-jupyter-12",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Installing Jupyter (1/2)",
    "text": "Installing Jupyter (1/2)\nThese instructions use pip, the recommended installation tool for Python.\nThe initial step is to verify that you have a functioning Python installation with pip installed.\n\nLinux/macOSWindows\n\n\n$ python --version \nPython 3.10.14\n$ pip --version\npip 24.2\n\n\nC:&gt; py --version \nPython 3.10.14\nC:&gt; py -m pip --version\npip 24.2\n\n\n\n\n\nConsult the appendix for other options, including conda, mamba. and pipenv."
  },
  {
    "objectID": "computing/01/slides.html#installing-jupyter-22",
    "href": "computing/01/slides.html#installing-jupyter-22",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Installing Jupyter (2/2)",
    "text": "Installing Jupyter (2/2)\nInstalling JupyterLab with pip:\n$ pip install jupyterlab\nOnce installed, run JupyterLab with:\n$ jupyter lab"
  },
  {
    "objectID": "computing/01/slides.html#sample-jupyter-notebooks",
    "href": "computing/01/slides.html#sample-jupyter-notebooks",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Sample Jupyter Notebooks",
    "text": "Sample Jupyter Notebooks\n\n01_ottawa_river_temperature (Jupyter Notebook)\n02_empty (Jupyter Notebook)\n03_missing_library (Jupyter Notebook)\n04_stock_price (Jupyter Notebook)\n05_central_limit (Jupyter Notebook)"
  },
  {
    "objectID": "computing/01/slides.html#missing-libraries",
    "href": "computing/01/slides.html#missing-libraries",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Missing libraries",
    "text": "Missing libraries\nLaunching 03_missing_library in Colab.\n\n\n\nWhat to do when libraries are missing in Google Colab?"
  },
  {
    "objectID": "computing/01/slides.html#stock_price",
    "href": "computing/01/slides.html#stock_price",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "04_stock_price",
    "text": "04_stock_price\nLaunching 04_stock_price in Colab."
  },
  {
    "objectID": "computing/01/slides.html#central_limit",
    "href": "computing/01/slides.html#central_limit",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "05_central_limit",
    "text": "05_central_limit\nLaunching 05_central_limit in Colab."
  },
  {
    "objectID": "computing/01/slides.html#summary",
    "href": "computing/01/slides.html#summary",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Summary",
    "text": "Summary\n\nIntroducing the tools, specifically Jupyter Notebooks and Google Colab."
  },
  {
    "objectID": "computing/01/slides.html#next-lecture",
    "href": "computing/01/slides.html#next-lecture",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Next lecture",
    "text": "Next lecture\n\nIntroduction to machine learning"
  },
  {
    "objectID": "computing/01/slides.html#one-of-my-favourite-ml-books",
    "href": "computing/01/slides.html#one-of-my-favourite-ml-books",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "One of my favourite ML books",
    "text": "One of my favourite ML books\n\n\n\n\n\nHands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow (Géron 2022) provides practical examples and leverages production-ready Python frameworks.\n\nComprehensive coverage includes not only the models but also libraries for hyperparameter tuning, data preprocessing, and visualization.\nCode examples and solutions to exercises available as Jupyter Notebooks on GitHub.\nAurélien Géron is a former YouTube Product Manager, who lead video classification for Search & Discovery."
  },
  {
    "objectID": "computing/01/slides.html#resources",
    "href": "computing/01/slides.html#resources",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Resources",
    "text": "Resources\n\nProject Jupyter Documentation\nGoogle Colab\nColab Primer"
  },
  {
    "objectID": "computing/01/slides.html#references",
    "href": "computing/01/slides.html#references",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "computing/01/slides.html#environment-management",
    "href": "computing/01/slides.html#environment-management",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Environment management",
    "text": "Environment management\n\n\n\n\n\n\nImportant\n\n\nDo not attempt to install these tools unless you are confident in your technical skills. An incorrect installation could waste significant time or even render your environment unusable. There is nothing wrong with using pip or Google Colab for your coursework. You can develop these installation skills later without impacting your grades."
  },
  {
    "objectID": "computing/01/slides.html#package-management",
    "href": "computing/01/slides.html#package-management",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Package management",
    "text": "Package management\n\nManaging package dependencies can be complex.\n\nA package manager addresses these challenges.\n\nDifferent projects may require different versions of the same libraries.\n\nPackage management tools, such as conda, facilitate the creation of virtual environments tailored to specific projects."
  },
  {
    "objectID": "computing/01/slides.html#anaconda",
    "href": "computing/01/slides.html#anaconda",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Anaconda",
    "text": "Anaconda\nAnaconda is a comprehensive package management platform for Python and R. It utilizes Conda to manage packages, dependencies, and environments.\n\nAnaconda is advantageous as it comes pre-installed with over 250 popular packages, providing a robust starting point for users.\nHowever, this extensive distribution results in a large file size, which can be a drawback.\nAdditionally, since Anaconda relies on conda, it also inherits the limitations and issues associated with conda (see subsequent slides)."
  },
  {
    "objectID": "computing/01/slides.html#miniconda",
    "href": "computing/01/slides.html#miniconda",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Miniconda",
    "text": "Miniconda\nMiniconda is a minimal version of Anaconda that includes only conda, Python, their dependencies, and a small selection of essential packages."
  },
  {
    "objectID": "computing/01/slides.html#conda",
    "href": "computing/01/slides.html#conda",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Conda",
    "text": "Conda\nConda is an open-source package and environment management system for Python and R. It facilitates the installation and management of software packages and the creation of isolated virtual environments.\n\nDependency conflicts due to complex package interdependencies can force the user reinstall Anaconda/Conda.\nPlague with large storage requirements and performance issues during package resolution."
  },
  {
    "objectID": "computing/01/slides.html#mamba",
    "href": "computing/01/slides.html#mamba",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Mamba",
    "text": "Mamba\nMamba is a reimplementation of the conda package manager in C++.\n\nIt is significantly faster than conda.\nIt consumes fewer computational resources.\nIt provides clearer and more informative error messages.\nIt is fully compatible with conda, making it a viable replacement.\n\nMicromamba is a fully statically-linked, self-contained executable. Its empty base environment ensures that the base is never corrupted, eliminating the need for reinstallation."
  },
  {
    "objectID": "computing/01/slides.html#further-your-education",
    "href": "computing/01/slides.html#further-your-education",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Further your education",
    "text": "Further your education\n\nThe Missing Semester of Your CS Education"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html",
    "href": "computing/01/01_ottawa_river_temperature.html",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "",
    "text": "Demonstrate a basic understanding of Jupyter Notebooks.\nExecute code cells within Jupyter Notebooks using Google Colab.\nModify a Jupyter Notebook with simple changes and execute the updated code cells in Google Colab."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#play-with-this-notebook-online-without-having-to-install-anything",
    "href": "computing/01/01_ottawa_river_temperature.html#play-with-this-notebook-online-without-having-to-install-anything",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Play with this notebook online without having to install anything",
    "text": "Play with this notebook online without having to install anything\nWhile the specifics of the code will be discussed in subsequent notebooks, it is important to note that this notebook requires the installation of both pandas and matplotlib. These libraries are pre-installed on Google Colab, facilitating immediate use. However, a Google account is needed in order to execute the code!\n\n  \n\nIf you are viewing this document on the course website, you are seeing the result of converting a Jupyter Notebook to HTML. You can download the corresponding Jupyter Notebook from the table of contents, typically located in the upper right corner when browsing on a computer. Alternatively, you can download it directly here."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#look-at-this-notebook-without-executing-any-code",
    "href": "computing/01/01_ottawa_river_temperature.html#look-at-this-notebook-without-executing-any-code",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Look at this notebook, without executing any code",
    "text": "Look at this notebook, without executing any code"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#cells",
    "href": "computing/01/01_ottawa_river_temperature.html#cells",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Cells",
    "text": "Cells\n\nCode Cells: These cells contain executable code, typically in Python, but other languages like R, Julia, and Scala are also supported. The code is executed in the kernel, and the output is displayed directly below the cell.\nMarkdown Cells: These cells contain text formatted using Markdown. They are used to add explanations, headers, bullet points, links, images, and other formatted text to the notebook.\nRaw Cells: These cells contain text that is not meant to be executed or rendered. They are useful for including code snippets or text that should remain unformatted."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#execution",
    "href": "computing/01/01_ottawa_river_temperature.html#execution",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Execution",
    "text": "Execution\n\nStandard Output: The output of code execution, including text, tables, and plots, is displayed directly below the code cell.\nRich Media Output: Jupyter notebooks support rich media output such as HTML, images, videos, LaTeX, and interactive widgets (e.g., Plotly, Bokeh)."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#importing-the-necessary-librairies",
    "href": "computing/01/01_ottawa_river_temperature.html#importing-the-necessary-librairies",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Importing the necessary librairies",
    "text": "Importing the necessary librairies\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport requests\nfrom io import BytesIO"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#fetching-the-data",
    "href": "computing/01/01_ottawa_river_temperature.html#fetching-the-data",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Fetching the data",
    "text": "Fetching the data\n\n\n\n\n\n\nWarning\n\n\n\nWhen working with Google Colab, it is essential to recognize that you are operating within a temporary environment. Any data or changes made will be deleted after the session ends. Therefore, it is imperative to download and securely store any data or results that you wish to retain.\nYou are also responsible for ensuring that the source code for your assignments remains private and is not publicly accessible.\n\n\n\n# URL of the Excel file\nurl = 'https://www.arcgis.com/sharing/rest/content/items/2dff4bca304f4308996681aa6265f64d/data'\n\n# Fetch the Excel file from the web\nresponse = requests.get(url)\nresponse.raise_for_status()  # Ensure we notice bad responses"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#reading-the-excel-file",
    "href": "computing/01/01_ottawa_river_temperature.html#reading-the-excel-file",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Reading the Excel file",
    "text": "Reading the Excel file\n\n# Read the Excel file into a pandas DataFrame\ndf = pd.read_excel(BytesIO(response.content), sheet_name='Britannia raw water temperature', header=None)"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#extracting-the-data-from-the-excel-file",
    "href": "computing/01/01_ottawa_river_temperature.html#extracting-the-data-from-the-excel-file",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Extracting the data from the Excel file",
    "text": "Extracting the data from the Excel file\nColumns B to U contain daily average temperatures for each year from 2005 to 2023, with each column corresponding to a specific year. Rows 11 to 375 represent daily average values, where row 11 corresponds to January 1 and row 375 corresponds to December 31. For example, cell B11 contains the average temperature for January 1, 2005, while cell U375 contains the average temperature for December 31, 2023.\n\n# Define the range of years and columns\nyears = range(2005, 2023 + 1)  # Up to 2023 as per your description\ncolumns = range(1, 21)  # Columns B to U (1-indexed in Excel, 0-indexed in pandas)\n\n# Prepare a dictionary to hold the data\ndata = {}\n\n# Extract data for each year\nfor year, col in zip(years, columns):\n    # Note: B11 to B375 corresponds to row indices 10 to 374 in pandas (0-indexed)\n    data[year] = df.iloc[10:375, col].values"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature.html#ploting-the-data",
    "href": "computing/01/01_ottawa_river_temperature.html#ploting-the-data",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Ploting the data",
    "text": "Ploting the data\n\n# Plot the data\nplt.figure(figsize=(12, 8))\n\nfor year in years:\n  if year == 2023:\n    plt.plot(data[year], label=str(year), linewidth=3, linestyle='--')\n  else:\n    plt.plot(data[year], label=str(year))\n\nplt.xlabel('Day of the Year')\nplt.ylabel('Daily Average Water Temperature')\nplt.title('Daily Average Ottawa River Water Temperature from 2005 to 2023')\nplt.legend(title='Year')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "",
    "text": "Demonstrate a basic understanding of Jupyter Notebooks.\nExecute code cells within Jupyter Notebooks using Google Colab.\nModify a Jupyter Notebook with simple changes and execute the updated code cells in Google Colab."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#play-with-this-notebook-online-without-having-to-install-anything",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#play-with-this-notebook-online-without-having-to-install-anything",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Play with this notebook online without having to install anything",
    "text": "Play with this notebook online without having to install anything\nWhile the specifics of the code will be discussed in subsequent notebooks, it is important to note that this notebook requires the installation of both pandas and matplotlib. These libraries are pre-installed on Google Colab, facilitating immediate use. However, a Google account is needed in order to execute the code!\n\n  \n\nIf you are viewing this document on the course website, you are seeing the result of converting a Jupyter Notebook to HTML. You can download the corresponding Jupyter Notebook from the table of contents, typically located in the upper right corner when browsing on a computer. Alternatively, you can download it directly here."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#look-at-this-notebook-without-executing-any-code",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#look-at-this-notebook-without-executing-any-code",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Look at this notebook, without executing any code",
    "text": "Look at this notebook, without executing any code"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#cells",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#cells",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Cells",
    "text": "Cells\n\nCode Cells: These cells contain executable code, typically in Python, but other languages like R, Julia, and Scala are also supported. The code is executed in the kernel, and the output is displayed directly below the cell.\nMarkdown Cells: These cells contain text formatted using Markdown. They are used to add explanations, headers, bullet points, links, images, and other formatted text to the notebook.\nRaw Cells: These cells contain text that is not meant to be executed or rendered. They are useful for including code snippets or text that should remain unformatted."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#execution",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#execution",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Execution",
    "text": "Execution\n\nStandard Output: The output of code execution, including text, tables, and plots, is displayed directly below the code cell.\nRich Media Output: Jupyter notebooks support rich media output such as HTML, images, videos, LaTeX, and interactive widgets (e.g., Plotly, Bokeh)."
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#importing-the-necessary-librairies",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#importing-the-necessary-librairies",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Importing the necessary librairies",
    "text": "Importing the necessary librairies\n\n# --- Setup & Imports (didactic) ---\nfrom __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Dict, Iterable\nfrom io import BytesIO\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport requests\n\n# Reproducibility\nRANDOM_SEED: int = 42\nnp.random.seed(RANDOM_SEED)\n\n# Plotting defaults for readability (do not hard-code colors)\nplt.rcParams[\"figure.dpi\"] = 120\nplt.rcParams[\"axes.spines.top\"] = False\nplt.rcParams[\"axes.spines.right\"] = False\n\ndef show_versions() -&gt; None:\n    \"\"\"Print library versions to make runs reproducible across environments.\"\"\"\n    print(f\"pandas: {pd.__version__}\")\n    print(f\"matplotlib: {plt.matplotlib.__version__}\")\n    print(f\"requests: {requests.__version__}\")\n\nshow_versions()\n\npandas: 2.3.2\nmatplotlib: 3.10.5\nrequests: 2.32.5"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#fetching-the-data",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#fetching-the-data",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Fetching the data",
    "text": "Fetching the data\n\n\n\n\n\n\nWarning\n\n\n\nWhen working with Google Colab, it is essential to recognize that you are operating within a temporary environment. Any data or changes made will be deleted after the session ends. Therefore, it is imperative to download and securely store any data or results that you wish to retain.\nYou are also responsible for ensuring that the source code for your assignments remains private and is not publicly accessible.\n\n\n\n# --- Download data with robust error handling and on-disk caching ---\nDATA_URL: str = \"https://www.arcgis.com/sharing/rest/content/items/2dff4bca304f4308996681aa6265f64d/data\"\nTIMEOUT_S: int = 30\n\n# Save a local cached copy to keep the notebook fast/reproducible offline\nCACHE_DIR = Path(\"data\")\nCACHE_DIR.mkdir(parents=True, exist_ok=True)\nCACHE_PATH = CACHE_DIR / \"ottawa_river_temperature.xlsx\"\n\ndef fetch_excel(url: str, cache_path: Path = CACHE_PATH, force: bool = False) -&gt; BytesIO:\n    \"\"\"\n    Download the Excel file from `url` (with timeout & basic UA), cache it on disk,\n    and return a BytesIO buffer for downstream parsing.\n\n    Parameters\n    ----------\n    url : str\n        The direct URL to the Excel file.\n    cache_path : Path\n        Local cache path. If it exists and `force` is False, the cached file is used.\n    force : bool\n        Force re-download even if the cache exists.\n\n    Returns\n    -------\n    BytesIO\n        In-memory buffer of the Excel content.\n    \"\"\"\n    if cache_path.exists() and not force:\n        return BytesIO(cache_path.read_bytes())\n\n    headers = {\"User-Agent\": \"CSI4106-Notebook/1.0 (+https://uottawa.ca)\"}\n    try:\n        resp = requests.get(url, headers=headers, timeout=TIMEOUT_S)\n        resp.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise SystemExit(f\"Error downloading data: {e}\") from e\n\n    cache_path.write_bytes(resp.content)\n    return BytesIO(resp.content)\n\nexcel_buf = fetch_excel(DATA_URL)\nprint(f\"Loaded Excel bytes: {len(excel_buf.getbuffer())} B\")\n\nLoaded Excel bytes: 12158233 B"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#reading-the-excel-file",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#reading-the-excel-file",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Reading the Excel file",
    "text": "Reading the Excel file\n\n# --- Load worksheet safely ---\nSHEET_NAME: str = \"Britannia raw water temperature\"\n\ndef load_table(excel: BytesIO, sheet_name: str = SHEET_NAME) -&gt; pd.DataFrame:\n    \"\"\"Read the worksheet as-is (no header), so we can inspect structure safely.\"\"\"\n    df = pd.read_excel(excel, sheet_name=sheet_name, header=None)\n    assert not df.empty, \"Sheet appears empty; check the sheet name or source.\"\n    return df\n\nraw_df: pd.DataFrame = load_table(excel_buf, SHEET_NAME)\nprint(raw_df.shape)\nraw_df.head(10)\n\n(376, 29)\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n\n0\nCity of Ottawa\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n5\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n7\nDaily recorded water temperature of raw water ...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n8\n(average of two readings, recorded 12 hrs apar...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9\nDate\n2005.0\n2006.0\n2007.0\n2008.0\n2009.0\n2010.0\n2011.0\n2012.0\n2013.0\n...\n2023.0\n2024.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n10 rows × 29 columns"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#extracting-the-data-from-the-excel-file",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#extracting-the-data-from-the-excel-file",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Extracting the data from the Excel file",
    "text": "Extracting the data from the Excel file\nColumns B to U contain daily average temperatures for each year from 2005 to 2023, with each column corresponding to a specific year. Rows 11 to 375 represent daily average values, where row 11 corresponds to January 1 and row 375 corresponds to December 31. For example, cell B11 contains the average temperature for January 1, 2005, while cell U375 contains the average temperature for December 31, 2023.\n\n# --- Transform to tidy daily time series per year ---\ndef extract_yearly_series(table: pd.DataFrame, years: Iterable[int]) -&gt; Dict[int, pd.Series]:\n    \"\"\"\n    Map each year to a pd.Series of daily average water temperature.\n    The source sheet places years in columns B..U (Excel 1-indexed), i.e., pandas columns 1..20,\n    corresponding to years 2005..2023. Days are expected in rows 2..367 (1..366 days).\n\n    This function is intentionally explicit about indices so that any future changes to the\n    source layout are easy to diagnose and fix.\n    \"\"\"\n    # Column mapping derived from the original notebook\n    base_year = 2005\n    base_col_index = 1  # column B in Excel -&gt; index 1 in pandas\n    max_year = 2023\n\n    mapping = {y: base_col_index + (y - base_year) for y in range(base_year, max_year + 1)}\n\n    out: Dict[int, pd.Series] = {}\n    for y in years:\n        col = mapping.get(y)\n        if col is None or col &gt;= table.shape[1]:\n            warnings.warn(f\"Year {y} not present in the worksheet; skipping.\")\n            continue\n\n        # Days in rows 2..367 (inclusive). Coerce to numeric and keep NaN for invalid cells.\n        s = pd.to_numeric(table.iloc[1:367, col], errors=\"coerce\").reset_index(drop=True)\n        s.index = pd.RangeIndex(start=1, stop=len(s) + 1, step=1)  # day-of-year as index starting at 1\n        out[y] = s\n\n    if not out:\n        raise ValueError(\"No year series extracted; verify sheet structure and mapping.\")\n    return out\n\nYEARS = range(2005, 2024)\nseries_by_year = extract_yearly_series(raw_df, YEARS)\n\n# Quick sanity checks\nassert 2005 in series_by_year and 2023 in series_by_year, \"Expected edge years missing.\"\nfor y, s in series_by_year.items():\n    assert s.dtype.kind in \"fc\", f\"Non-numeric series for {y}.\"\nlen(series_by_year), list(series_by_year)[:3], list(series_by_year)[-3:]\n\n(19, [2005, 2006, 2007], [2021, 2022, 2023])"
  },
  {
    "objectID": "computing/01/01_ottawa_river_temperature_didactic.html#ploting-the-data",
    "href": "computing/01/01_ottawa_river_temperature_didactic.html#ploting-the-data",
    "title": "Jupyter Notebook - Ottawa River Temperature",
    "section": "Ploting the data",
    "text": "Ploting the data\n\n# --- Plotting utility ---\ndef plot_years(series_map: Dict[int, pd.Series], *, highlight: int | None = None, title: str | None = None) -&gt; None:\n    \"\"\"Plot daily average temperature curves by year with sensible defaults.\"\"\"\n    plt.figure(figsize=(12, 8))\n\n    for y in sorted(series_map):\n        s = series_map[y].values\n        kw = {\"label\": str(y), \"linewidth\": 1.2}\n        if highlight is not None and y == highlight:\n            kw.update({\"linewidth\": 2.5, \"linestyle\": \"--\"})\n        plt.plot(s, **kw)\n\n    plt.xlabel(\"Day of the Year\")\n    plt.ylabel(\"Daily Average Water Temperature (°C)\")\n    if title is None:\n        yrs = (min(series_map), max(series_map))\n        title = f\"Daily Average Ottawa River Water Temperature ({yrs[0]}–{yrs[1]})\"\n    plt.title(title)\n    plt.legend(title=\"Year\", ncol=3, fontsize=9)\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n\nplot_years(series_by_year, highlight=2023)"
  },
  {
    "objectID": "computing/01/index.html",
    "href": "computing/01/index.html",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "",
    "text": "[\n]{.quarto-shortcode__ data-is-shortcode=“1” data-raw=“{{&lt; video https://youtu.be/xInYpVLf7LE title=\"CSI4106 F25 Jupyter Notebooks and Google Colab\"",
    "crumbs": [
      "**Computing**",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "computing/01/index.html#participate",
    "href": "computing/01/index.html#participate",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "",
    "text": "slides as a Jupyter Notebook"
  },
  {
    "objectID": "computing/01/index.html#practice",
    "href": "computing/01/index.html#practice",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Practice",
    "text": "Practice\n\n01_ottawa_river_temperature (Jupyter Notebook)\n02_empty (Jupyter Notebook)\n03_missing_library (Jupyter Notebook)\n04_stock_price (Jupyter Notebook)\n05_central_limit (Jupyter Notebook)\n\nThree notebooks from Aurélien Géron introducing essential concepts for machine learning. In the coming weeks, you might want to go through these at your own pace.\n\nnumpy – a fundamental library centered around N-dimensional array objects.\npandas – powerfull data analysis tools, centered around the DataFrame.\nvisualization – demonstrates how to use the matplotlib to produce beautiful graphs."
  },
  {
    "objectID": "computing/01/03_get_youtube_transcript.html",
    "href": "computing/01/03_get_youtube_transcript.html",
    "title": "Jupyter Notebook - YouTube Transcript API",
    "section": "",
    "text": "Learning objective\n\nIllustrate the process of identifying and resolving missing library issues in Google Colab.\n\n\n\n\n\n\n\nImportant\n\n\n\nThis example is meant to be executed in Google Colab.\n\n\n\n\nYouTube Transcript API\nIn this notebook, we aim to utilize the YouTube Transcript API to automatically download the transcript of the video titled Can Machines Think? by Noam Chomsky.\nFirst, let’s import YouTubeTranscriptApi and TextFormatter from youtube_transcript_api.\n\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom youtube_transcript_api.formatters import TextFormatter\n\nExecuting the code cell above will result in an error, as the youtube_transcript_api library is not installed by default in Google Colab.\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-1-c8308591d925&gt; in &lt;cell line: 2&gt;()\n      1 # ! pip install youtube-transcript-api\n----&gt; 2 from youtube_transcript_api import YouTubeTranscriptApi\n      3 from youtube_transcript_api.formatters import TextFormatter\n\nModuleNotFoundError: No module named 'youtube_transcript_api'\n\n---------------------------------------------------------------------------\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n---------------------------------------------------------------------------\nThis issue can be resolved by adding the following line of code before the first import statement. Try it!\n! pip install youtube-transcript-api\nOnce this issue has been solved, we can download and print the transcript. Try it!\n\ntranscript = YouTubeTranscriptApi.get_transcript(\"Ex9GbzX6tMo\")\nformatter = TextFormatter()\ninput_text = formatter.format_transcript(transcript)\nprint(input_text)\n\n\n\nExploration\n! allows to run Unix/Linux shell commands in IPython. Create a code cell and try these commands.\n\n! uname -a displays information about the system.\n! ls displays the content of the current directory.\n! ls / displays the content of the root directory.\n! pwd returns working directory name.\n\nThese commands are useful for debugging code, as they provide information about the computing environment, such as the operating system version and the contents of the local directory."
  },
  {
    "objectID": "computing/01/04_stock_price.html",
    "href": "computing/01/04_stock_price.html",
    "title": "Jupyter Notebook - Stock Prices",
    "section": "",
    "text": "Market Capitalization of NVIDIA and Intel (2012 - 2024)\nThe Python library yfinance is often used to download stock market data.\n\nimport yfinance as yf\nimport matplotlib.pyplot as plt\n\nLet’s define the stocks that are of interest for this analysis.\n\n# Define the tickers for NVIDIA and Intel\ntickers = ['NVDA', 'INTC']\n\nNow, downloading the data to our Colab instance or local computer.\n\n# Download the historical market data since 2012\ndata = yf.download(tickers, start='2012-01-01', end='2024-01-01', group_by='ticker')\n\nFocusing on the closing prices.\n\n# Extract the adjusted closing prices\nnvda_data = data['NVDA']['Close']\nintc_data = data['INTC']['Close']\n\nDrawing.\n\n# Plot the stock price data\nplt.figure(figsize=(12, 6))\nplt.plot(nvda_data.index, nvda_data, label='NVIDIA')\nplt.plot(intc_data.index, intc_data, label='Intel')\nplt.title('Stock Prices of NVIDIA and Intel (2012 - 2024)')\nplt.xlabel('Date')\nplt.ylabel('Stock Price (USD)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nNow calculating the market capitalisation.\n\n# Fetch the number of shares outstanding (this gives the most recent value)\nnvda_shares = yf.Ticker('NVDA').info['sharesOutstanding']\nintc_shares = yf.Ticker('INTC').info['sharesOutstanding']\n\n# Calculate market capitalization (Adjusted Close * shares outstanding)\nnvda_market_cap = data['NVDA']['Close'] * nvda_shares\nintc_market_cap = data['INTC']['Close'] * intc_shares\n\nWhile the share prices of NVIDIA and Intel are comparable, NVIDIA’s market capitalization has experienced a significant increase since 2020, in contrast to Intel’s more stable market capitalization.\n\n# Plot the market capitalization data\nplt.figure(figsize=(12, 6))\nplt.plot(nvda_market_cap.index, nvda_market_cap, label='NVIDIA')\nplt.plot(intc_market_cap.index, intc_market_cap, label='Intel')\nplt.title('Market Capitalization of NVIDIA and Intel (2012 - 2024)')\nplt.xlabel('Date')\nplt.ylabel('Market Capitalization (USD)')\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "computing/01/05_central_limit.html",
    "href": "computing/01/05_central_limit.html",
    "title": "Jupyter Notebook - Central Limit Theorem",
    "section": "",
    "text": "This example is derived from my personal notes. Jupyter notebooks can be effectively used for writing interactive notes and exploring ideas.\n\nCentral Limit Theorem\nThe Central Limit Theorem is a fundamental statistical concept that states that the distribution of sample means approximates a normal distribution (bell-shaped curve) as the sample size becomes large, regardless of the shape of the population distribution, provided that the samples are independent and identically distributed.\n\\[\n  \\text{sample standard deviation} = \\frac{\\text{population standard deviation}}{\\sqrt{\\text{sample size}}}\n\\]\nLet’s illustrate the concept with two popular but dissimilar probability distributions.\nTo refresh our memory, we will generate 1000 values from a uniform distribution with range 0 to 1, and plot the result.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample size\nsample_size = 1000\n\n# Generate values\nvalues = np.random.uniform(0, 1, sample_size)\n\n# Plot the histogram\nplt.hist(values, bins=20, edgecolor='black')\nplt.title(f'Sampling {sample_size} values from a Uniform Distribution')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\nIn this first example, 1000 samples are generated each with 31 values sampled from a uniform distribution with range \\([0,1]\\)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Number of samples and sample size\nnum_samples = 1000\nsample_size = 31\n\n# Generate samples and calculate their means\nsample_means = [np.mean(np.random.uniform(0, 1, sample_size)) for _ in range(num_samples)]\n\n# Plot the histogram of the sample means\nplt.hist(sample_means, bins=20, edgecolor='black')\nplt.title('Histogram of Sample Means (Uniform Distribution)')\nplt.xlabel('Sample Mean')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\nThe above histogram has the characteristic bell shape.\nFor the next example, we will turn our attention to the exponential probability distribution. Again, we will refresh our memory. The following shows the histogram for 1000 values generated from an exponential distribution with rate \\(\\lambda = \\frac{1}{4}\\). Hence, the scale, \\(\\beta=\\frac{1}{\\lambda}\\), is \\(4\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample size\nsample_size = 1000\n\n# Generate values\nvalues = np.random.exponential(scale=4, size=sample_size)\n\n# Plot the histogram\nplt.hist(values, bins=20, edgecolor='black')\nplt.title(f'Sampling {sample_size} values from an Exponential Distribution')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\nNow, let’s generate 1000 samples, each with 31 values sampled from an exponential distribution.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Number of samples and sample size\nnum_samples = 1000\nsample_size = 31\n\n# Scale parameter for the exponential distribution\nscale_parameter = 4\n\n# Generate the samples and calculate their means\nsample_means = [np.mean(np.random.exponential(scale=scale_parameter, size=sample_size)) for _ in range(num_samples)]\n\n# Plot the histogram of the sample means\nplt.hist(sample_means, bins=30, edgecolor='black')\nplt.title('Histogram of Sample Means (Exponential Distribution)')\nplt.xlabel('Sample Mean')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\nWhy does this matter? In experimental work, we frequently lack knowledge of the underlying distribution of the data. Yet, when we summarize experimental results using the mean, we can be confident that these means will follow a normal distribution. This allows us to apply statistical techniques such as calculating confidence intervals, conducting t-tests to compare the means of two different samples, or performing ANOVA to determine if there are differences among the means of three or more samples.\nAs a rule of thumb, the sample size should be at least 30 for the Central Limit Theorem to be applicable. This guideline is not universally applicable. For populations with significant skewness or outliers, larger sample sizes may be needed for the Central Limit Theorem to hold. Conversely, if the population distribution is already normal, even smaller sample sizes will yield a distribution of sample means that is approximately normal."
  },
  {
    "objectID": "computing/01/03_missing_library.html",
    "href": "computing/01/03_missing_library.html",
    "title": "Jupyter Notebook - Missing Library",
    "section": "",
    "text": "Learning objective\n\nIllustrate the process of identifying and resolving missing library issues in Google Colab.\n\n\n\n\n\n\n\nImportant\n\n\n\nThis example is meant to be executed in Google Colab.\n\n\n\n\nImport\nIn this notebook, we use the langdetect library to accurately identify the language of given text samples.\nFirst, let’s import langdetect.\n\nfrom langdetect import detect\n\nExecuting the code cell above will result in an error, as the langdetect library is not installed by default in Google Colab.\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n/tmp/ipython-input-193950075.py in &lt;cell line: 0&gt;()\n----&gt; 1 from langdetect import detect\n\nModuleNotFoundError: No module named 'langdetect'\n\n---------------------------------------------------------------------------\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n---------------------------------------------------------------------------\nThis issue can be resolved by adding the following line of code before the first import statement. Try it!\n! pip install langdetect\nOnce this issue has been solved, we can call detect. Try it!\n\ndetect(\"Bonjour tout le monde!\")\n\n\n\nBest Practice\nYou could have predicted this scenario. If the langdetect library is not installed, captured the resulting exception, and proceeded to install the library.\ntry:\n    from langdetect import detect\nexcept ImportError:\n    print(\"langdetect not found, installing...\")\n    import sys\n    ! pip install langdetect\n    from langdetect import detect  # retry after install\n\n\nExploration\n! allows to run Unix/Linux shell commands in IPython. Create a code cell and try these commands.\n\n! uname -a displays information about the system.\n! ls displays the content of the current directory.\n! ls / displays the content of the root directory.\n! pwd returns working directory name.\n\nThese commands are useful for debugging code, as they provide information about the computing environment, such as the operating system version and the contents of the local directory."
  },
  {
    "objectID": "computing/01/slides.html#lecture-notes",
    "href": "computing/01/slides.html#lecture-notes",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Lecture Notes",
    "text": "Lecture Notes\nEach lecture is provided as a Jupyter Notebook.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sigmoid function\ndef sigmoid(t):\n    return 1 / (1 + np.exp(-t))\n\n# Generate x values\nt = np.linspace(-6, 6, 400)\n\n# Compute y values for the sigmoid function\ny = sigmoid(t)\n\n# Create a figure and remove axes and grid\nfig, ax = plt.subplots()\nax.plot(t, y, color='black', linewidth=2)  # Keep the curve opaque\n\nplt.grid(True)\n\n# Set transparent background for the figure and axes\nfig.patch.set_alpha(0)  # Transparent background for the figure\n\nplt.show()\n\n\n\nThroughout the semester, the lectures will incorporate a variety of programming examples. The slides are provided in Jupyter Notebook format, allowing you to interact with the code directly. Since Jupyter Notebooks also support plain text, you can personalize the lecture notes by adding your own annotations."
  },
  {
    "objectID": "computing/01/slides.html#lecture-notes-output",
    "href": "computing/01/slides.html#lecture-notes-output",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Lecture Notes",
    "text": "Lecture Notes"
  },
  {
    "objectID": "computing/01/index.html#sample-jupyter-notebooks",
    "href": "computing/01/index.html#sample-jupyter-notebooks",
    "title": "Jupyter Notebooks and Google Colab",
    "section": "Sample Jupyter Notebooks",
    "text": "Sample Jupyter Notebooks\n\n01_ottawa_river_temperature (Jupyter Notebook)\n02_empty (Jupyter Notebook)\n03_missing_library (Jupyter Notebook)\n04_stock_price (Jupyter Notebook)\n05_central_limit (Jupyter Notebook)\n\nThree notebooks from Aurélien Géron introducing essential concepts for machine learning. In the coming weeks, you might want to go through these at your own pace.\n\nnumpy – a fundamental library centered around N-dimensional array objects.\npandas – powerfull data analysis tools, centered around the DataFrame.\nvisualization – demonstrates how to use the matplotlib to produce beautiful graphs.",
    "crumbs": [
      "**Computing**",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "lectures/02/slides.html#debunking-the-myths",
    "href": "lectures/02/slides.html#debunking-the-myths",
    "title": "Introduction to machine learning",
    "section": "Debunking the Myths",
    "text": "Debunking the Myths\n\n\n\n (Burkov 2019)\n\n\nLet’s start by telling the truth: machines don’t learn. (…) just like artificial intelligence is not intelligence, machine learning is not learning.\n\n\n\n\nAndriy Burkov, a machine learning expert based in Quebec City, Canada, authored The Hundred-Page Machine Learning Book, which is referenced at the end of this presentation. He is active on LinkedIn and publishes a newsletter, True Positive Weekly, where he shares significant developments and insights from the field that have attracted his attention each week."
  },
  {
    "objectID": "lectures/02/slides.html#message-of-the-day",
    "href": "lectures/02/slides.html#message-of-the-day",
    "title": "Introduction to machine learning",
    "section": "Message of the day",
    "text": "Message of the day\n\n\n\n\n\n\n\nFor the third year in a row, TIME magazine has released its list of the 100 most influential figures in the field of artificial intelligence.\n\n\nTIME100 AI 2025 - The 100 Most Influential People in AI 2025, TIME, 2025-08-28."
  },
  {
    "objectID": "lectures/02/slides.html#remark",
    "href": "lectures/02/slides.html#remark",
    "title": "Introduction to machine learning",
    "section": "Remark",
    "text": "Remark\nIn the evolution of intelligence, learning was one of the first milestones to emerge. It is also one of the most thoroughly understood mechanisms in natural intelligence.\n:::"
  },
  {
    "objectID": "lectures/02/slides.html#training-data-data-representation",
    "href": "lectures/02/slides.html#training-data-data-representation",
    "title": "Introduction to machine learning",
    "section": "3. Training data: data representation",
    "text": "3. Training data: data representation\n\n\n\n\n\n\n\n\n\nMoon Phase\nForecast\nOutdoor Temperature (°C)\nWater Temperature (°C)\n\n\n\n\nFull Moon\nSunny\n25\n22\n\n\nNew Moon\nCloudy\n18\n19\n\n\nFirst Quarter\nRainy\n15\n17\n\n\nLast Quarter\nSunny\n30\n24\n\n\nFull Moon\nCloudy\n20\n20\n\n\nNew Moon\nRainy\n22\n21\n\n\n\n\nThe data is often presented in a tabular (matrix) format, where each row represents an attribute vector (feature vector), typically denoted as \\(x_i\\), which corresponds to the \\(i\\)-th example in the training set."
  },
  {
    "objectID": "lectures/02/slides.html#training-data-label-representation",
    "href": "lectures/02/slides.html#training-data-label-representation",
    "title": "Introduction to machine learning",
    "section": "3. Training data: label representation",
    "text": "3. Training data: label representation\n\n\n\nFishing Day Likelihood\n\n\n\n\nExcellent\n\n\nAverage\n\n\nPoor\n\n\nExcellent\n\n\nAverage\n\n\nPoor\n\n\n\n\nThe labels are generally represented as a column vector, with \\(y_i\\) denoting the label for the \\(i\\)-th example."
  },
  {
    "objectID": "lectures/02/slides.html#example-palmer-pinguins-dataset",
    "href": "lectures/02/slides.html#example-palmer-pinguins-dataset",
    "title": "Introduction to machine learning",
    "section": "Example: Palmer Pinguins Dataset",
    "text": "Example: Palmer Pinguins Dataset\n\n\n\n\n\n\n\n\nThe Palmer penguins dataset by Allison Horst, Alison Hill, and Kristen Gorman was first made publicly available as an R package. The goal of the Palmer Penguins dataset is to replace the highly overused Iris dataset for data exploration & visualization.\n\n\nUsing this Python package you can easily load the Palmer penguins into your Python environment.\n\nInitially, we will examine the entire example from a high-level perspective to provide a clear overview of the steps involved. Subsequently, we will revisit this example in greater detail.\n\n\nThe Palmer penguins dataset by Allison Horst, Alison Hill, and Kristen Gorman. Artwork by @allison_horst"
  },
  {
    "objectID": "lectures/02/slides.html#example-in-case-of-a-missing-library",
    "href": "lectures/02/slides.html#example-in-case-of-a-missing-library",
    "title": "Introduction to machine learning",
    "section": "Example: In Case of a Missing Library",
    "text": "Example: In Case of a Missing Library\n\ntry:\n  from palmerpenguins import load_penguins\nexcept:\n  ! pip install palmerpenguins\n  from palmerpenguins import load_penguins\n\n\n\nIf you are executing this Jupyter Notebook within Google Colab or any environment where the library is not pre-installed, proceed with the installation."
  },
  {
    "objectID": "lectures/02/slides.html#example-wait-a-minute",
    "href": "lectures/02/slides.html#example-wait-a-minute",
    "title": "Introduction to machine learning",
    "section": "Example: Wait a Minute!",
    "text": "Example: Wait a Minute!\n\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Make predictions\n\ny_pred = clf.predict(X)\n\n# Evaluate the model\n\naccuracy = accuracy_score(y, y_pred)\nreport = classification_report(y, y_pred, target_names=target_names)\n\nprint(f'Accuracy: {accuracy:.2f}')\nprint('Classification Report:')\nprint(report)\n\n\n\n\n\n\n\nImportant\n\n\nThis example is misleading, or even flawed!\n\n\n\n\nThe performance of this classifier appears to be perfect at first glance. However, is it really?"
  },
  {
    "objectID": "lectures/02/slides.html#example-exploration-output",
    "href": "lectures/02/slides.html#example-exploration-output",
    "title": "Introduction to machine learning",
    "section": "Example: Exploration",
    "text": "Example: Exploration\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "lectures/02/slides.html#example-exploration-1-output",
    "href": "lectures/02/slides.html#example-exploration-1-output",
    "title": "Introduction to machine learning",
    "section": "Example: Exploration",
    "text": "Example: Exploration\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000"
  },
  {
    "objectID": "lectures/02/slides.html#example-visualizing-the-tree",
    "href": "lectures/02/slides.html#example-visualizing-the-tree",
    "title": "Introduction to machine learning",
    "section": "Example: Visualizing the Tree",
    "text": "Example: Visualizing the Tree\n\ntree.plot_tree(clf, \n               feature_names = X.columns,\n               class_names = target_names,\n               label = 'none',\n               filled = True)\nplt.show()"
  },
  {
    "objectID": "lectures/02/slides.html#example-loading-the-data-1",
    "href": "lectures/02/slides.html#example-loading-the-data-1",
    "title": "Introduction to machine learning",
    "section": "Example: loading the data",
    "text": "Example: loading the data\n\nfrom sklearn.datasets import load_iris\n\n# Load the Iris dataset\n\niris = load_iris()\n\n\n\nWhen using your own dataset, you will have to download the files as we have in the Ottawa River Temperature Jupyter Notebook.\n\n\nConveniently, scikit-learn comes with toy and real-world datasets to facilitate experimentation. See here for a description of load_iris."
  },
  {
    "objectID": "lectures/02/slides.html#example-using-a-decisiontree-1",
    "href": "lectures/02/slides.html#example-using-a-decisiontree-1",
    "title": "Introduction to machine learning",
    "section": "Example: Using a DecisionTree",
    "text": "Example: Using a DecisionTree\n\nfrom sklearn import tree\n\nclf = tree.DecisionTreeClassifier()\n\n\n\nThere are dozens of classifiers, including these ones: decision trees, support vector machines, k-nearest neighbors, logistic regression, and neural networks."
  },
  {
    "objectID": "lectures/02/slides.html#example-training-1",
    "href": "lectures/02/slides.html#example-training-1",
    "title": "Introduction to machine learning",
    "section": "Example: Training",
    "text": "Example: Training\n\n# It is customary to use X and y for the data and labels\n\nX, y = iris.data, iris.target\n\n# Training\n\nclf = clf.fit(X, y)\n\n\nAll the classifiers inherit from sklearn.base.BaseEstimator and sklearn.base.ClassifierMixin. Accordingly, all the classifiers implement fit, predict, and score.\nLe DecisionTreeClassifier de scikit-learn construit un arbre de décision en divisant récursivement l’ensemble de données en sous-ensembles, basé sur l’attribut qui résulte dans le gain d’information le plus élevé (par exemple, l’impureté de Gini, l’entropie). Voici une description concise du processus :\n\nInitialisation : L’algorithme commence avec l’ensemble de données entier comme nœud racine.\nCritères de division : Pour chaque nœud, il évalue toutes les divisions possibles à travers toutes les attributs pour trouver celle qui sépare le mieux les classes. Cela est généralement fait en minimisant un critère comme l’impureté de Gini ou l’entropie.\nDivision récursive : L’ensemble de données est divisé en sous-ensembles basés sur l’attribut et le seuil sélectionnés, créant des nœuds enfants. Ce processus est répété récursivement pour chaque nœud enfant.\nConditions d’arrêt : La division s’arrête lorsqu’un critère prédéfini est atteint, comme une profondeur maximale de l’arbre, un nombre minimum d’échantillons par feuille, ou si une division supplémentaire n’améliore pas significativement le gain d’information.\nNœuds terminaux : Une fois la division terminée, chaque nœud terminal se voit attribuer une étiquette de classe basée sur la classe majoritaire des échantillons dans ce nœud.\n\nL’arbre résultant peut ensuite être utilisé pour classifier de nouveaux échantillons en parcourant de la racine à un nœud terminal, en suivant les règles de décision définies à chaque nœud."
  },
  {
    "objectID": "lectures/02/slides.html#example-visualizing-the-tree-12-1",
    "href": "lectures/02/slides.html#example-visualizing-the-tree-12-1",
    "title": "Introduction to machine learning",
    "section": "Example: Visualizing the tree (1/2)",
    "text": "Example: Visualizing the tree (1/2)\n\nimport matplotlib.pyplot as plt\n\ntree.plot_tree(clf)\nplt.show()"
  },
  {
    "objectID": "lectures/02/slides.html#example-visualizing-the-tree-22-1",
    "href": "lectures/02/slides.html#example-visualizing-the-tree-22-1",
    "title": "Introduction to machine learning",
    "section": "Example: Visualizing the tree (2/2)",
    "text": "Example: Visualizing the tree (2/2)\n\ntree.plot_tree(clf, \n               feature_names=iris.feature_names, \n               class_names=iris.target_names,\n               label='none',\n               filled=True)\nplt.show()\n\n\n\n\n\n\n\n\n\nIn a DecisionTreeClassifier, each internal node of the tree represents a decision based on a feature, each branch represents the outcome of that decision, and each leaf node represents a class label. The decision tree makes predictions by traversing from the root to a leaf node, following the decision rules defined at each node. Decision trees are intuitive and easy to interpret but can be prone to overfitting if not properly regulated.\nTo build a decision tree, the method fit follows these steps:\n\nSelect the Best Attribute: Choose the attribute that best splits the data based on a criterion like Entropy, Gini Index (default), or Log Loss.\nCreate a Node: Make this attribute the root node of the tree, and create branches for each possible value of the attribute.\nSplit the Dataset: Divide the dataset into subsets, one for each branch, based on the attribute’s values.\nRepeat Recursively: For each subset, repeat steps 1-3 using only the data in that subset and excluding the attribute used at the parent node.\nStop Conditions: Stop the recursion when one of the following conditions is met:\n\nAll instances in a subset belong to the same class.\nNo more attributes are available for splitting.\nA predefined depth limit or minimum number of instances per node is reached.\n\nAssign Labels: For each leaf node, assign a class label based on the majority class of instances in that subset.\n\nThis process results in a tree where each path from the root to a leaf represents a classification rule.\nIn the figure above, the decision nodes contain the following information. - The decision rule, e.g. petal width (cm) &lt;= 0.8 - The Geni score. - The number of examples in the subset corresponding to this node of the tree. - The number of examples for each of the classes, in the subset corresponding to this node of the tree. - A prediction.\nDecision trees are constructed by incrementally adding decision nodes, guided by labeled training examples to determine optimal splits. An effective decision rule ideally segregates the training examples perfectly into their respective classes. For instance, the rule petal width (cm) &lt;= 0.8 exemplifies this: when the rule holds true (left child), all instances are classified as Setosa. Conversely, when the rule does not hold (right child), the subset contains only Versicolor and Virginica, with no Setosa instances. In essence, a good decision rule is one that significantly reduces entropy.\nSee: - Kingsford and Salzberg (2008), you can access the paper here, html or PDF, from a computer with a uOttawa IP address."
  },
  {
    "objectID": "lectures/02/slides.html#example-prediction-1",
    "href": "lectures/02/slides.html#example-prediction-1",
    "title": "Introduction to machine learning",
    "section": "Example: Prediction",
    "text": "Example: Prediction\n\n# Creatingg 2 test examples\n# 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'\n\nX_test = [[5.1, 3.5, 1.4, 0.2],[6.7, 3.0, 5.2, 2.3]]\n\n# Prediction\n\ny_test = clf.predict(X_test)\n\n# Printing the predicted labels for our two examples\n\nprint(iris.target_names[y_test])\n\n['setosa' 'virginica']"
  },
  {
    "objectID": "lectures/02/slides.html#example-complete-1",
    "href": "lectures/02/slides.html#example-complete-1",
    "title": "Introduction to machine learning",
    "section": "Example: Complete",
    "text": "Example: Complete\n\niris = load_iris()\nclf = tree.DecisionTreeClassifier()\nX, y = iris.data, iris.target\nclf = clf.fit(X, y)\ntree.plot_tree(clf)\nX_test = [[5.1, 3.5, 1.4, 0.2],[6.7, 3.0, 5.2, 2.3]]\ny_test = clf.predict(X_test)\nprint(iris.target_names[y_test])\n\n['setosa' 'virginica']"
  },
  {
    "objectID": "lectures/02/slides.html#example-performance-1",
    "href": "lectures/02/slides.html#example-performance-1",
    "title": "Introduction to machine learning",
    "section": "Example: Performance",
    "text": "Example: Performance\n\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Make predictions\n\ny_pred = clf.predict(X)\n\n# Evaluate the model\n\naccuracy = accuracy_score(y, y_pred)\nreport = classification_report(y, y_pred, target_names=iris.target_names)\n\nprint(f'Accuracy: {accuracy:.2f}')\nprint('Classification Report:')\nprint(report)\n\n\n\nThe performance of this classifier appears to be perfect at first glance. However, is it really?"
  },
  {
    "objectID": "lectures/02/slides.html#example-performance-1-output",
    "href": "lectures/02/slides.html#example-performance-1-output",
    "title": "Introduction to machine learning",
    "section": "Example: Performance",
    "text": "Example: Performance\n\nAccuracy: 1.00\nClassification Report:\n              precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        50\n  versicolor       1.00      1.00      1.00        50\n   virginica       1.00      1.00      1.00        50\n\n    accuracy                           1.00       150\n   macro avg       1.00      1.00      1.00       150\nweighted avg       1.00      1.00      1.00       150"
  },
  {
    "objectID": "lectures/02/slides.html#example-discussion-1",
    "href": "lectures/02/slides.html#example-discussion-1",
    "title": "Introduction to machine learning",
    "section": "Example: Discussion",
    "text": "Example: Discussion\nWe have demonstrated a complete example:\n\nLoading the data\nSelecting a classifier\nTraining the model\nVisualizing the model\nMaking a prediction\n\n\n\nHowever, several simplifications were made throughout this process."
  },
  {
    "objectID": "lectures/02/slides.html#example-exploration-2",
    "href": "lectures/02/slides.html#example-exploration-2",
    "title": "Introduction to machine learning",
    "section": "Example: Exploration",
    "text": "Example: Exploration\n\nprint(f'Dataset Description:\\n{iris[\"DESCR\"]}\\n')\n\nDataset Description:\n.. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n:Number of Instances: 150 (50 in each of three classes)\n:Number of Attributes: 4 numeric, predictive attributes and the class\n:Attribute Information:\n    - sepal length in cm\n    - sepal width in cm\n    - petal length in cm\n    - petal width in cm\n    - class:\n            - Iris-Setosa\n            - Iris-Versicolour\n            - Iris-Virginica\n\n:Summary Statistics:\n\n============== ==== ==== ======= ===== ====================\n                Min  Max   Mean    SD   Class Correlation\n============== ==== ==== ======= ===== ====================\nsepal length:   4.3  7.9   5.84   0.83    0.7826\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n============== ==== ==== ======= ===== ====================\n\n:Missing Attribute Values: None\n:Class Distribution: 33.3% for each of 3 classes.\n:Creator: R.A. Fisher\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n:Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher's paper. Note that it's the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher's paper is a classic in the field and\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n.. dropdown:: References\n\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n    Mathematical Statistics\" (John Wiley, NY, 1950).\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n    Structure and Classification Rule for Recognition in Partially Exposed\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n    on Information Theory, May 1972, 431-433.\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n    conceptual clustering system finds 3 classes in the data.\n  - Many, many more ..."
  },
  {
    "objectID": "lectures/02/slides.html#example-exploration-3",
    "href": "lectures/02/slides.html#example-exploration-3",
    "title": "Introduction to machine learning",
    "section": "Example: Exploration",
    "text": "Example: Exploration\n\nprint(f'Feature Names: {iris.feature_names}')\n\nFeature Names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n\n\n\nprint(f'Target Names: {iris.target_names}')\n\nTarget Names: ['setosa' 'versicolor' 'virginica']\n\n\n\nprint(f'Data Shape: {iris.data.shape}')\n\nData Shape: (150, 4)\n\n\n\nprint(f'Target Shape: {iris.target.shape}')\n\nTarget Shape: (150,)"
  },
  {
    "objectID": "lectures/02/slides.html#example-using-seaborn-1",
    "href": "lectures/02/slides.html#example-using-seaborn-1",
    "title": "Introduction to machine learning",
    "section": "Example: Using Seaborn",
    "text": "Example: Using Seaborn\n\nimport seaborn as sns\n\n# Map target values to species names\n\ndf['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n\n# Pairplot using seaborn\n\nsns.pairplot(df, hue='species', markers=[\"o\", \"s\", \"D\"])\nplt.suptitle(\"Pairwise Scatter Plots of Iris Features\", y=1.02)\nplt.show()\n\n\n\nWhat insights can be drawn from examining the graphs?\nThe image presents all pairwise scatter plots for the iris dataset features, with the diagonal displaying histograms for each individual feature. Each dot represents an example (\\(x\\)), and the colors indicate the corresponding labels (\\(y\\)).\nLet’s first consider the diagonal elements:\n\nIs it possible to classify the examples using a single feature?\nWe observe that sepal length or width alone cannot distinguish between the classes.\nHowever, petal length and width allow us to differentiate setosa from the other two varieties, although they do not separate versicolor and virginica effectively.\n\nThe class setosa frequently forms a distinct cluster."
  },
  {
    "objectID": "lectures/02/slides.html#example-using-seaborn-1-output",
    "href": "lectures/02/slides.html#example-using-seaborn-1-output",
    "title": "Introduction to machine learning",
    "section": "Example: Using Seaborn",
    "text": "Example: Using Seaborn"
  },
  {
    "objectID": "lectures/02/slides.html#example-training-and-test-set-1",
    "href": "lectures/02/slides.html#example-training-and-test-set-1",
    "title": "Introduction to machine learning",
    "section": "Example: Training and test set",
    "text": "Example: Training and test set\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into training and testing sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n\n\n\nWe will have a lot more to say about testing in the coming weeks.\nPractice: Experiment with different values for random_state. What do you observe? Why do you think this occurs? Why is it important to set the random_state value?\n\n\nOur initial classifier, a decision tree, was constructed using the entire dataset. While it provides the “best” fit for the data, we cannot ascertain its predictive accuracy without further evaluation."
  },
  {
    "objectID": "lectures/02/slides.html#example-creating-a-new-classifier-1",
    "href": "lectures/02/slides.html#example-creating-a-new-classifier-1",
    "title": "Introduction to machine learning",
    "section": "Example: Creating a new classifier",
    "text": "Example: Creating a new classifier\n\n# Train the model\nclf = tree.DecisionTreeClassifier()"
  },
  {
    "objectID": "lectures/02/slides.html#example-training-the-new-classifier-1",
    "href": "lectures/02/slides.html#example-training-the-new-classifier-1",
    "title": "Introduction to machine learning",
    "section": "Example: Training the new classifier",
    "text": "Example: Training the new classifier\n\n# Train the model\nclf.fit(X_train, y_train)"
  },
  {
    "objectID": "lectures/02/slides.html#example-making-predictions-1",
    "href": "lectures/02/slides.html#example-making-predictions-1",
    "title": "Introduction to machine learning",
    "section": "Example: Making predictions",
    "text": "Example: Making predictions\n\n# Make predictions\ny_pred = clf.predict(X_test)"
  },
  {
    "objectID": "lectures/02/slides.html#example-measuring-the-performance-1",
    "href": "lectures/02/slides.html#example-measuring-the-performance-1",
    "title": "Introduction to machine learning",
    "section": "Example: measuring the performance",
    "text": "Example: measuring the performance\n\nfrom sklearn.metrics import classification_report, accuracy_score\n# Make predictions\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred, target_names=iris.target_names)\n\nprint(f'Accuracy: {accuracy:.2f}')\nprint('Classification Report:')\nprint(report)\n\n\n\n\nHere is a discussion on model persistence for scikit-learn models."
  },
  {
    "objectID": "lectures/02/slides.html#example-measuring-the-performance-1-output",
    "href": "lectures/02/slides.html#example-measuring-the-performance-1-output",
    "title": "Introduction to machine learning",
    "section": "Example: measuring the performance",
    "text": "Example: measuring the performance\n\nAccuracy: 0.87\nClassification Report:\n              precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00         7\n  versicolor       0.83      0.83      0.83        12\n   virginica       0.82      0.82      0.82        11\n\n    accuracy                           0.87        30\n   macro avg       0.88      0.88      0.88        30\nweighted avg       0.87      0.87      0.87        30"
  },
  {
    "objectID": "lectures/04/slides.html#message-of-the-day",
    "href": "lectures/04/slides.html#message-of-the-day",
    "title": "Linear regression and gradient descent",
    "section": "Message of the Day",
    "text": "Message of the Day\n\n\n\n\n\n\n\nAlbania has appointed an AI minister, Diella, to the role of minister for public procurement. While the appointment is symbolic due to constitutional requirements, Diella aims to eliminate corruption in public tenders by leveraging AI for faster, more efficient, and accountable processes. The initiative has received mixed reactions, with some viewing it as a publicity stunt while others see potential for improving transparency and trust in public procurement.\n\n\nWorld’s first AI minister will eliminate corruption, says Albania’s PM, by Guy Delauney, BBC, 2025-09-12."
  },
  {
    "objectID": "lectures/03/slides.html#message-of-the-day",
    "href": "lectures/03/slides.html#message-of-the-day",
    "title": "Learning Algorithms",
    "section": "Message of the Day",
    "text": "Message of the Day\n\n\n\nLarge language models exhibit remarkable linguistic capabilities, prompting an increasing number of individuals to engage in personal dialogues with them. Murray Shanahan, affiliated with Google DeepMind and Imperial College, introduces an compelling framework for examining the “behavior” of these models. He conceptualizes their interactions through the lens of role play, as discussed in his recent work published in Nature.\n\nConsciousness, reasoning and the philosophy of AI with Murray Shanahan, in this Google DeepMind podcast, Hannah Fry interviews Murray Shanahan, 2025-04-24.\n\nDepending on the context of their interaction prompts, these models can adopt personas that simulate malevolent individuals, potentially offering advice with harmful consequences.\n\nOpenAI Eagerly Trying To Reduce AI Psychosis And Squash Co-Creation Of Human-AI Delusions When Using ChatGPT And GPT-5, by Lance Eliot, Forbes, 2025-09-02.\nWhat to know about ‘AI psychosis’ and the effect of AI chatbots on mental health, PBS News, 2025-08-31.\n\nHere is a reminder for the University of Ottawa’s wellness page, which offers a comprehensive array of resources, including medical and mental health-care services, designed to support your well-being and that of those around you.\n\nStudent Health and Wellness\n\n\n\nMicrosoft boss troubled by rise in reports of ‘AI psychosis’, BBC News, 2025-08-21."
  },
  {
    "objectID": "lectures/03/slides.html#learning-algorithms",
    "href": "lectures/03/slides.html#learning-algorithms",
    "title": "Learning Algorithms",
    "section": "Learning algorithms",
    "text": "Learning algorithms\nIn this lecture, we consider three radically different learning algorithms: k-nearest neighbors (KNN), decision trees, and linear regression.\nLearning Objectives\n\nExplain the process of training a model"
  },
  {
    "objectID": "lectures/03/slides.html#interpretable",
    "href": "lectures/03/slides.html#interpretable",
    "title": "Learning Algorithms",
    "section": "Interpretable",
    "text": "Interpretable\n\n\n\n\n\n\n\nDecision trees are valuable because they clearly delineate the rules learned by the model. The decision tree above illustrates the results of a study examining clinically significant anxiety symptoms. In this instance, the initial determinant was whether students reported having a positive home environment.\n\n\nAttribution: Public Health Agency of Canada"
  },
  {
    "objectID": "lectures/03/slides.html#linear-regression-1",
    "href": "lectures/03/slides.html#linear-regression-1",
    "title": "Learning Algorithms",
    "section": "Linear Regression",
    "text": "Linear Regression\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\[\n  \\hat{y_i} = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\n\nHere, \\(\\theta_{j}\\) is the \\(j\\)th parameter of the (linear) model, with \\(\\theta_0\\) being the bias term/parameter, and \\(\\theta_1 \\ldots \\theta_D\\) being the feature weights.\n\n\nIn statistical contexts, the notation \\(\\hat{y_i}\\) is employed to denote the estimator of the true value \\(y_i\\). This represents the predicted or estimated outcome based on a given model.\nConversely, in machine learning, the notation \\(h(x_i)\\) is used, where \\(h\\) represents the hypothesis function or model applied to the input data \\(x_i\\). The hypothesis function \\(h\\) is derived from a predefined hypothesis space, which encompasses the set of all possible models that can be used to map input data to predicted outcomes.\nThe parameter \\(\\theta_0\\) is called the bias term (also “intercept”) because:\n\nIt shifts the prediction independently of the inputs.\nGeometrically, it moves the regression hyperplane up or down (or left/right in classification), so the model is not forced to pass through the origin.\nIn machine learning terms, it acts like a constant offset, compensating for systematic effects not explained by the features.\n\nSo it’s called “bias” because it introduces a fixed baseline to which the contributions of the other parameters are added.\n\n\n\nIn my presentations, I use \\(\\hat{y_i}\\) and \\(h(x_i)\\) synonymously."
  },
  {
    "objectID": "lectures/03/slides.html#what-is-a-decision-tree",
    "href": "lectures/03/slides.html#what-is-a-decision-tree",
    "title": "Learning Algorithms",
    "section": "What is a Decision Tree?",
    "text": "What is a Decision Tree?\n\nA decision tree is a hierarchical structure represented as a directed acyclic graph, used for classification and regression tasks.\nEach internal node performs a binary test on a particular feature (\\(j\\)), such as evaluating whether the number of connections at a school surpasses a specified threshold.\nThe leaves function as decision nodes.\n\n\n\nDecision trees can extend beyond binary splits, as exemplified by algorithms like ID3, which accommodate nodes with multiple children.\n\n\nThe tree’s structure is inferred (learnt) from the training data."
  },
  {
    "objectID": "lectures/03/slides.html#classifying-new-instances-inference",
    "href": "lectures/03/slides.html#classifying-new-instances-inference",
    "title": "Learning Algorithms",
    "section": "Classifying New Instances (Inference)",
    "text": "Classifying New Instances (Inference)\n\nBegin at the root node of the decision tree. Proceed by answering a sequence of binary questions until a leaf node is reached. The label associated with this leaf denotes the classification of the instance.\nAlternatively, some algorithms may store a probability distribution at the leaf, representing the fraction of training samples corresponding to each class \\(k\\), across all possible classes \\(k\\).\n\n\nWhen a decision tree is used to solve a regression task, each leaf node stores a prediction value. Specifically:\n\\[\n\\hat{y}_\\text{leaf} = \\frac{1}{N_\\text{leaf}} \\sum_{i \\in \\text{leaf}} y_i,\n\\]\nwhere \\(N_\\text{leaf}\\) is the number of training samples that ended up in that leaf, and \\(y_i\\) are their target values."
  },
  {
    "objectID": "lectures/03/slides.html#palmer-pinguins-dataset",
    "href": "lectures/03/slides.html#palmer-pinguins-dataset",
    "title": "Learning Algorithms",
    "section": "Palmer Pinguins Dataset",
    "text": "Palmer Pinguins Dataset\n\n# Loading our dataset\n\ntry:\n  from palmerpenguins import load_penguins\nexcept:\n  ! pip install palmerpenguins\n  from palmerpenguins import load_penguins\n\npenguins = load_penguins()\n\n# Pairplot using seaborn\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.pairplot(penguins, hue='species', markers=[\"o\", \"s\", \"D\"])\nplt.suptitle(\"Pairwise Scatter Plots of Penguins Features\")\nplt.show()"
  },
  {
    "objectID": "lectures/03/slides.html#palmer-pinguins-dataset-output",
    "href": "lectures/03/slides.html#palmer-pinguins-dataset-output",
    "title": "Learning Algorithms",
    "section": "Palmer Pinguins Dataset",
    "text": "Palmer Pinguins Dataset"
  },
  {
    "objectID": "lectures/03/slides.html#binary-classification-problem",
    "href": "lectures/03/slides.html#binary-classification-problem",
    "title": "Learning Algorithms",
    "section": "Binary Classification Problem",
    "text": "Binary Classification Problem\n\nSeveral scatter plots reveal a distinct clustering of Gentoo instances.\nTo illustrate our next exemple, we propose a binary classification model: Gentoo versus non-Gentoo.\nOur analysis will concentrate on two key features: body mass and bill depth."
  },
  {
    "objectID": "lectures/03/slides.html#definition",
    "href": "lectures/03/slides.html#definition",
    "title": "Learning Algorithms",
    "section": "Definition",
    "text": "Definition\nA decision boundary is a “boundary” that partitions the underlying feature space into regions corresponding to different class labels.\n\n\nThe term boundary will be clarified over the next slides."
  },
  {
    "objectID": "lectures/03/slides.html#decision-boundary-1",
    "href": "lectures/03/slides.html#decision-boundary-1",
    "title": "Learning Algorithms",
    "section": "Decision Boundary",
    "text": "Decision Boundary\nThe decision boundary between these attributes can be represented as a line.\n\n\nCode\n# Import necessary libraries\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\ntry:\n  from palmerpenguins import load_penguins\nexcept:\n  ! pip install palmerpenguins\n  from palmerpenguins import load_penguins\n\n# Load the Palmer Penguins dataset\ndf = load_penguins()\n\n# Preserve only the necessary features: 'bill_depth_mm' and 'body_mass_g'\nfeatures = ['bill_depth_mm', 'body_mass_g']\ndf = df[features + ['species']]\n\n# Drop rows with missing values\ndf.dropna(inplace=True)\n\n# Create a binary problem: 'Gentoo' vs 'Not Gentoo'\ndf['species_binary'] = df['species'].apply(lambda x: 1 if x == 'Gentoo' else 0)\n\n# Define feature matrix X and target vector y\nX = df[features].values\ny = df['species_binary'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Function to plot initial scatter of data\ndef plot_scatter(X, y):\n    plt.figure(figsize=(9, 5))\n    plt.scatter(X[y == 1, 0], X[y == 1, 1], color='orange', edgecolors='k', marker='o', label='Gentoo')\n    plt.scatter(X[y == 0, 0], X[y == 0, 1], color='blue', edgecolors='k', marker='o', label='Not Gentoo')\n    plt.xlabel('Bill Depth (mm)')\n    plt.ylabel('Body Mass (g)')\n    plt.title('Scatter Plot of Bill Depth vs. Body Mass')\n    plt.legend()\n    plt.show()\n    \n# Plot the initial scatter plot\nplot_scatter(X_train, y_train)"
  },
  {
    "objectID": "lectures/03/slides.html#decision-boundary-1-output",
    "href": "lectures/03/slides.html#decision-boundary-1-output",
    "title": "Learning Algorithms",
    "section": "Decision Boundary",
    "text": "Decision Boundary"
  },
  {
    "objectID": "lectures/03/slides.html#decision-boundary-2",
    "href": "lectures/03/slides.html#decision-boundary-2",
    "title": "Learning Algorithms",
    "section": "Decision Boundary",
    "text": "Decision Boundary\nThe decision boundary between these attributes can be represented as a line.\n\n\nCode\n# Train a logistic regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Function to plot decision boundary\ndef plot_decision_boundary(X, y, model):\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n                         np.arange(y_min, y_max, 0.1))\n    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    \n    plt.figure(figsize=(9, 5))\n    plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n    plt.scatter(X[y == 1, 0], X[y == 1, 1], color='orange', edgecolors='k', marker='o', label='Gentoo')\n    plt.scatter(X[y == 0, 0], X[y == 0, 1], color='blue', edgecolors='k', marker='o', label='Not Gentoo')\n    plt.xlabel('Bill Depth (mm)')\n    plt.ylabel('Body Mass (g)')\n    plt.title('Logistic Regression Decision Boundary')\n    plt.legend()\n    plt.show()\n\n# Plot the decision boundary on the training set\nplot_decision_boundary(X_train, y_train, model)"
  },
  {
    "objectID": "lectures/03/slides.html#decision-boundary-2-output",
    "href": "lectures/03/slides.html#decision-boundary-2-output",
    "title": "Learning Algorithms",
    "section": "Decision Boundary",
    "text": "Decision Boundary"
  },
  {
    "objectID": "lectures/03/slides.html#definition-1",
    "href": "lectures/03/slides.html#definition-1",
    "title": "Learning Algorithms",
    "section": "Definition",
    "text": "Definition\nWe say that the data is linearly separable when two classes of data can be perfectly separated by a single linear boundary, such as a line in two-dimensional space or a hyperplane in higher dimensions."
  },
  {
    "objectID": "lectures/03/slides.html#simple-decision-doundary",
    "href": "lectures/03/slides.html#simple-decision-doundary",
    "title": "Learning Algorithms",
    "section": "Simple Decision Doundary",
    "text": "Simple Decision Doundary\n\n\n\n\n\n(a) training data, (b) quadratic curve, and (c) linear function.\n\nAttribution: (Geurts, Irrthum, and Wehenkel 2009)\n\n\nThe table on the left presents training data for a hypothetical binary classification task in a medical context, where the two attributes, \\(X_1\\) and \\(X_2\\), are used to predict the target variable, \\(y\\), which can take on two values: sick and healthy. You can imagine that \\(X_1\\) and \\(X_2\\) are measurements, such as blood pressure and heart rate or cholesterol and glucose levels.\nLogistic regression (c) employs a linear decision boundary. In this specific example, the decision boundary is represented by a straight line. Employing logistic regression for this problem results in several classification errors: red dots above the line, which should be classified as ‘sick’, are incorrectly predicted as ‘healthy’. Conversely, green dots below the line, which should be classified as ‘healthy’, are incorrectly predicted as ‘sick’."
  },
  {
    "objectID": "lectures/03/slides.html#complex-decision-boundary",
    "href": "lectures/03/slides.html#complex-decision-boundary",
    "title": "Learning Algorithms",
    "section": "Complex Decision Boundary",
    "text": "Complex Decision Boundary\n\n\n\n\n\nDecision trees are capable of generating irregular and non-linear decision boundaries.\n\nAttribution: ibidem.\n\n\nMake sure to understand the relationships between the eight decision rules delineated in the decision tree and the nine line segments represented in the scatter plot."
  },
  {
    "objectID": "lectures/03/slides.html#definition-revised",
    "href": "lectures/03/slides.html#definition-revised",
    "title": "Learning Algorithms",
    "section": "Definition (revised)",
    "text": "Definition (revised)\nA decision boundary is a hypersurface that partitions the underlying feature space into regions corresponding to different class labels."
  },
  {
    "objectID": "lectures/03/slides.html#constructing-a-decision-tree",
    "href": "lectures/03/slides.html#constructing-a-decision-tree",
    "title": "Learning Algorithms",
    "section": "Constructing a Decision Tree",
    "text": "Constructing a Decision Tree\n\nHow to construct (learnt) a decision tree?\nAre there some trees that are “better” than others?\nIs it feasible to construct an optimal decision tree with computational efficiency?\n\n\n\n(Hyafil and Rivest 1976)"
  },
  {
    "objectID": "lectures/03/slides.html#optimality",
    "href": "lectures/03/slides.html#optimality",
    "title": "Learning Algorithms",
    "section": "Optimality",
    "text": "Optimality\n\nLet \\(X = \\{x_1, \\ldots, x_n\\}\\) be a finite set of objects.\nLet \\(\\mathcal{T} = \\{T_1, \\ldots, T_t\\}\\) be a finite set of tests.\nFor each object and test, we have:\n\n\\(T_i(x_j)\\) is either true or false.\n\nAn optimal tree is one that completely identifies all the objects in \\(X\\) and \\(|T|\\) is minimum.\n\n\n\nHyafil and Rivest (1976) showed that constructing optimal binary decision trees is NP-Complete.\n\n\n(Hyafil and Rivest 1976)"
  },
  {
    "objectID": "lectures/03/slides.html#constructing-a-decision-tree-1",
    "href": "lectures/03/slides.html#constructing-a-decision-tree-1",
    "title": "Learning Algorithms",
    "section": "Constructing a Decision Tree",
    "text": "Constructing a Decision Tree\n\nIterative development: Initiate with an empty tree. Progressively introduce nodes, each informed by the training dataset, continuing until the dataset is completely classified or alternative termination criteria, such as maximum tree depth, are met.\n\n\n\nLearning is the process of building the tree from training data."
  },
  {
    "objectID": "lectures/03/slides.html#constructing-a-decision-tree-2",
    "href": "lectures/03/slides.html#constructing-a-decision-tree-2",
    "title": "Learning Algorithms",
    "section": "Constructing a Decision Tree",
    "text": "Constructing a Decision Tree\n\nInitial Node Construction:\n\nTo establish the root node, evaluate all available \\(D\\) features.\n\nFor each feature, assess various threshold values derived from the observed data within the training set."
  },
  {
    "objectID": "lectures/03/slides.html#constructing-a-decision-tree-3",
    "href": "lectures/03/slides.html#constructing-a-decision-tree-3",
    "title": "Learning Algorithms",
    "section": "Constructing a Decision Tree",
    "text": "Constructing a Decision Tree\n\nFor a numerical feature, the algorithm considers all possible split points (thresholds) in the feature’s range.\nThese split points are typically the midpoints between two consecutive, sorted unique values of the feature."
  },
  {
    "objectID": "lectures/03/slides.html#constructing-a-decision-tree-4",
    "href": "lectures/03/slides.html#constructing-a-decision-tree-4",
    "title": "Learning Algorithms",
    "section": "Constructing a Decision Tree",
    "text": "Constructing a Decision Tree\n\nFor a categorical feature with \\(k\\) unique values, the algorithm considers all possible ways of splitting the categories into two groups.\nFor instance, if the feature (forecast) has values, ‘Rainy’, ‘Cloudy’, and ‘Sunny’, it evaluates the following splits:\n\n\\(\\{\\mathrm{Rainy}\\}\\) vs. \\(\\{\\mathrm{Cloudy}, \\mathrm{Sunny}\\}\\),\n\\(\\{\\mathrm{Cloudy}\\}\\) vs. \\(\\{\\mathrm{Rainy}, \\mathrm{Sunny}\\}\\) ,\n\\(\\{\\mathrm{Sunny}\\}\\) vs. \\(\\{\\mathrm{Rainy}, \\mathrm{Cloudy}\\}\\)."
  },
  {
    "objectID": "lectures/03/slides.html#evaluation",
    "href": "lectures/03/slides.html#evaluation",
    "title": "Learning Algorithms",
    "section": "Evaluation",
    "text": "Evaluation\nWhat defines a “good” data split?\n\n\n\\(\\{\\mathrm{Rainy}\\}\\) vs. \\(\\{\\mathrm{Cloudy}, \\mathrm{Sunny}\\}\\) : \\([20,10,5]\\) and \\([10,10,15]\\).\n\\(\\{\\mathrm{Cloudy}\\}\\) vs. \\(\\{\\mathrm{Rainy}, \\mathrm{Sunny}\\}\\) : \\([40,0,0]\\) and \\([0,30,0]\\).\n\n\n\n\nWhere \\([20,10,5]\\) indicates that the subgroup contains 20 examples of the ‘Poor’, 10 for ‘Average’, and 5 for ‘Excellent’, for our predictive model to classify the likelihood of a successful fishing day."
  },
  {
    "objectID": "lectures/03/slides.html#evaluation-1",
    "href": "lectures/03/slides.html#evaluation-1",
    "title": "Learning Algorithms",
    "section": "Evaluation",
    "text": "Evaluation\n\nHeterogeneity (also referred to as impurity) and homogeneity are critical metrics for evaluating the composition of resulting data partitions.\nOptimally, each of these partitions should contain data entries from a single class to achieve maximum homogeneity.\nEntropy and the Gini index are two widely utilized metrics for assessing these characteristics."
  },
  {
    "objectID": "lectures/03/slides.html#evalution",
    "href": "lectures/03/slides.html#evalution",
    "title": "Learning Algorithms",
    "section": "Evalution",
    "text": "Evalution\nObjective function for sklearn.tree.DecisionTreeClassifier (CART):\n\\[\n  J(k,t_k) = \\frac{N_{\\text{left}}}{N_{\\text{parent}}} G_{\\text{left}} + \\frac{N_{\\text{right}}}{N_{\\text{parent}}} G_{\\text{right}}\n\\]\n\nThe cost of partitioning the data using feature \\(k\\) and threshold \\(t_k\\).\n\\(N_{\\text{left}}\\) and \\(N_{\\text{right}}\\) is the number of examples in the left and right subsets, respectively, and \\(N_{\\text{parent}}\\) is the number of examples before splitting the data.\n\\(G_{\\text{left}}\\) and \\(G_{\\text{right}}\\) is the impurity of the left and right subsets, respectively.\n\n\n\nMinimize or maximize \\(J\\)?"
  },
  {
    "objectID": "lectures/03/slides.html#gini-index",
    "href": "lectures/03/slides.html#gini-index",
    "title": "Learning Algorithms",
    "section": "Gini Index",
    "text": "Gini Index\n\nGini index (default)\n\n\\[\n  G_i = 1 - \\sum_{k=1}^n p_{i,k}^2\n\\]\n\n\\(p_{i,k}\\) is the proportion of the examples from this class \\(k\\) in the node \\(i\\).\nWhat is the maximum value of the Gini index?\n\n\n\nThe value of the Gini index is maximum when all the classes are equiprobable, i.e. the proportions are the same.\nFor a binary classification, \\(1 - [\\frac{1}{2}^2 + \\frac{1}{2}^2] = 0.5\\).\nFor the general case, \\(1 - n \\times \\frac{1}{n}^2 = 1 - \\frac{1}{n}\\), as \\(n \\to \\infty\\), \\(\\frac{1}{n} \\to 0\\), and the Gini index tends to 1."
  },
  {
    "objectID": "lectures/03/slides.html#gini-index-1",
    "href": "lectures/03/slides.html#gini-index-1",
    "title": "Learning Algorithms",
    "section": "Gini Index",
    "text": "Gini Index\nConsidering a binary classification problem:\n\n\\(1 - [(0/100)^2 + (100/100)^2] = 0\\) (pure)\n\\(1 - [(25/100)^2 + (75/100)^2] = 0.375\\)\n\\(1 - [(50/100)^2 + (50/100)^2] = 0.5\\)\n\n\nBased on the above, are we solving a minimization or maximization problem?\nWhen the problem is formulated as follows:\n\nFor each candidate split \\((k, t_k)\\), compute\n\n\\[\n  J(k,t_k) = \\frac{N_{\\text{left}}}{N_{\\text{parent}}} G_{\\text{left}} + \\frac{N_{\\text{right}}}{N_{\\text{parent}}} G_{\\text{right}}\n\\]\n\nThe algorithm then chooses the split with the lowest \\(J\\), i.e. the split that yields the smallest weighted impurity.\n\nMany textbooks describe this as maximizing impurity reduction (information gain), which is just\n\\[\n\\Delta G = G_{\\text{parent}} - J(k,t_k).\n\\]\nMaximizing \\(\\Delta G\\) has benefits.\nIf no potential split for a given parent node leads to a reduction in impurity, the recursive process of node splitting halts. In this scenario, the classification performance of the parent node surpasses that of any possible split.\nIf the algorithm is considering splitting a parent node, it means the \\(G_{\\text{parent}} &gt; 0\\), otherwise the process would have stopped.\nWhat about \\(\\frac{N_{\\text{left}}}{N_{\\text{parent}}}\\) and \\(\\frac{N_{\\text{right}}}{N_{\\text{parent}}}\\)?\nWhat happens if the number of examples in one child is very small?\nSuppose we isolate 1 sample (pure) into the left child, and leave \\(N-1\\) mixed in the right child.\n\nLeft child: \\(G_{left} = 0\\), weight = \\(1/N\\).\nRight child: \\(G_{right} \\approx G_{parent}\\), weighted by \\((N-1)/N\\).\n\nThus \\[\n   J(k,t_k) \\;\\approx\\; \\frac{N-1}{N} \\, G_{\\textrm{parent}} ,\n\\]\ntherefore\n\\[\n\\Delta \\;\\approx\\; \\, G_{\\textrm{parent}} - \\frac{N-1}{N} \\, G_{\\textrm{parent}} = \\frac{1}{N} \\, G_{\\textrm{parent}}.\n\\]\nThat’s only a tiny gain (shrinks as \\(N\\) grows)."
  },
  {
    "objectID": "lectures/03/slides.html#gini-index-2",
    "href": "lectures/03/slides.html#gini-index-2",
    "title": "Learning Algorithms",
    "section": "Gini Index",
    "text": "Gini Index\n\n\nCode\ndef gini_index(p):\n    \"\"\"Calculate the Gini index.\"\"\"\n    return 1 - (p**2 + (1 - p)**2)\n\n# Probability values for class 1\np_values = np.linspace(0, 1, 100)\n\n# Calculate Gini index for each probability\ngini_values = [gini_index(p) for p in p_values]\n\n# Plot the Gini index\nplt.figure(figsize=(8, 6))\nplt.plot(p_values, gini_values, label='Gini Index', color='b')\nplt.title('Gini Index for Binary Classification')\nplt.xlabel('Probability of Class 1 (p)')\nplt.ylabel('Gini Index')\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/03/slides.html#iris-dataset",
    "href": "lectures/03/slides.html#iris-dataset",
    "title": "Learning Algorithms",
    "section": "Iris Dataset",
    "text": "Iris Dataset\n\n\n\n\n\n\n\n\nAttribution: (Géron 2019), Figures 6.1 and 6.2"
  },
  {
    "objectID": "lectures/03/slides.html#complete-example",
    "href": "lectures/03/slides.html#complete-example",
    "title": "Learning Algorithms",
    "section": "Complete Example",
    "text": "Complete Example\n\n\n\nDecision and Classification Trees, Clearly Explained!!!, (18 m 7s) StatQuest, 2021-04-26"
  },
  {
    "objectID": "lectures/03/slides.html#limitations",
    "href": "lectures/03/slides.html#limitations",
    "title": "Learning Algorithms",
    "section": "Limitations",
    "text": "Limitations\n\nPossibly creates large trees\n\nChallenge for interpretation\nOverfitting\n\nGreedy algorithm, no guarantee to find the optimal tree. (Hyafil and Rivest 1976)\nSmall changes to the data set produce vastly different trees"
  },
  {
    "objectID": "lectures/03/slides.html#large-trees",
    "href": "lectures/03/slides.html#large-trees",
    "title": "Learning Algorithms",
    "section": "Large Trees",
    "text": "Large Trees\n\n\n\n\n\n\n\n(Stiglic et al. 2012)"
  },
  {
    "objectID": "lectures/03/slides.html#small-changes-to-the-dataset",
    "href": "lectures/03/slides.html#small-changes-to-the-dataset",
    "title": "Learning Algorithms",
    "section": "Small Changes to the Dataset",
    "text": "Small Changes to the Dataset\n\n\nCode\nfrom sklearn import tree\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Loading the dataset\n\nX, y = load_penguins(return_X_y = True)\n\ntarget_names = ['Adelie','Chinstrap','Gentoo']\n\n# Split the dataset into training and testing sets\n\nfor seed in (4, 7, 90, 96, 99, 2):\n\n  print(f'Seed: {seed}')\n\n  # Create new training and test sets based on a different random seed\n\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n\n  # Creating a new classifier\n\n  clf = tree.DecisionTreeClassifier(random_state=seed)\n\n  # Training\n\n  clf.fit(X_train, y_train)\n\n  # Make predictions\n\n  y_pred = clf.predict(X_test)\n\n  # Plotting the tree\n\n  tree.plot_tree(clf, \n               feature_names = X.columns,\n               class_names = target_names,\n               filled = True)\n  plt.show()\n\n  # Evaluating the model\n\n  accuracy = accuracy_score(y_test, y_pred)\n\n  report = classification_report(y_test, y_pred, target_names=target_names)\n\n  print(f'Accuracy: {accuracy:.2f}')\n  print('Classification Report:')\n  print(report)"
  },
  {
    "objectID": "lectures/03/slides.html#small-changes-to-the-dataset-output",
    "href": "lectures/03/slides.html#small-changes-to-the-dataset-output",
    "title": "Learning Algorithms",
    "section": "Small Changes to the Dataset",
    "text": "Small Changes to the Dataset\n\nSeed: 4\n\n\n\n\n\n\n\n\n\nAccuracy: 0.99\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       1.00      0.97      0.99        36\n   Chinstrap       0.94      1.00      0.97        17\n      Gentoo       1.00      1.00      1.00        16\n\n    accuracy                           0.99        69\n   macro avg       0.98      0.99      0.99        69\nweighted avg       0.99      0.99      0.99        69\n\nSeed: 7\n\n\n\n\n\n\n\n\n\nAccuracy: 0.91\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       0.96      0.83      0.89        30\n   Chinstrap       0.83      1.00      0.91        15\n      Gentoo       0.92      0.96      0.94        24\n\n    accuracy                           0.91        69\n   macro avg       0.90      0.93      0.91        69\nweighted avg       0.92      0.91      0.91        69\n\nSeed: 90\n\n\n\n\n\n\n\n\n\nAccuracy: 0.94\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       0.90      1.00      0.95        26\n   Chinstrap       0.93      0.88      0.90        16\n      Gentoo       1.00      0.93      0.96        27\n\n    accuracy                           0.94        69\n   macro avg       0.94      0.93      0.94        69\nweighted avg       0.95      0.94      0.94        69\n\nSeed: 96\n\n\n\n\n\n\n\n\n\nAccuracy: 0.90\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       0.83      0.97      0.89        30\n   Chinstrap       1.00      0.67      0.80        15\n      Gentoo       0.96      0.96      0.96        24\n\n    accuracy                           0.90        69\n   macro avg       0.93      0.86      0.88        69\nweighted avg       0.91      0.90      0.90        69\n\nSeed: 99\n\n\n\n\n\n\n\n\n\nAccuracy: 1.00\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       1.00      1.00      1.00        31\n   Chinstrap       1.00      1.00      1.00        12\n      Gentoo       1.00      1.00      1.00        26\n\n    accuracy                           1.00        69\n   macro avg       1.00      1.00      1.00        69\nweighted avg       1.00      1.00      1.00        69\n\nSeed: 2\n\n\n\n\n\n\n\n\n\nAccuracy: 0.55\nClassification Report:\n              precision    recall  f1-score   support\n\n      Adelie       0.62      0.97      0.75        30\n   Chinstrap       0.43      0.90      0.58        10\n      Gentoo       0.00      0.00      0.00        29\n\n    accuracy                           0.55        69\n   macro avg       0.35      0.62      0.44        69\nweighted avg       0.33      0.55      0.41        69"
  },
  {
    "objectID": "lectures/03/slides.html#stopping-criteria",
    "href": "lectures/03/slides.html#stopping-criteria",
    "title": "Learning Algorithms",
    "section": "Stopping Criteria",
    "text": "Stopping Criteria\n\nAll the examples in a given node belong to the same class.\nDepth of the tree would exceed max_depth.\nNumber of examples in the node is min_sample_split or less.\nNone of the splits decreases impurity sufficiently (min_impurity_decrease).\nSee documentation for other criteria."
  },
  {
    "objectID": "lectures/03/slides.html#learning-outcomes",
    "href": "lectures/03/slides.html#learning-outcomes",
    "title": "Learning Algorithms",
    "section": "Learning outcomes",
    "text": "Learning outcomes\n\nDifferentiate between model, objective, and optimizer in learning algorithms.\nExplain KNN for classification and regression, including uniform and distance-weighted prediction.\nDescribe decision trees and apply the split criterion using impurity measures such as Gini.\nInterpret decision boundaries and the concept of linear separability.\n\n\nAs indicated in the introductory lecture, I aim to present a series of concepts leading to deep learning. As a starting point, linear regression would be a logical choice as a primary learning algorithm to examine. Nonetheless, it is equally critical to possess a high-level understanding of various other learning algorithms, as they differ significantly in model structures and training processes. Therefore, I will briefly discuss k-nearest neighbours and decision trees, before introducing linear regression."
  },
  {
    "objectID": "lectures/03/slides.html#k-nearest-neighbours",
    "href": "lectures/03/slides.html#k-nearest-neighbours",
    "title": "Learning Algorithms",
    "section": "k-nearest neighbours",
    "text": "k-nearest neighbours\n\n\n\n\n\n\nKNeighborsClassifier, examples\nKNeighborsRegressor, exemples\n\n\n\nAs indicated in the introductory lecture, I aim to present a series of concepts leading to deep learning. As a starting point, linear regression would be a logical choice as a primary learning algorithm to examine. Nonetheless, it is equally critical to possess a high-level understanding of various other learning algorithms, as they differ significantly in model structures and training processes. Therefore, I will briefly discuss k-nearest neighbours and decision trees, before introducing linear regression.\nThe k-nearest neighbour (KNN) algorithm is a simple, non-parametric, instance-based learning method used for classification and regression. It classifies a data point based on the majority label of its \\(k\\) nearest neighbours in the feature space, where \\(k\\) is a user-defined constant. Distance metrics like Euclidean distance are commonly used to determine the nearest neighbours.\nIn the context of regression, the predicted value \\(\\hat{y}(x)\\) is calculated as a weighted sum of the labels of its \\(k\\) nearest neighbours. The weights can be uniform or based on distance, reflecting the proximity of each neighbour to the query point \\(x\\).\nFor a query point \\(x\\), let its \\(k\\) nearest neighbours have targets \\(y_1, \\dots, y_k\\) and distances \\(d_1, \\dots, d_k\\).\n\nUniform weights (default):\n\n\\[\n\\hat{y}(x) = \\frac{1}{k} \\sum_{i=1}^k y_i\n\\]\n\nDistance weights (the built-in option \"distance\"):\n\n\\[\n\\hat{y}(x) = \\frac{\\sum_{i=1}^k \\frac{1}{d_i} \\, y_i}{\\sum_{i=1}^k \\frac{1}{d_i}}\n\\]\nIn the above, as the distance \\(d_i\\) between the example \\(x_i\\) and the example \\(x\\) increases, the reciprocal \\(\\frac{1}{d_i}\\) decreases. Consequently, examples that are farther from \\(x\\) exert less influence on the predicted outcome, \\(\\hat{y}(x)\\).\nIn both cases, convex combination property guarantees that:\n\\[\n\\min(y_1, \\dots, y_k) \\;\\; \\leq \\;\\; \\hat{y}(x) \\;\\; \\leq \\;\\; \\max(y_1, \\dots, y_k).\n\\]\nA non-parametric algorithm does not make any assumptions about the underlying data distribution and does not learn a fixed set of parameters or a model during the training phase. Instead, it relies directly on the training data to make decisions at the time of classification or regression, making it flexible and adaptive to various data shapes but potentially computationally expensive at prediction time.\nKNN has clear limitations:\n\nComputational cost\n\nPrediction requires computing distances to all training points, \\(O(n)\\) per query.\n\nCurse of dimensionality\n\nIn high-dimensional spaces, distance metrics lose discriminative power.\n\nChoice of \\(k\\) and distance metric\n\nSmall \\(k\\): high variance, sensitive to noise/outliers.\nLarge \\(k\\): high bias, oversmoothing.\n\nSensitivity to feature scaling\n\nDistances are scale-dependent; variables with larger ranges dominate unless features are normalized/standardized.\n\nImbalanced data\n\nIn classification, if one class is much more frequent, KNN can be biased toward that class since neighbours are more likely to belong to it.\n\nNot extrapolative\n\nPredictions are always convex combinations (in regression) or majority votes (in classification) of training labels.\nThis means KNN cannot extrapolate trends outside the range of observed training data.\n\n\nIn scikit-learn, several models are commonly used for regression tasks. Here are some of the main models:\n\nLinear Regression (LinearRegression):\n\nA simple linear approach that models the relationship between the independent variables and the dependent variable by fitting a linear equation to the observed data.\n\nSupport Vector Regression (SVR):\n\nAn extension of Support Vector Machines (SVM) for regression tasks, which tries to fit the best line within a specified margin of tolerance.\n\nDecision Tree Regression (DecisionTreeRegressor):\n\nUses decision trees to model the relationship between the input features and the target variable by recursively splitting the data into subsets.\n\nRandom Forest Regression (RandomForestRegressor):\n\nAn ensemble method that uses multiple decision trees to improve predictive accuracy and control overfitting.\n\nGradient Boosting Regression (GradientBoostingRegressor):\n\nAnother ensemble method that builds sequential decision trees, where each tree corrects the errors of the previous one.\n\nK-Nearest Neighbors Regression (KNeighborsRegressor):\n\nA non-parametric method that predicts the target variable based on the average of the k-nearest neighbours in the feature space.\n\n\nThese models offer a range of approaches to handle different types of regression problems, each with its own strengths and suitable applications.\n\n\nAttribution: Nearest Neighbors Classification."
  },
  {
    "objectID": "lectures/03/slides.html#definition-2",
    "href": "lectures/03/slides.html#definition-2",
    "title": "Learning Algorithms",
    "section": "Definition",
    "text": "Definition\nProblem: find values for all the model parameters so that the model “best fits” the training data.\n\n\nThe Root Mean Square Error is a common performance measure for regression problems.\n\n\\[\n    \\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#characteristics",
    "href": "lectures/03/slides.html#characteristics",
    "title": "Learning Algorithms",
    "section": "Characteristics",
    "text": "Characteristics\nA typical learning algorithm comprises the following components:\n\nA model, often consisting of a set of weights whose values will be “learnt”.\nAn objective function.\n\nIn the case of regression, this is often a loss function, a function that quantifies misclassification. The Root Mean Square Error is a common loss function for regression problems. \\(\\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\\)\n\nOptimization algorithm"
  },
  {
    "objectID": "lectures/03/slides.html#minimizing-rmse",
    "href": "lectures/03/slides.html#minimizing-rmse",
    "title": "Learning Algorithms",
    "section": "Minimizing RMSE",
    "text": "Minimizing RMSE\n\n\n\n\n\n\n\nAttribution: Krishnavedala, CC BY-SA 3.0, via Wikimedia Commons"
  },
  {
    "objectID": "lectures/03/slides.html#remarks",
    "href": "lectures/03/slides.html#remarks",
    "title": "Learning Algorithms",
    "section": "Remarks",
    "text": "Remarks\n\nIt is crucial to separate the optimization algorithm from the problem it addresses.\nFor linear regression, an exact analytical solution exists, but it presents certain limitations.\nGradient descent serves as a general algorithm applicable not only to linear regression, but also to logistic regression, deep learning, t-SNE (t-distributed Stochastic Neighbor Embedding), among various other problems.\nThere exists a diverse range of optimization algorithms that do not rely on gradient-based methods."
  },
  {
    "objectID": "course-links.html#small-to-medium-datasets-very-student-friendly",
    "href": "course-links.html#small-to-medium-datasets-very-student-friendly",
    "title": "Useful links",
    "section": "",
    "text": "UCI Machine Learning Repository\nscikit-learn toy datasets",
    "crumbs": [
      "**Course information**",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#larger-datasets",
    "href": "course-links.html#larger-datasets",
    "title": "Useful links",
    "section": "",
    "text": "OpenML, integrates directly with scikit-learn\nPMLB (Penn Machine Learning Benchmarks)",
    "crumbs": [
      "**Course information**",
      "Useful links"
    ]
  },
  {
    "objectID": "course-links.html#competitions",
    "href": "course-links.html#competitions",
    "title": "Useful links",
    "section": "",
    "text": "Kaggle Datasets\n\nKaggle, a platform owned by Google, serves as an online community tailored for data scientists and machine learning practitioners. It facilitates participation in data science competitions, collaboration on various projects, and provides access to diverse datasets. Additionally, users can build models using its web-based tools.",
    "crumbs": [
      "**Course information**",
      "Useful links"
    ]
  },
  {
    "objectID": "lectures/03/slides.html#exercises",
    "href": "lectures/03/slides.html#exercises",
    "title": "Learning Algorithms",
    "section": "Exercises",
    "text": "Exercises\nDownload these examples to experiment with code variations. Notably, examine how changes in \\(k\\) impact classification decision boundaries and regression line smoothness.\n\nNearest Neighbors Classification\nNearest Neighbors Regression\nImportance of Feature Scaling\n\n\nThe scikit-learn website offers examples in Jupyter Notebook format, accessible via desktop browsers with links on the right."
  },
  {
    "objectID": "lectures/03/slides.html#k-nearest-neighbours-knn",
    "href": "lectures/03/slides.html#k-nearest-neighbours-knn",
    "title": "Learning Algorithms",
    "section": "k-nearest neighbours (KNN)",
    "text": "k-nearest neighbours (KNN)\n\n\n\n\n\n\nKNeighborsClassifier, examples\nKNeighborsRegressor, exemples\n\n\n\nAttribution: Nearest Neighbors Classification."
  },
  {
    "objectID": "lectures/03/slides.html#knn---learning",
    "href": "lectures/03/slides.html#knn---learning",
    "title": "Learning Algorithms",
    "section": "KNN - Learning",
    "text": "KNN - Learning\n\nLazy learning: no explicit training\nThe “model” is the dataset\n\n\nThe k-nearest neighbour (KNN) algorithm simply stores its training data. There is no explicit training. We call this “lazy learning”.\nWhen the number of examples is large, the low-dimensional data can be stored in a specialized data structure, such as kd-tree or ball tree, to accelerate the computation at inference time. For high-dimensional data, techniques, such as approximate nearest neighbour (ANN) have been developped."
  },
  {
    "objectID": "lectures/03/slides.html#knn---inference",
    "href": "lectures/03/slides.html#knn---inference",
    "title": "Learning Algorithms",
    "section": "KNN - Inference",
    "text": "KNN - Inference\n\nClassify/regress based on the labels/values of the \\(k\\) closest examples in feature space\n\n\n\nAlthough the inference cost may seem low, being linear with respect to the number of examples. It is important to remember that the typical workflow for a machine learning project is to train a model once and use that model for every query, where the number of queries can be quite large.\n\n\nCost is \\(\\mathcal{O}(ND)\\) per query (naïve), where \\(N\\) = number of examples, \\(D\\) = dimensions"
  },
  {
    "objectID": "lectures/03/slides.html#formal-definition",
    "href": "lectures/03/slides.html#formal-definition",
    "title": "Learning Algorithms",
    "section": "Formal Definition",
    "text": "Formal Definition\nGiven dataset \\(\\{(x_i, y_i)\\}_1^{N}\\) and an unseen example \\(x\\):\n\nCompute distances \\(d(x, x_i)\\)\nSelect the \\(k\\) smallest distances\nClassification: majority vote (possibly weighted by \\(1/d\\))\nRegression: average (possibly weighted)\n\n\nThe k-nearest neighbour (KNN) algorithm is a simple, non-parametric, instance-based learning method used for classification and regression. It classifies a data point based on the majority label of its \\(k\\) nearest neighbours in the feature space, where \\(k\\) is a user-defined constant. Distance metrics like Euclidean distance are commonly used to determine the nearest neighbours.\nIn the context of regression, the predicted value \\(\\hat{y}(x)\\) is calculated as a weighted sum of the labels of its \\(k\\) nearest neighbours. The weights can be uniform or based on distance, reflecting the proximity of each neighbour to the query point \\(x\\).\nFor a query point \\(x\\), let its \\(k\\) nearest neighbours have targets \\(y_1, \\dots, y_k\\) and distances \\(d_1, \\dots, d_k\\).\n\nUniform weights (default):\n\n\\[\n\\hat{y}(x) = \\frac{1}{k} \\sum_{i=1}^k y_i\n\\]\n\nDistance weights (the built-in option \"distance\"):\n\n\\[\n\\hat{y}(x) = \\frac{\\sum_{i=1}^k \\frac{1}{d_i} \\, y_i}{\\sum_{i=1}^k \\frac{1}{d_i}}\n\\]\nIn the above, as the distance \\(d_i\\) between the example \\(x_i\\) and the example \\(x\\) increases, the reciprocal \\(\\frac{1}{d_i}\\) decreases. Consequently, examples that are farther from \\(x\\) exert less influence on the predicted outcome, \\(\\hat{y}(x)\\).\nIn both cases, convex combination property guarantees that:\n\\[\n\\min(y_1, \\dots, y_k) \\;\\; \\leq \\;\\; \\hat{y}(x) \\;\\; \\leq \\;\\; \\max(y_1, \\dots, y_k).\n\\]\nA non-parametric algorithm does not make any assumptions about the underlying data distribution and does not learn a fixed set of parameters or a model during the training phase. Instead, it relies directly on the training data to make decisions at the time of classification or regression, making it flexible and adaptive to various data shapes but potentially computationally expensive at prediction time.\nKNN has clear limitations:\n\nComputational cost\n\nPrediction requires computing distances to all training points, \\(O(n)\\) per query.\n\nCurse of dimensionality\n\nIn high-dimensional spaces, distance metrics lose discriminative power.\n\nChoice of \\(k\\) and distance metric\n\nSmall \\(k\\): high variance, sensitive to noise/outliers.\nLarge \\(k\\): high bias, oversmoothing.\n\nSensitivity to feature scaling\n\nDistances are scale-dependent; variables with larger ranges dominate unless features are normalized/standardized.\n\nImbalanced data\n\nIn classification, if one class is much more frequent, KNN can be biased toward that class since neighbours are more likely to belong to it.\n\nNot extrapolative\n\nPredictions are always convex combinations (in regression) or majority votes (in classification) of training labels.\nThis means KNN cannot extrapolate trends outside the range of observed training data.\n\n\nIn scikit-learn, several models are commonly used for regression tasks. Here are some of the main models:\n\nLinear Regression (LinearRegression):\n\nA simple linear approach that models the relationship between the independent variables and the dependent variable by fitting a linear equation to the observed data.\n\nSupport Vector Regression (SVR):\n\nAn extension of Support Vector Machines (SVM) for regression tasks, which tries to fit the best line within a specified margin of tolerance.\n\nDecision Tree Regression (DecisionTreeRegressor):\n\nUses decision trees to model the relationship between the input features and the target variable by recursively splitting the data into subsets.\n\nRandom Forest Regression (RandomForestRegressor):\n\nAn ensemble method that uses multiple decision trees to improve predictive accuracy and control overfitting.\n\nGradient Boosting Regression (GradientBoostingRegressor):\n\nAnother ensemble method that builds sequential decision trees, where each tree corrects the errors of the previous one.\n\nK-Nearest Neighbors Regression (KNeighborsRegressor):\n\nA non-parametric method that predicts the target variable based on the average of the k-nearest neighbours in the feature space.\n\n\nThese models offer a range of approaches to handle different types of regression problems, each with its own strengths and suitable applications."
  },
  {
    "objectID": "lectures/04/slides.html#linear-regression-1",
    "href": "lectures/04/slides.html#linear-regression-1",
    "title": "Linear regression and gradient descent",
    "section": "Linear Regression",
    "text": "Linear Regression\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\[\n  \\hat{y_i} = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\n\nHere, \\(\\theta_{j}\\) is the \\(j\\)th parameter of the (linear) model, with \\(\\theta_0\\) being the bias term/parameter, and \\(\\theta_1 \\ldots \\theta_D\\) being the feature weights.\n\n\nIn statistical contexts, the notation \\(\\hat{y_i}\\) is employed to denote the estimator of the true value \\(y_i\\). This represents the predicted or estimated outcome based on a given model.\nConversely, in machine learning, the notation \\(h(x_i)\\) is used, where \\(h\\) represents the hypothesis function or model applied to the input data \\(x_i\\). The hypothesis function \\(h\\) is derived from a predefined hypothesis space, which encompasses the set of all possible models that can be used to map input data to predicted outcomes.\nThe parameter \\(\\theta_0\\) is called the bias term (also “intercept”) because:\n\nIt shifts the prediction independently of the inputs.\nGeometrically, it moves the regression hyperplane up or down (or left/right in classification), so the model is not forced to pass through the origin.\nIn machine learning terms, it acts like a constant offset, compensating for systematic effects not explained by the features.\n\nSo it’s called “bias” because it introduces a fixed baseline to which the contributions of the other parameters are added.\nIn a machine learning model, the parameters are the weights and the biases.\n\n\n\nIn my presentations, I use \\(\\hat{y_i}\\) and \\(h(x_i)\\) synonymously."
  },
  {
    "objectID": "lectures/04/slides.html#definition",
    "href": "lectures/04/slides.html#definition",
    "title": "Linear regression and gradient descent",
    "section": "Definition",
    "text": "Definition\nProblem: find values for all the model parameters so that the model “best fits” the training data.\n\n\nThe Root Mean Square Error is a common performance measure for regression problems.\n\n\\[\n    \\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\n\\]\n\nIn practical implementation, algorithms typically optimize the mean squared error (MSE) due to its mathematical tractability and the fact that it converges to the same parameter estimates as other error measures. While our current focus is on using MSE, the algorithm can be adapted to work with a range of objective functions."
  },
  {
    "objectID": "lectures/04/slides.html#minimizing-rmse",
    "href": "lectures/04/slides.html#minimizing-rmse",
    "title": "Linear regression and gradient descent",
    "section": "Minimizing RMSE",
    "text": "Minimizing RMSE\n\n\n\n\n\n\n\nAttribution: Krishnavedala, CC BY-SA 3.0, via Wikimedia Commons"
  },
  {
    "objectID": "lectures/04/slides.html#characteristics",
    "href": "lectures/04/slides.html#characteristics",
    "title": "Linear regression and gradient descent",
    "section": "Characteristics",
    "text": "Characteristics\nA typical learning algorithm comprises the following components:\n\nA model, often consisting of a set of parameters whose values will be “learnt”.\nAn objective function.\n\nIn the case of regression, this is often a loss function, a function that quantifies misclassification. The Root Mean Square Error is a common loss function for regression problems. \\[\n\\sqrt{\\frac{1}{N}\\sum_1^N [h(x_i) - y_i]^2}\n\\]\n\nOptimization algorithm"
  },
  {
    "objectID": "lectures/04/slides.html#remarks",
    "href": "lectures/04/slides.html#remarks",
    "title": "Linear regression and gradient descent",
    "section": "Remarks",
    "text": "Remarks\n\nIt is important to separate the optimization algorithm from the problem it addresses.\nFor linear regression, an exact analytical solution exists, but it presents certain limitations.\nGradient descent serves as a general algorithm applicable not only to linear regression, but also to logistic regression, deep learning, t-SNE (t-distributed Stochastic Neighbor Embedding), among various other problems.\nThere exists a diverse range of optimization algorithms that do not rely on gradient-based methods."
  },
  {
    "objectID": "lectures/04/slides.html#rationale-1",
    "href": "lectures/04/slides.html#rationale-1",
    "title": "Training",
    "section": "Rationale",
    "text": "Rationale\nLinear regression is introduced to conveniently present a well-known training algorithm, gradient descent. Additionally, it serves as a foundation for introducing logistic regression–a classification algorithm—which further facilitates discussions on artificial neural networks.\n\nLinear Regression\n\nGradient Descent\nLogistic Regression\n\nNeural Networks\n\n\n\n\nThe training algorithms for machine learning models can vary significantly depending on the model (e.g., decision trees, SVMs, etc.). In order to fit our schedule, we will concentrate on this specific sequence.\nThe concept of linear regression can be traced back to the early work of Sir Francis Galton in the late 19th century. Galton introduced the idea of “regression” in his 1886 paper, which focused on the relationship between the heights of parents and their children. He observed that children’s heights tended to regress towards the average, which led to the term “regression.”\nHowever, the mathematical formulation of linear regression is closely associated with the work of Karl Pearson, who in the early 20th century extended Galton’s ideas to create the method of least squares for fitting a linear model. The method itself, though, was developed earlier in 1805 by Adrien-Marie Legendre and independently by Carl Friedrich Gauss for astronomical data analysis.\nSee: Stanton (2001)."
  },
  {
    "objectID": "lectures/04/slides.html#linear-regression-2",
    "href": "lectures/04/slides.html#linear-regression-2",
    "title": "Training",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nA linear model assumes that the value of the label, \\(\\hat{y_i}\\), can be expressed as a linear combination of the feature values, \\(x_i^{(j)}\\): \\[\n\\hat{y_i} = h(x_i) = \\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)}\n\\]\n\nHere, \\(\\theta_{j}\\) is the \\(j\\)th parameter of the (linear) model, with \\(\\theta_0\\) being the bias term/parameter, and \\(\\theta_1 \\ldots \\theta_D\\) being the feature weights."
  },
  {
    "objectID": "lectures/04/slides.html#supervised-learning---regression-4",
    "href": "lectures/04/slides.html#supervised-learning---regression-4",
    "title": "Training",
    "section": "Supervised Learning - Regression",
    "text": "Supervised Learning - Regression\n\nThe training data is a collection of labelled examples.\n\n\\(\\{(x_i,y_i)\\}_{i=1}^N\\)\n\nEach \\(x_i\\) is a feature vector with \\(D\\) dimensions.\n\\(x_i^{(j)}\\) is the value of the feature \\(j\\) of the example \\(i\\),\\ for \\(j \\in 1 \\ldots D\\) and \\(i \\in 1 \\ldots N\\).\n\nThe label \\(y_i\\) is a real number.\n\nProblem: Given the data set as input, create a model that can be used to predict the value of \\(y\\) for an unseen \\(x\\)."
  },
  {
    "objectID": "lectures/04/slides.html#optimization-1",
    "href": "lectures/04/slides.html#optimization-1",
    "title": "Training",
    "section": "Optimization",
    "text": "Optimization\nUntil some termination criteria is met\\(^1\\):\n\nEvaluate the loss function, comparing \\(h(x_i)\\) to \\(y_i\\).\nMake small changes to the weights, in a way that reduces the value of the loss function.\n\n\n1: E.g. the value of the loss function no longer decreases or the maximum number of iterations."
  },
  {
    "objectID": "lectures/04/slides.html#old-faithful-eruptions",
    "href": "lectures/04/slides.html#old-faithful-eruptions",
    "title": "Linear regression and gradient descent",
    "section": "Old Faithful Eruptions",
    "text": "Old Faithful Eruptions\n\nimport pandas as pd\n\nWOLFRAM_CSV = \"https://raw.githubusercontent.com/turcotte/csi4106-f25/refs/heads/main/datasets/old_faithful_eruptions/Sample-Data-Old-Faithful-Eruptions.csv\"\ndf = pd.read_csv(WOLFRAM_CSV)\n\n# Renaming the columns\ndf = df.rename(columns={\"Duration\": \"eruptions\", \"WaitingTime\": \"waiting\"})\nprint(df.shape)\ndf.head(6)\n\n\n\n\nThe dataset used in this presentation was sourced from the Wolfram Research Data Repository, with its initial publication detailed in Azzalini and Bowman (1990).\n\n\nAttribution: Wolfram Research, “Sample Data: Old Faithful Eruptions” from the Wolfram Data Repository (2016) doi: 10.24097/wolfram.50727.data"
  },
  {
    "objectID": "lectures/04/slides.html#old-faithful-eruptions-output",
    "href": "lectures/04/slides.html#old-faithful-eruptions-output",
    "title": "Linear regression and gradient descent",
    "section": "Old Faithful Eruptions",
    "text": "Old Faithful Eruptions\n\n(272, 2)\n\n\n\n\n\n\n\n\n\neruptions\nwaiting\n\n\n\n\n0\n3.600\n79\n\n\n1\n1.800\n54\n\n\n2\n3.333\n74\n\n\n3\n2.283\n62\n\n\n4\n4.533\n85\n\n\n5\n2.883\n55"
  },
  {
    "objectID": "lectures/04/slides.html#quick-visualization",
    "href": "lectures/04/slides.html#quick-visualization",
    "title": "Linear regression and gradient descent",
    "section": "Quick Visualization",
    "text": "Quick Visualization\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6,4))\nplt.scatter(df[\"eruptions\"], df[\"waiting\"], s=20)\nplt.xlabel(\"Eruption duration (min)\")\nplt.ylabel(\"Waiting time to next eruption (min)\")\nplt.title(\"Old Faithful: eruptions vs waiting\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe duration of the current eruption appears to have a linear relationship with the subsequent wait time: shorter eruption durations tend to precede shorter wait times, while longer eruption durations are associated with longer wait times."
  },
  {
    "objectID": "lectures/04/slides.html#problem",
    "href": "lectures/04/slides.html#problem",
    "title": "Linear regression and gradient descent",
    "section": "Problem",
    "text": "Problem\n\nPredict the waiting time until the next eruption (min), \\(y\\), based on the duration of the current eruption (min), \\(x\\).\n\n\nSelecting a problem characterized by a single attribute allows us to better focus our discussion and enhance the clarity of visualization."
  },
  {
    "objectID": "lectures/04/slides.html#learning",
    "href": "lectures/04/slides.html#learning",
    "title": "Linear regression and gradient descent",
    "section": "Learning",
    "text": "Learning\n\n\nCode\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Prepare data\nX = df[[\"eruptions\"]].values  # shape (n_samples, 1)\ny = df[\"waiting\"].values      # shape (n_samples,)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Fit via SGDRegressor — linear model via gradient descent\nsgd = SGDRegressor(\n    loss=\"squared_error\",\n    penalty=None,\n    learning_rate=\"constant\",\n    eta0=0.01,\n    max_iter=2000,\n    tol=None,\n    random_state=42\n)\n\nsgd.fit(X_train, y_train)\n\nprint(\"Learned parameters:\")\nprint(f\"  intercept = {sgd.intercept_[0]:.3f}\")\nprint(f\"  slope     = {sgd.coef_[0]:.3f}\")\n\ny_pred = sgd.predict(X_test)\nprint(f\"Test MSE = {mean_squared_error(y_test, y_pred):.2f}\")\nprint(f\"Test R²  = {r2_score(y_test, y_pred):.3f}\")\n\n\nLearned parameters:\n  intercept = 32.910\n  slope     = 10.503\nTest MSE = 43.02\nTest R²  = 0.671"
  },
  {
    "objectID": "lectures/04/slides.html#visualization",
    "href": "lectures/04/slides.html#visualization",
    "title": "Linear regression and gradient descent",
    "section": "Visualization",
    "text": "Visualization\n\n\nCode\nimport numpy as np\n\n# Scatter the data\nplt.figure(figsize=(6,4))\nplt.scatter(X, y, color=\"steelblue\", s=30, alpha=0.7, label=\"data\")\n\n# Plot the fitted line\nx_line = np.linspace(0, X.max(), 100).reshape(-1, 1)\ny_line = sgd.predict(x_line)\nplt.plot(x_line, y_line, color=\"red\", linewidth=2, label=\"fitted line\")\n\nplt.xlabel(\"Eruption duration (min)\")\nplt.ylabel(\"Waiting time to next eruption (min)\")\nplt.title(\"Old Faithful: Linear regression via SGD\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIn the plot above, the line \\(x=0\\) is included to facilitate the visualization of the intercept, which is given by \\(\\theta_0 = 32.910\\)."
  },
  {
    "objectID": "lectures/04/slides.html#derivative-5",
    "href": "lectures/04/slides.html#derivative-5",
    "title": "Linear regression and gradient descent",
    "section": "Derivative",
    "text": "Derivative\n\n\n\n\n\n\n\n\n\n\n\n\n\nA negative derivative indicates that increasing the input variable will decrease the output value.\nAdditionally, the magnitude of the derivative quantifies how rapidly the output changes."
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent-single-feature",
    "href": "lectures/04/slides.html#gradient-descent-single-feature",
    "title": "Linear regression and gradient descent",
    "section": "Gradient Descent — Single Feature",
    "text": "Gradient Descent — Single Feature\n\nModel (hypothesis):\n\\[\nh(x_i; \\theta) = \\theta_0 + \\theta_1 x_i^{(1)}\n\\]\nLoss/cost function:\n\\[\nJ(\\theta_0, \\theta_1) = \\frac{1}{N}\\sum_{i=1}^N [h(x_i;\\theta) - y_i]^2\n\\]"
  },
  {
    "objectID": "lectures/04/slides.html#visualization-1",
    "href": "lectures/04/slides.html#visualization-1",
    "title": "Training",
    "section": "Visualization",
    "text": "Visualization"
  },
  {
    "objectID": "lectures/04/slides.html#visualization-1-output",
    "href": "lectures/04/slides.html#visualization-1-output",
    "title": "Training",
    "section": "Visualization",
    "text": "Visualization"
  },
  {
    "objectID": "lectures/04/slides.html#optimization-single-feature",
    "href": "lectures/04/slides.html#optimization-single-feature",
    "title": "Linear regression and gradient descent",
    "section": "Optimization — single feature",
    "text": "Optimization — single feature\n\nModel (hypothesis):\n\\[\nh(x_i; \\theta) = \\theta_0 + \\theta_1 x_i^{(1)}\n\\]\nLoss/cost function:\n\\[\nJ(\\theta_0, \\theta_1) = \\frac{1}{N}\\sum_{i=1}^N [h(x_i;\\theta) - y_i]^2\n\\]\n\n\n\nThis screen is paramount for our presentation, and it is essential to grasp its content fully, as it often causes confusion.\nIn machine learning, an algorithm generates a model, denoted as \\(h\\). This model is derived from the training data, represented by \\(X\\). After the model is trained, it can be utilized to predict outcomes for new, unseen data points, denoted by \\(x_{\\mathrm{new}}\\). Once trained, the model’s parameters, \\(\\theta\\), become fixed. The model functions by mapping each input \\(x_i\\) to a predicted output \\(\\hat{y}_i\\), \\(x_i \\mapsto \\hat{y}_i\\).\nThe cost function is used to determine the optimal parameter values, \\(\\theta\\), for the model \\(h\\). On this screen, the loss is specified as the mean squared error. Our goal is to identify \\(\\theta\\) such that the model \\(h\\) minimizes its error on the training dataset \\(X\\). The loss function maps the parameter pair \\((\\theta_0, \\theta_1)\\) to a non-negative real number \\(\\mathbb{R}_{\\ge0}\\), \\((\\theta_0,\\theta_1)\\mapsto\\mathbb{R}_{\\ge0}\\), which aggregates errors across all data points.\nGradient descent is a process that operates in the parameter space, where it adjusts \\(\\theta\\) to minimize the loss, rather than in the feature space of the data.\nThe notation \\(h(x_i; \\theta)\\) indicates that the value of the function \\(h\\) (of the model) depends on the input example \\(x_i\\) as well as the parameters \\(\\theta\\). The semicolon is used to semantically differentiate these two sets of values. This convention comes from the field of statistics. In machine learning, we also use the notation \\(h_{\\theta}(x_i)\\), which can be considered more appropriate. In this context, we refer to an indexed family of functions, where \\(\\theta\\) specifically determines which function \\(h_\\theta\\) should be used. This notation is read as follows: “the function \\(h\\), parameterized by \\(\\theta\\), applied to the input \\(x_i\\).”\n\n\nGoal: find \\(\\theta_0, \\theta_1\\) that minimize \\(J\\), by iteratively updating the parameters."
  },
  {
    "objectID": "lectures/04/slides.html#hypothesis-vs-parameter-space",
    "href": "lectures/04/slides.html#hypothesis-vs-parameter-space",
    "title": "Linear regression and gradient descent",
    "section": "Hypothesis vs Parameter Space",
    "text": "Hypothesis vs Parameter Space\n\n\n\n\n\n\n\n\n\n\nIn this example, we use the Old Faithful geyser eruption dataset.\nThe figure on the left illustrates the data within its feature space, where each line represents a distinct hypothesis. For instance, the horizontal blue line corresponds to the hypothesis defined by parameters \\((\\theta_0=0, \\theta_1=0)\\), while the orange line corresponds to \\((\\theta_0=10, \\theta_1=2)\\). The sequence of model parameters, or hypotheses, has been deliberately designed to elucidate the underlying concepts.\nConversely, the figure on the right depicts the parameter space, which is where optimization is performed. In this space, the vertical axis indicates the Mean Squared Error (MSE) for all combinations of \\(\\theta_0\\) and \\(\\theta_1\\). Specifically, a model characterized by these parameters would incur this level of error with the specified training data. During the training process, the data remains constant, whereas the parameters \\(\\theta_0\\) and \\(\\theta_1\\) are adjusted to minimize the error.\nIn the figure on the right, the progression of model parameters, denoted as (\\(\\theta_0, \\theta_1\\)) with the sequence \\(\\{(0.000, 0.000), (10.000, 2.000), (20.000, 4.000), (30.000, 7.000), (32.910, 10.503)\\}\\), illustrates a reduction in the mean squared error (MSE), \\(J(\\theta)\\)."
  },
  {
    "objectID": "lectures/04/slides.html#hypothesis-vs-parameter-space-1",
    "href": "lectures/04/slides.html#hypothesis-vs-parameter-space-1",
    "title": "Linear regression and gradient descent",
    "section": "Hypothesis vs Parameter Space",
    "text": "Hypothesis vs Parameter Space\n\n\n\n\n\n\n\n\n\n\nThes figures illustrate the same concept, but using a contour plot."
  },
  {
    "objectID": "lectures/04/slides.html#quick-visualization-1",
    "href": "lectures/04/slides.html#quick-visualization-1",
    "title": "Linear regression and gradient descent",
    "section": "Quick Visualization",
    "text": "Quick Visualization\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6,4))\nplt.scatter(df[\"eruptions\"], df[\"waiting\"], s=20)\nplt.xlabel(\"Eruption duration (min)\")\nplt.ylabel(\"Waiting time to next eruption (min)\")\nplt.title(\"Old Faithful: eruptions vs waiting\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "lectures/04/slides.html#old-faithful-geyser",
    "href": "lectures/04/slides.html#old-faithful-geyser",
    "title": "Linear regression and gradient descent",
    "section": "Old Faithful Geyser",
    "text": "Old Faithful Geyser\n\n\n\nOld Faithful, situated in Yellowstone National Park, is renowned as the world’s most famous geyser. It can reach eruption heights of up to 140 feet. Notably, its eruption intervals range between 60 and 110 minutes, contingent upon the duration of the preceding eruption.\n\n\nAttribution: Yellowstone National Park Trips"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---step-by-step",
    "href": "lectures/04/slides.html#gradient-descent---step-by-step",
    "title": "Linear regression and gradient descent",
    "section": "Gradient Descent - Step-by-Step",
    "text": "Gradient Descent - Step-by-Step"
  },
  {
    "objectID": "lectures/04/slides.html#gradient-descent---single-value-2",
    "href": "lectures/04/slides.html#gradient-descent---single-value-2",
    "title": "Linear regression and gradient descent",
    "section": "Gradient Descent - Single Value",
    "text": "Gradient Descent - Single Value\n\n\n\n\nCode\nimport sympy as sp\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the variable and function\nt = sp.symbols('t')\nf = t**2 + 4*t + 7\n\n# Compute the derivative\nf_prime = sp.diff(f, t)\n\n# Lambdify the functions for numerical plotting\nf_func = sp.lambdify(t, f, \"numpy\")\nf_prime_func = sp.lambdify(t, f_prime, \"numpy\")\n\n# Generate t values for plotting\nt_vals = np.linspace(-5, 2, 400)\n\n# Get y values for the function and its derivative\nf_vals = f_func(t_vals)\nf_prime_vals = f_prime_func(t_vals)\n\n# Plot the function and its derivative\nplt.plot(t_vals, f_vals, label=r'$J$', color='blue')\nplt.plot(t_vals, f_prime_vals, label=r\"$\\frac {\\partial}{\\partial \\theta_j}J(\\theta)$\", color='red')\n\n# Add labels and legend\nplt.axhline(0, color='black',linewidth=1)\nplt.axvline(0, color='black',linewidth=1)\nplt.title('Function and Derivative')\nplt.xlabel(r'$\\theta_j$')\nplt.ylabel(r'$J$')\nplt.legend()\n\n# Show the plot\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nWhen the value of \\(\\theta_j\\) is in the range \\((-2, \\infty]\\), \\(\\frac {\\partial}{\\partial \\theta_j}J(\\theta)\\) has a positive value.\nTherefore, \\(- \\alpha \\frac {\\partial}{\\partial \\theta_j}J(\\theta)\\) is negative.\nAccordingly, the value of \\(\\theta_j\\) is decreased.\n\n\n\n\nUpdating rule: \\(\\theta_j := \\theta_j - \\alpha \\frac {\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1) , \\text{for } j=0 \\text{ and } j=1\\)."
  },
  {
    "objectID": "lectures/04/slides.html#convergence",
    "href": "lectures/04/slides.html#convergence",
    "title": "Linear regression and gradient descent",
    "section": "Convergence",
    "text": "Convergence\n\n\nCode\n# 1. Define the symbolic variable and the function\nx = sp.Symbol('x', real=True)\nf_expr = 2*x**3 + 4*x**2 - 5*x + 1\n\n# 2. Compute the derivative of f\nf_prime_expr = sp.diff(f_expr, x)\n\n# 3. Convert symbolic expressions to Python functions\nf = sp.lambdify(x, f_expr, 'numpy')\nf_prime = sp.lambdify(x, f_prime_expr, 'numpy')\n\n# 4. Generate a range of x-values\nx_vals = np.linspace(-4, 2, 1000)\n\n# 5. Compute f and f' over this range\ny_vals = f(x_vals)\ny_prime_vals = f_prime(x_vals)\n\n# 6. Prepare LaTeX strings for legend\nf_label = rf'$f(x) = {sp.latex(f_expr)}$'\nf_prime_label = rf'$f^\\prime(x) = {sp.latex(f_prime_expr)}$'\n\n# 7. Plot f and f', with equations in the legend\nplt.figure(figsize=(8, 4))\nplt.plot(x_vals, y_vals, label=f_label)\nplt.plot(x_vals, y_prime_vals, label=f_prime_label)\n\n# 8. Shade the region between x-axis and f'(x) for the entire domain\nplt.fill_between(x_vals, y_prime_vals, 0, color='gray', alpha=0.2, interpolate=True,\n                 label='Region between 0 and f\\'(x)')\n\n# 9. Add reference line, labels, legend, etc.\nplt.axhline(0, color='black', linewidth=0.5)\nplt.title(rf'Function and its Derivative with Shading for $f^\\prime(x)$')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nThe first objective of this example is to illustrate that gradient descent is applicable to functions of arbitrary complexity, provided that the gradient can be computed or approximated at each iteration.\nFurthermore, the function must possesses at least one local minimum within the interval of interest.\n\n\n\nFor functions lacking a global minimum, gradient descent can continue descending indefinitely, preventing convergence."
  },
  {
    "objectID": "lectures/04/slides.html#learning-rate-1",
    "href": "lectures/04/slides.html#learning-rate-1",
    "title": "Linear regression and gradient descent",
    "section": "Learning Rate",
    "text": "Learning Rate\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**2\n\ndef grad_f(x):\n    return 2*x\n\n# Initial guess, learning rate, and number of gradient-descent steps\nx_current = 2.0\nlearning_rate = 1.1  # Too large =&gt; divergence\nnum_iterations = 5   # We'll do five updates\n\n# Store each x value in a list (trajectory) for plotting\ntrajectory = [x_current]\n\n# Perform gradient descent\nfor _ in range(num_iterations):\n    g = grad_f(x_current)\n    x_current = x_current - learning_rate * g\n    trajectory.append(x_current)\n\n# Prepare data for plotting\nx_vals = np.linspace(-5, 5, 1000)\ny_vals = f(x_vals)\n\n# Plot the function f(x)\nplt.figure(figsize=(6, 5))\nplt.plot(x_vals, y_vals, label=r\"$f(x) = x^2$\")\nplt.axhline(0, color='black', linewidth=0.5)\n\n# Plot the trajectory, labeling each iteration\nfor i, x_t in enumerate(trajectory):\n    y_t = f(x_t)\n    # Plot the point\n    plt.plot(x_t, y_t, 'ro')\n    # Label the iteration number\n    plt.text(x_t, y_t, f\"  {i}\", color='red')\n    # Connect consecutive points\n    if i &gt; 0:\n        x_prev = trajectory[i - 1]\n        y_prev = f(x_prev)\n        plt.plot([x_prev, x_t], [y_prev, y_t], 'r--')\n\n# Final touches\nplt.title(\"Gradient Descent Divergence with a Large Learning Rate\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/04/slides.html#fundamentals-by-herman-kamper",
    "href": "lectures/04/slides.html#fundamentals-by-herman-kamper",
    "title": "Linear regression and gradient descent",
    "section": "Fundamentals by Herman Kamper",
    "text": "Fundamentals by Herman Kamper"
  },
  {
    "objectID": "course-faq.html#method-from-the-preparation-pages",
    "href": "course-faq.html#method-from-the-preparation-pages",
    "title": "FAQ",
    "section": "Method from the “Preparation” pages",
    "text": "Method from the “Preparation” pages\n\nOn the Course Schedule page, you will find a column titled “Preparation” associated with each course session. Each entry in this column corresponds to a specific preparation page for the relevant course.\nFor example, for the course on Linear Regression and Gradient Descent, you can access the preparation page. In the section titled “Participate,” a link is provided to download a PDF version of the lecture notes.",
    "crumbs": [
      "**Course information**",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#revealjs",
    "href": "course-faq.html#revealjs",
    "title": "FAQ",
    "section": "Revealjs",
    "text": "Revealjs\n\nHTML Document Menu: At the bottom left of each presentation page.\nMenu Options: Select Tools, then PDF Export Mode (shortcut ‘e’).\nPrint: The page will reload with a print-friendly stylesheet. Use your browser’s file menu to print the document as a PDF. You can adjust the layout to display multiple slides per page if desired.",
    "crumbs": [
      "**Course information**",
      "FAQ"
    ]
  },
  {
    "objectID": "lectures/04/slides.html#stochastic-mini-batch-batch",
    "href": "lectures/04/slides.html#stochastic-mini-batch-batch",
    "title": "Linear regression and gradient descent",
    "section": "Stochastic, Mini-Batch, Batch",
    "text": "Stochastic, Mini-Batch, Batch\n\n\n\n\n\n\n\nAttribution: Géron (2022), Figure 4.10, 04_training_linear_models.ipynb"
  },
  {
    "objectID": "lectures/05/slides.html#message-of-the-day",
    "href": "lectures/05/slides.html#message-of-the-day",
    "title": "Logististic regression",
    "section": "Message of the Day",
    "text": "Message of the Day\n\n\n\n\n\n\n\nA 30 minutes podcast where Garry Kasparov is joined by cognitive scientist Gary Marcus.\nGarry Kasparov (b. 1963) is a Russian chess grandmaster and former World Chess Champion, widely regarded as one of the greatest players in history. He held the world’s top ranking for nearly two decades and is also known for his matches against IBM’s Deep Blue and his later political activism and writing.\nGary Marcus (b. 1965) is an American cognitive scientist, author, and entrepreneur. He is known for his critiques of deep learning, his work on language acquisition and cognitive development, and for founding several AI startups.\n\nKasparov and Marcus agree that AI is a tool—neither inherently utopian nor dystopian—and that the real risks stem from how it is used and by whom. Marcus emphasizes current AI systems still lack genuine understanding; they work by pattern recognition over vast datasets, not by grasping rules or concepts, which leads to alignment problems: machines frequently err or act in unforeseen ways. A major concern is how AI amplifies political deception, surveillance, and information manipulation—tools favored by autocratic or oligarchic interests. On the brighter side, they argue that we are not powerless: democratic societies still have levers—legal regulation, mass action, resistance, insistence on accountability—and might yet steer AI toward benefiting rather than undermining democracy. The default path is dangerous, but with political will, things need not slide irreversibly toward techno-fascism. (Summary generated by ChatGPT 5 on 2025-09-16)\n\n\n\nAI and the Rise of Techno-Fascism in the United States by Gary Kasparov, The Atlantic, 2025-09-05. (31m 13s)"
  },
  {
    "objectID": "lectures/05/slides.html#data-and-problem",
    "href": "lectures/05/slides.html#data-and-problem",
    "title": "Logististic regression",
    "section": "Data and Problem",
    "text": "Data and Problem\n\nDataset: Palmer Penguins\nTask: Binary classification to distinguish Gentoo penguins from non-Gentoo species\nFeature of Interest: Flipper length"
  },
  {
    "objectID": "lectures/05/slides.html#histogram",
    "href": "lectures/05/slides.html#histogram",
    "title": "Logististic regression",
    "section": "Histogram",
    "text": "Histogram\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntry:\n    from palmerpenguins import load_penguins\nexcept ImportError:\n    ! pip install palmerpenguins\n    from palmerpenguins import load_penguins\n\n# Load the Palmer Penguins dataset\ndf = load_penguins()\n\n# Keep only 'flipper_length_mm' and 'species'\ndf = df[['flipper_length_mm', 'species']]\n\n# Drop rows with missing values (NaNs)\ndf.dropna(inplace=True)\n\n# Create a binary label: 1 if Gentoo, 0 otherwise\ndf['is_gentoo'] = (df['species'] == 'Gentoo').astype(int)\n\n# Separate features (X) and labels (y)\nX = df[['flipper_length_mm']]\ny = df['is_gentoo']\n\n# Plot the distribution of flipper lengths by binary species label\nplt.figure(figsize=(10, 6))\nsns.histplot(data=df, x='flipper_length_mm', hue='is_gentoo', kde=True, bins=30, palette='Set1')\nplt.title('Distribution of Flipper Length (Gentoo vs. Others)')\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Frequency')\nplt.legend(title='Species', labels=['Gentoo', 'Non Gentoo'])\nplt.show()"
  },
  {
    "objectID": "lectures/05/slides.html#model",
    "href": "lectures/05/slides.html#model",
    "title": "Logististic regression",
    "section": "Model",
    "text": "Model\n\nGeneral Case: \\(P(y = k | x, \\theta)\\), where \\(k\\) is a class label.\nBinary Case: \\(y \\in {0,1}\\)\n\nPredict \\(P(y = 1 | x, \\theta)\\)"
  },
  {
    "objectID": "lectures/05/slides.html#x-y",
    "href": "lectures/05/slides.html#x-y",
    "title": "Logististic regression",
    "section": "X, y",
    "text": "X, y\n\nX\n\n\n\n\n\n\n\n\nflipper_length_mm\n\n\n\n\n0\n181.0\n\n\n1\n186.0\n\n\n2\n195.0\n\n\n4\n193.0\n\n\n5\n190.0\n\n\n...\n...\n\n\n339\n207.0\n\n\n340\n202.0\n\n\n341\n193.0\n\n\n342\n210.0\n\n\n343\n198.0\n\n\n\n\n342 rows × 1 columns\n\n\n\n\ny\n\n0      0\n1      0\n2      0\n4      0\n5      0\n      ..\n339    0\n340    0\n341    0\n342    0\n343    0\nName: is_gentoo, Length: 342, dtype: int64"
  },
  {
    "objectID": "lectures/05/slides.html#visualizing-our-data",
    "href": "lectures/05/slides.html#visualizing-our-data",
    "title": "Logististic regression",
    "section": "Visualizing our data",
    "text": "Visualizing our data\n\n\nCode\n# Scatter plot of flipper length vs. binary label (Gentoo or Not Gentoo)\nplt.figure(figsize=(10, 6))\n\n# Plot points labeled as Gentoo (is_gentoo = 1)\nplt.scatter(\n    df.loc[df['is_gentoo'] == 1, 'flipper_length_mm'],\n    df.loc[df['is_gentoo'] == 1, 'is_gentoo'],\n    color='blue',\n    label='Gentoo'\n)\n\n# Plot points labeled as Not Gentoo (is_gentoo = 0)\nplt.scatter(\n    df.loc[df['is_gentoo'] == 0, 'flipper_length_mm'],\n    df.loc[df['is_gentoo'] == 0, 'is_gentoo'],\n    color='red',\n    label='Not Gentoo'\n)\n\nplt.title('Flipper Length vs. Gentoo Indicator')\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Binary Label (1 = Gentoo, 0 = Not Gentoo)')\nplt.legend(loc='best')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/05/slides.html#intuition",
    "href": "lectures/05/slides.html#intuition",
    "title": "Logististic regression",
    "section": "Intuition",
    "text": "Intuition\nFitting a linear regression is not the answer, but \\(\\ldots\\)\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nX_new = pd.DataFrame([X.min(), X.max()], columns=X.columns)\n\ny_pred = lin_reg.predict(X_new)\n\n# Plot the scatter plot\nplt.figure(figsize=(5, 3))\nplt.scatter(X, y, c=y, cmap='bwr', edgecolor='k')\nplt.plot(X_new, y_pred, \"r-\")\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Binary Label (Gentoo or Not Gentoo)')\nplt.title('Flipper Length vs. Binary Label (Gentoo or Not Gentoo)')\nplt.yticks([0, 1], ['Not Gentoo', 'Gentoo'])\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/05/slides.html#intuition-continued",
    "href": "lectures/05/slides.html#intuition-continued",
    "title": "Logististic regression",
    "section": "Intuition (continued)",
    "text": "Intuition (continued)\n\n\n\n\n\n\n\n\n\n\n\n\n\nA high flipper_length_mm typically results in a model output approaching 1.\nConversely, a low flipper_length_mm generally yields a model output near 0.\nNotably, the model outputs are not confined to the [0, 1] interval and may occasionally fall below 0 or surpass 1."
  },
  {
    "objectID": "lectures/05/slides.html#intuition-continued-1",
    "href": "lectures/05/slides.html#intuition-continued-1",
    "title": "Logististic regression",
    "section": "Intuition (continued)",
    "text": "Intuition (continued)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor a single feature, the decision boundary is a specific point.\nIn this case, the decision boundary is approximately 205."
  },
  {
    "objectID": "lectures/05/slides.html#intuition-continued-2",
    "href": "lectures/05/slides.html#intuition-continued-2",
    "title": "Logististic regression",
    "section": "Intuition (continued)",
    "text": "Intuition (continued)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs flipper_length_mm increases from 205 to 230, confidence in classifying the example as Gentoo rises.\nConversely, as flipper_length_mm decreases from 205 to 170, confidence in classifying the example as non-Gentoo rises."
  },
  {
    "objectID": "lectures/05/slides.html#intuition-continued-3",
    "href": "lectures/05/slides.html#intuition-continued-3",
    "title": "Logististic regression",
    "section": "Intuition (continued)",
    "text": "Intuition (continued)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor values near the decision boundary, 205, some examples classify as Gentoo while others do not, leading to a classification uncertainty comparable to a coin flip (0.5 probability)."
  },
  {
    "objectID": "lectures/05/slides.html#logistic-function-2",
    "href": "lectures/05/slides.html#logistic-function-2",
    "title": "Logististic regression",
    "section": "Logistic function",
    "text": "Logistic function\n\n\nAn S-shaped curve, such as the standard logistic function (aka sigmoid), is termed a squashing function because it maps a wide input domain to a constrained output range.\n\\[\n  \\sigma(t) = \\frac{1}{1+e^{-t}}\n\\]\n\n\n\nCode\n# Create a figure\nfig, ax = plt.subplots()\nax.plot(t, sigma, color='blue', linewidth=2)  # Keep the curve opaque\n\n# Draw vertical axis at x = 0\nax.axvline(x=0, color='black', linewidth=1)\n\n# Add labels on the vertical axis\nax.set_yticks([0, 0.5, 1.0])\n\n# Add labels to the axes\nax.set_xlabel('t')\nax.set_ylabel(r'$\\sigma(t)$')\n\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/05/slides.html#notation",
    "href": "lectures/05/slides.html#notation",
    "title": "Logististic regression",
    "section": "Notation",
    "text": "Notation\n\nEquation for the logistic regression: \\[\n\\sigma(\\theta_0 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)})\n\\]\nMultipling \\(\\theta_0\\) (intercept/bias) by 1: \\[\n\\sigma(\\theta_0 \\times 1 + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)})\n\\]\nMultipling \\(\\theta_0\\) by \\(x_i^{(0)} = 1\\): \\[\n\\sigma(\\theta_0 x_i^{(0)} + \\theta_1 x_i^{(1)} + \\theta_2 x_i^{(2)} + \\ldots + \\theta_D x_i^{(D)})\n\\]"
  },
  {
    "objectID": "lectures/03/slides.html#resources",
    "href": "lectures/03/slides.html#resources",
    "title": "Learning Algorithms",
    "section": "Resources",
    "text": "Resources\n\nPlot the decision surface of decision trees trained on the iris dataset from sklearn\nDecision trees by Jan Kirenz, a Professor at HdM Stuttgart\nCS 320 Apr12-2021 (Part 2) - Decision Boundaries by Tyler Caraza-Harter, an Instructor at UW-Madison"
  },
  {
    "objectID": "lectures/05/slides.html#yann-lecun",
    "href": "lectures/05/slides.html#yann-lecun",
    "title": "Logististic regression",
    "section": "1989 Yann LeCun",
    "text": "1989 Yann LeCun"
  },
  {
    "objectID": "lectures/05/slides.html#handwritten-digit-recognition",
    "href": "lectures/05/slides.html#handwritten-digit-recognition",
    "title": "Logististic regression",
    "section": "Handwritten Digit Recognition",
    "text": "Handwritten Digit Recognition\nAims:\n\nDeveloping a logistic regression model for the recognition of handwritten digits.\nVisualize the insights and patterns the model has acquired.\n\n\n\nWe are using the UCI ML hand-written digits datasets."
  },
  {
    "objectID": "lectures/05/slides.html#visualization-4",
    "href": "lectures/05/slides.html#visualization-4",
    "title": "Logististic regression",
    "section": "Visualization",
    "text": "Visualization\n\n\nCode\nplt.figure(figsize=(10,5))\n\nfor index in range(len(clf.classes_)):\n    plt.subplot(2, 5, index + 1)\n    plt.title(f'y = {clf.classes_[index]}')\n    plt.imshow(clf.estimators_[index].coef_.reshape(width,width), \n               cmap=plt.cm.RdBu,\n               interpolation='bilinear')"
  },
  {
    "objectID": "lectures/06/slides.html#message-of-the-day",
    "href": "lectures/06/slides.html#message-of-the-day",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Message of the Day",
    "text": "Message of the Day\n\n\n\nTIME conducted interviews with the authors of a recent report from the Stanford Digital Economy Lab, titled “Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of Artificial Intelligence.” The report is available here and here is the abstract:\n\nThis paper examines changes in the labor market for occupations exposed to generative artificial intelligence using high-frequency administrative data from the largest payroll software provider in the United States. We present six facts that characterize these shifts. We find that since the widespread adoption of generative AI, early-career workers (ages 22-25) in the most AI-exposed occupations have experienced a 13 percent relative decline in employment even after controlling for firm-level shocks. In contrast, employment for workers in less exposed fields and more experienced workers in the same occupations has remained stable or continued to grow. We also find that adjustments occur primarily through employment rather than compensation. Furthermore, employment declines are concentrated in occupations where AI is more likely to automate, ratherthanaugment, humanlabor. Ourresultsarerobusttoalternativeexplanations, such as excluding technology-related firms and excluding occupations amenable to remote work. These six facts provide early, large-scale evidence consistent with the hypothesis that the AI revolution is beginning to have a significant and disproportionate impact on entry-level workers in the American labor market.\n\n\n\nAI’s “Significant Effect” on Entry-Level Work, TIME, 2025-09-05. (13m 55s)"
  },
  {
    "objectID": "lectures/06/slides.html#problem",
    "href": "lectures/06/slides.html#problem",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Problem",
    "text": "Problem\n\nGeneral Case: \\(P(y = k \\mid x, \\theta)\\), where \\(k\\) is a class label.\nBinary Case: \\(y \\in {0,1}\\)\n\nPredict \\(P(y = 1 \\mid x, \\theta)\\)\n\n\n\n\nFor a new instance \\(x_{\\textrm{new}}\\), determine the probability that it belongs to class \\(k\\), denoted as \\(P(y = k \\mid x_{\\textrm{new}}, \\theta)\\)."
  },
  {
    "objectID": "lectures/06/slides.html#logistic-regression-binary-classification",
    "href": "lectures/06/slides.html#logistic-regression-binary-classification",
    "title": "Geometric interpretation and cross-entry",
    "section": "Logistic Regression (Binary Classification)",
    "text": "Logistic Regression (Binary Classification)\nThe Logistic Regression model is defined as:\n\\[\n  h_\\theta(x_i) = \\sigma(\\theta x_i) = \\frac{1}{1+e^{- \\theta x_i}}\n  \\]\n\nPredictions are made as follows:\n\\(y_i = 0\\), if \\(h_\\theta(x_i) &lt; 0.5\\)\n\\(y_i = 1\\), if \\(h_\\theta(x_i) \\geq 0.5\\)\n\n\n\nIn the previous lecture, we considered an example wherein logistic regression was used to classify handwritten digits.\n\nThe classification problem was addressed using a one-vs-rest strategy, which involved training ten separate logistic regression models, each dedicated to recognizing a specific digit.\nEach model consisted of 65 parameters: one bias term and 64 weights. Each weight corresponded to a pixel (or attribute) of a \\(64 \\times 64\\) pixel image.\nThis method demonstrated an excellent performance, achieving an overall accuracy of 0.97.\nAnalyzing the weights provided insights into the areas of the image to which the model was most responsive (what does it pay attention to?).\n\n\n\nThe model assumes that the classes can be separated by a linear function in feature space."
  },
  {
    "objectID": "lectures/06/slides.html#geometric-interpretation-1",
    "href": "lectures/06/slides.html#geometric-interpretation-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Geometric Interpretation",
    "text": "Geometric Interpretation\n\nDo you recognize this equation? \\[\nw_1 x_1 + w_2 x_2 + \\ldots + w_D x_2\n\\]\nThis is the dot product of \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\), \\(\\mathbf{w} \\cdot \\mathbf{x}\\).\nWhat is the geometric interpretation of the dot product?\n\n\n\\[\n\\mathbf{w} \\cdot \\mathbf{x} = \\|\\mathbf{w}\\| \\|\\mathbf{x}\\| \\cos \\theta\n\\]\n\n\n\nIn certain contexts, it is advantageous to use \\(w\\) in place of \\(\\theta\\)."
  },
  {
    "objectID": "lectures/06/slides.html#geometric-interpretation-2",
    "href": "lectures/06/slides.html#geometric-interpretation-2",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Geometric Interpretation",
    "text": "Geometric Interpretation\n\\[\n\\mathbf{w} \\cdot \\mathbf{x} = \\|\\mathbf{w}\\| \\|\\mathbf{x}\\| \\cos \\theta\n\\]\n\nThe dot product determines the angle \\((\\theta)\\) between vectors.\nIt quantifies how much one vector extends in the direction of another.\nIts value is zero, if the vectors are perpendicular \\((\\theta = 90^\\circ)\\)."
  },
  {
    "objectID": "lectures/06/slides.html#geometric-interpretation-3",
    "href": "lectures/06/slides.html#geometric-interpretation-3",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Geometric Interpretation",
    "text": "Geometric Interpretation\n\nLogistic regression uses a linear combination of the input features, \\(\\mathbf{w} \\cdot \\mathbf{x} + b\\), as the argument to the sigmoid (logistic) function.\nGeometrically, \\(\\mathbf{w}\\) can be viewed as a vector normal to a hyperplane in the feature space, and any point \\(\\mathbf{x}\\) is projected onto \\(\\mathbf{w}\\) via the dot product \\(\\mathbf{w} \\cdot \\mathbf{x}\\)."
  },
  {
    "objectID": "lectures/06/slides.html#geometric-interpretation-4",
    "href": "lectures/06/slides.html#geometric-interpretation-4",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Geometric Interpretation",
    "text": "Geometric Interpretation\n\nThe decision boundary is where this linear combination equals zero, i.e., \\(\\mathbf{w} \\cdot \\mathbf{x} + b = 0\\).\nPoints on one side of the boundary have a positive dot product and are more likely to be classified as the positive class (1).\nPoints on the other side have a negative dot product and are more likely to be in the opposite class (0).\nThe sigmoid function simply turns this signed distance into a probability between 0 and 1."
  },
  {
    "objectID": "lectures/06/slides.html#logistic-regression",
    "href": "lectures/06/slides.html#logistic-regression",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nThe Logistic Regression model is defined as:\n\\[\n  h_\\theta(x_i) = \\sigma(\\theta x_i) = \\frac{1}{1+e^{- \\theta x_i}}\n  \\]\n\nPredictions are made as follows:\n\\(y_i = 0\\), if \\(h_\\theta(x_i) &lt; 0.5\\)\n\\(y_i = 1\\), if \\(h_\\theta(x_i) \\geq 0.5\\)\n\n\n\nIn the previous lecture, we considered an example wherein logistic regression was used to classify handwritten digits.\n\nThe classification problem was addressed using a one-vs-rest strategy, which involved training ten separate logistic regression models, each dedicated to recognizing a specific digit.\nEach model consisted of 65 parameters: one bias term and 64 weights. Each weight corresponded to a pixel (or attribute) of a \\(64 \\times 64\\) pixel image.\nThis method demonstrated an excellent performance, achieving an overall accuracy of 0.97.\nAnalyzing the weights provided insights into the areas of the image to which the model was most responsive (what does it pay attention to?).\n\nThe model presented above is expressed in its vectorized form, allowing it to be applied to problems involving multiple attributes. In the context of recognizing handwritten digits, the model utilizes 64 attributes, corresponding to individual pixels. The function \\(\\sigma\\) employed in this model is the logistic, or sigmoid, function.\n\n\nThe problem is formulated as a binary classification task, wherein the model presumes that the classes are separable by a linear function within the feature space."
  },
  {
    "objectID": "lectures/06/slides.html#model-overview",
    "href": "lectures/06/slides.html#model-overview",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Model Overview",
    "text": "Model Overview\n\nOur model is expressed in a vectorized form as:\n\\[\nh_\\theta(x_i) = \\sigma(\\theta x_i) = \\frac{1}{1+e^{- \\theta x_i}}\n\\]\nPrediction:\n\nAssign \\(y_i = 0\\), if \\(h_\\theta(x_i) &lt; 0.5\\); \\(y_i = 1\\), if \\(h_\\theta(x_i) \\geq 0.5\\)\n\n\n\nThe parameter vector \\(\\theta\\) is optimized using gradient descent.\nWhich loss function should be used and why?\n\n\nIn logistic regression, the output is regarded as a probability, with particular emphasis on the interpretation process."
  },
  {
    "objectID": "lectures/06/slides.html#remarks",
    "href": "lectures/06/slides.html#remarks",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Remarks",
    "text": "Remarks\n\nIn constructing machine learning models with libraries like scikit-learn or keras, one has to select a loss function or accept the default one.\nInitially, the terminology can be confusing, as identical functions may be referenced by various names.\nOur aim is to elucidate these complexities.\nIt is actually not that complicated!"
  },
  {
    "objectID": "lectures/06/slides.html#parameter-estimation",
    "href": "lectures/06/slides.html#parameter-estimation",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nLogistic regression is statistical model.\nIts output is \\(\\hat{y} = P(y = 1 | x, \\theta)\\).\n\\(P(y = 0 | x, \\theta) = 1 - \\hat{y}\\).\nAssumes that \\(y\\) values come from a Bernoulli distribution.\n\\(\\theta\\) is commonly found by Maximum Likelihood Estimation.\n\n\n\nThe expressions \\(\\hat{y}\\), \\(h_\\theta(x_i)\\), and \\(\\sigma(\\theta x_i)\\) represent the same concept, albeit at varying levels of abstraction and specificity."
  },
  {
    "objectID": "lectures/06/slides.html#parameter-estimation-1",
    "href": "lectures/06/slides.html#parameter-estimation-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\nMaximum Likelihood Estimation (MLE) is a statistical method used to estimate the parameters of a probabilistic model.\nIt identifies the parameter values that maximize the likelihood function, which measures how well the model explains the observed data."
  },
  {
    "objectID": "lectures/06/slides.html#likelihood-function",
    "href": "lectures/06/slides.html#likelihood-function",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Likelihood Function",
    "text": "Likelihood Function\nAssuming the \\(y\\) values are independent and identically distributed (i.i.d.), the likelihood function is expressed as the product of individual probabilities.\nIn other words, given our data, \\(\\{(x_i, y_i)\\}_{i=1}^N\\), the likelihood function is given by this equation. \\[\n\\mathcal{L}(\\theta) = \\prod_{i=1}^{N} P(y_i \\mid x_i, \\theta)\n\\]"
  },
  {
    "objectID": "lectures/06/slides.html#maximum-likelihood",
    "href": "lectures/06/slides.html#maximum-likelihood",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Maximum Likelihood",
    "text": "Maximum Likelihood\n\\[\n  \\hat{\\theta} = \\underset{\\theta \\in \\Theta}{\\arg \\max} \\mathcal{L}(\\theta) =  \\underset{\\theta \\in \\Theta}{\\arg \\max}  \\prod_{i=1}^{N} P(y_i \\mid x_i, \\theta)\n\\]\n\nObservations:\n\nMaximizing a function is equivalent to minimizing its negative.\nThe logarithm of a product equals the sum of its logarithms."
  },
  {
    "objectID": "lectures/06/slides.html#negative-log-likelihood",
    "href": "lectures/06/slides.html#negative-log-likelihood",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Negative Log-Likelihood",
    "text": "Negative Log-Likelihood\nMaximum likelihood \\[\n  \\hat{\\theta} = \\underset{\\theta \\in \\Theta}{\\arg \\max} \\mathcal{L}(\\theta) = \\underset{\\theta \\in \\Theta}{\\arg \\max}  \\prod_{i=1}^{N} P(y_i \\mid x_i, \\theta)\n\\]\nbecomes negative log-likelihood\n\\[\n\\hat{\\theta} = \\underset{\\theta \\in \\Theta}{\\arg \\min} - \\log \\mathcal{L(\\theta)} = \\underset{\\theta \\in \\Theta}{\\arg \\min} - \\log \\prod_{i=1}^{N} P(y_i \\mid x_i, \\theta) = \\underset{\\theta \\in \\Theta}{\\arg \\min} - \\sum_{i=1}^{N} \\log P(y_i \\mid x_i, \\theta)\n\\]"
  },
  {
    "objectID": "lectures/06/slides.html#mathematical-reformulation",
    "href": "lectures/06/slides.html#mathematical-reformulation",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Mathematical Reformulation",
    "text": "Mathematical Reformulation\nFor binary outcomes, the probability \\(P(y \\mid x, \\theta)\\) is:\n\\[\nP(y \\mid x, \\theta) =\n\\begin{cases}\n\\sigma(\\theta x), & \\text{if}\\ y = 1 \\\\\n1 - \\sigma(\\theta x), & \\text{if}\\ y = 0\n\\end{cases}\n\\]\n\nThis can be compactly expressed as:\n\\[\nP(y \\mid x, \\theta) = \\sigma(\\theta x)^y (1 - \\sigma(\\theta x))^{1-y}\n\\]\n\n\n\nThis “mathematical hack” validates the rationale for the label encoding."
  },
  {
    "objectID": "lectures/06/slides.html#loss-function-1",
    "href": "lectures/06/slides.html#loss-function-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Loss Function",
    "text": "Loss Function\nWe are now ready to write our loss function.\n\\[\nJ(\\theta) = - \\log \\mathcal{L(\\theta)} = - \\sum_{i=1}^{N} \\log P(y_i \\mid x_i, \\theta)\n\\] where \\(P(y \\mid x, \\theta) = \\sigma(\\theta x)^y (1 - \\sigma(\\theta x))^{1-y}\\).\nConsequently, \\[\nJ(\\theta) = - \\sum_{i=1}^{N} \\log [ \\sigma(\\theta x_i)^{y_i} (1 - \\sigma(\\theta x_i))^{1-y_i} ]\n\\]"
  },
  {
    "objectID": "lectures/06/slides.html#loss-function-continued",
    "href": "lectures/06/slides.html#loss-function-continued",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Loss Function (continued)",
    "text": "Loss Function (continued)\nSimplifying the equation. \\[\nJ(\\theta) = - \\sum_{i=1}^{N} \\log [ \\sigma(\\theta x_i)^{y_i} (1 - \\sigma(\\theta x_i))^{1-y_i} ]\n\\] by distributing the \\(\\log\\) into the square parenthesis. \\[\nJ(\\theta) = - \\sum_{i=1}^{N} [ \\log \\sigma(\\theta x_i)^{y_i} + \\log (1 - \\sigma(\\theta x_i))^{1-y_i} ]\n\\]"
  },
  {
    "objectID": "lectures/06/slides.html#loss-function-continued-1",
    "href": "lectures/06/slides.html#loss-function-continued-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Loss Function (continued)",
    "text": "Loss Function (continued)\nSimplifying the equation further. \\[\nJ(\\theta) = - \\sum_{i=1}^{N} [ \\log \\sigma(\\theta x_i)^{y_i} + \\log (1 - \\sigma(\\theta x_i))^{1-y_i} ]\n\\] by moving the exponents in front of the \\(\\log\\)s.\n\\[\nJ(\\theta) = - \\sum_{i=1}^{N} [ y_i \\log \\sigma(\\theta x_i) + (1-y_i) \\log (1 - \\sigma(\\theta x_i)) ]\n\\]\n\n\nThe rationale for these additional simplifications will be elucidated shortly."
  },
  {
    "objectID": "lectures/06/slides.html#one-more-thing",
    "href": "lectures/06/slides.html#one-more-thing",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "One More Thing",
    "text": "One More Thing\n\nDecision tree algorithms often employ entropy, a measure from information theory, to evaluate the quality of splits or partitions in decision rules.\nEntropy quantifies the uncertainty or impurity associated with the potential outcomes of a random variable."
  },
  {
    "objectID": "lectures/06/slides.html#entropy",
    "href": "lectures/06/slides.html#entropy",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Entropy",
    "text": "Entropy\nEntropy in information theory quantifies the uncertainty or unpredictability of a random variable’s possible outcomes. It measures the average amount of information produced by a stochastic source of data and is typically expressed in bits for binary systems. The entropy \\(H\\) of a discrete random variable \\(X\\) with possible outcomes \\(\\{x_1, x_2, \\ldots, x_n\\}\\) and probability mass function \\(P(X)\\) is given by:\n\\[\nH(X) = -\\sum_{i=1}^n P(x_i) \\log_2 P(x_i)\n\\]"
  },
  {
    "objectID": "lectures/06/slides.html#cross-entropy",
    "href": "lectures/06/slides.html#cross-entropy",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Cross-Entropy",
    "text": "Cross-Entropy\nCross-entropy quantifies the difference between two probability distributions, typically the true distribution and a predicted distribution.\n\\[\nH(p, q) = -\\sum_{i} p(x_i) \\log q(x_i)\n\\] where \\(p(x_i)\\) is the true probability distribution, and \\(q(x_i)\\) is the predicted probability distribution."
  },
  {
    "objectID": "lectures/06/slides.html#cross-entropy-1",
    "href": "lectures/06/slides.html#cross-entropy-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Cross-Entropy",
    "text": "Cross-Entropy\n\nConsider \\(y\\) as the true probability distribution and \\(\\hat{y}\\) as the predicted probability distribution.\nCross-entropy quantifies the discrepancy between these two distributions."
  },
  {
    "objectID": "lectures/06/slides.html#cross-entropy-2",
    "href": "lectures/06/slides.html#cross-entropy-2",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Cross-Entropy",
    "text": "Cross-Entropy\nConsider the negative log-likelihood loss function:\n\\[\nJ(\\theta) = - \\sum_{i=1}^{N} \\left[ y_i \\log \\sigma(\\theta x_i) + (1-y_i) \\log (1 - \\sigma(\\theta x_i)) \\right]\n\\]\nBy substituting \\(\\sigma(\\theta x_i)\\) with \\(\\hat{y_i}\\), the function becomes:\n\\[\nJ(\\theta) = - \\sum_{i=1}^{N} \\left[ y_i \\log \\hat{y_i} + (1-y_i) \\log (1 - \\hat{y_i}) \\right]\n\\]\nThis expression illustrates that the negative log-likelihood is optimized by minimizing the cross-entropy.\n\n\nInterpret the final equation as applying to all examples from 1 to \\(N\\) and all classes from 1 to \\(k\\). Here, \\(k=0\\) because we are addressing a binary classification problem.\n\n\nCross-entropy, log loss, and negative log-likelihood refer to the same concept."
  },
  {
    "objectID": "lectures/06/slides.html#for-each-example",
    "href": "lectures/06/slides.html#for-each-example",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "For Each Example",
    "text": "For Each Example\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nnp.random.seed(42)\n\n# Generate an array of p values from just above 0 to 1\np_values = np.linspace(0.001, 1, 1000)\n\n# Compute the natural logarithm of each p value\nln_p_values = - np.log(p_values)\n\n# Plot the graph\nplt.figure(figsize=(5, 4))\nplt.plot(p_values, ln_p_values, label=r'$-\\log(\\hat{y})$', color='b')\n\n# Add labels and title\nplt.xlabel(r'$\\hat{y}$')\nplt.ylabel(r'J')\nplt.title(r'Graph of $-\\log(\\hat{y})$ for $\\hat{y}$ from 0 to 1')\nplt.grid(True)\nplt.axhline(0, color='gray', lw=0.5)  # Add horizontal line at y=0\nplt.axvline(0, color='gray', lw=0.5)  # Add vertical line at x=0\n\n# Display the plot\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nFor each example:\n\nOnly one of the two terms in the summation is not zero.\n\\(1 - \\hat{y_i}\\) is \\(P(y = 0 \\mid x, \\theta)\\).\nAs \\(\\hat{y_i}\\) tends to 1.0, \\(- \\log(\\hat{y})\\) tends to zero.\nAs \\(\\hat{y_i}\\) tends to 0.0, indicating an incorrect prediction, \\(- \\log(\\hat{y})\\) tends to \\(\\infty\\).\nThis substantial penalty allows cross-entropy loss to converge more quickly than mean squared error.\n\n\n\n\\[\nJ(\\theta) = - \\sum_{i=1}^{N} \\left[ y_i \\log \\hat{y_i} + (1-y_i) \\log (1 - \\hat{y_i}) \\right]\n\\]"
  },
  {
    "objectID": "lectures/06/slides.html#remarks-1",
    "href": "lectures/06/slides.html#remarks-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Remarks",
    "text": "Remarks\n\nCross-entropy loss is particularly well-suited for probabilistic classification tasks due to its alignment with maximum likelihood estimation.\nIn logistic regression, cross-entropy loss preserves convexity, contrasting with the non-convex nature of mean squared error (MSE)1.\n\n\n\nIf you train logistic regression with the mean squared error (MSE) loss:\n\nThe composition of the sigmoid (nonlinear, S-shaped) with the quadratic loss produces a non-convex objective.\nThis leads to multiple local minima and poor optimization behavior.\nBy contrast, using the log-loss (cross-entropy) yields a convex objective in the parameters, making optimization well-behaved with gradient methods.\n\n\n\nWe will revisite cross-entropy loss when studying deep learning, especially in conjunction with the softmax function.\nIn linear regression, mean squared error loss is convex."
  },
  {
    "objectID": "lectures/06/slides.html#remarks-2",
    "href": "lectures/06/slides.html#remarks-2",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Remarks",
    "text": "Remarks\n\nFor classification problems, cross-entropy loss often achieves faster convergence compared to MSE, enhancing model efficiency.\nWithin deep learning architectures, MSE can exacerbate the vanishing gradient problem, an issue we will address in a subsequent discussion."
  },
  {
    "objectID": "lectures/06/slides.html#why-not-mse-as-a-loss-function",
    "href": "lectures/06/slides.html#why-not-mse-as-a-loss-function",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Why not MSE as a Loss Function?",
    "text": "Why not MSE as a Loss Function?"
  },
  {
    "objectID": "lectures/06/slides.html#what-is-the-difference",
    "href": "lectures/06/slides.html#what-is-the-difference",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "What is the Difference?",
    "text": "What is the Difference?"
  },
  {
    "objectID": "lectures/06/slides.html#logistic-function",
    "href": "lectures/06/slides.html#logistic-function",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Logistic Function",
    "text": "Logistic Function\n\n\n\\[\n  \\sigma(t) = \\frac{1}{1+e^{-t}}\n\\]\n\nAs \\(t \\to \\infty\\), \\(e^{-t} \\to 0\\), so \\(\\sigma(t) \\to 1\\).\nAs \\(t \\to -\\infty\\), \\(e^{-t} \\to \\infty\\), making the denominator approach infinity, so \\(\\sigma(t) \\to 0\\).\nWhen \\(t = 0\\), \\(e^{-t} = 0\\), resulting in a denominator of 2, so \\(\\sigma(t) = 0.5\\).\n\n\n\n\nCode\n# Sigmoid function\ndef sigmoid(t):\n    return 1 / (1 + np.exp(-t))\n\n# Generate t values\nt = np.linspace(-6, 6, 1000)\n\n# Compute y values for the sigmoid function\nsigma = sigmoid(t)\n\n# Create a figure\nfig, ax = plt.subplots()\nax.plot(t, sigma, color='blue', linewidth=2)  # Keep the curve opaque\n\n# Draw vertical axis at x = 0\nax.axvline(x=0, color='black', linewidth=1)\n\n# Add labels on the vertical axis\nax.set_yticks([0, 0.5, 1.0])\n\n# Add labels to the axes\nax.set_xlabel('t')\nax.set_ylabel(r'$\\sigma(t)$')\n\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#whats-special-about-e",
    "href": "lectures/06/slides.html#whats-special-about-e",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "What’s special about e?",
    "text": "What’s special about e?\n\n\n\\[\n  \\sigma(t) = \\frac{1}{1+e^{-t}}\n\\]\n\nInstead of \\(e\\), we might have used another constant, say 2.\nDerivative Simplicity: For the logistic function \\(\\sigma(x) = \\tfrac{1}{1 + e^{-x}}\\), the derivative simplifies to \\(\\sigma'(x) = \\sigma(x)(1 - \\sigma(x))\\). This elegant form arises because the exponential base \\(e\\) has the unique property that \\(\\tfrac{d}{dx} e^x = e^x\\), avoiding an extra multiplicative constant.\n\n\n\n\nCode\nimport math\n\ndef logistic(x, e):\n    \"\"\"Compute a modified logistic function using b rather than e.\"\"\"\n    return 1 / (1 + np.power(e, -x))\n\n# Define a range for x values.\nx = np.linspace(-6, 6, 400)\n\n# Plot 1: Varying e.\nplt.figure(figsize=(8, 6))\ne_values = [2, math.e, 4, 8, 16]  # different steepness values\n\nfor e in e_values:\n    plt.plot(x, logistic(x, e), label=f'e = {e}')\nplt.title('Effect of Varying e')\nplt.xlabel('x')\nplt.ylabel(r'$\\frac{1}{1+e^{-x}}$')\nplt.legend()\nplt.grid(True)\n\n\n\n\n\n\n\n\n\n\n\nIn the context of logistic regression, the choice of the mathematical constant \\(e\\) is not arbitrary but is supported by several compelling mathematical justifications. These justifications primarily relate to the harmonious integration of the logistic function with other mathematical frameworks. Although our primary focus was to visually demonstrate the potential implications of substituting a different constant, the inherent advantages of using \\(e\\) become evident upon closer examination of its mathematical properties and how they facilitate seamless integration with existing theories and models."
  },
  {
    "objectID": "lectures/06/slides.html#varying-w",
    "href": "lectures/06/slides.html#varying-w",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Varying w",
    "text": "Varying w\n\n\n\\[\n  \\sigma(wx + b)\n\\]\n\n\n\nCode\ndef logistic(x, w, b):\n    \"\"\"Compute the logistic function with parameters w and b.\"\"\"\n    return 1 / (1 + np.exp(-(w * x + b)))\n\n# Define a range for x values.\nx = np.linspace(-10, 10, 400)\n\n# Plot 1: Varying w (steepness) with b fixed at 0.\nplt.figure(figsize=(8, 6))\nw_values = [0.5, 1, 2, 5]  # different steepness values\nb = 0  # fixed bias\n\nfor w in w_values:\n    plt.plot(x, logistic(x, w, b), label=f'w = {w}, b = {b}')\nplt.title('Effect of Varying w (with b = 0)')\nplt.xlabel('x')\nplt.ylabel(r'$\\sigma(wx+b)$')\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#varying-b",
    "href": "lectures/06/slides.html#varying-b",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Varying b",
    "text": "Varying b\n\n\n\\[\n  \\sigma(wx + b)\n\\]\n\n\n\nCode\n# Plot 2: Varying b (horizontal shift) with w fixed at 1.\nplt.figure(figsize=(8, 6))\nw = 1  # fixed steepness\nb_values = [-5, -2, 0, 2, 5]  # different bias values\n\nfor b in b_values:\n    plt.plot(x, logistic(x, w, b), label=f'w = {w}, b = {b}')\nplt.title('Effect of Varying b (with w = 1)')\nplt.xlabel('x')\nplt.ylabel(r'$\\sigma(wx+b)$')\nplt.legend()\nplt.grid(True)\n\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#implementation-generating-data",
    "href": "lectures/06/slides.html#implementation-generating-data",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Implementation: Generating Data",
    "text": "Implementation: Generating Data\n\n# Generate synthetic data for a binary classification problem\n\nm = 100  # number of examples\nd = 2    # number of featues\n\nX = np.random.randn(m, d)\n\n# Define labels using a linear decision boundary with some noise:\n\nnoise = 0.5 * np.random.randn(m)\n\ny = (X[:, 0] + X[:, 1] + noise &gt; 0).astype(int)"
  },
  {
    "objectID": "lectures/06/slides.html#implementation-vizualization",
    "href": "lectures/06/slides.html#implementation-vizualization",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Implementation: Vizualization",
    "text": "Implementation: Vizualization\n\n\nCode\n# Visualize the decision boundary along with the data points\nplt.figure(figsize=(8, 6))\nplt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', label='Class 0')\nplt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', label='Class 1')\n\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.title(\"Data\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#implementation-cost-function",
    "href": "lectures/06/slides.html#implementation-cost-function",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Implementation: Cost Function",
    "text": "Implementation: Cost Function\n\n# Sigmoid function\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n# Cost function: binary cross-entropy\ndef cost_function(theta, X, y):\n    m = len(y)\n    h = sigmoid(X.dot(theta))\n    epsilon = 1e-5  # avoid log(0)\n    cost = -(1/m) * np.sum(y * np.log(h + epsilon) + (1 - y) * np.log(1 - h + epsilon))\n    return cost\n\n# Gradient of the cost function\ndef gradient(theta, X, y):\n    m = len(y)\n    h = sigmoid(X.dot(theta))\n    grad = (1/m) * X.T.dot(h - y)\n    return grad"
  },
  {
    "objectID": "lectures/06/slides.html#implementation-logistic-regression",
    "href": "lectures/06/slides.html#implementation-logistic-regression",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Implementation: Logistic Regression",
    "text": "Implementation: Logistic Regression\n\n# Logistic regression training using gradient descent\ndef logistic_regression(X, y, learning_rate=0.1, iterations=1000):\n    m, n = X.shape\n    theta = np.zeros(n)\n    cost_history = []\n    \n    for i in range(iterations):\n        theta -= learning_rate * gradient(theta, X, y)\n        cost_history.append(cost_function(theta, X, y))\n        \n    return theta, cost_history"
  },
  {
    "objectID": "lectures/06/slides.html#training",
    "href": "lectures/06/slides.html#training",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Training",
    "text": "Training\n\n# Add intercept term (bias)\nX_with_intercept = np.hstack([np.ones((m, 1)), X])\n\n# Train the logistic regression model\ntheta, cost_history = logistic_regression(X_with_intercept, y, learning_rate=0.1, iterations=1000)\n\nprint(\"Optimized theta:\", theta)\n\nOptimized theta: [-0.28840995  2.80390104  2.45238752]"
  },
  {
    "objectID": "lectures/06/slides.html#cost-function-convergence",
    "href": "lectures/06/slides.html#cost-function-convergence",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Cost Function Convergence",
    "text": "Cost Function Convergence\n\n\nCode\nplt.figure(figsize=(8, 6))\nplt.plot(cost_history, label=\"Cost\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Cost\")\nplt.title(\"Cost Function Convergence\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#decision-boundary-and-data-points",
    "href": "lectures/06/slides.html#decision-boundary-and-data-points",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Decision Boundary and Data Points",
    "text": "Decision Boundary and Data Points\n\n\nCode\nplt.figure(figsize=(8, 6))\nplt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', label='Class 0')\nplt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', label='Class 1')\n\n# Decision boundary: theta0 + theta1*x1 + theta2*x2 = 0\nx_vals = np.array([min(X[:, 0]) - 1, max(X[:, 0]) + 1])\ny_vals = -(theta[0] + theta[1] * x_vals) / theta[2]\nplt.plot(x_vals, y_vals, label='Decision Boundary', color='green')\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.title(\"Logistic Regression Decision Boundary\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#implementation-continued",
    "href": "lectures/06/slides.html#implementation-continued",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Implementation (continued)",
    "text": "Implementation (continued)\n\n# Predict function: returns class labels and probabilities for new data\ndef predict(theta, X, threshold=0.5):\n    probs = sigmoid(X.dot(theta))\n    return (probs &gt;= threshold).astype(int), probs"
  },
  {
    "objectID": "lectures/06/slides.html#predictions",
    "href": "lectures/06/slides.html#predictions",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Predictions",
    "text": "Predictions\n\n# New examples must include the intercept term.\n\n# Negative example (likely class 0): Choose a point far in the negative quadrant.\nexample_neg = np.array([1, -3, -3])\n\n# Positive example (likely class 1): Choose a point far in the positive quadrant.\nexample_pos = np.array([1, 3, 3])\n\n# Near decision boundary: Choose x1 = 0 and compute x2 from the decision boundary equation.\nx1_near = 0\nx2_near = -(theta[0] + theta[1] * x1_near) / theta[2]\nexample_near = np.array([1, x1_near, x2_near])\n\n\nIn the given example, each data point is characterized by two primary features. However, the representation includes three components. Why?\nThis discrepancy arises from an earlier discussed mathematical technique, where each instance is augmented with an additional term, \\(x_i^{(0)} = 1\\). This augmentation facilitates the expression of the model in a vectorized format, enhancing computational efficiency and simplicity."
  },
  {
    "objectID": "lectures/06/slides.html#predictions-continued",
    "href": "lectures/06/slides.html#predictions-continued",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Predictions (continued)",
    "text": "Predictions (continued)\n\n# Combine the examples into one array for prediction.\nnew_examples = np.vstack([example_neg, example_pos, example_near])\n\nlabels, probabilities = predict(theta, new_examples)\n\nprint(\"\\nPredictions on new examples:\")\n\nprint(\"Negative example {} -&gt; Prediction: {} (Probability: {:.4f})\".format(example_neg[1:], labels[0], probabilities[0]))\n\nprint(\"Positive example {} -&gt; Prediction: {} (Probability: {:.4f})\".format(example_pos[1:], labels[1], probabilities[1]))\n\nprint(\"Near-boundary example {} -&gt; Prediction: {} (Probability: {:.4f})\".format(example_near[1:], labels[2], probabilities[2]))\n\n\nPredictions on new examples:\nNegative example [-3 -3] -&gt; Prediction: 0 (Probability: 0.0000)\nPositive example [3 3] -&gt; Prediction: 1 (Probability: 1.0000)\nNear-boundary example [0.         0.11760374] -&gt; Prediction: 1 (Probability: 0.5000)"
  },
  {
    "objectID": "lectures/06/slides.html#visualizing-the-weight-vector",
    "href": "lectures/06/slides.html#visualizing-the-weight-vector",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Visualizing the Weight Vector",
    "text": "Visualizing the Weight Vector\nIn the previous lecture, we established that logistic regression determines a weight vector that is orthogonal to the decision boundary.\nConversely, the decision boundary itself is orthogonal to the weight vector, which is derived through gradient descent optimization."
  },
  {
    "objectID": "lectures/06/slides.html#visualizing-the-weight-vector-1",
    "href": "lectures/06/slides.html#visualizing-the-weight-vector-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Visualizing the Weight Vector",
    "text": "Visualizing the Weight Vector\n\n\nCode\n# Plot decision boundary and data points\nplt.figure(figsize=(8, 6))\nplt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', label='Class 0')\nplt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', label='Class 1')\n\n# Decision boundary: theta0 + theta1*x1 + theta2*x2 = 0\nx_vals = np.array([min(X[:, 0]) - 1, max(X[:, 0]) + 1])\ny_vals = -(theta[0] + theta[1] * x_vals) / theta[2]\nplt.plot(x_vals, y_vals, label='Decision Boundary', color='green')\n\n# --- Draw the normal vector ---\n# The normal vector is (theta[1], theta[2]).\n# Choose a reference point on the decision boundary. Here, we use x1 = 0:\nx_ref = 0\ny_ref = -theta[0] / theta[2]  # when x1=0, theta0 + theta2*x2=0  =&gt;  x2=-theta0/theta2\n\n# Create the normal vector from (theta[1], theta[2]).\nnormal = np.array([theta[1], theta[2]])\n\n# Normalize and scale for display\nnormal_norm = np.linalg.norm(normal)\nif normal_norm != 0:\n    normal_unit = normal / normal_norm\nelse:\n    normal_unit = normal\nscale = 2  # adjust scale as needed\nnormal_display = normal_unit * scale\n\n# Draw an arrow starting at the reference point\nplt.arrow(x_ref, y_ref, normal_display[0], normal_display[1],\n          head_width=0.1, head_length=0.2, fc='black', ec='black')\nplt.text(x_ref + normal_display[0]*1.1, y_ref + normal_display[1]*1.1, \n         r'$(\\theta_1, \\theta_2)$', color='black', fontsize=12)\n\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.title(\"Logistic Regression Decision Boundary and Normal Vector\")\nplt.legend()\nplt.gca().set_aspect('equal', adjustable='box')\nplt.ylim(-3, 3)\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#near-the-decision-boundary",
    "href": "lectures/06/slides.html#near-the-decision-boundary",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Near the Decision Boundary",
    "text": "Near the Decision Boundary\n\n\nCode\n# --- Visualization Setup ---\n# Create a grid over the feature space\nx1_range = np.linspace(X[:, 0].min()-1, X[:, 0].max()+1, 100)\nx2_range = np.linspace(X[:, 1].min()-1, X[:, 1].max()+1, 100)\nxx1, xx2 = np.meshgrid(x1_range, x2_range)\n\n# Construct the grid input (with intercept) for predictions\ngrid = np.c_[np.ones(xx1.ravel().shape), xx1.ravel(), xx2.ravel()]\n# Compute predicted probabilities over the grid\nprobs = sigmoid(grid.dot(theta)).reshape(xx1.shape)\n# --- Approach 2: 2D Contour (Heatmap) Plot ---\nplt.figure(figsize=(8, 6))\ncontour = plt.contourf(xx1, xx2, probs, cmap='spring', levels=50)\nplt.colorbar(contour)\nplt.xlabel('Feature x1')\nplt.ylabel('Feature x2')\nplt.title('Contour Plot (Heatmap) of Predicted Probabilities')\n# Overlay training data\nplt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', edgecolor='k', label='Class 0')\nplt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', edgecolor='k', label='Class 1')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#near-the-decision-boundary-1",
    "href": "lectures/06/slides.html#near-the-decision-boundary-1",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Near the Decision Boundary",
    "text": "Near the Decision Boundary\n\n\nCode\n# --- Approach 1: 3D Surface Plot ---\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\nsurface = ax.plot_surface(xx1, xx2, probs, cmap='spring', alpha=0.8)\nax.set_xlabel('Feature x1')\nax.set_ylabel('Feature x2')\nax.set_zlabel('Probability')\nax.set_title('3D Surface Plot of Logistic Regression Model')\nfig.colorbar(surface, shrink=0.5, aspect=5)\nplt.show()"
  },
  {
    "objectID": "lectures/06/slides.html#learning-outcomes",
    "href": "lectures/06/slides.html#learning-outcomes",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this presentation, you should be able to:\n\nDifferentiate between MSE and cross-entropy as loss functions.\nRelate maximum likelihood estimation to parameter learning in logistic regression.\nInterpret the geometric view of logistic regression as a linear decision boundary.\nImplement logistic regression with gradient descent on simple data."
  },
  {
    "objectID": "lectures/06/slides.html#summary",
    "href": "lectures/06/slides.html#summary",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Summary",
    "text": "Summary\nIn this presentation, we:\n\nDerived the likelihood and negative log-likelihood formulations.\nIllustrated the geometric interpretation of decision boundaries and weight vectors.\nImplemented logistic regression with gradient descent and visualized results."
  },
  {
    "objectID": "lectures/motd/slides.html#and-2024-09-18",
    "href": "lectures/motd/slides.html#and-2024-09-18",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-16 (and 2024-09-18)",
    "text": "2024-09-16 (and 2024-09-18)\n\n\n\n\n\n\n\n\n\n\nOpenAI released o1 on September 12, 2024: “o1 greatly improves over GPT-4o on challenging reasoning benchmarks. Solid bars show pass@1 accuracy and the shaded region shows the performance of majority vote (consensus) with 64 samples.”"
  },
  {
    "objectID": "lectures/motd/slides.html#and-2024-09-18-continued",
    "href": "lectures/motd/slides.html#and-2024-09-18-continued",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-16 (and 2024-09-18) (continued)",
    "text": "2024-09-16 (and 2024-09-18) (continued)\n\n\n\n\nVideos:\n\nBuilding OpenAI o1\nCoding with OpenAI o1\nScott Wu: OpenAI o1 & Coding\nCatherine Brownstein: Genetics\nMario Krenn: Quantum Physics\nOpenAI o1 playlist\n\n\n\n\nThe videos in this playlist range from 1:17 minute to 3:17 minutes in duration."
  },
  {
    "objectID": "lectures/motd/slides.html#section-2",
    "href": "lectures/motd/slides.html#section-2",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-23",
    "text": "2024-09-23\n\n\n\n“The next season of the #Complexity #podcast, ‘The Nature of Intelligence’, explores this question through conversations with cognitive and neuroscientists, animal cognition researchers, and AI experts in six episodes.””"
  },
  {
    "objectID": "lectures/motd/slides.html#continued-2",
    "href": "lectures/motd/slides.html#continued-2",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-16 (continued)",
    "text": "2024-09-16 (continued)\n\n\n\n\nVideos:\n\nBuilding OpenAI o1\nCoding with OpenAI o1\nScott Wu: OpenAI o1 & Coding\nCatherine Brownstein: Genetics\nMario Krenn: Quantum Physics\nOpenAI o1 playlist\n\n\n\n\nThe videos in this playlist range from 1:17 minute to 3:17 minutes in duration."
  },
  {
    "objectID": "lectures/motd/slides.html#section-3",
    "href": "lectures/motd/slides.html#section-3",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-25",
    "text": "2024-09-25\n\n\n\n\n\n\n\n\n\n\n2024 Waymo Safety Impact Report was published on 2024-09-05. Waymo is a subsidiary of Alphabet inc., Google’s parent company. It operates robotaxi services in 4 US cities."
  },
  {
    "objectID": "lectures/motd/slides.html#section-4",
    "href": "lectures/motd/slides.html#section-4",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-09-30",
    "text": "2024-09-30\n\n\n\n\n\n\n\nSuper Intelligence from The Future with Hannah Fry aired September 12th, 2024."
  },
  {
    "objectID": "lectures/motd/slides.html#section-5",
    "href": "lectures/motd/slides.html#section-5",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-10-07",
    "text": "2024-10-07\n\n\n\nClément Delangue, Hugging Face CEO, discusses AI for good. Specifically, the development by IBM and NASA of an open-source AI model for weather and climate analysis."
  },
  {
    "objectID": "lectures/motd/slides.html#section-6",
    "href": "lectures/motd/slides.html#section-6",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-10-09",
    "text": "2024-10-09\n\n\n\n\n\n\n\nThe Nobel Prize in Physics 2024 was awarded to John J. Hopfield and Geoffrey E. Hinton “for foundational discoveries and inventions that enable machine learning with artificial neural networks”"
  },
  {
    "objectID": "lectures/motd/slides.html#test",
    "href": "lectures/motd/slides.html#test",
    "title": "Message of the day (MOTD) - 2024",
    "section": "Test",
    "text": "Test"
  },
  {
    "objectID": "lectures/motd/slides.html#section-7",
    "href": "lectures/motd/slides.html#section-7",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-10-21",
    "text": "2024-10-21\n\n\nSir Demis Hassabis is the Co-founder and CEO of Google DeepMind, a leading company dedicated to addressing some of the most complex scientific and engineering challenges of our era to propel scientific advancement. A chess prodigy from the age of four, Hassabis achieved master-level proficiency by 13 and served as the captain for several England junior chess teams. In 2024, he was awarded the Nobel Prize in Chemistry for his contributions to the development of AlphaFold."
  },
  {
    "objectID": "lectures/motd/slides.html#section-8",
    "href": "lectures/motd/slides.html#section-8",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-10-28",
    "text": "2024-10-28\n\n\n\nYann LeCun, recognized as one of the three pioneers of deep learning and the inventor of Convolutional Neural Networks (CNNs), frequently engages in discussions with Elon Musk on the social media platform X (previously known as Twitter)."
  },
  {
    "objectID": "lectures/motd/slides.html#section-9",
    "href": "lectures/motd/slides.html#section-9",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-10-30",
    "text": "2024-10-30"
  },
  {
    "objectID": "lectures/motd/slides.html#section-10",
    "href": "lectures/motd/slides.html#section-10",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-11-04",
    "text": "2024-11-04"
  },
  {
    "objectID": "lectures/motd/slides.html#section-11",
    "href": "lectures/motd/slides.html#section-11",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-11-06",
    "text": "2024-11-06"
  },
  {
    "objectID": "lectures/motd/slides.html#section-12",
    "href": "lectures/motd/slides.html#section-12",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-11-11",
    "text": "2024-11-11"
  },
  {
    "objectID": "lectures/motd/slides.html#section-13",
    "href": "lectures/motd/slides.html#section-13",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-11-25",
    "text": "2024-11-25"
  },
  {
    "objectID": "lectures/motd/slides.html#section-14",
    "href": "lectures/motd/slides.html#section-14",
    "title": "Message of the day (MOTD) - 2024",
    "section": "2024-11-27",
    "text": "2024-11-27"
  },
  {
    "objectID": "lectures/06/slides.html#message-of-the-day-continued",
    "href": "lectures/06/slides.html#message-of-the-day-continued",
    "title": "Cross-entropy, geometric interpretation, and implementation",
    "section": "Message of the Day (continued)",
    "text": "Message of the Day (continued)\n\n\n\nHow AI is changing the job market, What in the World podcast, BBC World Service, 2025-09-16."
  },
  {
    "objectID": "lectures/07/slides.html#quote-of-day",
    "href": "lectures/07/slides.html#quote-of-day",
    "title": "Model evaluation",
    "section": "Quote of Day",
    "text": "Quote of Day\n\n\n\n\n\n\n\n\n\n\n2024 Waymo Safety Impact Report was published on 2024-09-05. Waymo is a subsidiary of Alphabet inc., Google’s parent company. It operates robotaxi services in 4 US cities."
  },
  {
    "objectID": "lectures/07/slides.html#model-fitting-1",
    "href": "lectures/07/slides.html#model-fitting-1",
    "title": "Model evaluation",
    "section": "Model fitting",
    "text": "Model fitting\n\n\n\n\n\n\n\n\n\n\n\n\nDuring our class discussions, we have touched upon the concepts of underfitting and overfitting. To delve deeper into these topics, let’s examine them in the context of polynomial regression.\n\n\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\n\nThis example was meant to illustrate that, in practice, we often have limited knowledge about the underlying model that generated the data."
  },
  {
    "objectID": "lectures/07/slides.html#generating-a-nonlinear-dataset",
    "href": "lectures/07/slides.html#generating-a-nonlinear-dataset",
    "title": "Model evaluation",
    "section": "Generating a nonlinear dataset",
    "text": "Generating a nonlinear dataset\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nnp.random.seed(42)\n\nX = 6 * np.random.rand(100, 1) - 3\ny = 0.5 * X ** 2 - X + 2 + np.random.randn(100, 1)\n\n\n\nIn machine learning experiments, specifying the seed of the random number generator is crucial for ensuring reproducibility. By setting a fixed seed, programmers can guarantee that the same sequence of random numbers will be generated each time the experiment is run. This consistency is vital for several reasons:\n\nReproducibility: It allows other programmers to replicate the experiment with the exact same conditions, facilitating verification and validation of results.\nComparative Analysis: It enables consistent comparison between different models or algorithms under the same initial conditions, ensuring that observed differences are due to the models themselves rather than variations in the random initialization.\nDebugging: It aids in debugging by providing a stable environment where issues can be consistently reproduced and investigated.\n\n\n\nAttribution: Géron (2022), 4"
  },
  {
    "objectID": "lectures/07/slides.html#linear-regression",
    "href": "lectures/07/slides.html#linear-regression",
    "title": "Model evaluation",
    "section": "Linear regression",
    "text": "Linear regression\n\n\n\n\n\n\n\n\n\n\nA linear model inadequately represents this dataset"
  },
  {
    "objectID": "lectures/07/slides.html#polynomialfeatures",
    "href": "lectures/07/slides.html#polynomialfeatures",
    "title": "Model evaluation",
    "section": "PolynomialFeatures",
    "text": "PolynomialFeatures\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_features = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly_features.fit_transform(X)\n\n\n\nX[0]\n\narray([-0.75275929])\n\n\n\n\n\nX_poly[0]\n\narray([-0.75275929,  0.56664654])\n\n\n\n\n\n\n\n sklearn.preprocessing.PolynomialFeatures\n\n\nGenerate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form \\([a, b]\\), the degree-2 polynomial features are \\([1, a, b, a^2, ab, b^2]\\)."
  },
  {
    "objectID": "lectures/07/slides.html#polynomialfeatures-1",
    "href": "lectures/07/slides.html#polynomialfeatures-1",
    "title": "Model evaluation",
    "section": "PolynomialFeatures",
    "text": "PolynomialFeatures\nGiven two features \\(a\\) and \\(b\\), PolynomialFeatures with degree=3 would add \\(a^2\\), \\(a^3\\), \\(b^2\\), \\(b^3\\), as well as, \\(ab\\), \\(a^2b\\), \\(ab^2\\)!\n\n\n\n\n\n\n\nWarning\n\n\nPolynomialFeatures(degree=d) adds \\(\\frac{(D+d)!}{d!D!}\\) features, where \\(D\\) is the original number of features.\n\n\n\n\nAdditionally, you have the option to engineer new features of your own."
  },
  {
    "objectID": "lectures/07/slides.html#polynomial-regression",
    "href": "lectures/07/slides.html#polynomial-regression",
    "title": "Model evaluation",
    "section": "Polynomial regression",
    "text": "Polynomial regression\n\n\n\n\n\n\n\n\n\nLinearRegression on PolynomialFeatures\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_poly, y)"
  },
  {
    "objectID": "lectures/07/slides.html#polynomial-regression-1",
    "href": "lectures/07/slides.html#polynomial-regression-1",
    "title": "Model evaluation",
    "section": "Polynomial regression",
    "text": "Polynomial regression\n\n\n\n\n\n\n\n\n\n\n\n\nThe data was generated according to the following equation, with the inclusion of Gaussian noise.\n\\[\n  y = 0.5 x^2 + 1.0 x + 2.0\n\\]\nPresented below is the learned model.\n\\[\n  \\hat{y} = 0.56 x^2 + (-1.06) x + 1.78\n\\]\n\n\nlin_reg.coef_, lin_reg.intercept_\n\n(array([[-1.06633107,  0.56456263]]), array([1.78134581]))\n\n\n\nGiven the noise present in our dataset, akin to what we would expect with real-world data, this model demonstrates a good fit."
  },
  {
    "objectID": "lectures/07/slides.html#overfitting-and-underfitting",
    "href": "lectures/07/slides.html#overfitting-and-underfitting",
    "title": "Model evaluation",
    "section": "Overfitting and underfitting",
    "text": "Overfitting and underfitting\n\n\n\n\n\n\n\n\n\nA low loss value on the training set does not necessarily indicate a “better” model.\n\n\nIn this example, the linear regression model is underfitting the training data, as indicated by its high mean squared error (loss) on the training set (red line). This suggests that the model makes numerous errors even on the training data.\nConversely, the polynomial model with degree=300 is overfitting the training data. It exhibits a low mean squared error (loss) on the training set (green line), implying that it makes few errors on the training data.\nHowever, the degree=300 polynomial model is likely to perform poorly on future predictions. The green curve extends beyond the boundaries of the image on the y-axis. For instance, for input values in the range of 2 to 3, the model predicts values exceeding 10 (as well as negative values), whereas the expected values should lie within the range of 2 to 4.\nThis illustrative example may seem simplistic since the data is generated from a quadratic equation and involves only a single attribute, making visualization straightforward. However, it serves to highlight a key point relevant to more complex models, such as deep neural networks. As the number of parameters increases, the model’s capacity to fit the training data also increases, which can lead to overfitting if not properly managed.\n\n\nAttribution: 04_training_linear_models.ipynb"
  },
  {
    "objectID": "lectures/07/slides.html#under--and-over--fitting",
    "href": "lectures/07/slides.html#under--and-over--fitting",
    "title": "Model evaluation",
    "section": "Under- and over- fitting",
    "text": "Under- and over- fitting\n\nUnderfitting:\n\nYour model is too simple (here, linear).\nUninformative features.\nPoor performance on both training and test data.\n\nOverfitting:\n\nYour model is too complex (tall decision tree, deep and wide neural networks, etc.).\nToo many features given the number of examples available.\nExcellent performance on the training set, but poor performance on the test set.\n\n\n\nIn the case of underfitting, adding more data to the training set will not help.\nIn the case of overfitting, adding more data would bring the train and test set learning curves closer."
  },
  {
    "objectID": "lectures/07/slides.html#learning-curves",
    "href": "lectures/07/slides.html#learning-curves",
    "title": "Model evaluation",
    "section": "Learning curves",
    "text": "Learning curves\n\nOne way to assess our models is to visualize the learning curves:\n\nA learning curve shows the performance of our model, here using RMSE, on both the training set and the test set.\nMultiple measurements are obtained by repeatedly training the model on larger and larger subsets of the data.\n\n\n\n\nSee: sklearn.model_selection.learning_curve."
  },
  {
    "objectID": "lectures/07/slides.html#learning-curve-underfitting",
    "href": "lectures/07/slides.html#learning-curve-underfitting",
    "title": "Model evaluation",
    "section": "Learning curve – underfitting",
    "text": "Learning curve – underfitting\n\n\n\n\n\n\n\n\n\nPoor performance on both training and test data.\n\n\nThis graph illustrates the learning curve for a linear regression model applied to data generated from a quadratic equation, which serves as our ongoing example.\nThe horizontal axis represents the size of the training set. Initially, the linear regression model is trained on a very small dataset, consisting of just one or a few examples, and the Root Mean Square Error (RMSE) is plotted for both the training and test sets. The size of the training set is then incrementally increased, a new model is trained, and the performance is recorded. This procedure continues until the entire dataset is utilized.\nKey observations from the graph include:\n\nWith only one or two examples, the model perfectly fits the training set, resulting in low RMSE for the training data.\nAs the size of the training set increases, the model struggles to fit the training data due to the quadratic nature of the data generation process. Consequently, the RMSE for the training set rises and stabilizes at a higher level.\nFor small training sets, the model performs poorly on the test set due to inadequate generalization, resulting in high RMSE.\nAs the training set size grows, the test set performance improves, indicated by decreasing RMSE, until it reaches a point where further increases in training set size do not yield significant improvements.\n\nThese learning curves are indicative of a model that is underfitting. Both the training and test set RMSE curves plateau at relatively high values and remain close to each other, as noted by Géron (2022).\n\n\nSource code: 04_training_linear_models.ipynb."
  },
  {
    "objectID": "lectures/07/slides.html#learning-curve-overfitting",
    "href": "lectures/07/slides.html#learning-curve-overfitting",
    "title": "Model evaluation",
    "section": "Learning curve – overfitting",
    "text": "Learning curve – overfitting\n\n\n\n\n\n\n\n\n\nExcellent performance on the training set, but poor performance on the test set.\n\n\n\nFor a training set of up to 14 data points, the polynomial fits the training data perfectly, resulting in an RMSE of zero.\nThe error on the training data in this instance is significantly lower.\nA notable gap between the two curves indicates that the model performs substantially better on the training data compared to the test data.\n\n\n\nPolynomial with degree=14."
  },
  {
    "objectID": "lectures/07/slides.html#overfitting---deep-nets---loss",
    "href": "lectures/07/slides.html#overfitting---deep-nets---loss",
    "title": "Model evaluation",
    "section": "Overfitting - deep nets - loss",
    "text": "Overfitting - deep nets - loss\n\n\n\n\n\n\n\n\n\n\n\nNeural networks will be covered in detail later in our course. The graph presented here illustrates the variation in the loss function as a deep learning model undergoes training.\nThis example utilizes the IMDB movie review sentiment classification dataset available in Keras. The dataset comprises 25,000 movie reviews from IMDB, each labeled with a sentiment (positive or negative).\nThe model consists of three dense layers with sizes 16, 16, and 1, respectively. It includes a total of 160,305 trainable parameters.\nThe network is trained using mini-batch stochastic gradient descent with a batch size of 512. The horizontal axis represents the number of epochs, where each epoch indicates that the model has seen the entire training set once. During each epoch, the stochastic gradient descent algorithm updates the model parameters iteratively using mini-batches of 512 examples.\nI selected this example to illustrate that a neural network with with sufficient capacity (number of parameters) can minimize training errors almost to zero, as reducing training error is the primary objective of optimization. However, the graph clearly demonstrates that beyond a certain point, the learned patterns become specific to the training set rather than general principles. Generalization, rather than mere memorization, is the ultimate goal of machine learning.\nOverfitting occurs when a model learns the details and noise in the training data to an extent that it negatively impacts the model’s performance on new data. This can result in a decision boundary that fits the training data too tightly, capturing noise and irrelevant details rather than general patterns.\n\n\nExample from Chollet (2017) Chapter 3 (chapter04_getting-started-with-neural-networks.ipynb, ipynb from 2021 edition)."
  },
  {
    "objectID": "lectures/07/slides.html#overfitting---deep-nets---accuracy",
    "href": "lectures/07/slides.html#overfitting---deep-nets---accuracy",
    "title": "Model evaluation",
    "section": "Overfitting - deep nets - accuracy",
    "text": "Overfitting - deep nets - accuracy\n\n\n\n\n\n\n\n\n\n\nThis graph similarly illustrates the variation in accuracy for both the training and test sets as the model undergoes training."
  },
  {
    "objectID": "lectures/07/slides.html#biasvariance-tradeoff",
    "href": "lectures/07/slides.html#biasvariance-tradeoff",
    "title": "Model evaluation",
    "section": "Bias/Variance Tradeoff",
    "text": "Bias/Variance Tradeoff\n\nBias:\n\nError from overly simplistic models\nHigh bias can lead to underfitting\n\nVariance:\n\nError from overly complex models\nSensitivity to fluctuations in the training data\nHigh variance can lead to overfitting\n\nTradeoff:\n\nAim for a model that generalizes well to new data\nMethods: cross-validation, regularization, ensemble learning\n\n\n\n\nHastie, Tibshirani, and Friedman (2009)"
  },
  {
    "objectID": "lectures/07/slides.html#related-videos",
    "href": "lectures/07/slides.html#related-videos",
    "title": "Model evaluation",
    "section": "Related videos",
    "text": "Related videos\n\nOther videos include:\n\nBias and Variance, StatQuest (great visual summary)\nBias/Variance (C2W1L02), Stanford, Andrew Ng\nIntuition behind bias and variance, Sebastian Raschka"
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix",
    "href": "lectures/07/slides.html#confusion-matrix",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\n\n\n\n\n\n\n\n\n\nPositive (Predicted)\nNegative (Predicted)\n\n\n\n\nPositive (Actual)\nTrue positive (TP)\nFalse negative (FN)\n\n\nNegative (Actual)\nFalse positive (FP)\nTrue negative (TN)\n\n\n\n\n\n\nIn statistical analysis, False Positives (FP) are commonly referred to as Type I errors, and False Negatives (FN) are known as Type II errors.\nThe diagonal elements represent the correctly predicted outcomes, namely true positives (TP) and true negatives (TN).\nIn contrast, the off-diagonal elements correspond to incorrect predictions, specifically false positives (FP) and false negatives (FN).\nThe confusion matrix encapsulates all essential information required to assess the performance of a classification model.\nWhile the confusion matrix provides a comprehensive view, more concise metrics such as accuracy, precision, recall, and the F\\(_1\\) score are often more intuitive and practical for summarizing model performance.\n\n\n\nA confusion matrix is a table summarizing the performance of a classification algorithm (here for a binary classification task)."
  },
  {
    "objectID": "lectures/07/slides.html#sklearn.metrics.confusion_matrix",
    "href": "lectures/07/slides.html#sklearn.metrics.confusion_matrix",
    "title": "Performance Evaluation",
    "section": "sklearn.metrics.confusion_matrix",
    "text": "sklearn.metrics.confusion_matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nconfusion_matrix(y_actual,y_pred)\n\narray([[1, 2],\n       [3, 4]])\n\n\n\n\ntn, fp, fn, tp = confusion_matrix(y_actual, y_pred).ravel().tolist()\n(tn, fp, fn, tp)\n\n(1, 2, 3, 4)\n\n\n\nBy default, sklearn.metrics.confusion_matrix determines the set of labels from the data (\\(\\textrm{y_true} \\cup \\textrm{y_pred}\\)), and then:\n\nIt sorts them in ascending order (which for strings or mixed types corresponds to Python’s lexicographic ordering).\nIt then builds the matrix so that row i corresponds to the true class with label labels[i], and column j corresponds to the predicted class with label labels[j].\n\nSo if you don’t pass labels=..., you may get a confusion matrix with class order that is not what you expect — especially if your classes are strings, or if you assume the order follows the order of appearance in the dataset.\nExample\nfrom sklearn.metrics import confusion_matrix\n\ny_true = [\"dog\", \"cat\", \"cat\", \"dog\"]\ny_pred = [\"dog\", \"dog\", \"cat\", \"cat\"]\n\nprint(confusion_matrix(y_true, y_pred))\nOutput:\n[[1 1]\n [1 1]]\nHere the rows/columns are in lexicographic order: [\"cat\", \"dog\"]. So the matrix is:\n\nRow 0: true = “cat”\nRow 1: true = “dog”\n\nControlling order\nTo force a specific order, you should pass the labels argument:\nconfusion_matrix(y_true, y_pred, labels=[\"dog\", \"cat\"])\nThis will swap the row/column order accordingly."
  },
  {
    "objectID": "lectures/07/slides.html#perfect-prediction",
    "href": "lectures/07/slides.html#perfect-prediction",
    "title": "Performance Evaluation",
    "section": "Perfect Prediction",
    "text": "Perfect Prediction\n\ny_actual = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\ny_pred   = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n\nconfusion_matrix(y_actual,y_pred)\n\narray([[4, 0],\n       [0, 6]])\n\n\n\n\ntn, fp, fn, tp = confusion_matrix(y_actual, y_pred).ravel().tolist()  \n(tn, fp, fn, tp)\n\n(4, 0, 0, 6)\n\n\n\nWhen an algorithm achieves perfect classification accuracy, all non-zero values in the confusion matrix appear exclusively along its diagonal.\nAll off-diagonal entries, which represent misclassifications, will be zero."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---multiple-classes",
    "href": "lectures/07/slides.html#confusion-matrix---multiple-classes",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - Multiple Classes",
    "text": "Confusion Matrix - Multiple Classes\n\n\nCode\nfrom sklearn.datasets import load_digits\n\nimport numpy as np\nnp.random.seed(42)\n\ndigits = load_digits()\n\nX = digits.data\ny = digits.target\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\nclf = OneVsRestClassifier(LogisticRegression())\n\nclf = clf.fit(X_train, y_train)\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nX_test = scaler.transform(X_test)\ny_pred = clf.predict(X_test)\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe image displays a heatmap of the confusion matrix for the digit classification task. This task, a multiclass classification problem, was addressed using OneVsRestClassifier and LogisticRegression.\nThe confusion matrix summarizes the predictions made on the test set, which is a subset of the data that was neither used for training nor for preprocessing with StandardScaler.\nThe confusion matrix encapsulates all the results from applying the classifier to the test set. However, to summarize this information more succinctly, we often refer to performance metrics.\n\n\nConfusion matrix for the digits example presented in the previous lecture."
  },
  {
    "objectID": "lectures/07/slides.html#source-code",
    "href": "lectures/07/slides.html#source-code",
    "title": "Model evaluation",
    "section": "Source code",
    "text": "Source code\n\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\n\nX = digits.data\ny = digits.target\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\nclf = OneVsRestClassifier(LogisticRegression())\n\nclf = clf.fit(X_train, y_train)\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nX_test = scaler.transform(X_test)\ny_pred = clf.predict(X_test)\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n\nplt.show()"
  },
  {
    "objectID": "lectures/07/slides.html#visualizing-errors",
    "href": "lectures/07/slides.html#visualizing-errors",
    "title": "Performance Evaluation",
    "section": "Visualizing errors",
    "text": "Visualizing errors\n\nmask = (y_test == 9) & (y_pred == 8)\n\nX_9_as_8 = X_test[mask]\n\ny_9_as_8 = y_test[mask]\n\n\n\nCode\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\n\nX = digits.data\ny = digits.target\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\nclf = OneVsRestClassifier(LogisticRegression())\n\nclf = clf.fit(X_train, y_train)\n\nX_test = scaler.transform(X_test)\ny_pred = clf.predict(X_test)\n\nmask = (y_test == 9) & (y_pred == 8)\n\nX_9_as_8 = X_test[mask]\n\ny_9_as_8 = y_test[mask]\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(4,2))\n\nfor index, (image, label) in enumerate(zip(X_9_as_8, y_9_as_8)):\n    plt.subplot(1, len(X_9_as_8), index + 1)\n    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n    plt.title(f'y = {label}')\n\n\n\n\n\n\n\n\n\n\n\nIn the confusion matrix on the previous screen, we had seen that there were examples for which the true label was 9, but the prediction was was 8. We can visualize the examples to see if we understand the nature of those errors."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---multiple-classes-1",
    "href": "lectures/07/slides.html#confusion-matrix---multiple-classes-1",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - Multiple Classes",
    "text": "Confusion Matrix - Multiple Classes\n\n\n\n\n\n\n\n\n\n\n\nIt is often preferable to summarize the classifier’s performance with a single metric."
  },
  {
    "objectID": "lectures/07/slides.html#accuracy",
    "href": "lectures/07/slides.html#accuracy",
    "title": "Performance Evaluation",
    "section": "Accuracy",
    "text": "Accuracy\nHow accurate is this result?\n\\[\n  \\mathrm{accuracy} = \\frac{\\mathrm{TP}+\\mathrm{TN}}{\\mathrm{TP}+\\mathrm{TN}+\\mathrm{FP}+\\mathrm{FN}} = \\frac{\\mathrm{TP}+\\mathrm{TN}}{\\mathrm{N}}\n\\]\n\nfrom sklearn.metrics import accuracy_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\naccuracy_score(y_actual,y_pred)\n\n0.5\n\n\n\n\nAccuracy is the ratio of correctly predicted instances to the total number of predictions."
  },
  {
    "objectID": "lectures/07/slides.html#accuracy-1",
    "href": "lectures/07/slides.html#accuracy-1",
    "title": "Performance Evaluation",
    "section": "Accuracy",
    "text": "Accuracy\n\ny_actual = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\ny_pred   = [1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n\naccuracy_score(y_actual,y_pred)\n\n0.0\n\n\n\ny_actual = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\ny_pred   = [0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n\naccuracy_score(y_actual,y_pred)\n\n1.0\n\n\n\n\nAccuracy is a number between 0 (all wrong) and 1 (perfect)."
  },
  {
    "objectID": "lectures/07/slides.html#accuracy-can-be-misleading",
    "href": "lectures/07/slides.html#accuracy-can-be-misleading",
    "title": "Performance Evaluation",
    "section": "Accuracy can be misleading",
    "text": "Accuracy can be misleading\n\ny_actual = [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\ny_pred   = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\naccuracy_score(y_actual,y_pred)\n\n0.8\n\n\n\n\nAccuracy can be misleading in the context of class imbalance, as it disproportionately reflects the performance on the majority class, thereby masking poor performance on the minority class.\nAs class imbalance increases, the accuracy metric becomes increasingly misleading.\n\n\nWhy is it problematic?"
  },
  {
    "objectID": "lectures/07/slides.html#precision",
    "href": "lectures/07/slides.html#precision",
    "title": "Performance Evaluation",
    "section": "Precision",
    "text": "Precision\nAKA, positive predictive value (PPV).\n\\[\n  \\mathrm{precision} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}\n\\]\n\nfrom sklearn.metrics import precision_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nprecision_score(y_actual, y_pred)\n\n0.6666666666666666\n\n\n\n\nCan you think of a problem or situation where precision is paramount?\nA classic example: medical screening for a rare but serious disease.\n\nSuppose you have a test for a disease with very low prevalence (say 1 in 10,000).\nIf your model predicts “positive” too loosely, you will generate many false positives.\nHere, precision (the proportion of predicted positives that are actually true positives) is crucial:\n\n\\[\n\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n\\]\n\nA high precision means that when the test says “positive,” it is very likely correct.\nThis reduces unnecessary anxiety, costs, and follow-up procedures for patients incorrectly flagged.\n\nOther real-world settings where precision is key:\n\nSpam detection: High precision ensures that emails classified as spam are really spam (minimizing false positives that would hide real emails).\nLegal document search / e-discovery: High precision ensures that returned documents are relevant, reducing time wasted on irrelevant results.\nRecommender systems: High precision means that recommended items are very likely to be of interest, improving user trust.\n\n\n\nPrecision is the proportion of true positive predictions among all positive predictions."
  },
  {
    "objectID": "lectures/07/slides.html#precision-alone-is-not-enough",
    "href": "lectures/07/slides.html#precision-alone-is-not-enough",
    "title": "Performance Evaluation",
    "section": "Precision alone is not enough",
    "text": "Precision alone is not enough\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n\nprecision_score(y_actual,y_pred)\n\n1.0\n\n\n\n\nAn algorithm that makes a small number of high-confidence predictions might achieve a high precision score, but this may not necessarily be useful."
  },
  {
    "objectID": "lectures/07/slides.html#recall",
    "href": "lectures/07/slides.html#recall",
    "title": "Performance Evaluation",
    "section": "Recall",
    "text": "Recall\nAKA sensitivity or true positive rate (TPR) \\[\n  \\mathrm{recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\n\\]\n\nfrom sklearn.metrics import recall_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nrecall_score(y_actual,y_pred)\n\n0.5714285714285714\n\n\n\n\nCan you think of a problem or situation where recall is paramount?\nAn example where recall is the critical measure: cancer diagnosis (screening for malignant tumors).\n\nHere, false negatives (missing an actual cancer case) are far more dangerous than false positives.\nRecall measures the proportion of actual positives correctly identified:\n\n\\[\n\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n\\]\n\nA high recall means the test finds nearly all patients with cancer, even if it also produces some false alarms.\nMissing a true case (low recall) could mean a patient doesn’t receive treatment in time — a much more serious error than investigating a few extra false positives.\n\nOther real-world settings where recall matters most:\n\nSecurity / Intrusion detection: Better to flag all suspicious activity (even with false positives) than miss a real attack.\nSearch engines: For certain queries (e.g., legal precedent search, medical literature search), recall ensures you retrieve all relevant documents.\nEmergency response systems: For natural disaster warnings, high recall ensures no real threat goes unnoticed.\n\n\n\nRecall is the proportion of true positive instances correctly identified among all actual positive instances."
  },
  {
    "objectID": "lectures/07/slides.html#f_1-score",
    "href": "lectures/07/slides.html#f_1-score",
    "title": "Performance Evaluation",
    "section": "F\\(_1\\) score",
    "text": "F\\(_1\\) score\n\\[\n\\begin{align*}\n  F_1~\\mathrm{score} &= \\frac{2}{\\frac{1}{\\mathrm{precision}}+\\frac{1}{\\mathrm{recall}}} = 2 \\times \\frac{\\mathrm{precision}\\times\\mathrm{recall}}{\\mathrm{precision}+\\mathrm{recall}} \\\\\n                     &= \\frac{\\mathrm{TP}}{\\mathrm{FP}+\\frac{\\mathrm{FN}+\\mathrm{FP}}{2}}\n\\end{align*}\n\\]\n\nfrom sklearn.metrics import f1_score\n\ny_actual = [0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\ny_pred   = [0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n\nf1_score(y_actual,y_pred)\n\n0.6153846153846154\n\n\n\n\n\nThe harmonic mean places greater emphasis on lower values, while the arithmetic mean treats all values equally.\nUsing the harmonic mean ensures that a high score is only achieved when both precision and recall are high, thus providing a more holistic measure of a classifier’s performance in scenarios with imbalanced datasets.\nThe F\\(_1\\) score favors classifiers that achieve a balance between precision and recall.\nIncreasing recall often results in a decrease in precision, and vice versa. This phenomenon is known as the precision/recall trade-off.\n\n\n\nF\\(_1\\) is the harmonic mean of precision and recall."
  },
  {
    "objectID": "lectures/07/slides.html#micro-performance-metrics",
    "href": "lectures/07/slides.html#micro-performance-metrics",
    "title": "Performance Evaluation",
    "section": "Micro Performance Metrics",
    "text": "Micro Performance Metrics\n\nMicro performance metrics aggregate the contributions of all instances to compute average performance metrics like precision, recall, or F1 score.\nThis approach treats each individual prediction equally, regardless of its class, as it considers the total number of true positives, false positives, and false negatives across all classes.\nConsequently, micro metrics are particularly sensitive to the performance on frequent classes because they are more numerous and thus have a greater influence on the overall metric."
  },
  {
    "objectID": "lectures/07/slides.html#macro-performance-metrics",
    "href": "lectures/07/slides.html#macro-performance-metrics",
    "title": "Performance Evaluation",
    "section": "Macro Performance Metrics",
    "text": "Macro Performance Metrics\n\nMacro performance metrics compute the performance metric independently for each class and then average these metrics.\nThis approach treats each class equally, regardless of its frequency, providing an evaluation that equally considers performance across both frequent and infrequent classes.\nConsequently, macro metrics are less sensitive to the performance on frequent classes."
  },
  {
    "objectID": "lectures/07/slides.html#micromacro-metrics",
    "href": "lectures/07/slides.html#micromacro-metrics",
    "title": "Performance Evaluation",
    "section": "Micro/Macro Metrics",
    "text": "Micro/Macro Metrics\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\n# Sample data\ny_true = ['Cat'] * 42 + ['Dog'] *  7 + ['Fox'] * 11\ny_pred = ['Cat'] * 39 + ['Dog'] *  1 + ['Fox'] *  2 + \\\n         ['Cat'] *  4 + ['Dog'] *  3 + ['Fox'] *  0 + \\\n         ['Cat'] *  5 + ['Dog'] *  1 + ['Fox'] *  5\n\nConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n\n\n\n\n\n\n\n\n\nThe dataset can be conceptualized as resulting from an image classification task, involving images of cats, dogs, and foxes. Reflecting common trends observed on the internet, images of cats are disproportionately represented, leading to a class imbalance issue."
  },
  {
    "objectID": "lectures/07/slides.html#micromacro-precision",
    "href": "lectures/07/slides.html#micromacro-precision",
    "title": "Performance Evaluation",
    "section": "Micro/Macro Precision",
    "text": "Micro/Macro Precision\n\nfrom sklearn.metrics import classification_report, precision_score\n\nprint(classification_report(y_true, y_pred), \"\\n\")\n\nprint(\"Micro precision: {:.2f}\".format(precision_score(y_true, y_pred, average='micro')))\nprint(\"Macro precision: {:.2f}\".format(precision_score(y_true, y_pred, average='macro')))\n\n              precision    recall  f1-score   support\n\n         Cat       0.81      0.93      0.87        42\n         Dog       0.60      0.43      0.50         7\n         Fox       0.71      0.45      0.56        11\n\n    accuracy                           0.78        60\n   macro avg       0.71      0.60      0.64        60\nweighted avg       0.77      0.78      0.77        60\n \n\nMicro precision: 0.78\nMacro precision: 0.71"
  },
  {
    "objectID": "lectures/07/slides.html#micromacro-recall",
    "href": "lectures/07/slides.html#micromacro-recall",
    "title": "Performance Evaluation",
    "section": "Micro/Macro Recall",
    "text": "Micro/Macro Recall\n\n\n\n\n\n\n\n\n\n\n\n              precision    recall  f1-score   support\n\n         Cat       0.81      0.93      0.87        42\n         Dog       0.60      0.43      0.50         7\n         Fox       0.71      0.45      0.56        11\n\n    accuracy                           0.78        60\n   macro avg       0.71      0.60      0.64        60\nweighted avg       0.77      0.78      0.77        60\n \n\nMicro recall: 0.78\nMacro recall: 0.60"
  },
  {
    "objectID": "lectures/07/slides.html#micromacro-metrics-medical-data",
    "href": "lectures/07/slides.html#micromacro-metrics-medical-data",
    "title": "Performance Evaluation",
    "section": "Micro/Macro Metrics (Medical Data)",
    "text": "Micro/Macro Metrics (Medical Data)\n\n\n\n\n\n\n\n\n\n\nConsider a medical dataset, such as those involving diagnostic tests or imaging, comprising 990 normal samples and 10 abnormal (tumor) samples. This represents the ground truth."
  },
  {
    "objectID": "lectures/07/slides.html#micromacro-metrics-medical-data-1",
    "href": "lectures/07/slides.html#micromacro-metrics-medical-data-1",
    "title": "Performance Evaluation",
    "section": "Micro/macro metrics (medical data)",
    "text": "Micro/macro metrics (medical data)\n\n\n              precision    recall  f1-score   support\n\n      Normal       1.00      0.99      1.00       990\n      Tumour       0.55      0.60      0.57        10\n\n    accuracy                           0.99      1000\n   macro avg       0.77      0.80      0.78      1000\nweighted avg       0.99      0.99      0.99      1000\n \n\nMicro precision: 0.99\nMacro precision: 0.77\n\n\nMicro recall: 0.99\nMacro recall: 0.80\n\n\n\n\nThe precision for the Tumour class is low. However, due to the small sample size, this does not significantly impact the micro-averaged precision."
  },
  {
    "objectID": "lectures/07/slides.html#hand-written-digits-revisited",
    "href": "lectures/07/slides.html#hand-written-digits-revisited",
    "title": "Performance Evaluation",
    "section": "Hand-Written Digits (Revisited)",
    "text": "Hand-Written Digits (Revisited)\nLoading the dataset\n\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import fetch_openml\n\ndigits = fetch_openml('mnist_784', as_frame=False)\nX, y = digits.data, digits.target\n\nPlotting the first five examples\n\n\n\n\n\n\n\n\n\nThese images have dimensions of \\(28 \\times 28\\) pixels."
  },
  {
    "objectID": "lectures/07/slides.html#creating-a-binary-classification-task",
    "href": "lectures/07/slides.html#creating-a-binary-classification-task",
    "title": "Performance Evaluation",
    "section": "Creating a Binary Classification Task",
    "text": "Creating a Binary Classification Task\n\n# Creating a binary classification task (one vs the rest)\n\nsome_digit = X[0]\nsome_digit_y = y[0]\n\ny = (y == some_digit_y)\ny\n\narray([ True, False, False, ..., False,  True, False], shape=(70000,))\n\n\n\n\n# Creating the training and test sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
  },
  {
    "objectID": "lectures/07/slides.html#sgdclassifier",
    "href": "lectures/07/slides.html#sgdclassifier",
    "title": "Performance Evaluation",
    "section": "SGDClassifier",
    "text": "SGDClassifier\n\nfrom sklearn.linear_model import SGDClassifier\n\nclf = SGDClassifier()\nclf.fit(X_train, y_train)\n\nclf.predict(X[0:5]) # small sanity check\n\narray([ True, False, False, False, False])\n\n\n\n\nThe SGDClassifier is a linear classifier that utilizes stochastic gradient descent (SGD) for training. Compared to LogisticRegression, it can offer faster training times, particularly for large datasets. Additionally, SGDClassifier allows for the adjustment of the decision threshold in subsequent examples."
  },
  {
    "objectID": "lectures/07/slides.html#performance",
    "href": "lectures/07/slides.html#performance",
    "title": "Performance Evaluation",
    "section": "Performance",
    "text": "Performance\n\nfrom sklearn.metrics import accuracy_score\n\ny_pred = clf.predict(X_test)\n\naccuracy_score(y_test, y_pred)\n\n0.9572857142857143\n\n\nWow!"
  },
  {
    "objectID": "lectures/07/slides.html#not-so-fast",
    "href": "lectures/07/slides.html#not-so-fast",
    "title": "Performance Evaluation",
    "section": "Not so Fast",
    "text": "Not so Fast\n\nfrom sklearn.dummy import DummyClassifier\n\ndummy_clf = DummyClassifier()\n\ndummy_clf.fit(X_train, y_train)\n\n\n\ny_pred = dummy_clf.predict(X_test)\n\naccuracy_score(y_test, y_pred)\n\n0.906\n\n\n\n\nWhy is the accuracy so high despite this classifier ignoring the input data?\nThe high accuracy is attributed to the class distribution within the dataset. Approximately 10% of the samples correspond to the digit ‘5’, which is the positive class in our binary classification task. Consequently, about 90% of the samples are ‘not 5’ and belong to the negative class. Since the DummyClassifier always predicts the majority class, its accuracy is expected to be around 90%.\nThis underscores the point that accuracy is often not the best metric, particularly when dealing with imbalanced datasets.\n\n\n\nThe DummyClassifier in scikit-learn generates predictions without considering the input features. By default, it consistently predicts the most frequent class label in the training data. It is a simple baseline classifier."
  },
  {
    "objectID": "lectures/07/slides.html#precision-recall-trade-off",
    "href": "lectures/07/slides.html#precision-recall-trade-off",
    "title": "Model evaluation",
    "section": "Precision-recall trade-off",
    "text": "Precision-recall trade-off\n\n\n\nAttribution: Géron (2022) Figure 3.4"
  },
  {
    "objectID": "lectures/07/slides.html#precision-recall-trade-off-1",
    "href": "lectures/07/slides.html#precision-recall-trade-off-1",
    "title": "Performance Evaluation",
    "section": "Precision-Recall Trade-Off",
    "text": "Precision-Recall Trade-Off\n\n\n\nAttribution: Géron (2022) Figure 3.4"
  },
  {
    "objectID": "lectures/07/slides.html#precisionrecall-curve",
    "href": "lectures/07/slides.html#precisionrecall-curve",
    "title": "Performance Evaluation",
    "section": "Precision/Recall Curve",
    "text": "Precision/Recall Curve\n\n\nCode\nimport matplotlib.patches as patches  # extra code – for the curved arrow\n\nplt.figure(figsize=(5, 5))  # extra code – not needed, just formatting\n\nplt.plot(recalls, precisions, linewidth=2, label=\"Precision/Recall Curve\")\n\n# extra code – just beautifies and saves Figure 3–6\nplt.plot([recalls[idx], recalls[idx]], [0., precisions[idx]], \"k:\")\nplt.plot([0.0, recalls[idx]], [precisions[idx], precisions[idx]], \"k:\")\nplt.plot([recalls[idx]], [precisions[idx]], \"ko\",\n         label=\"Point at threshold 3,000\")\nplt.gca().add_patch(patches.FancyArrowPatch(\n    (0.79, 0.60), (0.61, 0.78),\n    connectionstyle=\"arc3,rad=.2\",\n    arrowstyle=\"Simple, tail_width=1.5, head_width=8, head_length=10\",\n    color=\"#444444\"))\nplt.text(0.56, 0.62, \"Higher\\nthreshold\", color=\"#333333\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.axis([0, 1, 0, 1])\nplt.grid()\nplt.legend(loc=\"lower left\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n(Géron 2022) 03_classification.ipynb."
  },
  {
    "objectID": "lectures/07/slides.html#roc-curve",
    "href": "lectures/07/slides.html#roc-curve",
    "title": "Model evaluation",
    "section": "ROC curve",
    "text": "ROC curve\nReceiver Operating Characteristics (ROC) curve\n\nTrue positive rate (TPR) against false positive rate (FPR)\nAn ideal classifier has TPR close to 1.0 and FPR close to 0.0\n\\(\\mathrm{TPR} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\\) (recall, sensitivity)\nTPR approaches one when the number of false negative predictions is low\n\\(\\mathrm{FPR} = \\frac{\\mathrm{FP}}{\\mathrm{FP}+\\mathrm{TN}}\\) (aka~[1-specificity])\nFPR approaches zero when the number of false positive is low\n\n\nROC (Receiver Operating Characteristic) curves are popular in machine learning and statistics for several reasons:\n\nComprehensive Performance Evaluation: ROC curves provide a visual representation of a classifier’s performance across all possible thresholds. By plotting the True Positive Rate (TPR) against the False Positive Rate (FPR), it allows practitioners to evaluate the trade-off between sensitivity (recall) and specificity.\nThreshold Independence: Unlike metrics like accuracy, ROC curves evaluate classifier performance without relying on a specific decision threshold. This makes them particularly useful in comparing models across varying thresholds.\nHandling Imbalanced Datasets: For datasets with class imbalances (where one class is much more frequent than the other), ROC curves are more informative than accuracy, which can be misleading. The curve captures the model’s ability to distinguish between classes irrespective of their distribution.\nArea Under the Curve (AUC): The Area Under the ROC Curve (AUC) provides a single value summary of the model’s performance. AUC-ROC is often used as a benchmark metric to compare different models, with values ranging from 0.5 (random guessing) to 1.0 (perfect classification).\nBroad Applicability: ROC curves can be used for any binary classification task and are easily extended to multiclass problems using techniques like one-vs-rest classification, making them versatile in evaluating classifiers.\n\nOverall, their ability to offer a broad, threshold-independent view of model performance, especially in imbalanced scenarios, makes ROC curves a popular choice for evaluating classifiers."
  },
  {
    "objectID": "lectures/07/slides.html#roc-curve-1",
    "href": "lectures/07/slides.html#roc-curve-1",
    "title": "Performance Evaluation",
    "section": "ROC Curve",
    "text": "ROC Curve\nReceiver Operating Characteristics (ROC) curve\n\nTrue positive rate (TPR) against false positive rate (FPR)\nAn ideal classifier has TPR close to 1.0 and FPR close to 0.0\n\\(\\mathrm{TPR} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\\) (recall, sensitivity)\nTPR approaches one when the number of false negative predictions is low\n\\(\\mathrm{FPR} = \\frac{\\mathrm{FP}}{\\mathrm{FP}+\\mathrm{TN}}\\) (aka~[1-specificity])\nFPR approaches zero when the number of false positive is low\n\n\nROC (Receiver Operating Characteristic) curves are popular in machine learning and statistics for several reasons:\n\nComprehensive Performance Evaluation: ROC curves provide a visual representation of a classifier’s performance across all possible thresholds. By plotting the True Positive Rate (TPR) against the False Positive Rate (FPR), it allows practitioners to evaluate the trade-off between sensitivity (recall) and specificity.\nThreshold Independence: Unlike metrics like accuracy, ROC curves evaluate classifier performance without relying on a specific decision threshold. This makes them particularly useful in comparing models across varying thresholds.\nArea Under the Curve (AUC): The Area Under the ROC Curve (AUC) provides a single value summary of the model’s performance. AUC-ROC is often used as a benchmark metric to compare different models, with values ranging from 0.5 (random guessing) to 1.0 (perfect classification).\nBroad Applicability: ROC curves can be used for any binary classification task and are easily extended to multiclass problems using techniques like one-vs-rest classification, making them versatile in evaluating classifiers."
  },
  {
    "objectID": "lectures/07/slides.html#aucroc",
    "href": "lectures/07/slides.html#aucroc",
    "title": "Performance Evaluation",
    "section": "AUC/ROC",
    "text": "AUC/ROC\n\n\nCode\nfrom sklearn.metrics import roc_auc_score\n\ny_pred_prob_lr = lr.predict_proba(X_test)[:, 1]\ny_pred_prob_knn = knn.predict_proba(X_test)[:, 1]\ny_pred_prob_dt = dt.predict_proba(X_test)[:, 1]\ny_pred_prob_rf = rf.predict_proba(X_test)[:, 1]\n\n# Compute ROC curves\nfpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_prob_lr)\nfpr_knn, tpr_knn, _ = roc_curve(y_test, y_pred_prob_knn)\nfpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred_prob_dt)\nfpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_prob_rf)\n\n# Compute AUC scores\nauc_lr = roc_auc_score(y_test, y_pred_prob_lr)\nauc_knn = roc_auc_score(y_test, y_pred_prob_knn)\nauc_dt = roc_auc_score(y_test, y_pred_prob_dt)\nauc_rf = roc_auc_score(y_test, y_pred_prob_rf)\n\n# Plot ROC curves\nplt.figure(figsize=(5, 5)) # plt.figure()\nplt.plot(fpr_lr, tpr_lr, color='blue', label=f'Logistic Regression (AUC = {auc_lr:.2f})')\nplt.plot(fpr_knn, tpr_knn, color='green', label=f'K-Nearest Neighbors (AUC = {auc_knn:.2f})')\nplt.plot(fpr_dt, tpr_dt, color='orange', label=f'Decision Tree (AUC = {auc_dt:.2f})')\nplt.plot(fpr_rf, tpr_rf, color='purple', label=f'Random Forest (AUC = {auc_rf:.2f})')\nplt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line for random chance\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curves for Logistic Regression, KNN, Decision Tree, and Random Forest')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nROC curves provide a visual representation of a classifier’s performance across all possible thresholds. By plotting the True Positive Rate (TPR) against the False Positive Rate (FPR), it allows practitioners to evaluate the trade-off between sensitivity (recall) and specificity.\nUnlike metrics like accuracy, ROC curves evaluate classifier performance without relying on a specific decision threshold. This makes them particularly useful in comparing models across varying thresholds."
  },
  {
    "objectID": "lectures/07/slides.html#the-7-steps-of-machine-learning",
    "href": "lectures/07/slides.html#the-7-steps-of-machine-learning",
    "title": "Model evaluation",
    "section": "The 7 steps of machine learning",
    "text": "The 7 steps of machine learning"
  },
  {
    "objectID": "lectures/07/slides.html#prologue",
    "href": "lectures/07/slides.html#prologue",
    "title": "Model evaluation",
    "section": "Prologue",
    "text": "Prologue"
  },
  {
    "objectID": "lectures/07/slides.html#further-reading",
    "href": "lectures/07/slides.html#further-reading",
    "title": "Performance Evaluation",
    "section": "Further reading",
    "text": "Further reading\n\n\n\n\n\n\n\nThis book, which examines various aspects of the evaluation process with an emphasis on classification algorithms, has excellent ratings on Amazon!\nNathalie Japkowicz was formely a professor that the University of Ottawa. She now works at the American University in Washington.\nMohak Shah completed his PhD at the University of Ottawa. He has held several positions in the industry, including AI and Machine Learning Vice President for LG Electronics.\n\n\nJapkowicz and Shah (2011)"
  },
  {
    "objectID": "lectures/07/slides.html#message-of-the-day",
    "href": "lectures/07/slides.html#message-of-the-day",
    "title": "Performance Evaluation",
    "section": "Message of the Day",
    "text": "Message of the Day\n\n\n\n\n\n\n\n\n\n\nIn a recent interview with Bloomberg Technology, Demis Hassabis discussed the innovative work of Isomorphic Labs in significantly expediting drug development processes. Below is a summary of Hassabis’ notable achievements:\n\nA chess prodigy from a young age, Hassabis began playing at four years old and achieved an Elo rating of approximately 2300 by the age of 13.\nHe co-founded DeepMind in 2010 alongside Shane Legg and Mustafa Suleyman, where he currently serves as CEO.\nUnder his leadership, DeepMind has pioneered several groundbreaking advancements in artificial intelligence, including the development of AlphaGo and, notably, AlphaFold and AlphaFold2, which are pivotal in protein structure prediction.\nIn recognition of his contributions to protein structure prediction, Hassabis was awarded the Nobel Prize in Chemistry in 2024.\nIn 2021, he founded Isomorphic Labs, which concentrates on the application of AI in drug discovery and translational science.\n“The Thinking Game” is a documentary that explores the life of Demis Hassabis, the evolution of DeepMind, and the pursuit of artificial general intelligence (AGI).\n\nIn a related vein, an article titled “Which diseases will you have in 20 years? This AI accurately predicts your risks” was published in Nature on September 17, 2025. This brief news piece discusses Delphi-2M, a large language model designed to analyze an individual’s medical records and lifestyle factors to provide risk assessments for over 1,000 diseases. Complementing the article, a podcast is also available for further insights.\n\n\nDemis Hassabis: The CEO Working to Solve Cancer With AI, Bloomberg Technology, 2025-09-14."
  },
  {
    "objectID": "lectures/07/slides.html#learning-outcomes",
    "href": "lectures/07/slides.html#learning-outcomes",
    "title": "Performance Evaluation",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nDescribe the structure and role of the confusion matrix in model evaluation.\nCompute and interpret accuracy, precision, recall, and \\(F_1\\) score.\nIdentify the pitfalls of using accuracy with imbalanced datasets.\nDifferentiate between micro and macro averaging for performance metrics.\nAnalyze precision-recall trade-offs and construct ROC curves, including the calculation of AUC.\nImplement the calculation or ROC curves and AUC in Python."
  },
  {
    "objectID": "lectures/07/slides.html#on-performance-measures",
    "href": "lectures/07/slides.html#on-performance-measures",
    "title": "Performance Evaluation",
    "section": "On Performance Measures",
    "text": "On Performance Measures\n\nSokolova, M. & Lapalme, G. (2009). A systematic analysis of performance measures for classification tasks. Information Processing and Management, 45(4), 427–437.\n\nScopus: 4,222 citations\nGoogle Scholar: 6,839 citations"
  },
  {
    "objectID": "lectures/07/slides.html#evaluating-learning-algorithms",
    "href": "lectures/07/slides.html#evaluating-learning-algorithms",
    "title": "Performance Evaluation",
    "section": "Evaluating Learning Algorithms",
    "text": "Evaluating Learning Algorithms\n\n\n\n\n\nThis book, 4.6 stars rating on Amazon, delves into the evaluation process, particularly focusing on classification algorithms (Japkowicz and Shah 2011).\nNathalie Japkowicz previously served as a professor at the University of Ottawa and is currently affiliated with American University in Washington.\nMohak Shah, who earned his PhD from the University of Ottawa, has held numerous industry roles, including Vice President of AI and Machine Learning at LG Electronics."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix-1",
    "href": "lectures/07/slides.html#confusion-matrix-1",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\nGiven a test set with \\(N\\) examples and a classifier \\(h(x):\\)\n\\[\nC_{i,j} = \\sum_{k = 1}^N [y_k = i \\wedge h(x_k) = j]\n\\]\nWhere \\(C\\) is \\(l \\times l\\) matrix, for a dataset with \\(l\\) classes.\n\n\nLet us now examine the general case of a confusion matrix with \\(l\\) classes, which may initially appear “confusing” to comprehend.\n\n\nA confusion matrix \\(C\\) is defined such that each element \\(C_{i,j}\\) represents the count of observations actually belonging to class \\(i\\) but predicted to belong to class \\(j\\)."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix-2",
    "href": "lectures/07/slides.html#confusion-matrix-2",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\n\nThe total number of examples of the (actual) class \\(i\\) is \\[\nC_{i \\cdot} = \\sum_{j=1}^l C_{i,j}\n\\]\nThe total number of examples assigned to the (predicted) class \\(j\\) by classiﬁer \\(h\\) is \\[\nC_{\\cdot j} = \\sum_{i=1}^l C_{i,j}\n\\]"
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix-3",
    "href": "lectures/07/slides.html#confusion-matrix-3",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\n\nTerms on the diagonal denote the total number of examples classified correctly by classifier \\(h\\). Hence, the number of correctly classified examples is \\[\n\\sum_{i=1}^l C_{i,i}\n\\]\nNon-diagonal terms represent misclassifications."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---multi-class",
    "href": "lectures/07/slides.html#confusion-matrix---multi-class",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - Multi-Class",
    "text": "Confusion Matrix - Multi-Class\nTo evaluate performance in a multi-class setting, one typically derives “one-vs-all” metrics for each class from the confusion matrix. These metrics are then averaged using specific weighting schemes."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---multi-class-1",
    "href": "lectures/07/slides.html#confusion-matrix---multi-class-1",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - Multi-Class",
    "text": "Confusion Matrix - Multi-Class\n\n\n\n\n\n\n\nUsing data from the 20 newsgroups text dataset from scikit-learn.org."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---true-positive",
    "href": "lectures/07/slides.html#confusion-matrix---true-positive",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - True Positive",
    "text": "Confusion Matrix - True Positive\n\n\n\n\n\n\n\ncomp.graphics is the true class (\\(i\\))."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---false-positive",
    "href": "lectures/07/slides.html#confusion-matrix---false-positive",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - False Positive",
    "text": "Confusion Matrix - False Positive\n\n\n\n\n\n\n\ncomp.graphics is the true class (\\(i\\))."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---false-negative",
    "href": "lectures/07/slides.html#confusion-matrix---false-negative",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - False Negative",
    "text": "Confusion Matrix - False Negative\n\n\n\n\n\n\n\ncomp.graphics is the true class (\\(i\\))."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---true-negative",
    "href": "lectures/07/slides.html#confusion-matrix---true-negative",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - True Negative",
    "text": "Confusion Matrix - True Negative\n\n\n\n\n\n\n\ncomp.graphics is the true class (\\(i\\))."
  },
  {
    "objectID": "lectures/07/slides.html#confusion-matrix---multi-class-2",
    "href": "lectures/07/slides.html#confusion-matrix---multi-class-2",
    "title": "Performance Evaluation",
    "section": "Confusion Matrix - Multi-Class",
    "text": "Confusion Matrix - Multi-Class\n\n\n\n\n\n\n\ncomp.graphics is the true class (\\(i\\))."
  },
  {
    "objectID": "lectures/07/slides.html#multi-class",
    "href": "lectures/07/slides.html#multi-class",
    "title": "Performance Evaluation",
    "section": "Multi-Class",
    "text": "Multi-Class\nTo evaluate performance in a multi-class setting, one typically derives “one-vs-all” metrics for each class from the confusion matrix. These metrics are then averaged using specific weighting schemes.\n\nTrue Positives (\\(\\mathrm{TP}_i\\)): Diagonal entry \\(C_{i,i}\\)\nFalse Positives (\\(\\mathrm{FP}_i\\)): Sum of column \\(i\\) excluding \\(C_{i,i}\\)\nFalse Negatives (\\(\\mathrm{FN}_i\\)): Sum of row \\(i\\) excluding \\(C_{i,i}\\)\nTrue Negatives (\\(\\mathrm{TN}_i\\)): \\(N - (\\mathrm{TP}_i + \\mathrm{FP}_i + \\mathrm{FN}_i)\\)"
  },
  {
    "objectID": "lectures/07/slides.html#multi-class-1",
    "href": "lectures/07/slides.html#multi-class-1",
    "title": "Performance Evaluation",
    "section": "Multi-Class",
    "text": "Multi-Class\nTo evaluate performance in a multi-class setting, one typically derives “one-vs-all” metrics for each class from the confusion matrix. These metrics are then averaged using specific weighting schemes.\n\n\\(\\mathrm{TP}_i = C_{i,i}\\)\n\\(\\mathrm{FP}_i = \\sum_{k \\ne i} C_{k,i}\\)\n\\(\\mathrm{FN}_i = \\sum_{k \\ne i} C_{i,k}\\)\n\\(\\mathrm{TN}_i = \\sum_{j \\ne i} \\sum_{k \\ne i} C_{j,k}\\)"
  },
  {
    "objectID": "lectures/07/slides.html#multi-class-2",
    "href": "lectures/07/slides.html#multi-class-2",
    "title": "Performance Evaluation",
    "section": "Multi-Class",
    "text": "Multi-Class\nWhen calculating precision, recall, and \\(F_1\\), one usually compute “one-vs-all” metrics for each class. Then, average them using weighting schemes (macro, micro).\n\nTrue Positives (\\(\\mathrm{TP}_i\\)): Diagonal entry \\(C_{i,i}\\)\nFalse Positives (\\(\\mathrm{FP}_i\\)): Sum of column \\(i\\) excluding \\(C_{i,i}\\)\nFalse Negatives (\\(\\mathrm{FN}_i\\)): Sum of row \\(i\\) excluding \\(C_{i,i}\\)\nTrue Negatives (\\(\\mathrm{TN}_i\\)): \\(N - (\\mathrm{TP}_i + \\mathrm{FP}_i + \\mathrm{FN}_i)\\)"
  },
  {
    "objectID": "lectures/07/slides.html#multi-class-3",
    "href": "lectures/07/slides.html#multi-class-3",
    "title": "Performance Evaluation",
    "section": "Multi-Class",
    "text": "Multi-Class\nWhen calculating precision, recall, and \\(F_1\\), one usually compute “one-vs-all” metrics for each class. Then, average them using weighting schemes (macro, micro).\n\n\\(\\mathrm{TP}_i = C_{i,i}\\)\n\\(\\mathrm{FP}_i = \\sum_{k \\ne i} C_{k,i}\\)\n\\(\\mathrm{FN}_i = \\sum_{k \\ne i} C_{i,k}\\)\n\\(\\mathrm{TN}_i = \\sum_{j \\ne i} \\sum_{k \\ne i} C_{j,k}\\)"
  },
  {
    "objectID": "lectures/07/slides.html#micromacro-precision-1",
    "href": "lectures/07/slides.html#micromacro-precision-1",
    "title": "Performance Evaluation",
    "section": "Micro/Macro Precision",
    "text": "Micro/Macro Precision\n\nMacro-average precision is calculated as the mean of the precision scores1 for each class: \\(\\frac{0.81 + 0.60 + 0.71}{3} = 0.71\\).\nWhereas, the micro-average precision is calculated using the formala, \\(\\frac{TP}{TP+FP}\\) and the data from the entire confusion matrix \\(\\frac{39+3+5}{39+3+5+9+2+2} = \\frac{47}{60} = 0.78\\)\n\n\nThe high micro-average precision observed here is primarily due to the high precision and large number of examples in the majority class, Cat. This masks the classifier’s relatively poor performance on the minority classes, Dog and Fox.\nIn a balanced dataset, both micro-average and macro-average metrics yield similar scores.\nHowever, in an imbalanced dataset, significant disparities in classifier performance between the majority and minority classes will result in divergent micro-average and macro-average scores. Specifically, the classifier tends to underperform on the minority class(es), leading to these discrepancies.\nIn macro-average metrics, each class contributes equally to the final metric calculation, irrespective of the number of examples it contains. This means that the performance metric for each class are computed independently and then averaged, without considering the proportion of instances that each class represents in the dataset. Consequently, macro-averaging ensures that each class has an equal impact on the overall metric, which can be particularly useful in cases where the class distribution is imbalanced.\n\nTherefore, macro-average precision remains unaffected by the varying number of examples across different classes."
  },
  {
    "objectID": "lectures/07/slides.html#micromacro-recall-1",
    "href": "lectures/07/slides.html#micromacro-recall-1",
    "title": "Performance Evaluation",
    "section": "Micro/Macro Recall",
    "text": "Micro/Macro Recall\n\nMacro-average recall is calculated as the mean of the recall scores for each class: \\(\\frac{0.93 + 0.43 + 0.45}{3} = 0.60\\).\nWhereas, the micro-average recall is calculated using the formala, \\(\\frac{TP}{TP+FN}\\) and the data from the entire confusion matrix \\(\\frac{39+3+5}{39+3+5+3+4+6} = \\frac{39}{60} = 0.78\\)"
  },
  {
    "objectID": "lectures/07/slides.html#example",
    "href": "lectures/07/slides.html#example",
    "title": "Performance Evaluation",
    "section": "Example",
    "text": "Example\nUsing the 20 newsgroups text dataset from scikit-learn.org.\nComprises around 18,000 newsgroups posts on 20 topics.\n\n\nCode\n## https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html\n\nfrom time import time\n\n## Load Dataset\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ncategories = [\n    \"alt.atheism\",\n    \"talk.religion.misc\",\n    \"comp.graphics\",\n    \"sci.space\",\n]\n\ndef size_mb(docs):\n    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n\ndef load_dataset(verbose=False, remove=()):\n    \"\"\"Load and vectorize the 20 newsgroups dataset.\"\"\"\n\n    data_train = fetch_20newsgroups(\n        subset=\"train\",\n        categories=categories,\n        shuffle=True,\n        random_state=42,\n        remove=remove,\n    )\n\n    data_test = fetch_20newsgroups(\n        subset=\"test\",\n        categories=categories,\n        shuffle=True,\n        random_state=42,\n        remove=remove,\n    )\n\n    # order of labels in `target_names` can be different from `categories`\n    target_names = data_train.target_names\n\n    # split target in a training set and a test set\n    y_train, y_test = data_train.target, data_test.target\n\n    # Extracting features from the training data using a sparse vectorizer\n    t0 = time()\n    vectorizer = TfidfVectorizer(\n        sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\"\n    )\n    X_train = vectorizer.fit_transform(data_train.data)\n    duration_train = time() - t0\n\n    # Extracting features from the test data using the same vectorizer\n    t0 = time()\n    X_test = vectorizer.transform(data_test.data)\n    duration_test = time() - t0\n\n    feature_names = vectorizer.get_feature_names_out()\n\n    if verbose:\n        # compute size of loaded data\n        data_train_size_mb = size_mb(data_train.data)\n        data_test_size_mb = size_mb(data_test.data)\n\n        # print(\n        #     f\"{len(data_train.data)} documents - \"\n        #     f\"{data_train_size_mb:.2f}MB (training set)\"\n        # )\n        # print(f\"{len(data_test.data)} documents - {data_test_size_mb:.2f}MB (test set)\")\n        # print(f\"{len(target_names)} categories\")\n        # print(\n        #     f\"vectorize training done in {duration_train:.3f}s \"\n        #     f\"at {data_train_size_mb / duration_train:.3f}MB/s\"\n        # )\n        # print(f\"n_samples: {X_train.shape[0]}, n_features: {X_train.shape[1]}\")\n        # print(\n        #     f\"vectorize testing done in {duration_test:.3f}s \"\n        #     f\"at {data_test_size_mb / duration_test:.3f}MB/s\"\n        # )\n        # print(f\"n_samples: {X_test.shape[0]}, n_features: {X_test.shape[1]}\")\n\n    return X_train, X_test, y_train, y_test, feature_names, target_names\n\nX_train, X_test, y_train, y_test, feature_names, target_names = load_dataset(\n    verbose=True\n)\n\n## Training and Prediction\n\nfrom sklearn.linear_model import RidgeClassifier\n\nclf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\n## Display the Confusion Matrix\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nfig, ax = plt.subplots(figsize=(10, 5))\nConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax)\nax.xaxis.set_ticklabels(target_names)\nax.yaxis.set_ticklabels(target_names)\n_ = ax.set_title(\n    f\"Confusion Matrix for {clf.__class__.__name__}\"\n)"
  },
  {
    "objectID": "lectures/07/slides.html#example-output",
    "href": "lectures/07/slides.html#example-output",
    "title": "Performance Evaluation",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "lectures/07/slides.html#example-1",
    "href": "lectures/07/slides.html#example-1",
    "title": "Performance Evaluation",
    "section": "Example",
    "text": "Example\n\ncm = confusion_matrix(y_test, y_pred)"
  },
  {
    "objectID": "lectures/07/slides.html#tp-fp-fn-tn",
    "href": "lectures/07/slides.html#tp-fp-fn-tn",
    "title": "Performance Evaluation",
    "section": "TP, FP, FN, TN",
    "text": "TP, FP, FN, TN\n\ndef true_positive(cm, i):\n    return cm[i,i] # diagonal entry i,i\n\ndef false_positive(cm, i):\n    return np.sum(cm[:, i]) - cm[i,i] # col - TP_i\n\ndef false_negative(cm, i):\n    return np.sum(cm[i, :]) - cm[i,i] # row - TP_i\n\ndef true_negative(cm, i):\n  N = cm.sum()\n  TP = true_positive(cm, i)\n  FP = false_positive(cm, i)\n  FN = false_negative(cm, i)\n  return N - (TP + FP + FN)"
  },
  {
    "objectID": "lectures/07/slides.html#precision-1",
    "href": "lectures/07/slides.html#precision-1",
    "title": "Performance Evaluation",
    "section": "Precision",
    "text": "Precision\n\ndef precision_micro(cm):\n    _, l = cm.shape\n    tp = fp = 0\n    for i in range(l):\n        tp += true_positive(cm, i)\n        fp += false_positive(cm, i)\n    return tp / (tp+fp)\n\ndef precision_macro(cm):\n    _, l = cm.shape\n    precision = 0\n    for i in range(l):\n        tp = true_positive(cm, i)\n        fp = false_positive(cm, i)\n        precision += tp/(tp+fp)\n    return precision/l"
  },
  {
    "objectID": "lectures/07/slides.html#precision-micro-average",
    "href": "lectures/07/slides.html#precision-micro-average",
    "title": "Performance Evaluation",
    "section": "Precision Micro Average",
    "text": "Precision Micro Average\n\\[\n  \\frac{(258+380+371+199)}{(258+380+371+199)+(40+38+22+45)}\n\\] where\n\n40 = 2 + 1 + 37\n38 = 7 + 22 + 9\n22 = 12 + 4 + 6\n45 = 42 + 3 + 0\n\n\n\n89.28307465 %"
  },
  {
    "objectID": "lectures/07/slides.html#precision-macro-average",
    "href": "lectures/07/slides.html#precision-macro-average",
    "title": "Performance Evaluation",
    "section": "Precision Macro Average",
    "text": "Precision Macro Average\n\n\\(\\mathrm{Precision}_0 = \\frac{258}{258+(2+1+37)} = 0.8657718121\\)\n\\(\\mathrm{Precision}_1 = \\frac{380}{380+(7+22+9)} = 0.9090909091\\)\n\\(\\mathrm{Precision}_2 = \\frac{371}{371+(12+4+6)} = 0.9440203562\\)\n\\(\\mathrm{Precision}_3 = \\frac{199}{199+(42+3+0)} = 0.8155737705\\)\n\n\\(\\mathrm{Precision}_3 = \\frac{0.8657718121 + 0.9090909091 + 0.9440203562 + 0.8155737705}{4}\\)\n\n\n88.3614212 %"
  },
  {
    "objectID": "lectures/07/slides.html#recall-1",
    "href": "lectures/07/slides.html#recall-1",
    "title": "Performance Evaluation",
    "section": "Recall",
    "text": "Recall\n\ndef recall_micro(cm):\n    _, l = cm.shape\n    tp = fn = 0\n    for i in range(l):\n        tp += true_positive(cm, i)\n        fn += false_negative(cm, i)\n    return tp / (tp+fn)\n\ndef recall_macro(cm):\n    _, l = cm.shape\n    recall = 0\n    for i in range(l):\n        tp = true_positive(cm, i)\n        fn = false_negative(cm, i)\n        recall += tp / (tp+fn)\n    return recall/l"
  },
  {
    "objectID": "lectures/07/slides.html#precision-recall-trade-off-2",
    "href": "lectures/07/slides.html#precision-recall-trade-off-2",
    "title": "Performance Evaluation",
    "section": "Precision-Recall Trade-Off",
    "text": "Precision-Recall Trade-Off\n\n\nCode\nfrom sklearn.model_selection import cross_val_predict\ny_scores = cross_val_predict(clf, X_train, y_train, cv=3, method=\"decision_function\")\n\nfrom sklearn.metrics import precision_recall_curve\n\nprecisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n\nthreshold = 3000\n\nplt.figure(figsize=(8, 4))  # extra code – it's not needed, just formatting\nplt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\nplt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\nplt.vlines(threshold, 0, 1.0, \"k\", \"dotted\", label=\"threshold\")\n\n# extra code – this section just beautifies and saves Figure 3–5\nidx = (thresholds &gt;= threshold).argmax()  # first index ≥ threshold\nplt.plot(thresholds[idx], precisions[idx], \"bo\")\nplt.plot(thresholds[idx], recalls[idx], \"go\")\nplt.axis([-50000, 50000, 0, 1])\nplt.grid()\nplt.xlabel(\"Threshold\")\nplt.legend(loc=\"center right\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAs the decision threshold decreases, a higher number of examples are predicted as positive, potentially leading the classifier to eventually label all instances as positive.\nConversely, as the decision threshold increases, fewer examples are classified as positive, which may result in the classifier predicting no positive instances at all.\nFor certain applications, a classifier with high precision is essential. For example, consider a scenario where each prediction necessitates a costly laboratory experiment to verify its accuracy, such as in a pharmaceutical company aiming to discover new drugs. Here, the classifier predicts whether a compound is active. Given the high cost of experiments to validate candidates, the company would prioritize focusing on the most promising compounds first.\nIn contrast, consider a scenario involving cancer screening, such as using mammograms to detect breast cancer. In this case, it may be preferable to lower the decision threshold, thereby increasing the number of false-positive predictions. Although this approach results in more patients undergoing additional tests, such as biopsies, it can potentially save more lives by ensuring that fewer cases of cancer go undetected.\n\n\nSGDClassifier is used because it allows to vary the decision treshold (boundary) to produce a plot illustrating the precision-recall tradeoff. (Géron 2022) 03_classification.ipynb."
  },
  {
    "objectID": "lectures/07/slides.html#roc-curve-2",
    "href": "lectures/07/slides.html#roc-curve-2",
    "title": "Performance Evaluation",
    "section": "ROC Curve",
    "text": "ROC Curve"
  },
  {
    "objectID": "lectures/07/slides.html#roc-curve-3",
    "href": "lectures/07/slides.html#roc-curve-3",
    "title": "Performance Evaluation",
    "section": "ROC Curve",
    "text": "ROC Curve\n\n\nCode\nidx_for_90_precision = (precisions &gt;= 0.90).argmax()\nthreshold_for_90_precision = thresholds[idx_for_90_precision]\ny_train_pred_90 = (y_scores &gt;= threshold_for_90_precision)\n\nfrom sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_train, y_scores)\n\nidx_for_threshold_at_90 = (thresholds &lt;= threshold_for_90_precision).argmax()\ntpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]\n\nplt.figure(figsize=(5, 5))  # extra code – not needed, just formatting\nplt.plot(fpr, tpr, linewidth=2, label=\"ROC curve\")\nplt.plot([0, 1], [0, 1], 'k:', label=\"Random classifier's ROC curve\")\nplt.plot([fpr_90], [tpr_90], \"ko\", label=\"Threshold for 90% precision\")\n\n# extra code – just beautifies and saves Figure 3–7\nplt.gca().add_patch(patches.FancyArrowPatch(\n    (0.20, 0.89), (0.07, 0.70),\n    connectionstyle=\"arc3,rad=.4\",\n    arrowstyle=\"Simple, tail_width=1.5, head_width=8, head_length=10\",\n    color=\"#444444\"))\nplt.text(0.12, 0.71, \"Higher\\nthreshold\", color=\"#333333\")\nplt.xlabel('False Positive Rate (Fall-Out)')\nplt.ylabel('True Positive Rate (Recall)')\nplt.grid()\nplt.axis([0, 1, 0, 1])\nplt.legend(loc=\"lower right\", fontsize=13)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nIt is common to measure the area under the curve, represented as AUC. Specifically, the area under the ROC curve. This allows to compare\n\n\nAttribution: 03_classification.ipynb"
  },
  {
    "objectID": "lectures/07/slides.html#pima-indians-diabetes-dataset",
    "href": "lectures/07/slides.html#pima-indians-diabetes-dataset",
    "title": "Performance Evaluation",
    "section": "Pima Indians Diabetes Dataset",
    "text": "Pima Indians Diabetes Dataset\n\nfrom sklearn.datasets import fetch_openml\n\n# Load the Pima Indians Diabetes dataset\npima = fetch_openml(name='diabetes', version=1, as_frame=True)\n\n# Extract the features and target\nX = pima.data\ny = pima.target\n\n# Convert target labels 'tested_negative' and 'tested_positive' to 0 and 1\ny = y.map({'tested_negative': 0, 'tested_positive': 1})\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\n\nPima Indians Diabetes Dataset as described in Knowler et al. (1981) [PubMed]."
  },
  {
    "objectID": "lectures/07/slides.html#comparing-multiple-classifiers",
    "href": "lectures/07/slides.html#comparing-multiple-classifiers",
    "title": "Performance Evaluation",
    "section": "Comparing Multiple Classifiers",
    "text": "Comparing Multiple Classifiers\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier"
  },
  {
    "objectID": "lectures/07/slides.html#comparing-multiple-classifiers-1",
    "href": "lectures/07/slides.html#comparing-multiple-classifiers-1",
    "title": "Performance Evaluation",
    "section": "Comparing Multiple Classifiers",
    "text": "Comparing Multiple Classifiers\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\n\n\n\nUsing the default parameters."
  },
  {
    "objectID": "lectures/07/slides.html#implementation-logistic-regression",
    "href": "lectures/07/slides.html#implementation-logistic-regression",
    "title": "Performance Evaluation",
    "section": "Implementation: Logistic Regression",
    "text": "Implementation: Logistic Regression\nBelow is our implementation of the logistic regression.\n\n\nCode\ndef sigmoid(z):\n    \"\"\"Compute the sigmoid function.\"\"\"\n    return 1 / (1 + np.exp(-z))\n\ndef cost_function(theta, X, y):\n    \"\"\"\n    Compute the binary cross-entropy cost.\n    theta: parameter vector\n    X: feature matrix (each row is an example)\n    y: true binary labels (0 or 1)\n    \"\"\"\n    m = len(y)\n    h = sigmoid(X.dot(theta))\n    # Add a small epsilon to avoid log(0)\n    epsilon = 1e-5\n    cost = -(1/m) * np.sum(y * np.log(h + epsilon) + (1 - y) * np.log(1 - h + epsilon))\n    return cost\n\ndef gradient(theta, X, y):\n    \"\"\"Compute the gradient of the cost with respect to theta.\"\"\"\n    m = len(y)\n    h = sigmoid(X.dot(theta))\n    return (1/m) * X.T.dot(h - y)\n\ndef logistic_regression(X, y, learning_rate=0.1, iterations=1000):\n    \"\"\"\n    Train logistic regression using gradient descent.\n    Returns the optimized parameter vector theta and the history of cost values.\n    \"\"\"\n    m, n = X.shape\n    theta = np.zeros(n)\n    cost_history = []\n    for i in range(iterations):\n        theta -= learning_rate * gradient(theta, X, y)\n        cost_history.append(cost_function(theta, X, y))\n    return theta, cost_history\n\ndef predict_probabilities(theta, X):\n    \"\"\"Return predicted probabilities for the positive class.\"\"\"\n    return sigmoid(X.dot(theta))"
  },
  {
    "objectID": "lectures/07/slides.html#implementation-roc",
    "href": "lectures/07/slides.html#implementation-roc",
    "title": "Performance Evaluation",
    "section": "Implementation: ROC",
    "text": "Implementation: ROC\n\ndef compute_roc_curve(y_true, y_scores, thresholds):\n    tpr_list, fpr_list = [], []\n    for thresh in thresholds:\n        # Classify as positive if predicted probability &gt;= threshold\n        y_pred = (y_scores &gt;= thresh).astype(int)\n        TP = np.sum((y_true == 1) & (y_pred == 1))\n        FN = np.sum((y_true == 1) & (y_pred == 0))\n        FP = np.sum((y_true == 0) & (y_pred == 1))\n        TN = np.sum((y_true == 0) & (y_pred == 0))\n        TPR = TP / (TP + FN) if (TP + FN) &gt; 0 else 0\n        FPR = FP / (FP + TN) if (FP + TN) &gt; 0 else 0\n        tpr_list.append(TPR)\n        fpr_list.append(FPR)\n        \n    tpr_list.reverse()\n    fpr_list.reverse()\n\n    return np.array(fpr_list), np.array(tpr_list)"
  },
  {
    "objectID": "lectures/07/slides.html#implementation-auc-roc",
    "href": "lectures/07/slides.html#implementation-auc-roc",
    "title": "Performance Evaluation",
    "section": "Implementation: AUC ROC",
    "text": "Implementation: AUC ROC\n\ndef compute_auc(fpr, tpr):\n    \"\"\"\n    Compute the Area Under the Curve (AUC) using the trapezoidal rule.\n    \n    fpr: array of false positive rates\n    tpr: array of true positive rates\n    \"\"\"\n    return np.trapezoid(tpr, fpr)\n\n\n\nThe Trapezoidal Rule (trapezoid), akin to the Riemann Sum, is a numerical method for approximating the definite integral of a function. By partitioning the area under the curve into trapezoids rather than rectangles, it typically yields a more precise approximation."
  },
  {
    "objectID": "lectures/07/slides.html#example-generate-data-predictions",
    "href": "lectures/07/slides.html#example-generate-data-predictions",
    "title": "Performance Evaluation",
    "section": "Example: Generate Data + Predictions",
    "text": "Example: Generate Data + Predictions\n\n# Generate synthetic data for binary classification\nnp.random.seed(seed)\nm = 1000  # number of samples\nX = np.random.randn(m, 2)\nnoise = 0.5 * np.random.randn(m)\n\n# Define labels: a noisy linear combination thresholded at 0\ny = (X[:, 0] + X[:, 1] + noise &gt; 0).astype(int)\n\n# Add an intercept term (a column of ones) to X\nX_intercept = np.hstack([np.ones((m, 1)), X])\n\nX_train, X_test, y_train, y_test = train_test_split(X_intercept, y, random_state=seed)\n\n# Train logistic regression model using gradient descent\ntheta, cost_history = logistic_regression(X_train, y_train, learning_rate=0.1, iterations=1000)"
  },
  {
    "objectID": "lectures/07/slides.html#example-plot",
    "href": "lectures/07/slides.html#example-plot",
    "title": "Performance Evaluation",
    "section": "Example: Plot",
    "text": "Example: Plot\n\n\nCode\n# Compute predicted probabilities for the positive class on the test set\ny_probs = predict_probabilities(theta, X_test)\n\n# Define a set of threshold values between 0 and 1 (e.g., 100 equally spaced thresholds)\nthresholds = np.linspace(0, 1, 100)\n\n# Compute the ROC curve (FPR and TPR for each threshold)\nfpr, tpr = compute_roc_curve(y_test, y_probs, thresholds)\nauc_value = compute_auc(fpr, tpr)\n\n# Plot the ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % auc_value)\nplt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random classifier')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()"
  },
  {
    "objectID": "lectures/07/slides.html#see-also",
    "href": "lectures/07/slides.html#see-also",
    "title": "Performance Evaluation",
    "section": "See Also",
    "text": "See Also\n\nMulticlass Receiver Operating Characteristic (ROC) presents examples of micro- and macro- average curves."
  },
  {
    "objectID": "lectures/07/slides.html#summary-1",
    "href": "lectures/07/slides.html#summary-1",
    "title": "Performance Evaluation",
    "section": "Summary",
    "text": "Summary\n\nExamined classification model evaluation techniques, focusing on confusion matrices and key metrics: accuracy, precision, recall, and \\(F_1\\) score.\nAddressed the limitations of accuracy in imbalanced datasets, introducing micro and macro averaging techniques.\nExplored the precision-recall trade-off and ROC analysis, including the area under the curve (AUC).\nProvided practical insights through Python implementations."
  },
  {
    "objectID": "lectures/07/slides.html#prologue-1",
    "href": "lectures/07/slides.html#prologue-1",
    "title": "Performance Evaluation",
    "section": "Prologue",
    "text": "Prologue"
  },
  {
    "objectID": "lectures/07/slides.html#confusionmatrixdisplay",
    "href": "lectures/07/slides.html#confusionmatrixdisplay",
    "title": "Performance Evaluation",
    "section": "ConfusionMatrixDisplay",
    "text": "ConfusionMatrixDisplay\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nseed = 42\n\nX, y = make_classification(n_samples = 500, random_state=seed)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n\nclf = LogisticRegression(random_state=seed)\n\nclf.fit(X_train, y_train)\n\npredictions = clf.predict(X_test)\n\ncm = confusion_matrix(y_test, predictions, labels=[1, 0])\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Positive\", \"Negative\"])\n\ndisp.plot()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nWe employ the make_classification function to generate a synthetic dataset, which are subsequently analyzed using a LogisticRegression model. For both confusion_matrix and ConfusionMatrixDisplay, we configure the labels to ensure that the ‘Positive’ class precedes, aligning with the tabular data presented in the previous screen. The resulting confusion matrix yields the following values: True Positives (TP) = 37, False Negatives (FN) = 10, False Positives (FP) = 3, and True Negatives (TN) = 50."
  },
  {
    "objectID": "lectures/08/slides.html#dataset---openml",
    "href": "lectures/08/slides.html#dataset---openml",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Dataset - openml",
    "text": "Dataset - openml\n\n\n\n www.openml.org\n\n\nOpenML is an open platform for sharing datasets, algorithms, and experiments - to learn how to learn better, together.\n\n\n\n\n\nimport numpy as np\nnp.random.seed(42)\n\nfrom sklearn.datasets import fetch_openml\n\ndiabetes = fetch_openml(name='diabetes', version=1)\nprint(diabetes.DESCR)\n\n\n\nToday’s dataset is the PIMA dataset, which contains 768 instances and 8 numerical attributes. The numerical nature of these attributes facilitates our analysis. Additionally, since the data originates from a published paper, it likely reflects careful data collection, potentially leading to robust results, as the authors would have needed high-quality data to support their publication."
  },
  {
    "objectID": "lectures/08/slides.html#dataset---openml-output",
    "href": "lectures/08/slides.html#dataset---openml-output",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Dataset - openml",
    "text": "Dataset - openml\nAuthor: Vincent Sigillito\nSource: Obtained from UCI\nPlease cite: UCI citation policy\n\nTitle: Pima Indians Diabetes Database\nSources:\n\nOriginal owners: National Institute of Diabetes and Digestive and Kidney Diseases\nDonor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu) Research Center, RMI Group Leader Applied Physics Laboratory The Johns Hopkins University Johns Hopkins Road Laurel, MD 20707 (301) 953-6231\nDate received: 9 May 1990\n\nPast Usage:\n\nSmith,J.W., Everhart,J.E., Dickson,W.C., Knowler,W.C., & Johannes,R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In {it Proceedings of the Symposium on Computer Applications and Medical Care} (pp. 261–265). IEEE Computer Society Press.\nThe diagnostic, binary-valued variable investigated is whether the patient shows signs of diabetes according to World Health Organization criteria (i.e., if the 2 hour post-load plasma glucose was at least 200 mg/dl at any survey examination or if found during routine medical care). The population lives near Phoenix, Arizona, USA.\nResults: Their ADAP algorithm makes a real-valued prediction between 0 and 1. This was transformed into a binary decision using a cutoff of 0.448. Using 576 training instances, the sensitivity and specificity of their algorithm was 76% on the remaining 192 instances.\n\nRelevant Information: Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage. ADAP is an adaptive learning routine that generates and executes digital analogs of perceptron-like devices. It is a unique algorithm; see the paper for details.\nNumber of Instances: 768\nNumber of Attributes: 8 plus class\nFor Each Attribute: (all numeric-valued)\n\nNumber of times pregnant\nPlasma glucose concentration a 2 hours in an oral glucose tolerance test\nDiastolic blood pressure (mm Hg)\nTriceps skin fold thickness (mm)\n2-Hour serum insulin (mu U/ml)\nBody mass index (weight in kg/(height in m)^2)\nDiabetes pedigree function\nAge (years)\nClass variable (0 or 1)\n\nMissing Attribute Values: None\nClass Distribution: (class value 1 is interpreted as “tested positive for diabetes”)\nClass Value Number of instances 0 500 1 268\nBrief statistical analysis:\nAttribute number: Mean: Standard Deviation:\n\n                3.8     3.4\n              120.9    32.0\n               69.1    19.4\n               20.5    16.0\n               79.8   115.2\n               32.0     7.9\n                0.5     0.3\n               33.2    11.8\n\n\nRelabeled values in attribute ‘class’ From: 0 To: tested_negative\nFrom: 1 To: tested_positive\nDownloaded from openml.org."
  },
  {
    "objectID": "lectures/08/slides.html#dataset---return_x_y",
    "href": "lectures/08/slides.html#dataset---return_x_y",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Dataset - return_X_y",
    "text": "Dataset - return_X_y\nfetch_openml returns a Bunch, a DataFrame, or X and y\n\nfrom sklearn.datasets import fetch_openml\n\nX, y = fetch_openml(name='diabetes', version=1, return_X_y=True)\n\n\nMild imbalance (ratio less than 3 or 4)\n\nprint(y.value_counts())\n\nclass\ntested_negative    500\ntested_positive    268\nName: count, dtype: int64\n\n\n\n\nConverting the target labels to 0 and 1\n\ny = y.map({'tested_negative': 0, 'tested_positive': 1})"
  },
  {
    "objectID": "lectures/08/slides.html#training-and-test-set",
    "href": "lectures/08/slides.html#training-and-test-set",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Training and test set",
    "text": "Training and test set\nSometimes called holdout method.\n\nGuideline: Typically, allocate 80% of your dataset for training and reserve the remaining 20% for testing.\nTraining Set: This subset of data is utilized to train your model.\nTest Set: This is an independent subset used exclusively at the final stage to assess the model’s performance.\n\n\nCommon Training and Testing Ratios\n\n80:20 Split:\n\nTraining Set: 80% of the data\nTesting Set: 20% of the data\nThis is a widely used default split that provides a balance between having enough data to train the model and enough data to evaluate its performance.\n\n90:10 Split:\n\nTraining Set: 90% of the data\nTesting Set: 10% of the data\nThis split might be used when the dataset is very large, ensuring a substantial amount of data for training while still having a decent-sized test set.\n\n\nConsiderations for Choosing the Split Ratio\n\nDataset Size:\n\nFor large datasets, a smaller proportion can be reserved for testing (e.g., 90:10) since even 10% of a large dataset can provide a robust evaluation.\n\nModel Complexity:\n\nComplex models with many parameters may require more training data to avoid overfitting, suggesting a larger training set.\n\nValidation Set:\n\nSee discussion below.\n\nImbalanced Datasets:\n\nFor imbalanced datasets, it’s essential to ensure that both the training and testing sets represent the class distribution adequately. Stratified sampling can be used to maintain the class proportions in both sets."
  },
  {
    "objectID": "lectures/08/slides.html#training-and-test-set-1",
    "href": "lectures/08/slides.html#training-and-test-set-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Training and test set",
    "text": "Training and test set\nTraining Error:\n\nGenerally tends to be low\nAchieved by optimizing learning algorithms to minimize error through parameter adjustments (e.g., weights)"
  },
  {
    "objectID": "lectures/08/slides.html#training-and-test-set-2",
    "href": "lectures/08/slides.html#training-and-test-set-2",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Training and test set",
    "text": "Training and test set\nGeneralization Error: The error rate observed when the model is evaluated on new, unseen data."
  },
  {
    "objectID": "lectures/08/slides.html#training-and-test-set-3",
    "href": "lectures/08/slides.html#training-and-test-set-3",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Training and test set",
    "text": "Training and test set\nUnderfitting:\n\nHigh training error\nModel is too simple to capture underlying patterns\nPoor performance on both training and new data\n\nOverfitting:\n\nLow training error, but high generalization error\nModel captures noise or irrelevant patterns\nPoor performance on new, unseen data"
  },
  {
    "objectID": "lectures/08/slides.html#definition",
    "href": "lectures/08/slides.html#definition",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Definition",
    "text": "Definition\nCross-validation is a method used to evaluate and improve the performance of machine learning models.\nIt involves partitioning the dataset into multiple subsets, training the model on some subsets while validating it on the remaining ones."
  },
  {
    "objectID": "lectures/08/slides.html#k-fold-cross-validation",
    "href": "lectures/08/slides.html#k-fold-cross-validation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "k-fold cross-validation",
    "text": "k-fold cross-validation\n\nDivide the dataset into \\(k\\) equally sized parts (folds).\nTraining and validation:\n\nFor each iteration, one fold is used as the validation set, the remaining \\(k\\)-1 folds are used as the training set.\n\nEvaluation: The model’s performance is evaluated in each iteration, resulting in \\(k\\) performance measures.\nAggregation: Statistics are calculated based on \\(k\\) performance measures.\n\n\n\nIn science, to estimate the value of a constant, it is common to repeat the experiment multiple times in order to calculate the mean and standard deviation of the obtained measurements. A high variance raises questions about the reliability of the experiment. Similarly, \\(k\\)-fold cross-validation generates \\(k\\) distinct evaluations. This method not only provides a more accurate estimate of the model’s performance but also assesses its robustness against data variability.\n\n\nCommon choices for the value of \\(k\\) are 3, 5, 7, and 10."
  },
  {
    "objectID": "lectures/08/slides.html#fold-cross-validation",
    "href": "lectures/08/slides.html#fold-cross-validation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "3-Fold Cross-validation",
    "text": "3-Fold Cross-validation\n\n\n\n\n\n\n\n\n\n\n\nEach row of the table represents an iteration within the \\(k\\)-fold cross-validation process, with the number of iterations equating to the number of folds. In each iteration, one fold is designated for validation, while the remaining \\(k-1\\) folds are utilized for training the model.\n\n\nWith each iteration, \\(2/3\\) of the dataset is used for training and \\(1/3\\) for validation."
  },
  {
    "objectID": "lectures/08/slides.html#fold-cross-validation-1",
    "href": "lectures/08/slides.html#fold-cross-validation-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "5-Fold Cross-validation",
    "text": "5-Fold Cross-validation\n\n\n\n\n\n\n\n\n\n\n\nWith each iteration, \\(4/5\\) of the dataset is used for training and \\(1/5\\) for validation."
  },
  {
    "objectID": "lectures/08/slides.html#more-reliable-model-evaluation",
    "href": "lectures/08/slides.html#more-reliable-model-evaluation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "More Reliable Model Evaluation",
    "text": "More Reliable Model Evaluation\n\nMore reliable estimate of model performance compared to a single train-test split.\nReduces the variability associated with a single split, leading to a more stable and unbiased evaluation.\nFor large values of \\(k\\)1, consider the average, variance, and confidence interval.\n\n10-fold cross-validation."
  },
  {
    "objectID": "lectures/08/slides.html#better-generalization",
    "href": "lectures/08/slides.html#better-generalization",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Better Generalization",
    "text": "Better Generalization\n\nHelps in assessing how the model generalizes to an independent dataset.\nIt ensures that the model’s performance is not overly optimistic or pessimistic by averaging results over multiple folds."
  },
  {
    "objectID": "lectures/08/slides.html#efficient-use-of-data",
    "href": "lectures/08/slides.html#efficient-use-of-data",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Efficient Use of Data",
    "text": "Efficient Use of Data\n\nParticularly beneficial for small datasets, cross-validation ensures that every data point is used for both training and validation.\nThis maximizes the use of available data, leading to more accurate and reliable model training.\n\n\n\nSome examples are more informative for learning algorithms, sometimes those near the decision boundary."
  },
  {
    "objectID": "lectures/08/slides.html#hyperparameter-tuning",
    "href": "lectures/08/slides.html#hyperparameter-tuning",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameter Tuning",
    "text": "Hyperparameter Tuning\n\nCommonly used during hyperparameter tuning, allowing for the selection of the best model parameters based on their performance across multiple folds.\nThis helps in identifying the optimal configuration that balances bias and variance."
  },
  {
    "objectID": "lectures/08/slides.html#challenges",
    "href": "lectures/08/slides.html#challenges",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Challenges",
    "text": "Challenges\n\nComputational Cost: Requires multiple model trainings.\n\nLeave-One-Out (LOO): Extreme case where ( k = N ).\n\nClass Imbalance: Folds may not represent minority classes.\n\nUse Stratified Cross-Validation to maintain class proportions.\n\nComplexity: Error-prone implementation, especially for nested cross-validation, bootstraps, or integration into larger pipelines.\n\n\nLeave-one-out cross-validation (LOO-CV) can lead to overoptimistic performance evaluation, particularly in certain contexts.\nHere’s why:\n1.  **High Variance**: In LOO-CV, each iteration uses almost all the data for training, leaving only one instance for testing. This can result in high variance in the test error across iterations because the model is trained on nearly the full dataset. Since each training set is very similar to the full dataset, it can lead to overly optimistic estimates of generalization error, especially when the dataset is small or the model has high variance (e.g., decision trees or k-nearest neighbors).\n2.  **Overfitting**: Since LOO-CV uses nearly the entire dataset for training in each iteration, complex models (especially ones prone to overfitting) can fit very closely to the data, which might result in a low training error but a misleadingly low test error in some cases.\n3.  **Limited assessment of generalization**: LOO-CV might not give a reliable estimate of how well the model generalizes to completely unseen data because the difference between the training set and the full dataset is minimal, leading to a smaller gap between training and test performance.\nIn practice, this can make the evaluation appear more optimistic than it would be with more robust methods like k-fold cross-validation, where the test sets are larger, and the model has less opportunity to overfit the training data.\nStratified (in cross-validation): a sampling strategy where each fold preserves the class distribution of the full dataset, ensuring that every class is represented proportionally in both training and validation splits."
  },
  {
    "objectID": "lectures/08/slides.html#cross_val_score",
    "href": "lectures/08/slides.html#cross_val_score",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "cross_val_score",
    "text": "cross_val_score\n\nfrom sklearn import tree\n\nclf = tree.DecisionTreeClassifier()\n\nfrom sklearn.model_selection import cross_val_score    \n\nclf_scores = cross_val_score(clf, X, y, cv=5)\n\nprint(\"\\nScores:\", clf_scores)\nprint(f\"\\nMean: {clf_scores.mean():.2f}\")\nprint(f\"\\nStandard deviation: {clf_scores.std():.2f}\")\n\n\nScores: [0.71428571 0.66883117 0.71428571 0.79738562 0.73202614]\n\nMean: 0.73\n\nStandard deviation: 0.04\n\n\n\n\nAs previously discussed, a significant limitation of decision trees is their propensity for overfitting, which leads to high variance when applied to new datasets. This issue is evident in the observed performance variability, with accuracy ranging from 67% to 79%, which is undesirable for achieving robust model generalization.\n\n\nsklearn.model_selection.cross_val_score, see also cross_validate."
  },
  {
    "objectID": "lectures/08/slides.html#workflow",
    "href": "lectures/08/slides.html#workflow",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Workflow",
    "text": "Workflow\n\n\n\n\n\n\n\nThe above image implicitly introduces three categories of data subsets: training, validation, and test.\n\n\nAttribution: Cross-validation: evaluating estimator performance"
  },
  {
    "objectID": "lectures/08/slides.html#workflow---implementation",
    "href": "lectures/08/slides.html#workflow---implementation",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Workflow - implementation",
    "text": "Workflow - implementation\n\nfrom sklearn.datasets import fetch_openml\n\nX, y = fetch_openml(name='diabetes', version=1, return_X_y=True)\n\ny = y.map({'tested_negative': 0, 'tested_positive': 1})\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\n\nTo maintain simplicity in these lecture notes, we have not applied any pre-processing steps."
  },
  {
    "objectID": "lectures/08/slides.html#definition-1",
    "href": "lectures/08/slides.html#definition-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Definition",
    "text": "Definition\nA hyperparameter is a configuration external to the model that is set prior to the training process and governs the learning process, influencing model performance and complexity.\n\n\nThe weights of a model, which are learned by the learning algorithm, are often referred to as the model’s parameters. To avoid confusion, user-defined parameters, such as the learning rate \\(\\alpha\\), are termed hyperparameters. Unlike model parameters, hyperparameters are not learned by the learning algorithm."
  },
  {
    "objectID": "lectures/08/slides.html#hyperparameters---decision-tree",
    "href": "lectures/08/slides.html#hyperparameters---decision-tree",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameters - Decision Tree",
    "text": "Hyperparameters - Decision Tree\n\ncriterion: gini, entropy, log_loss, measure the quality of a split.\nmax_depth: limits the number of levels in the tree to prevent overfitting.\n\n\n\nSee: DecisionTreeClassifier"
  },
  {
    "objectID": "lectures/08/slides.html#hyperparameters---logistic-regression",
    "href": "lectures/08/slides.html#hyperparameters---logistic-regression",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameters - Logistic Regression",
    "text": "Hyperparameters - Logistic Regression\n\npenalty: l1 or l2, helps in preventing overfitting.\nsolver: liblinear, newton-cg, lbfgs, sag, saga.\nmax_iter: maximum number of iterations taken for the solvers to converge.\ntol: stopping criteria, smaller values mean higher precision.\n\n\n\nSee: LogisticRegression and SGDClassifier."
  },
  {
    "objectID": "lectures/08/slides.html#hyperparameters---knn",
    "href": "lectures/08/slides.html#hyperparameters---knn",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameters - KNN",
    "text": "Hyperparameters - KNN\n\nn_neighbors: number of neighbors to use for \\(k\\)-neighbors queries.\nweights: uniform or distance, equal weight or distance-based weight.\n\n\n\nSee: KNeighborsClassifier"
  },
  {
    "objectID": "lectures/08/slides.html#experiment-max_depth",
    "href": "lectures/08/slides.html#experiment-max_depth",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: max_depth",
    "text": "Experiment: max_depth\n\nfor value in [3, 5, 7, None]:\n\n  clf = tree.DecisionTreeClassifier(max_depth=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\nmax_depth = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")\n\n\nmax_depth =  3\nMean: 0.74\nStandard deviation: 0.04\n\nmax_depth =  5\nMean: 0.76\nStandard deviation: 0.04\n\nmax_depth =  7\nMean: 0.73\nStandard deviation: 0.04\n\nmax_depth =  None\nMean: 0.71\nStandard deviation: 0.05"
  },
  {
    "objectID": "lectures/08/slides.html#experiment-criterion",
    "href": "lectures/08/slides.html#experiment-criterion",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: criterion",
    "text": "Experiment: criterion\n\nfor value in [\"gini\", \"entropy\", \"log_loss\"]:\n\n  clf = tree.DecisionTreeClassifier(max_depth=5, criterion=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\ncriterion = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")\n\n\ncriterion =  gini\nMean: 0.76\nStandard deviation: 0.04\n\ncriterion =  entropy\nMean: 0.75\nStandard deviation: 0.05\n\ncriterion =  log_loss\nMean: 0.75\nStandard deviation: 0.05\n\n\n\nFor this specific problem and dataset, the criterion parameter has a limited impact on the learning process."
  },
  {
    "objectID": "lectures/08/slides.html#experiment-n_neighbors",
    "href": "lectures/08/slides.html#experiment-n_neighbors",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: n_neighbors",
    "text": "Experiment: n_neighbors\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfor value in range(1, 11):\n\n  clf = KNeighborsClassifier(n_neighbors=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\nn_neighbors = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")"
  },
  {
    "objectID": "lectures/08/slides.html#experiment-n_neighbors-output",
    "href": "lectures/08/slides.html#experiment-n_neighbors-output",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: n_neighbors",
    "text": "Experiment: n_neighbors\n\n\nn_neighbors =  1\nMean: 0.67\nStandard deviation: 0.05\n\nn_neighbors =  2\nMean: 0.71\nStandard deviation: 0.03\n\nn_neighbors =  3\nMean: 0.69\nStandard deviation: 0.05\n\nn_neighbors =  4\nMean: 0.73\nStandard deviation: 0.03\n\nn_neighbors =  5\nMean: 0.72\nStandard deviation: 0.03\n\nn_neighbors =  6\nMean: 0.73\nStandard deviation: 0.05\n\nn_neighbors =  7\nMean: 0.74\nStandard deviation: 0.04\n\nn_neighbors =  8\nMean: 0.75\nStandard deviation: 0.04\n\nn_neighbors =  9\nMean: 0.73\nStandard deviation: 0.05\n\nn_neighbors =  10\nMean: 0.73\nStandard deviation: 0.04"
  },
  {
    "objectID": "lectures/08/slides.html#experiment-weights",
    "href": "lectures/08/slides.html#experiment-weights",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Experiment: weights",
    "text": "Experiment: weights\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfor value in [\"uniform\", \"distance\"]:\n\n  clf = KNeighborsClassifier(n_neighbors=5, weights=value)\n\n  clf_scores = cross_val_score(clf, X_train, y_train, cv=10)\n\n  print(\"\\nweights = \", value)\n  print(f\"Mean: {clf_scores.mean():.2f}\")\n  print(f\"Standard deviation: {clf_scores.std():.2f}\")\n\n\nweights =  uniform\nMean: 0.72\nStandard deviation: 0.03\n\nweights =  distance\nMean: 0.73\nStandard deviation: 0.04\n\n\n\nFor this specific problem and dataset, the weights parameter has a limited impact on the learning process.\nAt this point, you might hypothesize that certain combinations of hyperparameters could be more optimal than others."
  },
  {
    "objectID": "lectures/08/slides.html#hyperparameter-tuning-grid-search",
    "href": "lectures/08/slides.html#hyperparameter-tuning-grid-search",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Hyperparameter Tuning: Grid Search",
    "text": "Hyperparameter Tuning: Grid Search\n\nMany hyperparameters need tuning\n\nMajor disadvantage of ML algorithms\n\nManual exploration of combinations is tedious\nGrid search is more systematic\n\nEnumerate all possible hyperparameter combinations\nTrain on training set, evaluate on validation set\n\n\n\n\nThe training set referred to here is different from the one previously mentioned. In each iteration of the \\(k\\)-fold cross-validation process, a unique training and validation set is created.\nIn some contexts, the choice of the model itself can be considered a hyperparameter. For instance, when performing model selection within a machine learning pipeline, different algorithms (e.g., decision trees, support vector machines, neural networks) can be treated as hyperparameters. This approach allows for the selection of the best-performing model through automated processes such as grid search or random search, alongside the tuning of other hyperparameters.\nThus, while traditionally hyperparameters refer to settings within a specific model, the model choice can also be incorporated into hyperparameter optimization frameworks.\nAs will be discussed later, the choice of the number of layers and the number of nodes are often considered hyperparameters when training deep learning algorithms.\n\n\nInitially, try powers of 2 or 10. Next, refine with grid search near optimal values if time permits."
  },
  {
    "objectID": "lectures/08/slides.html#gridsearchcv",
    "href": "lectures/08/slides.html#gridsearchcv",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "GridSearchCV",
    "text": "GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n  {'max_depth': range(1, 10),\n   'criterion': [\"gini\", \"entropy\", \"log_loss\"]}\n]\n\nclf = tree.DecisionTreeClassifier()\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)\n\n(grid_search.best_params_, grid_search.best_score_)\n\n({'criterion': 'gini', 'max_depth': 5}, np.float64(0.7481910124074653))"
  },
  {
    "objectID": "lectures/08/slides.html#gridsearchcv-1",
    "href": "lectures/08/slides.html#gridsearchcv-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "GridSearchCV",
    "text": "GridSearchCV\n\nparam_grid = [\n  {'n_neighbors': range(1, 15),\n   'weights': [\"uniform\", \"distance\"]}\n]\n\nclf = KNeighborsClassifier()\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)\n\n(grid_search.best_params_, grid_search.best_score_)\n\n({'n_neighbors': 14, 'weights': 'uniform'}, np.float64(0.7554165363361485))\n\n\n\nThe variable param_grid contains a dictionary specifying the names of the parameters to be tuned, along with the respective values to be tested.\nIn this instance, the parameters n_neighbors and weights are being tuned. However, additional parameters could be included if necessary."
  },
  {
    "objectID": "lectures/08/slides.html#gridsearchcv-2",
    "href": "lectures/08/slides.html#gridsearchcv-2",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "GridSearchCV",
    "text": "GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\n\n# 2 * 5 * 5 * 3 = 150 tests!\n\nparam_grid = [\n  {'penalty': [\"l1\", \"l2\", None],\n   'solver' : ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n   'max_iter' : [100, 200, 400, 800, 1600],\n   'tol' : [0.01, 0.001, 0.0001]}\n]\n\nclf = LogisticRegression()\n\ngrid_search = GridSearchCV(clf, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)\n\n(grid_search.best_params_, grid_search.best_score_)\n\n({'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001},\n np.float64(0.7756646856427901))"
  },
  {
    "objectID": "lectures/08/slides.html#randomized-search",
    "href": "lectures/08/slides.html#randomized-search",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Randomized Search",
    "text": "Randomized Search\n\nLarge number of combinations (many hyperparameters, many values)\nUse RandomizedSearchCV:\n\nSupply list of values or probability distribution for hyperparameters\nSpecify number of iterations (combinations to try)\nPredictable execution time\n\n\n\n\nSee: Comparing randomized search and grid search for hyperparameter estimation."
  },
  {
    "objectID": "lectures/08/slides.html#workflow-1",
    "href": "lectures/08/slides.html#workflow-1",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Workflow",
    "text": "Workflow\n\n\n\n\n\n\n\nAs the ongoing example illustrates, in addition to evaluating various hyperparameter values, multiple models can also be tested.\n\n\nAttribution: Cross-validation: evaluating estimator performance"
  },
  {
    "objectID": "lectures/08/slides.html#finally-we-proceed-with-testing",
    "href": "lectures/08/slides.html#finally-we-proceed-with-testing",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Finally, we proceed with testing",
    "text": "Finally, we proceed with testing\n\nclf = LogisticRegression(max_iter=100, penalty='l2', solver='newton-cg', tol=0.001)\n\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.83      0.83      0.83        52\n           1       0.64      0.64      0.64        25\n\n    accuracy                           0.77        77\n   macro avg       0.73      0.73      0.73        77\nweighted avg       0.77      0.77      0.77        77\n\n\n\n\n\nIt appears that we are facing a class imbalance issue, which should have been identified earlier in our workflow!"
  },
  {
    "objectID": "lectures/08/slides.html#summary",
    "href": "lectures/08/slides.html#summary",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Summary",
    "text": "Summary\n\nTraining Set Size: Impact on model efficacy and generalization.\nAttribute Encoding: Evaluation of techniques to capture biological phenomena.\nPreprocessing:\n\nData Scaling\nHandling Missing Values\nManaging Class Imbalance"
  },
  {
    "objectID": "lectures/08/slides.html#next-lecture",
    "href": "lectures/08/slides.html#next-lecture",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Next lecture",
    "text": "Next lecture\n\nWe will further discuss machine learning engineering."
  },
  {
    "objectID": "lectures/08/slides.html#references",
    "href": "lectures/08/slides.html#references",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "References",
    "text": "References\n\n\nRussell, Stuart, and Peter Norvig. 2020. Artificial Intelligence: A Modern Approach. 4th ed. Pearson. http://aima.cs.berkeley.edu/."
  },
  {
    "objectID": "lectures/08/slides.html#message-of-the-day",
    "href": "lectures/08/slides.html#message-of-the-day",
    "title": "Model Evaluation and Hyperparameter Tuning",
    "section": "Message of the Day",
    "text": "Message of the Day\n\n\n\n\n\n\n\n\nEPFL, ETH Zurich and the Swiss National Supercomputing Centre (CSCS) released Apertus 2 September, Switzerland’s first large-scale, open, multilingual language model — a milestone in generative AI for transparency and diversity.\n\n\nwww.swiss-ai.org/apertus\nDownloads available at Hugging Face\nPublic access\n\nShould Canada undertake such an extensive project?\nCanada is recognized for its exceptional AI research, supported by several renowned research institutions and scholars. Notable examples include:\n\nThe Vector Institute in Toronto, which is home to distinguished researchers like Geoffrey Hinton, a recipient of the 2018 Turing Award for his pioneering work in deep learning and the 2024 Nobel Prize in Physics.\nMila in Montréal, led by Yoshua Bengio, another 2018 Turing Award laureate recognized for his contributions to deep learning.\nThe Alberta Machine Intelligence Institute (Amii), where Richard S. Sutton is a key figure and was awarded the 2024 Turing Award for his influential work in reinforcement learning.\n\nThese institutions and individuals underscore Canada’s leadership and ongoing commitment to advancing artificial intelligence research.\nThe Digital Research Alliance of Canada, supported by a $2 billion commitment from the Government of Canada in 2024, provides cutting-edge infrastructure for advanced research. Notably, the high-performance computing resource, Nibi, was launched on July 31, 2025. It features 134,400 CPU cores and 288 NVIDIA H100 GPUs, significantly enhancing computational capacity. For further technical specifications, please refer to the technical documentation.\n\n\nApertus: a fully open, transparent, multilingual language model, ETH Zürich, Press Release, 2025-09-02."
  },
  {
    "objectID": "lectures/07/LogisticRegression.html",
    "href": "lectures/07/LogisticRegression.html",
    "title": "Logistic regression trained with (batch) gradient descent",
    "section": "",
    "text": "In this notebook, we develop a custom implementation of logistic regression, employing batch gradient descent for training. Additionally, we implement the compute_roc_curve and compute_auc functions. Subsequently, we analyze two realistic yet straightforward datasets utilizing scikit-learn libraries."
  },
  {
    "objectID": "lectures/07/LogisticRegression.html#step-0-import-librairies-set-global-variables",
    "href": "lectures/07/LogisticRegression.html#step-0-import-librairies-set-global-variables",
    "title": "Logistic regression trained with (batch) gradient descent",
    "section": "Step 0: Import librairies, set global variables",
    "text": "Step 0: Import librairies, set global variables\n\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_blobs\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression as SKLogisticRegression\n\nseed=42"
  },
  {
    "objectID": "lectures/07/LogisticRegression.html#step-1-create-a-toy-dataset",
    "href": "lectures/07/LogisticRegression.html#step-1-create-a-toy-dataset",
    "title": "Logistic regression trained with (batch) gradient descent",
    "section": "Step 1: Create a toy dataset",
    "text": "Step 1: Create a toy dataset\n\nX, y = make_blobs(n_samples=1000, n_features=2, centers=2, cluster_std=2.5, random_state=42)\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\nVisualizing the training set.\n\n\nCode\nplt.figure(figsize=(7, 6))\n\nplt.scatter(\n    X_train[y_train == 0, 0], X_train[y_train == 0, 1],\n    color=\"tab:blue\", marker=\"o\", edgecolor=\"k\", alpha=0.8, label=\"Class 0 (train)\"\n)\nplt.scatter(\n    X_train[y_train == 1, 0], X_train[y_train == 1, 1],\n    color=\"tab:orange\", marker=\"o\", edgecolor=\"k\", alpha=0.8, label=\"Class 1 (train)\"\n)\n\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.title(\"Training Data Before Logistic Regression\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "lectures/07/LogisticRegression.html#step-2-train-our-logisticregression-class",
    "href": "lectures/07/LogisticRegression.html#step-2-train-our-logisticregression-class",
    "title": "Logistic regression trained with (batch) gradient descent",
    "section": "Step 2: Train our LogisticRegression class",
    "text": "Step 2: Train our LogisticRegression class\n\nmodel = LogisticRegression(learning_rate=0.1, max_iter=500, random_state=42)\nmodel.fit(X_train, y_train)\n\n&lt;__main__.LogisticRegression at 0x107bfffd0&gt;\n\n\n\n\nCode\n# --- Step 3: Predictions and classification report ---\ny_pred = model.predict(X_test)\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_test, y_pred))\n\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99       151\n           1       0.99      0.98      0.99       149\n\n    accuracy                           0.99       300\n   macro avg       0.99      0.99      0.99       300\nweighted avg       0.99      0.99      0.99       300\n\n\n\n\n\nCode\n# --- Step 4: Plot the loss history ---\n\nlosses = model.get_loss_history()\n\nplt.figure(figsize=(7, 6)) \nplt.plot(losses, label=\"Training Loss (BCE)\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Logistic Regression Training Loss\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# --- Step 5: Decision boundary (2D) ---\n# Works because we used n_features=2 above.\n# If you use more than 2 features, select two columns to visualize (e.g., X[:, :2]).\n\ndef plot_decision_boundary(model, X_train, y_train, X_test, y_test, h=0.02):\n    \"\"\"\n    Plot probability heatmap, 0.5 decision contour, and data points.\n\n    Parameters\n    ----------\n    model : fitted LogisticRegression (our class)\n    X_train, y_train : training data (2D features)\n    X_test, y_test   : test data (2D features)\n    h : float, grid step size (smaller -&gt; finer mesh)\n    \"\"\"\n    # 1) Build a mesh over the feature space (with padding for nicer margins)\n    x_min = min(X_train[:, 0].min(), X_test[:, 0].min()) - 0.5\n    x_max = max(X_train[:, 0].max(), X_test[:, 0].max()) + 0.5\n    y_min = min(X_train[:, 1].min(), X_test[:, 1].min()) - 0.5\n    y_max = max(X_train[:, 1].max(), X_test[:, 1].max()) + 0.5\n\n    xx, yy = np.meshgrid(\n        np.arange(x_min, x_max, h),\n        np.arange(y_min, y_max, h)\n    )\n    grid = np.c_[xx.ravel(), yy.ravel()]\n\n    # 2) Predict probabilities on the grid (class 1)\n    Z = model.predict_proba(grid).reshape(xx.shape)\n\n    # 3) Plot\n    plt.figure(figsize=(7, 6))\n\n    # Heatmap of P(y=1|x); levels=25 for smooth look\n    cntr = plt.contourf(xx, yy, Z, levels=25, alpha=0.8)\n    cbar = plt.colorbar(cntr)\n    cbar.set_label(\"P(class = 1)\")\n\n    # Decision boundary at probability 0.5\n    plt.contour(xx, yy, Z, levels=[0.5], linewidths=2)\n\n    # Training points\n    plt.scatter(\n        X_train[y_train == 0, 0], X_train[y_train == 0, 1],\n        marker=\"o\", edgecolor=\"k\", alpha=0.9, label=\"Train: class 0\"\n    )\n    plt.scatter(\n        X_train[y_train == 1, 0], X_train[y_train == 1, 1],\n        marker=\"o\", edgecolor=\"k\", alpha=0.9, label=\"Train: class 1\"\n    )\n\n    # Test points (different marker)\n    plt.scatter(\n        X_test[y_test == 0, 0], X_test[y_test == 0, 1],\n        marker=\"^\", edgecolor=\"k\", alpha=0.9, label=\"Test: class 0\"\n    )\n    plt.scatter(\n        X_test[y_test == 1, 0], X_test[y_test == 1, 1],\n        marker=\"^\", edgecolor=\"k\", alpha=0.9, label=\"Test: class 1\"\n    )\n\n    plt.xlabel(\"Feature 1\")\n    plt.ylabel(\"Feature 2\")\n    plt.title(\"Logistic Regression Decision Boundary (P=0.5)\")\n    plt.legend(loc=\"best\", frameon=True)\n    plt.tight_layout()\n    plt.show()\n\nplot_decision_boundary(model, X_train, y_train, X_test, y_test)"
  },
  {
    "objectID": "lectures/07/LogisticRegression.html#implementation-auc-roc",
    "href": "lectures/07/LogisticRegression.html#implementation-auc-roc",
    "title": "Logistic regression trained with (batch) gradient descent",
    "section": "Implementation: AUC ROC",
    "text": "Implementation: AUC ROC\n\ndef compute_auc(fpr, tpr):\n    \"\"\"\n    Compute the Area Under the Curve (AUC) using the trapezoidal rule.\n    \n    fpr: array of false positive rates\n    tpr: array of true positive rates\n    \"\"\"\n    return np.trapezoid(tpr, fpr)"
  },
  {
    "objectID": "lectures/07/LogisticRegression.html#example-plot",
    "href": "lectures/07/LogisticRegression.html#example-plot",
    "title": "Logistic regression trained with (batch) gradient descent",
    "section": "Example: Plot",
    "text": "Example: Plot\n\n\nCode\n# Compute predicted probabilities for the positive class on the test set\ny_probs = model.predict_proba(X_test)\n\n# Define a set of threshold values between 0 and 1 (e.g., 100 equally spaced thresholds)\nthresholds = np.linspace(0, 1, 100)\n\n# Compute the ROC curve (FPR and TPR for each threshold)\nfpr, tpr = compute_roc_curve(y_test, y_probs, thresholds)\nauc_value = compute_auc(fpr, tpr)\n\n# Plot the ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % auc_value)\nplt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random classifier')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()"
  },
  {
    "objectID": "lectures/07/index.html#practice",
    "href": "lectures/07/index.html#practice",
    "title": "Performance Evaluation",
    "section": "Practice",
    "text": "Practice\n\nLogisticRegression - Here is an implementation of logistic regression, complemented by discussions on Receiver Operating Characteristic (ROC) curves and the Area Under the Curve (AUC). It also includes illustrative examples to demonstrate these concepts."
  }
]